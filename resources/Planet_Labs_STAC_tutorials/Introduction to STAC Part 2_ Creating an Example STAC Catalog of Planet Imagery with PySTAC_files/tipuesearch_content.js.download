var tipuesearch = {"pages":[{"title":" Planet Developer Center ","text":"\n\n\n\n\n\n Planet Developer Center \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPIs\n\n\n\n\n\nData\n\n\nAnalytics\n\n\nBasemaps\n\n\nTile Services\n\n\n\n\n\n\nTasking\n\n\nOrders\n\n\nSubscriptions\n\n\nReports\n\n\n\n\n\n\n\nApps\n\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nAnalytics Feed Viewer\n\n\nTasking Dashboard\n\n\n\n\n\nImagery\n\n\n\n\nScenes\n\nPlanetScope\n\n\nSkySat\n\n\nRapidEye\n\n\n\n\n\nBasemaps\n\nVisual\n\n\nSurface Reflectance\n\n\n\n\n\n\n\nintegrations\n\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nGoogle Earth\n                    Engine Delivery\n\n\n\n\n\nResources\n\n\n\n\nGet Started Guides\n\n\nPlanet School\n\n\nOpen Source Tools\n\n\nNICFI Program\n\n\nDev Trial Program\n\n\n\n\n\nChangelog\n\n\n\nChangelog\n\n\nPlanet Status\n\n\n\n\n\nDeveloper Blog\n\n\n\n\n\n\n\n\n\n\n Developer Resource Center \n\n\n\n\n\n\n\nDocs\n\n\nAPI Docs\n\n\nExplorer User Guide\n\n\nGet Started\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nGIS Integrations\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nApps\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nFeed Viewer\n\n\nPlanetSchool\n\n\nOpen Source\n\n\n\n\n\n\n\n\n\nSee Change, Change the World\n\n        Explore documentation, references, tutorials, and tools: everything you need to start using Planet today.\n    \n\n Get started now \n\n            or join the conversation at \n            Planet Community\n\n\n\n\n\nLake Okeechobee, FL\n\n\n\n\n\n\n\n\n\nDocumentation\nBrowse user guides, documentation and full API references for Planet's APIs, GIS Integrations, Imagery and Apps\n\nSee All Docs\n\n\n\nAPI Doc quick links:\n\n\n\n        Data:\n        search for, filter & download Planet\n        imagery\n        \n\n\n\n        Analytics:\n        Access analytic products derived from Planet imagery\n        \n\n\n\n        Basemaps:\n        Access to Planet's mosaiced basemap services \n        \n\n\n\n        Tile Services:\n        Planet's XYZ & WMTS tile protocol services\n        \n\n\n\n        Tasking:\n        Create, edit, cancel and manage SkySat point\n        collection orders\n        \n\n\n\n        Orders:\n        Create processing pipelines with analysis-ready\n        data\n        \n\n\n\n        Subscriptions:\n        Subscribe to continuous cloud delivery of imagery\n        \n\n\n\n        Reports:\n        Download useage reports\n        \n\n \n\n\n\n\n\n\n\n\n\n\n\nLevel up at Planet\n                                School\n\nFollow in-depth guides and\n                        hands-on tutorials at Planet School: level up the\n                        skills you need to get the most out of Planet's\n                    platform\n\nLearn More\n\n\n\n\n\n\n\n\n\nWhat's New\n\nApril 19 2023\n\nNew  ✨¶\n\nIt is now easier to preview and order imagery. When you search for imagery, you will see three new buttons. Click X items button to check out each satellite image from that date and make the best choice. Click the eye button to preview the imagery from that date on the map. Click the cart button to add the imagery to your order …\n\nRead More\n\n\nMarch 23 2023\n\nImprovements 🙌🏻¶\nComposite orders with multiple product bundles are no longer supported\nTo ensure a more streamlined process and reduce the occurrence of failures, we have decided to discontinue support for composite orders that contain multiple product bundles. This change prevents downstream failures, resulting in a more efficient and reliable process. Going forward, users cannot submit composite orders with multiple product bundles, but must submit …\n\nRead More\n\n\nMarch 16 2023\n\nCan Planet data or the Planet platform be used with Python? It can, and not by accident. Planet is working to make it so. This post attempts to explain what the Python Geospatial Stack is and Planet’s role in keeping the stack in good shape so that developers continue to get value from it.\n\nRead More\n\n\nFebruary 23 2023\n\nDirectly Integrating Planet Data Delivery with Google Earth Engine\n\nRead More\n\n\nSee all platform updates\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPI Reference Docs\n\n\nData\n\n\nAnalytics\n\n\n\n                                Basemaps\n                            \n\n\n\n                                Tile Services\n\n\n\n                                Tasking\n\n\n\n                                Orders\n\n\n\n                                Subscriptions\n\n\n\n                              Reports\n\n\n\n\n\n\nQuick Links\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nIntegrations\n\n Planet School\n\n\nOpen Source Tools\n\n\nNICFI Users\n\n\n\n\n\n\nDeveloper Support\n\n\nDeveloper Program\n\n\nPlanet Community\n\n\nFAQs\n\n\nContact Us\n\n\nDeveloper Newsletter\n\n\n\n\n\n\nCompany\n\n\nPlanet\n\n\nHelp Center\n\n\nTalk to Sales\n\n\n\n\n\n\n\n\n\n\n        © 2023 Planet Labs PBC All rights reserved. |\n        Privacy Policy |\n        California Privacy Notice |\n        Your Privacy Choices  |\n        Terms of Use |\n        Cookie notice\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":"","url":"https://developers.planet.com/index.html"},{"title":" Planet Docs ","text":"\n\n\n\n\n\n Planet Docs \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPIs\n\n\n\n\n\nData\n\n\nAnalytics\n\n\nBasemaps\n\n\nTile Services\n\n\n\n\n\n\nTasking\n\n\nOrders\n\n\nSubscriptions\n\n\nReports\n\n\n\n\n\n\n\nApps\n\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nAnalytics Feed Viewer\n\n\nTasking Dashboard\n\n\n\n\n\nImagery\n\n\n\n\nScenes\n\nPlanetScope\n\n\nSkySat\n\n\nRapidEye\n\n\n\n\n\nBasemaps\n\nVisual\n\n\nSurface Reflectance\n\n\n\n\n\n\n\nintegrations\n\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nGoogle Earth\n                    Engine Delivery\n\n\n\n\n\nResources\n\n\n\n\nGet Started Guides\n\n\nPlanet School\n\n\nOpen Source Tools\n\n\nNICFI Program\n\n\nDev Trial Program\n\n\n\n\n\nChangelog\n\n\n\nChangelog\n\n\nPlanet Status\n\n\n\n\n\nDeveloper Blog\n\n\n\n\n\n\n\n\n\n\n Developer Resource Center \n\n\n\n\n\n\n\nDocs\n\n\nAPI Docs\n\n\nExplorer User Guide\n\n\nGet Started\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nGIS Integrations\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nApps\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nFeed Viewer\n\n\nPlanetSchool\n\n\nOpen Source\n\n\n\n\n\n\n\n\n\n Planet Documentation\n\n        Everything you need to start using Planet services\n    \n\n\n\nFlooding outside Colusa, California\n\n\n\n\n\n\n\n\n\nPlanet APIs\nBrowse documentation and full reference guides for Planet's public APIs\n\nSee All\n\n\n\n\n\n\n        Data:\n        search for, filter & download Planet\n        imagery\n        \n\n\n\n        Analytics:\n        Access analytic products derived from Planet imagery\n        \n\n\n\n        Basemaps:\n        Access to Planet's mosaiced basemap services \n        \n\n\n\n        Tile Services:\n        Planet's XYZ & WMTS tile protocol services\n        \n\n\n\n        Tasking:\n        Create, edit, cancel and manage SkySat point\n        collection orders\n        \n\n\n\n        Orders:\n        Create processing pipelines with analysis-ready\n        data\n        \n\n\n\n        Subscriptions:\n        Subscribe to continuous cloud delivery of imagery\n        \n\n\n\n        Reports:\n        Download useage reports\n        \n\n \n\n\n\n\n\n\n\nGIS Integrations\nDiscover, stream, and download Planet imagery directly into a GIS application\n\nSee All\n\n\n\n\n\n\n                                Planet QGIS Plugin\n                            \n\n\n\n                                ArcGIS Pro Add-In\n                            \n\n\n\n                                Planet's Google Earth Engine Delivery\n                            \n\n\n\n\n\n\n\n\n\n\nOpen Source Tools\nFree & open-source tools to help developers get the most out of Planet's platform\n\nSee All\n\n\n\n\n\n\n                                Python Library & CLI\n                            \n                            —\n                            \n                              Documentation & Examples \n                            \n\n\n\n                                Jupyter Notebooks\n                            \n                            —\n                            \n                              Notebook Tutorials\n                            \n\n\n\n                                Planet QGIS Plugin\n                            \n                            —\n                            \n                              Documentation\n                            \n\n\n\n                                Staccado\n                            \n                            —\n                            \n                                SpatioTemporal Asset Catalogs Spec\n                            \n\n\n\n\n\n\n\n\n\n\n\nPlanet Apps\nMore ways to discover Planet data directly in your browser\n\nSee All\n\n\n\n\n\n\n                                Planet Explorer \n                            \n                            —\n                            \n                                User Guide\n                            \n\n\n\n                                Planet Analytic Feed Viewer\n                            \n                            —\n                            \n                                User Guide\n                            \n\n\n\n                                Planet Tasking Dashboard \n                            \n                            —\n                            \n                                User Guide\n                            \n\n\n\n                                Planet Basemap Viewer \n                            \n                            —\n                            \n                                User Guide\n                            \n\n\n\n                                Planet Stories\n                            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPI Reference Docs\n\n\nData\n\n\nAnalytics\n\n\n\n                                Basemaps\n                            \n\n\n\n                                Tile Services\n\n\n\n                                Tasking\n\n\n\n                                Orders\n\n\n\n                                Subscriptions\n\n\n\n                              Reports\n\n\n\n\n\n\nQuick Links\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nIntegrations\n\n Planet School\n\n\nOpen Source Tools\n\n\nNICFI Users\n\n\n\n\n\n\nDeveloper Support\n\n\nDeveloper Program\n\n\nPlanet Community\n\n\nFAQs\n\n\nContact Us\n\n\nDeveloper Newsletter\n\n\n\n\n\n\nCompany\n\n\nPlanet\n\n\nHelp Center\n\n\nTalk to Sales\n\n\n\n\n\n\n\n\n\n\n        © 2023 Planet Labs PBC All rights reserved. |\n        Privacy Policy |\n        California Privacy Notice |\n        Your Privacy Choices  |\n        Terms of Use |\n        Cookie notice\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":"","url":"https://developers.planet.com/docs/index.html"},{"title":" Planet APIs ","text":"\n\n\n\n\n\n Planet APIs \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPIs\n\n\n\n\n\nData\n\n\nAnalytics\n\n\nBasemaps\n\n\nTile Services\n\n\n\n\n\n\nTasking\n\n\nOrders\n\n\nSubscriptions\n\n\nReports\n\n\n\n\n\n\n\nApps\n\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nAnalytics Feed Viewer\n\n\nTasking Dashboard\n\n\n\n\n\nImagery\n\n\n\n\nScenes\n\nPlanetScope\n\n\nSkySat\n\n\nRapidEye\n\n\n\n\n\nBasemaps\n\nVisual\n\n\nSurface Reflectance\n\n\n\n\n\n\n\nintegrations\n\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nGoogle Earth\n                    Engine Delivery\n\n\n\n\n\nResources\n\n\n\n\nGet Started Guides\n\n\nPlanet School\n\n\nOpen Source Tools\n\n\nNICFI Program\n\n\nDev Trial Program\n\n\n\n\n\nChangelog\n\n\n\nChangelog\n\n\nPlanet Status\n\n\n\n\n\nDeveloper Blog\n\n\n\n\n\n\n\n\n\n\n Developer Resource Center \n\n\n\n\n\n\n\nDocs\n\n\nAPI Docs\n\n\nExplorer User Guide\n\n\nGet Started\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nGIS Integrations\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nApps\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nFeed Viewer\n\n\nPlanetSchool\n\n\nOpen Source\n\n\n\n\n\n\n\n\n\n Planet APIs \n\n        Everything you need to start using Planet services\n    \n\n\n\nFlooding outside Colusa, California\n\n\n\n\n\n\n\nMeet Our APIs\nYou'll need a Planet API key to use any of Planet's APIs:\n        learn how to find yours here. \n        \n\n\n\n\nsatellite\n\n Data \n Your portal to Planet's daily imagery archives: search\n                    for, filter, and download data programmatically\n\n\n\n\n\nperm_data_setting\n\nAnalytics\nAccess Analytics Feeds: analytic products derived from\n                        Planet imagery\n                        \n\n\n\n\n\nmap\n\n Basemaps \n Mosaiced basemap services make it\n                    easy to visualize Planet imagery in desktop or web mapping\n                    applications \n\n\n\n\n\nlayers\n\n Tile Services \n Provides access to Planet's XYZ & WMTS tile\n                            protocol service, allowing you to visualize Planet\n                            imagery in any compatible client \n\n\n\n\n\ngps_fixed\n\n Tasking\nCreate, edit, cancel and manage your SkySat point collection\n                            orders\n\n\n\n\n\ncloud\n\n Orders\nUse raster tools to create analysis ready data,\n                        have Planet data delivered directly to your cloud\n                        storage, and more\n                        \n\n\n\n\n\nsend\n\nSubscriptions\nPlanet's next-gen data delivery API. With a single\n                        API call, Subscriptions allows you to subscribe to\n                        continuous cloud delivery of imagery and metadata\n                        collections which meet your item filter criteria. \n\n\n\n\n\nsummarize\n\nReports\n\n                        Download usage reports systematically for your internal\n                        processing and analysis.\n                        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPI Reference Docs\n\n\nData\n\n\nAnalytics\n\n\n\n                                Basemaps\n                            \n\n\n\n                                Tile Services\n\n\n\n                                Tasking\n\n\n\n                                Orders\n\n\n\n                                Subscriptions\n\n\n\n                              Reports\n\n\n\n\n\n\nQuick Links\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nIntegrations\n\n Planet School\n\n\nOpen Source Tools\n\n\nNICFI Users\n\n\n\n\n\n\nDeveloper Support\n\n\nDeveloper Program\n\n\nPlanet Community\n\n\nFAQs\n\n\nContact Us\n\n\nDeveloper Newsletter\n\n\n\n\n\n\nCompany\n\n\nPlanet\n\n\nHelp Center\n\n\nTalk to Sales\n\n\n\n\n\n\n\n\n\n\n        © 2023 Planet Labs PBC All rights reserved. |\n        Privacy Policy |\n        California Privacy Notice |\n        Your Privacy Choices  |\n        Terms of Use |\n        Cookie notice\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":"","url":"https://developers.planet.com/docs/apis/index.html"},{"title":" Planet Apps","text":"\n\n\n\n\n\n Planet Apps\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPIs\n\n\n\n\n\nData\n\n\nAnalytics\n\n\nBasemaps\n\n\nTile Services\n\n\n\n\n\n\nTasking\n\n\nOrders\n\n\nSubscriptions\n\n\nReports\n\n\n\n\n\n\n\nApps\n\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nAnalytics Feed Viewer\n\n\nTasking Dashboard\n\n\n\n\n\nImagery\n\n\n\n\nScenes\n\nPlanetScope\n\n\nSkySat\n\n\nRapidEye\n\n\n\n\n\nBasemaps\n\nVisual\n\n\nSurface Reflectance\n\n\n\n\n\n\n\nintegrations\n\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nGoogle Earth\n                    Engine Delivery\n\n\n\n\n\nResources\n\n\n\n\nGet Started Guides\n\n\nPlanet School\n\n\nOpen Source Tools\n\n\nNICFI Program\n\n\nDev Trial Program\n\n\n\n\n\nChangelog\n\n\n\nChangelog\n\n\nPlanet Status\n\n\n\n\n\nDeveloper Blog\n\n\n\n\n\n\n\n\n\n\n Developer Resource Center \n\n\n\n\n\n\n\nDocs\n\n\nAPI Docs\n\n\nExplorer User Guide\n\n\nGet Started\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nGIS Integrations\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nApps\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nFeed Viewer\n\n\nPlanetSchool\n\n\nOpen Source\n\n\n\n\n\n\n\n\n\n Planet Apps\n\n        Planet's platform in your browser\n    \n\n\n\nFlooding outside Colusa, California\n\n\n\n\n\n\n\nPlanet Apps\n\n\n\n\nPlanet Explorer\n\n\n\n\n                       App\n\n\n\n                       User Guide\n\nSearch and analyze Planet's catalog of geospatial imagery in your browser\n\n\n\n\n\nAnalytics Feed Viewer\n\n\n\n\n                       App\n\n\n\n                       User Guide\n\nDisplay detections from Planet Analytic Feeds and source imagery\n\n\n\n\n\nTasking Dashboard\n\n\n\n\n                       App\n\n\n\n                       User Guide\n\nStreamline and manage your SkySat tasking order\n                   submissions\n\n\n\n\n\nBasemaps Viewer\n\n\n\n\n                       App\n\nBrowse and order mosaics from Planet's basemaps archive\n\n\n\n\n\nPlanet Stories\n\n\n\n\n                       App\n\nCreate an animated story showing change over time in your area of interest\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPI Reference Docs\n\n\nData\n\n\nAnalytics\n\n\n\n                                Basemaps\n                            \n\n\n\n                                Tile Services\n\n\n\n                                Tasking\n\n\n\n                                Orders\n\n\n\n                                Subscriptions\n\n\n\n                              Reports\n\n\n\n\n\n\nQuick Links\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nIntegrations\n\n Planet School\n\n\nOpen Source Tools\n\n\nNICFI Users\n\n\n\n\n\n\nDeveloper Support\n\n\nDeveloper Program\n\n\nPlanet Community\n\n\nFAQs\n\n\nContact Us\n\n\nDeveloper Newsletter\n\n\n\n\n\n\nCompany\n\n\nPlanet\n\n\nHelp Center\n\n\nTalk to Sales\n\n\n\n\n\n\n\n\n\n\n        © 2023 Planet Labs PBC All rights reserved. |\n        Privacy Policy |\n        California Privacy Notice |\n        Your Privacy Choices  |\n        Terms of Use |\n        Cookie notice\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":"","url":"https://developers.planet.com/docs/apps/index.html"},{"title":"Planet Data API Reference","text":"\n\n\n\n\n\nPlanet Data API Reference\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPIs\n\n\n\n\n\nData\n\n\nAnalytics\n\n\nBasemaps\n\n\nTile Services\n\n\n\n\n\n\nTasking\n\n\nOrders\n\n\nSubscriptions\n\n\nReports\n\n\n\n\n\n\n\nApps\n\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nAnalytics Feed Viewer\n\n\nTasking Dashboard\n\n\n\n\n\nImagery\n\n\n\n\nScenes\n\nPlanetScope\n\n\nSkySat\n\n\nRapidEye\n\n\n\n\n\nBasemaps\n\nVisual\n\n\nSurface Reflectance\n\n\n\n\n\n\n\nintegrations\n\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nGoogle Earth\n                    Engine Delivery\n\n\n\n\n\nResources\n\n\n\n\nGet Started Guides\n\n\nPlanet School\n\n\nOpen Source Tools\n\n\nNICFI Program\n\n\nDev Trial Program\n\n\n\n\n\nChangelog\n\n\n\nChangelog\n\n\nPlanet Status\n\n\n\n\n\nDeveloper Blog\n\n\n\n\n\n\n\n\n\n\n Developer Resource Center \n\n\n\n\n\n\n\nDocs\n\n\nAPI Docs\n\n\nExplorer User Guide\n\n\nGet Started\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nGIS Integrations\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nApps\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nFeed Viewer\n\n\nPlanetSchool\n\n\nOpen Source\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPI Reference Docs\n\n\nData\n\n\nAnalytics\n\n\n\n                                Basemaps\n                            \n\n\n\n                                Tile Services\n\n\n\n                                Tasking\n\n\n\n                                Orders\n\n\n\n                                Subscriptions\n\n\n\n                              Reports\n\n\n\n\n\n\nQuick Links\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nIntegrations\n\n Planet School\n\n\nOpen Source Tools\n\n\nNICFI Users\n\n\n\n\n\n\nDeveloper Support\n\n\nDeveloper Program\n\n\nPlanet Community\n\n\nFAQs\n\n\nContact Us\n\n\nDeveloper Newsletter\n\n\n\n\n\n\nCompany\n\n\nPlanet\n\n\nHelp Center\n\n\nTalk to Sales\n\n\n\n\n\n\n\n\n\n\n        © 2023 Planet Labs PBC All rights reserved. |\n        Privacy Policy |\n        California Privacy Notice |\n        Your Privacy Choices  |\n        Terms of Use |\n        Cookie notice\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":"","url":"https://developers.planet.com/docs/apis/data/reference/index.html"},{"title":"Planet API Reference","text":"\n\n\n\n\n\nPlanet API Reference\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPIs\n\n\n\n\n\nData\n\n\nAnalytics\n\n\nBasemaps\n\n\nTile Services\n\n\n\n\n\n\nTasking\n\n\nOrders\n\n\nSubscriptions\n\n\nReports\n\n\n\n\n\n\n\nApps\n\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nAnalytics Feed Viewer\n\n\nTasking Dashboard\n\n\n\n\n\nImagery\n\n\n\n\nScenes\n\nPlanetScope\n\n\nSkySat\n\n\nRapidEye\n\n\n\n\n\nBasemaps\n\nVisual\n\n\nSurface Reflectance\n\n\n\n\n\n\n\nintegrations\n\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nGoogle Earth\n                    Engine Delivery\n\n\n\n\n\nResources\n\n\n\n\nGet Started Guides\n\n\nPlanet School\n\n\nOpen Source Tools\n\n\nNICFI Program\n\n\nDev Trial Program\n\n\n\n\n\nChangelog\n\n\n\nChangelog\n\n\nPlanet Status\n\n\n\n\n\nDeveloper Blog\n\n\n\n\n\n\n\n\n\n\n Developer Resource Center \n\n\n\n\n\n\n\nDocs\n\n\nAPI Docs\n\n\nExplorer User Guide\n\n\nGet Started\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nGIS Integrations\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nApps\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nFeed Viewer\n\n\nPlanetSchool\n\n\nOpen Source\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPI Reference Docs\n\n\nData\n\n\nAnalytics\n\n\n\n                                Basemaps\n                            \n\n\n\n                                Tile Services\n\n\n\n                                Tasking\n\n\n\n                                Orders\n\n\n\n                                Subscriptions\n\n\n\n                              Reports\n\n\n\n\n\n\nQuick Links\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nIntegrations\n\n Planet School\n\n\nOpen Source Tools\n\n\nNICFI Users\n\n\n\n\n\n\nDeveloper Support\n\n\nDeveloper Program\n\n\nPlanet Community\n\n\nFAQs\n\n\nContact Us\n\n\nDeveloper Newsletter\n\n\n\n\n\n\nCompany\n\n\nPlanet\n\n\nHelp Center\n\n\nTalk to Sales\n\n\n\n\n\n\n\n\n\n\n        © 2023 Planet Labs PBC All rights reserved. |\n        Privacy Policy |\n        California Privacy Notice |\n        Your Privacy Choices  |\n        Terms of Use |\n        Cookie notice\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":"","url":"https://developers.planet.com/docs/basemaps/reference/index.html"},{"title":"Planet API Reference","text":"\n\n\n\n\n\nPlanet API Reference\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPIs\n\n\n\n\n\nData\n\n\nAnalytics\n\n\nBasemaps\n\n\nTile Services\n\n\n\n\n\n\nTasking\n\n\nOrders\n\n\nSubscriptions\n\n\nReports\n\n\n\n\n\n\n\nApps\n\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nAnalytics Feed Viewer\n\n\nTasking Dashboard\n\n\n\n\n\nImagery\n\n\n\n\nScenes\n\nPlanetScope\n\n\nSkySat\n\n\nRapidEye\n\n\n\n\n\nBasemaps\n\nVisual\n\n\nSurface Reflectance\n\n\n\n\n\n\n\nintegrations\n\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nGoogle Earth\n                    Engine Delivery\n\n\n\n\n\nResources\n\n\n\n\nGet Started Guides\n\n\nPlanet School\n\n\nOpen Source Tools\n\n\nNICFI Program\n\n\nDev Trial Program\n\n\n\n\n\nChangelog\n\n\n\nChangelog\n\n\nPlanet Status\n\n\n\n\n\nDeveloper Blog\n\n\n\n\n\n\n\n\n\n\n Developer Resource Center \n\n\n\n\n\n\n\nDocs\n\n\nAPI Docs\n\n\nExplorer User Guide\n\n\nGet Started\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nGIS Integrations\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nApps\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nFeed Viewer\n\n\nPlanetSchool\n\n\nOpen Source\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPI Reference Docs\n\n\nData\n\n\nAnalytics\n\n\n\n                                Basemaps\n                            \n\n\n\n                                Tile Services\n\n\n\n                                Tasking\n\n\n\n                                Orders\n\n\n\n                                Subscriptions\n\n\n\n                              Reports\n\n\n\n\n\n\nQuick Links\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nIntegrations\n\n Planet School\n\n\nOpen Source Tools\n\n\nNICFI Users\n\n\n\n\n\n\nDeveloper Support\n\n\nDeveloper Program\n\n\nPlanet Community\n\n\nFAQs\n\n\nContact Us\n\n\nDeveloper Newsletter\n\n\n\n\n\n\nCompany\n\n\nPlanet\n\n\nHelp Center\n\n\nTalk to Sales\n\n\n\n\n\n\n\n\n\n\n        © 2023 Planet Labs PBC All rights reserved. |\n        Privacy Policy |\n        California Privacy Notice |\n        Your Privacy Choices  |\n        Terms of Use |\n        Cookie notice\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":"","url":"https://developers.planet.com/apis/orders/reference/index.html"},{"title":"Planet API Reference","text":"\n\n\n\n\n\nPlanet API Reference\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPIs\n\n\n\n\n\nData\n\n\nAnalytics\n\n\nBasemaps\n\n\nTile Services\n\n\n\n\n\n\nTasking\n\n\nOrders\n\n\nSubscriptions\n\n\nReports\n\n\n\n\n\n\n\nApps\n\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nAnalytics Feed Viewer\n\n\nTasking Dashboard\n\n\n\n\n\nImagery\n\n\n\n\nScenes\n\nPlanetScope\n\n\nSkySat\n\n\nRapidEye\n\n\n\n\n\nBasemaps\n\nVisual\n\n\nSurface Reflectance\n\n\n\n\n\n\n\nintegrations\n\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nGoogle Earth\n                    Engine Delivery\n\n\n\n\n\nResources\n\n\n\n\nGet Started Guides\n\n\nPlanet School\n\n\nOpen Source Tools\n\n\nNICFI Program\n\n\nDev Trial Program\n\n\n\n\n\nChangelog\n\n\n\nChangelog\n\n\nPlanet Status\n\n\n\n\n\nDeveloper Blog\n\n\n\n\n\n\n\n\n\n\n Developer Resource Center \n\n\n\n\n\n\n\nDocs\n\n\nAPI Docs\n\n\nExplorer User Guide\n\n\nGet Started\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nGIS Integrations\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nApps\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nFeed Viewer\n\n\nPlanetSchool\n\n\nOpen Source\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPI Reference Docs\n\n\nData\n\n\nAnalytics\n\n\n\n                                Basemaps\n                            \n\n\n\n                                Tile Services\n\n\n\n                                Tasking\n\n\n\n                                Orders\n\n\n\n                                Subscriptions\n\n\n\n                              Reports\n\n\n\n\n\n\nQuick Links\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nIntegrations\n\n Planet School\n\n\nOpen Source Tools\n\n\nNICFI Users\n\n\n\n\n\n\nDeveloper Support\n\n\nDeveloper Program\n\n\nPlanet Community\n\n\nFAQs\n\n\nContact Us\n\n\nDeveloper Newsletter\n\n\n\n\n\n\nCompany\n\n\nPlanet\n\n\nHelp Center\n\n\nTalk to Sales\n\n\n\n\n\n\n\n\n\n\n        © 2023 Planet Labs PBC All rights reserved. |\n        Privacy Policy |\n        California Privacy Notice |\n        Your Privacy Choices  |\n        Terms of Use |\n        Cookie notice\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":"","url":"https://developers.planet.com/docs/tasking/reference/index.html"},{"title":"Tasking API Reference for Pluto","text":"\n\n\n\n\n\nTasking API Reference for Pluto\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPIs\n\n\n\n\n\nData\n\n\nAnalytics\n\n\nBasemaps\n\n\nTile Services\n\n\n\n\n\n\nTasking\n\n\nOrders\n\n\nSubscriptions\n\n\nReports\n\n\n\n\n\n\n\nApps\n\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nAnalytics Feed Viewer\n\n\nTasking Dashboard\n\n\n\n\n\nImagery\n\n\n\n\nScenes\n\nPlanetScope\n\n\nSkySat\n\n\nRapidEye\n\n\n\n\n\nBasemaps\n\nVisual\n\n\nSurface Reflectance\n\n\n\n\n\n\n\nintegrations\n\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nGoogle Earth\n                    Engine Delivery\n\n\n\n\n\nResources\n\n\n\n\nGet Started Guides\n\n\nPlanet School\n\n\nOpen Source Tools\n\n\nNICFI Program\n\n\nDev Trial Program\n\n\n\n\n\nChangelog\n\n\n\nChangelog\n\n\nPlanet Status\n\n\n\n\n\nDeveloper Blog\n\n\n\n\n\n\n\n\n\n\n Developer Resource Center \n\n\n\n\n\n\n\nDocs\n\n\nAPI Docs\n\n\nExplorer User Guide\n\n\nGet Started\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nGIS Integrations\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nApps\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nFeed Viewer\n\n\nPlanetSchool\n\n\nOpen Source\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPI Reference Docs\n\n\nData\n\n\nAnalytics\n\n\n\n                                Basemaps\n                            \n\n\n\n                                Tile Services\n\n\n\n                                Tasking\n\n\n\n                                Orders\n\n\n\n                                Subscriptions\n\n\n\n                              Reports\n\n\n\n\n\n\nQuick Links\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nIntegrations\n\n Planet School\n\n\nOpen Source Tools\n\n\nNICFI Users\n\n\n\n\n\n\nDeveloper Support\n\n\nDeveloper Program\n\n\nPlanet Community\n\n\nFAQs\n\n\nContact Us\n\n\nDeveloper Newsletter\n\n\n\n\n\n\nCompany\n\n\nPlanet\n\n\nHelp Center\n\n\nTalk to Sales\n\n\n\n\n\n\n\n\n\n\n        © 2023 Planet Labs PBC All rights reserved. |\n        Privacy Policy |\n        California Privacy Notice |\n        Your Privacy Choices  |\n        Terms of Use |\n        Cookie notice\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":"","url":"https://developers.planet.com/docs/tasking/reference-pluto/index.html"},{"title":"Planet API Reference","text":"\n\n\n\n\n\nPlanet API Reference\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPIs\n\n\n\n\n\nData\n\n\nAnalytics\n\n\nBasemaps\n\n\nTile Services\n\n\n\n\n\n\nTasking\n\n\nOrders\n\n\nSubscriptions\n\n\nReports\n\n\n\n\n\n\n\nApps\n\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nAnalytics Feed Viewer\n\n\nTasking Dashboard\n\n\n\n\n\nImagery\n\n\n\n\nScenes\n\nPlanetScope\n\n\nSkySat\n\n\nRapidEye\n\n\n\n\n\nBasemaps\n\nVisual\n\n\nSurface Reflectance\n\n\n\n\n\n\n\nintegrations\n\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nGoogle Earth\n                    Engine Delivery\n\n\n\n\n\nResources\n\n\n\n\nGet Started Guides\n\n\nPlanet School\n\n\nOpen Source Tools\n\n\nNICFI Program\n\n\nDev Trial Program\n\n\n\n\n\nChangelog\n\n\n\nChangelog\n\n\nPlanet Status\n\n\n\n\n\nDeveloper Blog\n\n\n\n\n\n\n\n\n\n\n Developer Resource Center \n\n\n\n\n\n\n\nDocs\n\n\nAPI Docs\n\n\nExplorer User Guide\n\n\nGet Started\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nGIS Integrations\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nApps\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nFeed Viewer\n\n\nPlanetSchool\n\n\nOpen Source\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPI Reference Docs\n\n\nData\n\n\nAnalytics\n\n\n\n                                Basemaps\n                            \n\n\n\n                                Tile Services\n\n\n\n                                Tasking\n\n\n\n                                Orders\n\n\n\n                                Subscriptions\n\n\n\n                              Reports\n\n\n\n\n\n\nQuick Links\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nIntegrations\n\n Planet School\n\n\nOpen Source Tools\n\n\nNICFI Users\n\n\n\n\n\n\nDeveloper Support\n\n\nDeveloper Program\n\n\nPlanet Community\n\n\nFAQs\n\n\nContact Us\n\n\nDeveloper Newsletter\n\n\n\n\n\n\nCompany\n\n\nPlanet\n\n\nHelp Center\n\n\nTalk to Sales\n\n\n\n\n\n\n\n\n\n\n        © 2023 Planet Labs PBC All rights reserved. |\n        Privacy Policy |\n        California Privacy Notice |\n        Your Privacy Choices  |\n        Terms of Use |\n        Cookie notice\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":"","url":"https://developers.planet.com/docs/analytics/reference/index.html"},{"title":"Planet Python Client","text":"\n\n\n\n\n\nPlanet Python Client\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPIs\n\n\n\n\n\nData\n\n\nAnalytics\n\n\nBasemaps\n\n\nTile Services\n\n\n\n\n\n\nTasking\n\n\nOrders\n\n\nSubscriptions\n\n\nReports\n\n\n\n\n\n\n\nApps\n\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nAnalytics Feed Viewer\n\n\nTasking Dashboard\n\n\n\n\n\nImagery\n\n\n\n\nScenes\n\nPlanetScope\n\n\nSkySat\n\n\nRapidEye\n\n\n\n\n\nBasemaps\n\nVisual\n\n\nSurface Reflectance\n\n\n\n\n\n\n\nintegrations\n\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nGoogle Earth\n                    Engine Delivery\n\n\n\n\n\nResources\n\n\n\n\nGet Started Guides\n\n\nPlanet School\n\n\nOpen Source Tools\n\n\nNICFI Program\n\n\nDev Trial Program\n\n\n\n\n\nChangelog\n\n\n\nChangelog\n\n\nPlanet Status\n\n\n\n\n\nDeveloper Blog\n\n\n\n\n\n\n\n\n\n\n Developer Resource Center \n\n\n\n\n\n\n\nDocs\n\n\nAPI Docs\n\n\nExplorer User Guide\n\n\nGet Started\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nGIS Integrations\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nApps\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nFeed Viewer\n\n\nPlanetSchool\n\n\nOpen Source\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n            Planet SDK for Python V2\n\nThe Planet SDK for Python and No-Code Command Line Interface (CLI) makes it easy to work with Planet’s APIs in Python: the 2.0 release of our Python SDK abstracts out the details of interacting with Planet’s APIs, so you can focus on actually using the data and building workflows. We’ve also built a new Command-Line Interface to enable that same easy interaction with Planet APIs – without using code.\nCheck out the documentation here to learn more about how it works, and don’t miss the Tips & Tricks section for some nifty examples of how you can use the Planet CLI alongside your favorite geospatial tools like GDAL/OGR, Fiona (fio), Kepler.gl, Placemark.io, and more.\nBoth the SDK and the CLI support the Orders, Data, and Subscriptions APIs. To \n        get started, install it from pip with `pip install planet`, explore the CLI, and then dive into the Python Guide. Be sure to not miss the SDK Examples that link to a number of Python Notebooks. If you’re already a user of the V1 Python Client, check out our upgrade guide for tips on migrating your code to V2.\nWe’re very interested in hearing from you all as you start using this new toolkit, so don’t hesitate to ask for help or share your feedback with us: just post here on the Planet Community Developers Forum and tag your post with ‘sdk’ or ‘cli’.\n\n\n                Planet Python Client V1\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\nAPI Reference Docs\n\n\nData\n\n\nAnalytics\n\n\n\n                                Basemaps\n                            \n\n\n\n                                Tile Services\n\n\n\n                                Tasking\n\n\n\n                                Orders\n\n\n\n                                Subscriptions\n\n\n\n                              Reports\n\n\n\n\n\n\nQuick Links\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nIntegrations\n\n Planet School\n\n\nOpen Source Tools\n\n\nNICFI Users\n\n\n\n\n\n\nDeveloper Support\n\n\nDeveloper Program\n\n\nPlanet Community\n\n\nFAQs\n\n\nContact Us\n\n\nDeveloper Newsletter\n\n\n\n\n\n\nCompany\n\n\nPlanet\n\n\nHelp Center\n\n\nTalk to Sales\n\n\n\n\n\n\n\n\n\n\n        © 2023 Planet Labs PBC All rights reserved. |\n        Privacy Policy |\n        California Privacy Notice |\n        Your Privacy Choices  |\n        Terms of Use |\n        Cookie notice\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":"","url":"https://developers.planet.com/docs/pythonclient/index.html"},{"title":"Planet Subscriptions API Reference","text":"\n\n\n\n\n\nPlanet Subscriptions API Reference\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPIs\n\n\n\n\n\nData\n\n\nAnalytics\n\n\nBasemaps\n\n\nTile Services\n\n\n\n\n\n\nTasking\n\n\nOrders\n\n\nSubscriptions\n\n\nReports\n\n\n\n\n\n\n\nApps\n\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nAnalytics Feed Viewer\n\n\nTasking Dashboard\n\n\n\n\n\nImagery\n\n\n\n\nScenes\n\nPlanetScope\n\n\nSkySat\n\n\nRapidEye\n\n\n\n\n\nBasemaps\n\nVisual\n\n\nSurface Reflectance\n\n\n\n\n\n\n\nintegrations\n\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nGoogle Earth\n                    Engine Delivery\n\n\n\n\n\nResources\n\n\n\n\nGet Started Guides\n\n\nPlanet School\n\n\nOpen Source Tools\n\n\nNICFI Program\n\n\nDev Trial Program\n\n\n\n\n\nChangelog\n\n\n\nChangelog\n\n\nPlanet Status\n\n\n\n\n\nDeveloper Blog\n\n\n\n\n\n\n\n\n\n\n Developer Resource Center \n\n\n\n\n\n\n\nDocs\n\n\nAPI Docs\n\n\nExplorer User Guide\n\n\nGet Started\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nGIS Integrations\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nApps\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nFeed Viewer\n\n\nPlanetSchool\n\n\nOpen Source\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPI Reference Docs\n\n\nData\n\n\nAnalytics\n\n\n\n                                Basemaps\n                            \n\n\n\n                                Tile Services\n\n\n\n                                Tasking\n\n\n\n                                Orders\n\n\n\n                                Subscriptions\n\n\n\n                              Reports\n\n\n\n\n\n\nQuick Links\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nIntegrations\n\n Planet School\n\n\nOpen Source Tools\n\n\nNICFI Users\n\n\n\n\n\n\nDeveloper Support\n\n\nDeveloper Program\n\n\nPlanet Community\n\n\nFAQs\n\n\nContact Us\n\n\nDeveloper Newsletter\n\n\n\n\n\n\nCompany\n\n\nPlanet\n\n\nHelp Center\n\n\nTalk to Sales\n\n\n\n\n\n\n\n\n\n\n        © 2023 Planet Labs PBC All rights reserved. |\n        Privacy Policy |\n        California Privacy Notice |\n        Your Privacy Choices  |\n        Terms of Use |\n        Cookie notice\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":"","url":"https://developers.planet.com/docs/subscriptions/reference/index.html"},{"title":"Planet Reports API Reference","text":"\n\n\n\n\n\nPlanet Reports API Reference\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPIs\n\n\n\n\n\nData\n\n\nAnalytics\n\n\nBasemaps\n\n\nTile Services\n\n\n\n\n\n\nTasking\n\n\nOrders\n\n\nSubscriptions\n\n\nReports\n\n\n\n\n\n\n\nApps\n\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nAnalytics Feed Viewer\n\n\nTasking Dashboard\n\n\n\n\n\nImagery\n\n\n\n\nScenes\n\nPlanetScope\n\n\nSkySat\n\n\nRapidEye\n\n\n\n\n\nBasemaps\n\nVisual\n\n\nSurface Reflectance\n\n\n\n\n\n\n\nintegrations\n\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nGoogle Earth\n                    Engine Delivery\n\n\n\n\n\nResources\n\n\n\n\nGet Started Guides\n\n\nPlanet School\n\n\nOpen Source Tools\n\n\nNICFI Program\n\n\nDev Trial Program\n\n\n\n\n\nChangelog\n\n\n\nChangelog\n\n\nPlanet Status\n\n\n\n\n\nDeveloper Blog\n\n\n\n\n\n\n\n\n\n\n Developer Resource Center \n\n\n\n\n\n\n\nDocs\n\n\nAPI Docs\n\n\nExplorer User Guide\n\n\nGet Started\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nGIS Integrations\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nApps\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nFeed Viewer\n\n\nPlanetSchool\n\n\nOpen Source\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPI Reference Docs\n\n\nData\n\n\nAnalytics\n\n\n\n                                Basemaps\n                            \n\n\n\n                                Tile Services\n\n\n\n                                Tasking\n\n\n\n                                Orders\n\n\n\n                                Subscriptions\n\n\n\n                              Reports\n\n\n\n\n\n\nQuick Links\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nIntegrations\n\n Planet School\n\n\nOpen Source Tools\n\n\nNICFI Users\n\n\n\n\n\n\nDeveloper Support\n\n\nDeveloper Program\n\n\nPlanet Community\n\n\nFAQs\n\n\nContact Us\n\n\nDeveloper Newsletter\n\n\n\n\n\n\nCompany\n\n\nPlanet\n\n\nHelp Center\n\n\nTalk to Sales\n\n\n\n\n\n\n\n\n\n\n        © 2023 Planet Labs PBC All rights reserved. |\n        Privacy Policy |\n        California Privacy Notice |\n        Your Privacy Choices  |\n        Terms of Use |\n        Cookie notice\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":"","url":"https://developers.planet.com/docs/reports/reference/index.html"},{"title":" Contact Developer Relations at Planet ","text":"\n\n\n\n\n\n Contact Developer Relations at Planet \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPIs\n\n\n\n\n\nData\n\n\nAnalytics\n\n\nBasemaps\n\n\nTile Services\n\n\n\n\n\n\nTasking\n\n\nOrders\n\n\nSubscriptions\n\n\nReports\n\n\n\n\n\n\n\nApps\n\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nAnalytics Feed Viewer\n\n\nTasking Dashboard\n\n\n\n\n\nImagery\n\n\n\n\nScenes\n\nPlanetScope\n\n\nSkySat\n\n\nRapidEye\n\n\n\n\n\nBasemaps\n\nVisual\n\n\nSurface Reflectance\n\n\n\n\n\n\n\nintegrations\n\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nGoogle Earth\n                    Engine Delivery\n\n\n\n\n\nResources\n\n\n\n\nGet Started Guides\n\n\nPlanet School\n\n\nOpen Source Tools\n\n\nNICFI Program\n\n\nDev Trial Program\n\n\n\n\n\nChangelog\n\n\n\nChangelog\n\n\nPlanet Status\n\n\n\n\n\nDeveloper Blog\n\n\n\n\n\n\n\n\n\n\n Developer Resource Center \n\n\n\n\n\n\n\nDocs\n\n\nAPI Docs\n\n\nExplorer User Guide\n\n\nGet Started\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nGIS Integrations\n\n\nPlanet QGIS Plugin\n\n\nArcGIS Pro Add-In\n\n\nApps\n\n\nPlanet Explorer\n\n\nPlanet Stories\n\n\nBasemaps Viewer\n\n\nFeed Viewer\n\n\nPlanetSchool\n\n\nOpen Source\n\n\n\n\n\n\n\n\n\n \n\n\n\nBay Bridge, California\n\n\n\n\n\n\n\nContact Developer Relations at Planet\nYou can reach us directly at developers@planet.com or by submitting the form to the right.\n\nView Survey\n\n\n\n\n\n\n\n\n\n\n\nAPI Reference Docs\n\n\nData\n\n\nAnalytics\n\n\n\n                                Basemaps\n                            \n\n\n\n                                Tile Services\n\n\n\n                                Tasking\n\n\n\n                                Orders\n\n\n\n                                Subscriptions\n\n\n\n                              Reports\n\n\n\n\n\n\nQuick Links\n\n\nChangelog\n\n\nDeveloper Blog\n\n\nIntegrations\n\n Planet School\n\n\nOpen Source Tools\n\n\nNICFI Users\n\n\n\n\n\n\nDeveloper Support\n\n\nDeveloper Program\n\n\nPlanet Community\n\n\nFAQs\n\n\nContact Us\n\n\nDeveloper Newsletter\n\n\n\n\n\n\nCompany\n\n\nPlanet\n\n\nHelp Center\n\n\nTalk to Sales\n\n\n\n\n\n\n\n\n\n\n        © 2023 Planet Labs PBC All rights reserved. |\n        Privacy Policy |\n        California Privacy Notice |\n        Your Privacy Choices  |\n        Terms of Use |\n        Cookie notice\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":"","url":"https://developers.planet.com/contact-us/index.html"},{"title":"Geospatial Data","text":"Overview Whether you're a data scientist, a software developer, or perhaps just a curious hobbyist: you may find yourself wondering what's so special about spatial data? If so, you're not alone: read on for a gentle introduction to this unique type of data. When you've finished, continue at Planet School to learn more about using geospatial data to gain insights into the world around us. What are we talking about? Let's begin with some terminology: there are a lot of different terms you may hear people use for more or less the same type of thing. Already here we've used both geospatial and spatial interchangably. Before we go on, let's establish some common ground. You might have heard the acronym GIS : GIS stands for G eographic I nformation S ystems , and can refer to computer systems, infrastructure, software, data, or any mix of these things together. A GIS user uses GIS tools created by a GIS developer to interact with GIS data. Over time, as the importance of location information has increased in areas outside the traditional GIS industry, the term \"GIS\" has evolved to refer to anything related to geospatial data. As for that: Geospatial , or just Spatial , data is simply data with location information included: geospatial datasets connect a what to a where . Within Planet School , we most commonly use geospatial (or spatial ), in order to emphasize the industry-agnostic application of this type of data. Spatial isn't so special Let's take a look at \"regular\" data, versus \"spatial\" data, using a public dataset from data.austintexas.gov . Below is a table of data. Each row represents a single record, and each column has a name describing its content. If you've ever edited data in a spreadsheet, this probably seems familiar: Table of firestations in Austin, TX To turn that table of data into geospatial data, all we need to do is add location information to each record. Here, we've added longitude and latitude (or lon/lat ) coordinates to the data. Pairs of lon/lat values are used to represent a point on the Earth's surface (later in this tutorial we'll learn more about coordinates): Table of firestations in Austin, TX with longitude & latitude (X,Y) coordinates Using that location information, we can then create a map of our original data. Each point on this map represents one record from the data table: Spatial data, visualized: a map of firestations in Austin, TX Vector vs. Raster Geospatial data comes in two flavors: vector , and raster . When working with geospatial data, knowing the type of data you are interacting with can help you choose the right tools for the job: for example, one command-line interface for extracting metadata information about your dataset may be better suited for vector data, while another similar tool works better for raster data. Vector data is composed of points, lines, and polygons: In a vector dataset, each point represents a value at a specific X,Y point in space. Vector data is best suited for representing discrete features: e.g., the firestations represented by points in the example above. Other examples might be roads represented by lines, or lakes by polygons. In contrast, raster data is composed of pixels: small, uniformly-sized, grid cells: Vector vs. Raster In a raster dataset, each pixel has a value. Pixels representing equivalent data have the same value: Rasters are well-suited for representing continuous data across a broad area: for example, elevation data or temperature measurements. Raster pixels may also be used to represent color values: satellite imagery is an example of this kind of data. In the following image, zooming in on an area allows you to see how each tiny square has a unique value; when put together these pixels make up an image. Section from a PlanetScope satellite image Common geospatial file types As you start to explore the wide world of geospatial data, it can be useful to become familiar with a few of the most common file types you might run across. There are dozens, if not hundreds, of formats of geospatial data, but some of the more popular formats include: GeoJSON A standardized format for representing vector data features. Based on JSON, GeoJSON can be edited in any text editor, and is especially well-suited to geospatial data transmitted over the web Shapefile A very popular vector data file format: despite the name, a \"shapefile\" is actually a collection of files with a common filename prefix (i.e., mydata.shp + mydata.shx + mydata.dbf ) GeoTIFF An ordinary TIFF image file, with location information included: spatial reference information is either embedded within the TIFF file itself, or (in some versions) included as a *.tfw sidecar file alongside the TIFF. Used to store raster data. In the guides and tutorials you'll find here on Planet's Developer Center , the most common files types you'll run across are GeoJSON and GeoTIFF. Some of the tools you can learn about here can be used to easily convert data between common geospatial file formats. Defining location Earlier we learned that geospatial data is data with location information attached. But how, exactly, do we define \"location\"? Coordinates In a 3D world, specific points in space can be referred to using their coordinates along each of three directional axes: A point defined by it's `X, Y, Z` position Coordinate Systems The geometric concept above also applies to geographic space: any point on the Earth can be described by its latitude , longitude , and (optionally) its elevation . The systems that are used to describe points on the Earth's surface are called geographic coordinate systems (GCS). A GCS uses a mathematically-defined surface called an ellipsoid to represent the Earth's shape. Complex computations based on that ellipsoid define the coordinates that can be used to reference a unique point. There are many coordinate systems, some more common than others: WGS 84 is the one you will see used most often. Map Projections Map Projections allow us to translate locations from a 3D surface (like a globe) onto a flat surface (like a map). Imagine peeling an orange, and then attempting to flatten the peel on a table: it will never perfectly lie flat, and you'll find yourself trying to stretch, cut, or squash the peel in the attempt. Similarly, because the Earth is not flat, map projections must always distort the features they map in some way. Different projections might be chosen depending on the way they distort an area's features. Geospatial data that has been transformed in order to fit a flat surface is called projected data. The projection used for this transformation is part of the geospatial information (metadata) unique to your data file. Similarly, data that has not been transformed from a global model is called unprojected : in this case, the geographic coordinate system will be included in the metadata for that data file. Next Steps Now that you've learned a bit about what makes geospatial data special, you should find yourself better equipped to begin working with this kind of data. Head back to Planet School for more foundational concepts -- or dive in to the Quickstart if you're ready to get started with Planet's API. Appendix: terms to know Geospatial data Data that has location information associated with each object described Vector Geospatial data composed of points, lines, or polygons: each point represents a value Raster Geospatial data composed of pixels (or grid cells ): each pixel represents a value Coordinate A pair of (X,Y) values used to reference a point in space: in a GCS these are long, lat (longitude, latitude) numbers Coordinate System A way of representing data about the Earth's surface on a 3-dimensional (global) surface, using degrees of latitude and longitude to describe points. Also known as a Geographic Coordinate System (GCS) Map Projection A way of translating 3-dimensional data into 2-dimensional space: projections are how we flatten global data onto a map's surface. Also known as a Projected Coordinate System","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/geospatial-data/","loc":"https://developers.planet.com/docs/planetschool/geospatial-data/"},{"title":"REST APIs","text":"Overview If you're new to the idea of REST APIs, you may find the concept a bit intimidating -- maybe you're not quite sure where to even start getting started. If this sounds familiar, then good news! You're not alone. In this guide, you'll learn some common API-related terms, and get a general introduction to how data can be transmitted online. After that we'll practice using a real API to send and receive data to and from a remote internet server (no programming necessary!). By the end of the lesson, you will be equipped to begin using other APIs - including Planet's API - in real-world situations. What are we talking about? First thing's first: let's demystify some of the jargon that you'll likely encounter when talking about, or working with, web APIs: An API , or Application Programming Interface , defines a way of communicating between software applications. REST stands for Representational State Transfer , and is an architectural style of creating web services that communicate with web resources. JSON stands for JavaScript Object Notation , and is a standard text-based format that's used to represent structured data. If those definitions seem a bit opaque, don't worry! For the most part these are broad concepts that software developers use to inform the work they do. As an API user, as long as you have a general familiarity with the terms, you are good to go. A note about names: when talking about web services that allow us to access resources over the web, we commonly say REST (or RESTful ) API . In many cases, however, you may simply hear API used to refer to a REST API. You may have noticed that here in this guide, we're also using the phrase web API interchangably with those terms. Any of the above is acceptable, and will be understood just fine in the context of \"working with data services over the web\". How does the web work? Before we continue learning about web APIs, take a moment to ask yourself: What happens when I type 'www.google.com' and hit enter in my browser? In order to better understand how communication over the web works, let's break down what goes on behind-the-scenes when you access a website in your browser: URL → IP Address When you enter a URL like www.google.com , that URL is translated into an IP address: a unique address representing a destination on the internet. Browser requests information from that IP Once your browser knows the destination for the URL you typed, it makes a request to that destination. Server at IP responds to the request The IP address our URL translated into leads to a web server: when this server receives an incoming request, it parses that request & generates a response . The response is then sent from the server, back to your browser. Browser renders the response Once your browser receives the response to its original request, it will attempt to render the result in your browser window: e.g., displaying images, drawing clickable buttons, setting font sizes and colors, etc. You view the result! : What is JSON? JSON stands for JavaScript Object Notation , and is a standard text-based format that's used to represent structured data. JSON is based on, and resembles, JavaScript object formatting. Even though it is based on JavaScript, JSON works independently of JavaScript and many different programming languages are capable of reading JSON. Let's break this down in case you're not familiar with JavaScript objects. { \"nameOfThisGroup\": \"Dog Squad\", \"whereAreThey\": \"In the dog house\", \"whenFormed\": 2020, \"darkSecret\": \"Leader is a cat\", \"active\": true, \"members\": [ { \"name\": \"Atlas the Active\", \"age\": 2, \"species\": \"Dog\", \"breed\": \"Australian Kelpie\", \"powers\": [ \"Leaving it\", \"Infiltrating locked spaces\", \"Time travel\" ] }, { \"name\": \"Athena the Great\", \"age\": 9, \"species\": \"Dog\", \"breed\": \"Newfoundland\", \"powers\": [ \"Radioactive drool\", \"Stashing the goods\", \"Teleportation\" ] }, { \"name\": \"Lilith\", \"age\": 5000, \"species\": \"Cat\", \"breed\": \"Short-haired\", \"powers\": [ \"Immortality\", \"Flight\", \"X-ray vision\" ] }, { \"name\": \"Merlin\", \"age\": 3, \"species\": \"Cat\", \"breed\": \"Tabby\", \"powers\": [ \"Sleep of the dead\", \"Master of the chase\", \"Invisibility\" ] } ] } If you take a look at the above example, you'll see that objects are essentially standard data types arranged in a way that is easily readable for many programming languages. The data is typically arranged in a parent child, or nested, format, creating a data hierarchy. At the beginning you see the information about the group as a whole (the parent), in this case, a squad of super hero house pets, and below that are the members of the group (the children) and their individual information. As you can see, each member has the same list of data, with their individual values given after the assigned data. The data types used include strings (or lists of characters), numbers, arrays, and booleans (true or false) If you'd like to further explore JSON, there are many great resources available. Check out JSON Lint: JSON Online Validator and Formatter , JSON.org , Working with JSON - Learn web development | MDN , and JSON and APIs with Python . Requests & Responses When we communicate over the web, HTTP , or H yper T ext T ransfer P rotocol, is the 'language' that clients like our web browser use to communicate with web servers. HTTP defines a standardized way of communicating information through a series of requests and responses . A client makes a request , using HTTP, to a server. In return, the server will send a response back to the client. Headers & Bodies Both requests and responses have two parts: a header , and (optionally) a body . Request allow the client to send information about the request to the server. Similarly, response headers contain information about the response. We'll learn more about what kind of meta-information headers can contain later in this tutorial. In both requests & responses, the body contains the actual data being transmitted: for example, in a weather API that returns temperatures at a given location, the temperature data would be returned in the response body. Request Methods In REST APIs, every request has an HTTP method type associated with it: this method is used to signal the type of action the request wishes to perform. The most common HTTP methods include: GET A GET request asks to receive a copy of a resource POST A POST request sends data to a server in order to create a new resource PUT A PUT request sends data to a server in order to modify an existing resource DELETE A DELETE request is - as you might imagine - sent to delete a resource When working with REST APIs, we often talk about requests by method type; e.g., we might \"make a GET request\" or \"POST to the API\". Response Codes HTTP responses don't have methods, but they do have status codes: HTTP status codes are included in the header of every response in a REST API. Status codes include information about the result of the original request: if all goes well, for example, the 200 - OK status code is returned. You may be familiar with some of the more common HTTP status codes, such as: 404 - Not Found The requested resource was not found 401 - Unauthorized Your request is not authorized to be completed 500 - Internal Server Error Something went wrong while the server was processing your request You can read more about these and other HTTP status codes at httpstatuses.com . URLs In REST APIs, resources are located at U niform R esource L ocators (URLs). URLs can include paths: http://example.com/path/to/resource Here, the nested path path/to indicates the resource resource 's location, for example within a directory on the remote server's file system. URLs can also include query strings: http://example.com/path/to/resource?name=cat&color=black Here, the ? at the end of the path indicates the beginning of a query string: in this example, the query string is name=cat&color=black . Query strings can be used to query a resource based on given fields (like \"name\" and \"color\" here) and values (like \"cat\" and \"black\"). Authentication & Authorization Most REST APIs require you to be authenticated in order to use them. Authentication allows the API service to connect a request to a specific user. An authenticated user has successfully identified themselves to the API when making their request. There are many different ways of providing authentication when making an API request. Some of the more common include using a username & password, or sending an API key as part of the request. To use the Planet API, for example, you create a user account, which then gives you access to a unique API key. Authentication is not to be confused with Authorization : a REST API may restrict some resources based on level of authorized access. For example, one authenticated user may be authorized to request an existing resource, but may not be authorized to delete a resource. Common tools for all platforms: curl, Postman There are a number of tools that make it easier to interact with APIs. Two common ones, that are available for most platforms, are curl and Postman . If you're comfortable with the command line, curl is a great command-line tool that is already installed on most modern operating systems. If you're looking for either something with a graphical interface, or perhaps more feature-ful than curl, then Postman is also a great tool to add to your toolbox. To check if curl is installed on your computer, open a terminal/command prompt (Windows users: open Powershell), and at the prompt type: curl --help If you get a long result showing command usage information, curl is installed and ready to use. If, however, you see \"command not found\" -- then use the Download Wizard here to download the curl executable for your operating system. To use Postman, you can either install it as a Chrome browser extension, or as a standalone native application. You can find the Chrome extension here , or get the native application from here . The remaining API examples in this tutorial will use curl, but you are welcome to use any tool you prefer to follow along. Putting it all together Finally! At this point we've talked a bit about how the web works, and how REST APIs function as a way of requesting & receiving data. Now let's put what we've learned into practice and use a real API: we'll use The Cat API , an API that responds to requests for images of cats with a random image result. We'll start by making a GET request. Type the following curl command at a command prompt: curl -v GET https://api.thecatapi.com/v1/images/search A closer look at that line, broken down into separate parts: Here we're making a GET request to an API. We've used the optional -v flag for curl in order to have the command print verbose output. Now let's take a closer look at what that command does: When you make a request using curl, the first thing you see is the IP address the target URL resolves to (in this case, 23.217.138.110 ) followed by your request's headers. Following our request headers comes the response header section: here, we see that the server returned a 200 status code, followed by the date & time the response was sent. The next few lines encode additional information about the response. Finally, we see the response body: in this case, the body itself is a block of JSON-formatted text content. If you read this JSON response, you'll notice an image URL value encoded within. Copy that URL to your browser & view the result: https://cdn2.thecatapi.com/images/MTk2NzgzNw.jpg Congratulations, you've successfully requested an image of a cat from the Cat API! Even more API practice Let's create a slightly more complex query string by chaining multiple queries together. Also, now that we're familiar with headers, we can drop the -v verbose flag so that curl only outputs the response body: curl -X GET \"https://api.thecatapi.com/v1/images/search?category_ids=1\" Here we're requesting a JSON-formatted response returning only images that are JPEGs of cats in the category \"hats\". The Cat API has a number of image categories (like \"hats\"), with number ids assigned to each category: as an exercise, use the API docs here to learn how to make an API request that returns the complete list of categories. We can even practice using an API key for authentication with The Cat API. To get your own API key, you'll need to request one from here . Once your key has been emailed to you, replace the dummy key \"12345\" in the example below with your own: curl -X GET \"https://api.thecatapi.com/v1/images/search?category_ids=1&api_key=12345\" REST APIs for developers While curl is a useful tool for authenticating requests quickly, its utility is confined to to the command line. Perhaps a user wants to build a web app showing only the cutest of kitties. They would have to integrate the Cat API into the backend of their application. Below is a practical example of a Python request to my favorite API: import requests # install the requests library to make a get request BASE_URL = 'https://api.thecatapi.com/v1/images/search' headers = { 'x-api-key': '12345' } # authenticate request by sending api key in headers as specified in the cat api documentation kitties = requests.get(BASE_URL, headers=headers) print(kitties) # prints the (hopefully 200) response for kitties Where to go from here Now that you've made a few requests against The Cat API, you're ready to move on: at this point you've equipped yourself with enough knowledge to use a real-world data API like Planet's API. From here, you can continue by following our API Quickstart guides to get up & running with the Planet API.","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/rest-apis/","loc":"https://developers.planet.com/docs/planetschool/rest-apis/"},{"title":"Satellite Imagery","text":"Overview So you've downloaded your first Planet image. There's something on your computer that came from space. Cool! So now what? Well, first things first: look at it! If you open it in Windows Picture Viewer (WPV) or Apple's Preview, the image may look totally black. Don't worry, it's not broken! That's just an analytic file appropriate for scientific applications, and WPV & Preview expect 8- or 16-bit images . The values in the analytic file can be scaled in a program like Photoshop or GIMP, or opened and scaled in GIS software like QGIS. But if you want something that looks like what you expect out of the box, download the visual file instead. *Fig. 1: Analytic file on the left. Visual on the right.* So now that you can see something, you may wonder what you're looking at. Well, imaging satellites have digital cameras attached to telescopes - like a sports photojournalist's setup, but in space! *Credit: [Wikipedia](https://en.wikipedia.org/wiki/Sports_photography)* These cameras are fancier than cell phone cameras, but the pixels you see when you zoom into a selfie are the same type of thing you see when you zoom into a satellite image. They represent the intensity of light reflected off the objects the camera was pointed at. As an aside, Planet's cofounders actually launched a cell phone to the edge of the atmosphere, and recent phone sats even captured photos! The main difference between Planet's cameras and a photojournalist's is that our camera is sitting in space and pointing at the ground. Oh, and it's surrounded by lots of electronics to help it understand where it is, stay there, and transmit images to the ground. Because we know where the satellite is pointing and the height of the orbit, we know that each pixel represents a specific place and covers 3 to 5 meters on the ground - depending on the orbit and the length of the telescope. This helps us put images on a map, like what you see in Google Maps. Anyway, an image contains some combination of bands, or data \"layers\", that represent each of the different wavelengths of light recorded by the sensor. Planet's satellites record red, green, blue, and near-infrared (NIR) light reflecting off the ground. Even though our eyes don't see it, near-infrared (NIR) light provides extremely helpful information! Our RapidEye images capture NIR as well as red edge information, which falls between \"pure\" red and NIR. People are most familiar with RGB images, because that's what we see out in the world. You can see where visible light appears in the electromagnetic spectrum in the figure below. *Fig. 2 Electromagnetic spectrum (Credit: [NASA](http://imagine.gsfc.nasa.gov/science/toolbox/emspectrum1.html))* This image of San Francisco shows that Golden Gate Park reflects a lot of green light and absorbs red and blue light (which makes it look green to us). Seafoam along the western coast reflects red, green AND blue light (which makes it look white to us). *Fig. 3 Planet image of San Francisco.* Other satellites and instruments record light in different parts of the electromagnetic spectrum, including ultraviolet or thermal infrared. Bees can even see ultraviolet light! *Fig. 4 What a bee sees vs. what we see.* Interestingly, chlorophyll reflects a lot of near-infrared (NIR) light, which means it's useful for highlighting plants. Water absorbs NIR light, so it's easy to distinguish green water from green plants. Check out the image below - it alternates between a normal RGB image and a false-color image created with NIR, red and blue bands. That green lake in the upper left looks a lot like the green forest NE of center - except when you look at the false color image: the lake looks black, while the dense forest is dark red. As you might imagine, this is really useful for agricultural applications - like checking crop health (more chlorophyll = healthier growth) - or tracking deforestation. *Fig. 5: Standard RapidEye RGB image near Santa Cruz vs. false color with NIR* Other materials reflect different wavelengths of light in different ways. The graphs below show the spectral signatures of different features you might see in a satellite image (see Figs. 6 & 7). We can use these spectral signatures to classify different types of features on the ground. The graphs below show the amount of light reflected off a particular surface at a particular wavelength of light. So what can you actually see in our imagery? Look for patterns across a landscape? Measure urban growth? Track fires, sandstorms, floods? Do you know what to look for? This NASA guide offers useful tips for visually inspecting and interpreting images - no code necessary! The most interesting thing about our imagery is the fact that it is updated so often. Because we have so many satellites in space (137 at the time of writing, but we're launching more soon), we can image the same place frequently. Once our full constellation is launched later this year, we'll be imaging the entire world every day. So we'll be able to watch crops grow, buildings appear, or deforestation spread - all as it happens. No one has been able to do that in such detail before, so we're very excited about the possibilities. Next Steps If you're familiar with REST APIs, you can jump directly to our API Quickstart guides to get up & running with Planet's public data API. If you need an introduction to APIs, start here .","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/satellite-imagery/","loc":"https://developers.planet.com/docs/planetschool/satellite-imagery/"},{"title":"Working with Rasters in GDAL","text":"Overview Clip a Raster to an Area of Interest Digital Elevation Model (DEM) Unit Conversion The first step is to determine the conversion betweet feet and meters -- a quick and easy internet search reminds us that 1 foot equals .3048 meters. Great! Now we have what we need to convert our DEM's values from one unit of measurement to the other. To run the conversion, do: gdal_translate -scale 0 0.3048 0 1 input.tif output.tif This seems a bit magical, so let's break it down: gdal_translate The specific GDAL command we're calling -scale Indicates we want to rescale the input pixel values to generate a new output 0 0.3048 0 1 The order of numbers here indicate: source_min, source_max, destination_min, destination_max . In other words, For more information on this, and other gdal_translate commands, also check out this docs page . Vector Mask Creation - mask areas where elevation greater than x - mask areas where veg index greater than y Generate a Vegetation Index","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/working-with-rasters-in-gdal/","loc":"https://developers.planet.com/docs/planetschool/working-with-rasters-in-gdal/"},{"title":"Landsat 8","text":"Landsat 8 standard terrain-corrected scenes in path/row framing. This data set includes imagery from Landsat 8 satellite operated by USGS. Products Overview The Geometric Processing Subsystem (GPS) creates L1 geometrically corrected imagery (L1G) from L1R products. The geometrically corrected products can be systematic terrain corrected (L1Gt) or precision terrain-corrected products (L1T). The GPS generates a satellite model, prepares a resampling grid, and resamples the data to create an L1Gt or L1T product. The GPS performs sophisticated satellite geometric correction to create the image according to the map projection and orientation specified for the L1 standard product. Landsat 8 data is packed into zip files by band. All data is passed through in the original provider's format, so please visit USGS for more details. Attribution Data available from the U.S. Geological Survey. See USGS Visual Identity System Guidance for further details. Item Properties Property Name Description Type _permissions Assets available for the item which the authenticated user has permission to download. array geometry Geographic boundary of the item's footprint, formatted as a GeoJSON polygon. json id Globally unique item identifier. string acquired Timestamp representing the date and time of acquisition (in UTC). datetime anomalous_pixels Ratio of pixels that may have errors. Represented spatially in the UDM. double cloud_cover Ratio of the pixels covered by clouds. double collection Landsat collection number. integer columns Number of columns in the image. integer data_type The processing level of the product. string epsg_code Ortho tile grid cell that the item is located in (not used if Scene). integer gsd Ground sample distance - the distance between pixel centers as measured on the ground in meters. double instrument Name of the satellite instrument used to collect the image. string item_type Name of the item type. string origin_x ULX coordinate of the extent of the data. The coordinate references the top left corner of the top left pixel. double origin_y ULY coordinate of the extent of the data. The coordinate references the top left corner of the top left pixel. double pixel_resolution Pixel resolution of the imagery in meters. double processed Timestamp that the item was processed. datetime product_id Unique identifier of the product. string provider Name of the item provider (e.g. \"planetscope\", \"rapideye\"). string published Timestamp that the item was published to the Planet API. datetime quality_category Planet image quality metric: Standard or Test . To qualify for \"standard\" image quality an image must meet a variety of quality standards, for example: PAN motion blur less than 1.15 pixels, compression bits per pixel less than 3. If the image does not meet these criteria it is considered \"test\" quality. string rows Number of rows in the image. integer satellite_id Globally unique satellite identifier. string sun_azimuth The angle of the sun, as seen by the observer, measured clockwise from the north (0 - 360). double sun_elevation The angle of the sun above the horizon (0 - 90). double updated Timestamp that the item record was last updated. datetime usable_data Percentage of pixels that are usable, subtracting cloud cover and black fill. double view_angle The satellite's across-track, off-nadir viewing angle. Positive numbers denote east, negative numbers denote west (-25 - +25). double wrs_path Nearest WRS (Worldwide Reference System) path to the line-of-sight scene center. integer wrs_row Nearest WRS (Worldwide Reference System) Row to the line-of-sight scene center. integer Available Asset Types Asset Name Description analytic_b1 Band 1 (caoastal/aerosol) - Radiometrically calibrated GeoTiff product suitable for analytic applications. analytic_b2 Band 2 (blue) - Radiometrically calibrated GeoTiff product suitable for analytic applications. analytic_b3 Band 3 (greeb) - Radiometrically calibrated GeoTiff product suitable for analytic applications. analytic_b4 Band 4 (red) - Radiometrically calibrated GeoTiff product suitable for analytic applications. analytic_b5 Band 5 (near-infrared) - Radiometrically calibrated GeoTiff product suitable for analytic applications. analytic_b6 Band 6 (swir-1) - Radiometrically calibrated GeoTiff product suitable for analytic applications. analytic_b7 Band 7 (swir-2) - Radiometrically calibrated GeoTiff product suitable for analytic applications. analytic_b8 Band 8 (pan) - Radiometrically calibrated GeoTiff product suitable for analytic applications. analytic_b9 Band 9 (cirrus) - Radiometrically calibrated GeoTiff product suitable for analytic applications. analytic_b10 Band 10 (tir-1) - Radiometrically calibrated GeoTiff product suitable for analytic applications. analytic_b11 Band 11 (tir-2) - Radiometrically calibrated GeoTiff product suitable for analytic applications. analytic_bqa QA band of analytic products. metadata_txt Analytic asset MTL XML metadata file. visual Color corrected GeoTiff product for visual applications.","tags":"data-api","url":"https://developers.planet.com/docs/data/landsat-8","loc":"https://developers.planet.com/docs/data/landsat-8"},{"title":"PSOrthoTile","text":"Deprecating PSOrthoTile Planet is deprecating the PSOrthoTile item type on Wednesday, March 22, 2023 with plans to formally end-of-life the item types on Tuesday, June 20, 2023. We recommend all customers begin to migrate to the PSScene item type now. The PSScene item type provides the same spectral bands and pixel values as PSOrthoTile. Planet will continue to publish imagery to the PSOrthoTile item type June 20, 2023. After June 20, 2023, Planet will no longer publish images to the PSOrthoTile item type. For more information and tips on migrating, see the PSOrthoTile Deprecation and Migration Plan . PlanetScope Ortho Tiles as 25 km x 25 km UTM tiles. This data set includes imagery from all PlanetScope sensors. Products Overview All Ortho Tile products are provided in GeoTIFF format. The ortho tile product GeoTIFFs are resampled at 3.125 meters, and projected in the UTM projection using the WGS84 datum. An alpha mask is provided as a binary color channel, and can be used to remove or hide low quality pixels near the periphery of a given scene. This mask compensates for effects due to vignetting, low SNR, or hot or cold pixels. PlanetScope Ortho Tiles are based on a worldwide, fixed UTM grid system. The grid is defined in 24 km by 24 km tile centers, with 1 km of overlap (each tile has an additional 500 m overlap with adjacent tiles), resulting in 25 km by 25 km tiles. For PlanetScope split-frame satellites, imagery is collected as a series of overlapping framed scenes from a single satellite in a single pass. These scenes are subsequently orthorectified and an ortho tile is then generated from a collection of consecutive scenes, typically 4 to 5. The PlanetScope Ortho Tile products are radiometrically, sensor, and geometrically corrected and aligned to a cartographic map projection. The geometric correction uses fine DEMs with a post spacing of between 30 and 90 meters. GCPs are used in the creation of every image and the accuracy of the product will vary from region to region based on available GCPs. Product band order: Band 1 = Blue Band 2 = Green Band 3 = Red Band 4 = Near-infrared (analytic products only) Analytic 5B Product band order: Band 1 = Blue Band 2 = Green Band 3 = Red Band 4 = Red-Edge Band 5 = Near-infrared Item Properties Property Name Description Type _permissions Assets available for the item which the authenticated user has permission to download. array geometry Geographic boundary of the item's footprint, formatted as a GeoJSON polygon. json id Globally unique item identifier. string acquired Timestamp that the item was captured. datetime anomalous_pixels Percentage of pixels which may have errors. Represented spatially in the UDM. double [0-100] black_fill The percentage of the item containing black fill. double [0-100] clear_confidence_percent percentage value: per-pixel algorithmic confidence in 'clear' classification int [0-100] clear_percent Percent of clear values in dataset. Clear values represents scene content areas (non-blackfilled) that are deemed to be not impacted by cloud, haze, shadow and/or snow. int [0-100] cloud_cover Average ratio of cloud coverage. double [0-100] cloud_percent Percent of cloud values in dataset. Cloud values represent scene content areas (non-blackfilled) that contain opaque clouds which prevent reliable interpretation of the land cover content. int [0-100] columns Number of columns in the image. integer epsg_code Ortho tile grid cell that the item is located in (not used if Scene). integer grid_cell The grid cell identifier of the gridded item. string ground_control Positional accuracy of the item. If the item has uncertain positional accuracy, this value will be false. boolean gsd Ground sample distance - the distance between pixel centers as measured on the ground in meters. double heavy_haze_percent Percent of heavy haze values in dataset. Heavy haze values represent scene content areas (non-blackfilled) that contain thin low altitude clouds, higher altitude cirrus clouds, soot and dust which allow fair recognition of land cover features, but not having reliable interpretation of the radiometry or surface reflectance. int [0-100] instrument Name of the satellite instrument used to collect the image. string item_type Name of the item type. string light_haze_percent Percent of light haze values in dataset. Light haze values represent scene content areas (non-blackfilled) that contain thin low altitude clouds, higher altitude cirrus clouds, soot and dust which allow reliable recognition of land cover features, and have up to +/-10% uncertainty on commonly used indices (EVI and NDWI). int [0-100] origin_x ULX coordinate of the extent of the data. The coordinate references the top left corner of the top left pixel. double origin_y ULY coordinate of the extent of the data. The coordinate references the top left corner of the top left pixel. double pixel_resolution Pixel resolution of the imagery in meters. double provider Name of the item provider (e.g. \"planetscope\", \"rapideye\"). string published Timestamp that the item was published to the Planet API. datetime publishing_stage Stage of publishing for an item. PSOrthoTiles will be first published in \"standard\" stage and graduate to a \"finalized\" stage. string quality_category Metric for image quality. To qualify for \"standard\" image quality an image must meet a variety of quality standards, for example: sun altitude greater than or equal to 10 degrees, off nadir view angle less than 20 degrees, and saturated pixels fewer than 20%. If the image does not meet these criteria it is considered \"test\" quality. string rows Number of rows in the image. integer satellite_azimuth Spacecraft off track pointing direction, in degrees (0-360) float satellite_id Globally unique satellite identifier. string strip_id The unique identifier of the image strip that the item came from. string sun_azimuth The angle of the sun, as seen by the observer, measured clockwise from the north (0 - 360). float sun_elevation The angle of the sun above the horizon (0 - 90). double updated Timestamp that the item record was last updated. datetime usable_data Percentage of pixels that are usable, subtracting cloud cover and black fill. double [0-100] view_angle The satellite's across-track, off-nadir viewing angle. Positive numbers denote east, negative numbers denote west (-25 - +25). double visible_confidence_percent Visible values represent the fraction of the scene content (excluding the portion of the image which contains blackfill) which is comprised of clear, light haze, shadow, snow/ice categories, and is given as a percentage ranging from zero to one hundred. int [0-100] visible_percent Average of confidence percent for clear_percent, light_haze_percent, shadow_percent and snow_ice_percent int [0-100] Available Asset Types Asset Name Description analytic Radiometrically calibrated GeoTiff product suitable for analytic applications. analytic_5b Radiometrically calibrated GeoTiff product suitable for analytic applications. Has 5 analytic bands, including red-edge. Supported only for the PlanetScope PSB.SD instrument. analytic_5b_xml Analytic 5B asset XML metadata file. Supported only for the PlanetScope PSB.SD instrument. analytic_dn Non-radiometrically calibrated GeoTiff product suitable for analytic applications. analytic_dn_xml Analytic DN asset XML metadata file. analytic_sr Atmospherically corrected surface reflectance GeoTiff product. analytic_xml Analytic asset XML metadata file. visual Color-corrected GeoTiff product for visual applications. visual_xml Visual asset XML metadata file. udm Usable Data Mask - Usable data bit mask GeoTIFF for visual and analytic assets. udm2 Usable Data Mask 2.0. Read more about this new asset here.","tags":"data-api","url":"https://developers.planet.com/docs/data/psorthotile","loc":"https://developers.planet.com/docs/data/psorthotile"},{"title":"PSScene","text":"This item-type includes imagery from PlanetScope sensors. PlanetScope images are from three different sensors: PS2, PS2.SD, and PSB.SB. Sensors PS2 and PS2.SD deliver four bands: red, green, blue, and near-infrared. PSB.SD sensor has an additional four bands: green I, yellow, coastal blue, and red edge. The earliest PS2 imagery available on July, 2014 to April 29, 2022. The earliest PS2.SD imagery available is on March, 2019 to April 22, 2022. The earliest PSB.SD imagery available is mid-March, 2020 to current monitoring. Products overview Planet offers two geometry types for PlanetScope imagery: Basic and Ortho. Basic Scene is not orthorectified or corrected for terrain distortions. Ortho Scene is orthorectified with additional post processing applied. By default, both Basic and Ortho products are provided as GeoTIFF images. Containing geospatial metadata, the GeoTIFF file format is used in GIS and other remote sensing software. GeoTIFFs are resampled at 3 meters and are projected into the UTM projection using the WGS84 Datum. Each GeoTIFF image can be converted to Cloud Optimized GeoTIFF and National Imagery Transmission Format 2.1 using the File Format tool in the Orders API and the Subscriptions API . The analytic products are accompanied by a Usable Data Mask (UDM2) file. The UDM2 file is a raster file that consists of eight bands that provide information about each pixel quality in the scene. Each band provides context on whether a pixel is clear, cloudy, shadowed, etc. These bands allow users to remove pixels that aren't useful after they download the image. UMD2 also compensates for effects due to vignetting, low signal-to-noise, or hot or cold pixels. The PlanetScope Ortho Scene product is orthorectified and is designed for applications that require imagery with an accurate geolocation and cartographic projection. These scenes have been processed to remove distortions caused by terrain. Ortho Scenes are delivered as Visual (RGB) and Analytic products. Ortho Scenes are radiometrically-, sensor-, and geometrically-corrected products projected to a cartographic map projection. The geometric correction uses fine Digital Elevation Models (DEMs) with a post spacing of between 30 and 90 meters. The PlanetScope Basic Scene product is a scaled Top of Atmosphere Radiance (TOAR) (at sensor) and sensor-corrected product, providing imagery as seen from the spacecraft without correction for any geometric distortions. It has scene-based framing and is not mapped to a cartographic projection. The Basic Scene product is designed for users with advanced image processing capabilities who plan to geometrically correct the product themselves. The imagery data is accompanied by Rational Polynomial Coefficients (RPCs) to enable orthorectification by the user. Ground Control Points (GCPs) are used in the creation of every image and the accuracy of the product varies from region to region based on available GCPs. PlanetScope satellites collect imagery as a series of overlapping frame scenes and are not organized to any particular grid system. Ortho Scenes enable users to stitch scenes together and to clip them to a tiling grid. To read more about PlanetScope imagery, see the PlanetScope Product Specification . PlanetScope band order The following lists band orders of each asset. The 3-band and 4-band assets have the same band order, while the 8-band assets change to accommodate for the additional four bands. For additional explanations of band type order and the imagery returned from different sensor data, see Understanding PlanetScope Instruments . 3-Band asset band order The 3-band visual (natural color) band order is: Band 1 = Red Band 2 = Green Band 3 = Blue 4-Band asset band order The 4-band multispectral band order is: Band 1 = Blue Band 2 = Green Band 3 = Red Band 4 = Near-infrared 8-Band asset band order The 8-band multispectral band order is: Band 1 = Coastal Blue Band 2 = Blue Band 3 = Green I Band 4 = Green Band 5 = Yellow Band 6 = Red Band 7 = Red Edge Band 8 = Near-infrared Item properties Property Name Description Type _permissions Assets available for the item which the authenticated user has permission to download. array geometry Geographic boundary, formatted as a GeoJSON polygon. json id Globally unique item identifier. string acquired Timestamp when the item was captured. datetime anomalous_pixels Percentage of pixels that may have errors. Represented spatially in the UDM. double clear_confidence_percent Percentage value: per-pixel algorithmic confidence in 'clear' classification. int [0‑100] clear_percent Percent of clear values in the dataset. Clear values represent scene content areas (non-blackfilled) deemed to be not impacted by cloud, haze, shadow, or snow. int [0‑100] cloud_cover Ratio of the area covered by clouds to that which is uncovered. double cloud_percent Percent of cloud values in the dataset. Cloud values represent scene content areas (non-blackfilled) that contain opaque clouds which prevent reliable interpretation of the land cover content. int [0‑100] ground_control Positional accuracy of the item. If the item has uncertain positional accuracy, this value is false. boolean gsd Ground sample distance - the distance between pixel centers as measured on the ground in meters. double heavy_haze_percent Percent of heavy haze values in the dataset. Heavy haze values represent scene content areas (non-blackfilled) that contain thin low altitude clouds, higher altitude cirrus clouds, soot, and dust which allow fair recognition of land cover features, but not having reliable interpretation of the radiometry or surface reflectance. int [0‑100] instrument Name of the satellite instrument used to collect the image. string item_type Name of the item type. string light_haze_percent Percent of light haze values in the dataset. Light haze values represent scene content areas (non-blackfilled) that contain thin, low-altitude clouds, higher altitude cirrus clouds, and soot and dust which allow reliable recognition of land cover features, and that have up to +/-10% uncertainty on commonly used indices (EVI and NDWI). int [0‑100] pixel_resolution Pixel resolution of the imagery in meters. double provider Name of the item provider (e.g. \"planetscope\", \"rapideye\"). string published Timestamp when the item was published to the Planet API. datetime publishing_stage Stage of publishing for an item. SkySatScenes are first published in a \"preview\" stage and graduate to a \"finalized\" stage. string quality_category Planet image quality metric: \"standard\" or \"test\". To qualify for \"standard\" image quality an image must meet a variety of quality standards, for example: PAN motion blur less than 1.15 pixels, compression bits per pixel less than 3. If the image does not meet these criteria it is considered \"test\" quality. string satellite_azimuth Spacecraft off track pointing direction, in degrees (0-360). float satellite_id Globally unique satellite identifier. string shadow_percent Percent of shadow values in the dataset. Shadow values represent scene content areas (non-blackfilled) not fully exposed to the solar illumination as a result of atmospheric transmission losses due to cloud, haze, soot, and dust, and therefore do not allow for reliable interpretation of the radiometry or surface reflectance. int [0‑100] snow_ice_percent Percent of snow and ice values in dataset. Snow_ice values represent scene content areas (non-blackfilled) that are hidden below snow or ice. int [0-100] strip_id The unique identifier of the image stripe that the item came from. string sun_azimuth The angle of the sun, as seen by the observer, measured clockwise from the north (0 - 360). double sun_elevation The angle of the sun above the horizon (0 - 90). double updated Timestamp when the item record was last updated. datetime view_angle The satellite's across-track, off-nadir viewing angle. Positive numbers denote east, negative numbers denote west (-25 - +25). double visible_confidence_percent Visible values represent the fraction of the scene content (excluding the portion of the image which contains blackfill) which comprises clear, light haze, shadow, snow/ice categories, and is given as a percentage ranging from zero to one hundred. int [0‑100] visible_percent Average of confidence percent for clear_percent, light_haze_percent, shadow_percent and snow_ice_percent. int [0‑100] Available asset types Asset Name Description ortho_analytic_3b Radiometrically-calibrated analytic image stored as 16-bit scaled radiance. ( Note: This product is only available for instrument type \"PS2\" ). ortho_analytic_4b Radiometrically-calibrated analytic image stored as 16-bit scaled radiance. ortho_analytic_8b Radiometrically-calibrated analytic image stored as 16-bit scaled radiance. ortho_analytic_8b_sr PlanetScope atmospherically corrected surface reflectance product. ortho_analytic_8b_xml Radiometrically-calibrated analytic image metadata. ortho_analytic_4b_sr PlanetScope atmospherically corrected surface reflectance product. ortho_analytic_4b_xml Radiometrically-calibrated analytic image metadata. ortho_analytic_3b_xml Radiometrically-calibrated analytic image metadata. ( Note: This product is only available for instrument type \"PS2\" ). basic_analytic_4b Unorthorectified radiometrically-calibrated analytic image stored as 16-bit scaled radiance. basic_analytic_8b Unorthorectified radiometrically-calibrated analytic image stored as 16-bit scaled radiance. basic_analytic_8b_xml Unorthorectified radiometrically-calibrated analytic image metadata. basic_analytic_4b_rpc Rational polynomial coefficient for unorthorectified analytic image stored as 12-bit digital numbers. basic_analytic_4b_xml Unorthorectified radiometrically-calibrated analytic image metadata. basic_udm2 Unorthorectified usable data mask (Cloud 2.0). Read more about this new asset. ortho_udm2 Usable data mask (Cloud 2.0). ortho_visual Visual image with color-correction.","tags":"data-api","url":"https://developers.planet.com/docs/data/psscene","loc":"https://developers.planet.com/docs/data/psscene"},{"title":"REOrthoTile","text":"RapidEye Orthorectified 5-Band Imagery as 25km x 25km UTM Tiles. This data set includes imagery from all RapidEye sensors. Products Overview All ortho tile products are provided in GeoTIFF format. The ortho tile product GeoTIFFs are resampled at 3.125 meters and projected in the UTM projection using the WGS84 datum. An alpha mask is provided as a binary color channel. The alpha mask can be used to remove or hide low-image-quality pixels near the periphery of a given scene. The alpha mask compensates for effects due to vignetting, low SNR, or hot or cold pixels. The RapidEye Ortho Tile products offer RapidEye Satellite imagery orthorectified as individual 25 km by 25 km tiles. This product was designed for a wide variety of applications that require imagery with an accurate geolocation and cartographic projection. It has been processed to remove distortions caused by terrain and can be used for many cartographic purposes. The RapidEye Ortho Tile products are radiometrically, sensor and geometrically corrected and aligned to a cartographic map projection. The geometric correction uses fine DEMs with a post spacing of between 30 and 90 meters. GCPs are used in the creation of every image and the accuracy of the product will vary from region to region based on available GCPs. RapidEye Ortho Tile products are output as 25 km by 25 km tiles referenced to a fixed, standard RapidEye image tile grid system. Product band order: Band 1 = Blue Band 2 = Green Band 3 = Red Band 4 = Red edge (analytic products only) Band 5 = Near-infrared (analytic products only) Item Properties Property Name Description Type _permissions Assets available for the item which the authenticated user has permission to download. array geometry Geographic boundary of the item's footprint, formatted as a GeoJSON polygon. json id Globally unique item identifier. string acquired Timestamp that the item was captured. datetime anomalous_pixels Percentage of pixels that may have errors. Represented spatially in the UDM. double black_fill The percentage of the item containing black fill. double catalog_id Base RapidEye Level 3A catalog id. string cloud_cover Average percentage of cloud coverage. double columns Number of columns in the image. integer epsg_code Ortho tile grid cell that the item is located in (not used if Scene). integer grid_cell The grid cell identifier of the gridded item. string ground_control Positional accuracy of the item. If the item has uncertain positional accuracy, this value will be false. boolean gsd Ground sample distance - the distance between pixel centers as measured on the ground in meters. double item_type Name of the item type. string origin_x ULX coordinate of the extent of the data. The coordinate references the top left corner of the top left pixel. double origin_y ULY coordinate of the extent of the data. The coordinate references the top left corner of the top left pixel. double pixel_resolution Pixel resolution of the imagery in meters. double provider Name of the item provider (e.g. \"planetscope\", \"rapideye\"). string published Timestamp that the item was published to the Planet API. datetime rows Number of rows in the image. integer satellite_id Globally unique satellite identifier. string strip_id The unique identifier of the image stripe that the item came from. stringsun_azimuth sun_azimuth The angle of the sun, as seen by the observer, measured clockwise from the north (0 - 360). double sun_elevation The angle of the sun above the horizon (0 - 90). double updated Timestamp that the item record was last updated. datetime usable_data Percentage of pixels that are usable, subtracting cloud cover and black fill. double view_angle The satellite's across-track, off-nadir viewing angle. Positive numbers denote east, negative numbers denote west (-25 - +25). double Available Asset Types Asset Name Description analytic Radiometrically calibrated GeoTiff product suitable for analytic applications. analytic_sr Atmospherically corrected surface reflectance GeoTiff product. analytic_xml Analytic asset XML metadata file. udm Unusable Data Mask - Unusable data bit mask in GeoTIFF format for the visual and analytic scene assets. visual Color-corrected GeoTiff product for visual applications. visual_xml Visual asset XML metadata file.","tags":"data-api","url":"https://developers.planet.com/docs/data/reorthotile","loc":"https://developers.planet.com/docs/data/reorthotile"},{"title":"REScene","text":"RapidEye Basic 5-band imagery with strip-based framing. This data set includes imagery from all RapidEye sensors. Products Overview The visual and analytic products are in GeoTIFF. The GeoTIFFs are resampled at 3 meters and projected in the UTM projection using the WGS84 datum. An alpha mask is provided as a binary color channel, and can be used to remove or hide low quality pixels near the periphery of a given scene. This mask compensates for effects due to vignetting, low SNR, or hot or cold pixels. The RapidEye Basic product is the least processed of the available RapidEye imagery products. This product is designed for customers with advanced image processing capabilities and a desire to geometrically correct the product themselves. The products are available in GeoTIFF and NITF formats. The RapidEye Basic Scene product is radiometrically and sensor corrected, providing imagery as seen from the spacecraft without correction for any geometric distortions inherent in the imaging process, and is not mapped to a cartographic projection. The imagery data is accompanied by all spacecraft telemetry necessary for the processing of the data into a geo-corrected form, or when matched with a stereo pair, for the generation of digital elevation data. Resolution of the images is 6.5 meters GSD at nadir. The images are resampled to a coordinate system defined by an idealized basic camera model for band alignment. The radiometric corrections applied to this product are: Correction of relative differences of the radiometric response between detectors. Non-responsive detector filling which fills null values from detectors that are no longer responding. Conversion to absolute radiometric values based on calibration coefficients. The geometric sensor corrections applied to this product correct for: Internal detector geometry which combines the two sensor chipsets into a virtual array. Optical distortions caused by sensor optics. Registration of all bands together to ensure all bands line up with each other correctly. Product band order: Band 1 = Blue Band 2 = Green Band 3 = Red Band 4 = Red edge Band 5 = Near-infrared Item Properties Property Name Description Type _permissions Assets available for the item which the authenticated user has permission to download. array geometry Geographic boundary of the item's footprint, formatted as a GeoJSON polygon. json id Globally unique item identifier. string acquired Timestamp that the item was captured. datetime anomalous_pixels Percentage of pixels that may have errors. Represented spatially in the UDM. double black_fill The percentage of the item containing black fill. double catalog_id Base RapidEye Level 3A catalog id. string cloud_cover Average percentage of cloud coverage. double columns Number of columns in the image. integer gsd Ground sample distance - the distance between pixel centers as measured on the ground in meters. double item_type Name of the item type. string provider Name of the item provider (e.g. \"planetscope\", \"rapideye\"). string published Timestamp that the item was published to the Planet API. datetime rows Number of rows in the image. integer satellite_id Globally unique satellite identifier. string strip_id The unique identifier of the image stripe that the item came from. string sun_azimuth The angle of the sun, as seen by the observer, measured clockwise from the north (0 - 360). double sun_elevation The angle of the sun above the horizon (0 - 90). double updated Timestamp that the item record was last updated. datetime usable_data Percentage of pixels that are usable, subtracting cloud cover and black fill. double view_angle The satellite's across-track, off-nadir viewing angle. Positive numbers denote east, negative numbers denote west (-25 - +25). double Available Asset Types Asset Name Description basic_analytic_b1 Band 1 (blue) - Top of atmosphere radiance (at sensor) and sensor corrected GeoTiff product. Scene based framing and not projected to a cartographic projection. basic_analytic_b1_nitf Band 1 (blue) - Top of atmosphere radiance (at sensor) and sensor corrected NITF product. Scene based framing and not projected to a cartographic projection. basic_analytic_b2 Band 2 (green) - Top of atmosphere radiance (at sensor) and sensor corrected GeoTiff product. Scene based framing and not projected to a cartographic projection. basic_analytic_b2_nitf Band 2 (green) - Top of atmosphere radiance (at sensor) and sensor corrected NITF product. Scene based framing and not projected to a cartographic projection. basic_analytic_b3 Band 3 (red) - Top of atmosphere radiance (at sensor) and sensor corrected GeoTiff product. Scene based framing and not projected to a cartographic projection. basic_analytic_b3_nitf Band 3 (red) - Top of atmosphere radiance (at sensor) and sensor corrected NITF product. Scene based framing and not projected to a cartographic projection. basic_analytic_b4 Band 4 (red edge) - Top of atmosphere radiance (at sensor) and sensor corrected GeoTiff product. Scene based framing and not projected to a cartographic projection. basic_analytic_b4_nitf Band 4 (red edge) - Top of atmosphere radiance (at sensor) and sensor corrected NITF product. Scene based framing and not projected to a cartographic projection. basic_analytic_b5 Band 5 (near-infrared) - Top of atmosphere radiance (at sensor) and sensor corrected GeoTiff product. Scene based framing and not projected to a cartographic projection. basic_analytic_b5_nitf Band 5 (near-infrared) - Top of atmosphere radiance (at sensor) and sensor corrected NITF product. Scene based framing and not projected to a cartographic projection. basic_analytic_xml Analytic asset XML metadata file. basic_analytic_xml_nitf Basic analytic NITF XML metadata file. basic_analytic_sci RapidEye spacecraft XML metadata file. basic_analytic_rpc Rational Polynomial Coefficients text file used to orthorectify the basic_analytic asset. basic_udm Unusable Data Mask - Unusable data bit mask in GeoTIFF format for the basic analytic scene assets. browse Visual browse image for the asset.","tags":"data-api","url":"https://developers.planet.com/docs/data/rescene","loc":"https://developers.planet.com/docs/data/rescene"},{"title":"Sentinel2L1C","text":"Sentinel-2 standard terrain-corrected scenes in path/row framing. This data set includes imagery from Sentinel-2 satellites operated by ESA. Products Overview Sentinel-2 data is provided in jpeg2000 format. For detailed characteristics of the Sentinel-2 sensor and mission, refer to the official Sentinel-2 documentation . Attribution Sentinel-2 data is provided free of charge to users. For more information on access to this data, please see the Legal notice on the use of Copernicus Sentinel Data and Service Information. Item Properties Property Name Description Type _permissions Assets available for the item which the authenticated user has permission to download. array geometry Geographic boundary of the item's footprint, formatted as a GeoJSON polygon. json id Globally unique item identifier. string abs_orbit_number Absolute orbit number. integer acquired Timestamp that the item was captured. datetime anomalous_pixels Percentage of pixels that may have errors. Represented spatially in the UDM. double black_fill The percentage of the item containing black fill. double cloud_cover Average percentage of cloud coverage. double columns Number of columns in the image. integer data_type The processing level of the product. string datatake_id Unique identifier of the data take. string epsg_code Ortho tile grid cell that the item is located in (not used if Scene). integer granule_id Unique identifier of the granule PDI. string gsd Ground sample distance - the distance between pixel centers as measured on the ground in meters. double instrument Name of the satellite instrument used to collect the image. string item_type Name of the item type. string mgrs_grid_id The Military Grid Reference System (MGRS) ID. string origin_x ULX coordinate of the extent of the data. The coordinate references the top left corner of the top left pixel. double origin_y ULY coordinate of the extent of the data. The coordinate references the top left corner of the top left pixel. double pixel_resolution Pixel resolution of the imagery in meters. double product_generation_time Time it took to process the product. integer product_id Unique identifier of the product. string provider Name of the item provider (e.g. \"planetscope\", \"rapideye\"). string published Timestamp that the item was published to the Planet API. datetime quality_category Planet image quality metric: Standard or Test . To qualify for \"standard\" image quality an image must meet a variety of quality standards, for example: PAN motion blur less than 1.15 pixels, compression bits per pixel less than 3. If the image does not meet these criteria it is considered \"test\" quality. string rel_orbit_number Relative orbit number (within the cycle). integer rows Number of rows in the image. integer s2_processor_version Version of the s2 processor. string satellite_id Globally unique satellite identifier. string sun_azimuth The angle of the sun, as seen by the observer, measured clockwise from the north (0 - 360). double sun_elevation The angle of the sun above the horizon (0 - 90). double updated Timestamp that the item record was last updated. datetime usable_data Percentage of pixels that are usable, subtracting cloud cover and black fill. double view_angle The satellite's across-track, off-nadir viewing angle. Positive numbers denote east, negative numbers denote west (-25 - +25). double Available Asset Types Asset Name Description analytic_b1 Band 1 (caoastal/aerosol) - Radiometrically calibrated GeoTiff suitable for analytic applications. analytic_b2 Band 2 (blue) - Radiometrically calibrated GeoTiff suitable for analytic applications. analytic_b3 Band 3 (green) - Radiometrically calibrated GeoTiff suitable for analytic applications. analytic_b4 Band 4 (red) - Radiometrically calibrated GeoTiff suitable for analytic applications. analytic_b5 Band 5 (red-edge-1) - Radiometrically calibrated GeoTiff suitable for analytic applications. analytic_b6 Band 6 (red-edge-2) - Radiometrically calibrated GeoTiff suitable for analytic applications. analytic_b7 Band 7 (red-edge-3) - Radiometrically calibrated GeoTiff suitable for analytic applications. analytic_b8 Band 8 (near-infrared) - Radiometrically calibrated GeoTiff suitable for analytic applications. analytic_b8a Band 8a (narrow near-infrared) - Radiometrically calibrated GeoTiff suitable for analytic applications. analytic_b9 Band 9 (water vapor) - Radiometrically calibrated GeoTiff suitable for analytic applications. analytic_b10 Band 10 (cirrus) - Radiometrically calibrated GeoTiff suitable for analytic applications. analytic_b11 Band 11 (swir-1) - Radiometrically calibrated GeoTiff suitable for analytic applications. analytic_b12 Band 12 (swir-2) - Radiometrically calibrated GeoTiff suitable for analytic applications. metadata_aux Analytic asset metadata file. visual Color-corrected GeoTiff product for visual applications.","tags":"data-api","url":"https://developers.planet.com/docs/data/sentinel2l1c","loc":"https://developers.planet.com/docs/data/sentinel2l1c"},{"title":"SkySatCollect","text":"The SkySat Collect product is an orthorectified composite of SkySat scenes from a SkySat collection. Products Overview A typical SkySat collect ranges from approximately 50-70 SkySat scenes and contains 4 multispectral bands, as well as the panchromatic band. This product is sensor and geometrically corrected, and is projected to a cartographic map projection. The geometric correction uses fine Digital Elevation Models (DEMs) with a post spacing of between 30 and 90 meters. Ground Control Points (GCPs) are used in the creation of every image and the accuracy of the product will vary from region to region based on available GCPs. Item Properties Property Name Description Type _permissions Assets available for the item which the authenticated user has permission to download. array geometry Geographic boundary of the item's footprint, formatted as a GeoJSON polygon. json id Globally unique item identifier. string acquired Timestamp that the item was captured. datetime clear_confidence_percent percentage value: per-pixel algorithmic confidence in 'clear' classification int [0-100] clear_percent Percent of clear values in dataset. Clear values represents scene content areas (non-blackfilled) that are deemed to be not impacted by cloud, haze, shadow and/or snow. int [0-100] cloud_cover Average percentage of cloud coverage. double cloud_percent Percent of cloud values in dataset. Cloud values represent scene content areas (non-blackfilled) that contain opaque clouds which prevent reliable interpretation of the land cover content. int [0-100] ground_control_ratio Ratio of individual scenes that are successfully rectified. double gsd Ground sample distance - the distance between pixel centers as measured on the ground in meters. double heavy_haze_percent Percent of heavy haze values in dataset. Heavy haze values represent scene content areas (non-blackfilled) that contain thin low altitude clouds, higher altitude cirrus clouds, soot and dust which allow fair recognition of land cover features, but not having reliable interpretation of the radiometry or surface reflectance. int [0-100] item_type Name of the item type. string light_haze_percent Percent of light haze values in dataset. Light haze values represent scene content areas (non-blackfilled) that contain thin low altitude clouds, higher altitude cirrus clouds, soot and dust which allow reliable recognition of land cover features, and have up to +/-10% uncertainty on commonly used indices (EVI and NDWI). int [0-100] pixel_resolution Pixel resolution of the imagery in meters. double provider Name of the item provider (e.g. \"planetscope\", \"rapideye\"). string published Timestamp that the item was published to the Planet API. datetime publishing_stage Stage of publishing for an item. SkySatCollect items will be first published and remain in \"finalized\" stage. string quality_category Metric for image quality. To qualify for \"standard\" image quality an image must meet a variety of quality standards, for example: sun altitude greater than or equal to 10 degrees, off nadir view angle less than 20 degrees, and saturated pixels fewer than 20%. If the image does not meet these criteria it is considered \"test\" quality. string satellite_azimuth Angle from true north to the satellite vector at the time of imaging, averaged across the full SkySatCollect, projected on the horizontal plane in degrees (0 - 360). double satellite_id Globally unique satellite identifier. string shadow_percent Percent of shadow values in dataset. Shadow values represent scene content areas (non-blackfilled) that are not fully exposed to the solar illumination as a result of atmospheric transmission losses due to cloud, haze, soot and dust, and therefore do not allow for reliable interpretation of the radiometry or surface reflectance. int [0-100] snow_ice_percent Percent of snow and ice values in dataset. Snow_ice values represent scene content areas (non-blackfilled) that are hidden below snow and/or ice. int [0-100] strip_id The unique identifier of the image stripe that the item came from. string sun_azimuth The angle of the sun, as seen by the observer, measured clockwise from the north (0 - 360). double sun_elevation The angle of the sun above the horizon (0 - 90). double updated Timestamp that the item record was last updated. datetime view_angle The satellite's across-track, off-nadir viewing angle. Positive numbers denote east, negative numbers denote west (-25 - +25). double visible_confidence_percent Visible values represent the fraction of the scene content (excluding the portion of the image which contains blackfill) which is comprised of clear, light haze, shadow, snow/ice categories, and is given as a percentage ranging from zero to one hundred. int [0-100] visible_percent Average of confidence percent for clear_percent, light_haze_percent, shadow_percent and snow_ice_percent int [0-100] Available Asset Types Asset Name Description basic_l1a_all_frames Compressed folder with all basic l1a panchromatic frames and accompanying RPCs and pinhole json files that make up the collect. ortho_analytic Radiometrically calibrated GeoTiff suitable for analytic applications ortho_analytic_sr Orthorectified product, radiometrically calibrated and atmospherically corrected to surface reflectance ortho_analytic_dn Non-radiometrically calibrated GeoTiff suitable for analytic applications. ortho_analytic_udm Unusable Data Mask - Unusable data bit mask in GeoTIFF format for the analytic scene assets. ortho_analytic_udm2 Orthorectified usable data mask (Cloud 2.0) ortho_panchromatic Orthorectified Radiometrically-calibrated panchromatic image stored as 16-bit scaled radiance ortho_panchromatic_dn Basic sensor corrected panchromatic band GeoTiff. Scene based framing and not projected to a cartographic projection. ortho_panchromatic_udm Unusable Data Mask - Unusable data bit mask in GeoTIFF format for the pansharpened DN scene assets. ortho_panchromatic_udm2 Orthorectified usable data mask (Cloud 2.0) ortho_pansharpened Color corrected and pansharpened GeoTiff for visual applications. ortho_pansharpened_udm Unusable Data Mask - Unusable data bit mask in GeoTIFF format for the pansharpened scene assets. ortho_pansharpened_udm2 Orthorectified usable data mask (Cloud 2.0) ortho_visual Color corrected GeoTiff for visual applications.","tags":"data-api","url":"https://developers.planet.com/docs/data/skysatcollect","loc":"https://developers.planet.com/docs/data/skysatcollect"},{"title":"SkySatScene","text":"The SkySat ortho scene product is orthorectified and designed for a wide variety of applications that require imagery with an accurate geolocation and cartographic projection. It has been processed to remove distortions caused by terrain and can be used for cartographic purposes. Products Overview The SkySat Ortho Scene product includes Visual, Analytic, Panchromatic, and Pansharpened Multispectral imagery that is uncalibrated and in a raw digital number format. The Ortho Scene product is sensor and geometrically corrected, and is projected to a cartographic map projection. The geometric correction uses fine Digital Elevation Models (DEMs) with a post spacing of between 30 and 90 meters. Ground Control Points (GCPs) are used in the creation of every image and the accuracy of the product will vary from region to region based on available GCPs. Item Properties Property Name Description Type _permissions Assets available for the item which the authenticated user has permission to download. array geometry Geographic boundary of the item's footprint, formatted as a GeoJSON polygon. json id Globally unique item identifier. string acquired Timestamp that the item was captured. datetime camera_id Camera used for imaging. string clear_confidence_percent percentage value: per-pixel algorithmic confidence in 'clear' classification int [0-100] clear_percent Percent of clear values in dataset. Clear values represents scene content areas (non-blackfilled) that are deemed to be not impacted by cloud, haze, shadow and/or snow. int [0-100] cloud_cover Average percentage of cloud coverage. double cloud_percent Percent of cloud values in dataset. Cloud values represent scene content areas (non-blackfilled) that contain opaque clouds which prevent reliable interpretation of the land cover content. int [0-100] ground_control Positional accuracy of the item. If the item has uncertain positional accuracy, this value will be false. boolean gsd Ground sample distance - the distance between pixel centers as measured on the ground in meters. double heavy_haze_percent Percent of heavy haze values in dataset. Heavy haze values represent scene content areas (non-blackfilled) that contain thin low altitude clouds, higher altitude cirrus clouds, soot and dust which allow fair recognition of land cover features, but not having reliable interpretation of the radiometry or surface reflectance. int [0-100] item_type Name of the item type. string light_haze_percent Percent of light haze values in dataset. Light haze values represent scene content areas (non-blackfilled) that contain thin low altitude clouds, higher altitude cirrus clouds, soot and dust which allow reliable recognition of land cover features, and have up to +/-10% uncertainty on commonly used indices (EVI and NDWI). int [0-100] pixel_resolution Pixel resolution of the imagery in meters. double provider Name of the item provider (e.g. \"planetscope\", \"rapideye\"). string published Timestamp that the item was published to the Planet API. datetime publishing_stage Stage of publishing for an item. SkySatCollect items will be first published and remain in \"finalized\" stage. string quality_category Metric for image quality. To qualify for \"standard\" image quality an image must meet a variety of quality standards, for example: sun altitude greater than or equal to 10 degrees, off nadir view angle less than 20 degrees, and saturated pixels fewer than 20%. If the image does not meet these criteria it is considered \"test\" quality. string satellite_azimuth Angle from true north to the satellite vector at the time of imaging, averaged across the full SkySatCollect, projected on the horizontal plane in degrees (0 - 360). double satellite_id Globally unique satellite identifier. string shadow_percent Percent of shadow values in dataset. Shadow values represent scene content areas (non-blackfilled) that are not fully exposed to the solar illumination as a result of atmospheric transmission losses due to cloud, haze, soot and dust, and therefore do not allow for reliable interpretation of the radiometry or surface reflectance. int [0-100] snow_ice_percent Percent of snow and ice values in dataset. Snow_ice values represent scene content areas (non-blackfilled) that are hidden below snow and/or ice. int [0-100] strip_id The unique identifier of the image stripe that the item came from. string sun_azimuth The angle of the sun, as seen by the observer, measured clockwise from the north (0 - 360). double sun_elevation The angle of the sun above the horizon (0 - 90). double updated Timestamp that the item record was last updated. datetime view_angle The satellite's across-track, off-nadir viewing angle. Positive numbers denote east, negative numbers denote west (-25 - +25). double visible_confidence_percent Visible values represent the fraction of the scene content (excluding the portion of the image which contains blackfill) which is comprised of clear, light haze, shadow, snow/ice categories, and is given as a percentage ranging from zero to one hundred. int [0-100] visible_percent Average of confidence percent for clear_percent, light_haze_percent, shadow_percent and snow_ice_percent int [0-100] Available Asset Types Asset Name Description basic_analytic Top of atmosphere radiance (at sensor) and sensor corrected GeoTiff product. Scene based framing and not projected to a cartographic projection. basic_analytic_dn Basic sensor corrected scene GeoTiff product. Scene based framing and not projected to a cartographic projection. basic_analytic_dn_rpc Rational Polynomial Coefficients text file used to orthorectify basic_analytic_dn asset. basic_analytic_rpc Rational Polynomial Coefficients text file used to orthorectify the basic_analytic asset. basic_analytic_udm Usable Data Mask - Usable data bit mask in GeoTIFF format for basic analytic scene assets. basic_analytic_udm2 Usable Data Mask 2.0. Read more about this new asset here. basic_l1a_panchromatic_dn Basic, pre-super resolution, panchromatic GeoTiff product. basic_l1a_panchromatic_dn_rpc Rational Polynomial Coefficients text file used to orthorectify the basic_l1a_panchromatic asset. basic_panchromatic Unorthorectified Radiometrically-calibrated panchromatic image stored as 16-bit scaled radiance basic_panchromatic_dn Basic sensor corrected panchromatic band GeoTiff. Scene based framing and not projected to a cartographic projection. basic_panchromatic_dn_rpc Rational Polynomial Coefficients text file used to orthorectify basic_panchromatic_dn asset. basic_panchromatic_rpc Rational polynomial coefficient for unorthorectified panchromatic image stored as 12-bit digital numbers basic_panchromatic_udm2 Usable Data Mask 2.0. Read more about this new asset here. ortho_analytic Radiometrically calibrated GeoTiff suitable for analytic applications ortho_analytic_sr Orthorectified product, radiometrically calibrated and atmospherically corrected to surface reflectance ortho_analytic_dn Non-radiometrically calibrated GeoTiff suitable for analytic applications. ortho_analytic_udm Unusable Data Mask - Unusable data bit mask in GeoTIFF format for the analytic scene assets. ortho_analytic_udm2 Usable Data Mask 2.0. Read more about this new asset here. ortho_panchromatic Orthorectified Radiometrically-calibrated panchromatic image stored as 16-bit scaled radiance ortho_panchromatic_dn Basic sensor corrected panchromatic band GeoTiff. Scene based framing and not projected to a cartographic projection. ortho_panchromatic_udm Unusable Data Mask - Unusable data bit mask in GeoTIFF format for the pansharpened DN scene assets. ortho_panchromatic_udm2 Usable Data Mask 2.0. Read more about this new asset here. ortho_pansharpened Color corrected and pansharpened GeoTiff for visual applications. ortho_pansharpened_udm Unusable Data Mask - Unusable data bit mask in GeoTIFF format for the pansharpened scene assets. ortho_pansharpened_udm2 Usable Data Mask 2.0. Read more about this new asset here. ortho_visual Color corrected GeoTiff for visual applications.","tags":"data-api","url":"https://developers.planet.com/docs/data/skysatscene","loc":"https://developers.planet.com/docs/data/skysatscene"},{"title":"SkySatVideo","text":"The SkySat Video products include a video mpeg-4 file, with all captured frames used to produce the video as L1A panchromatic scenes. Products Overview Full motion videos are collected between 30 and 120 seconds by a single camera from any of the active SkySats. Videos are collected using only the Panchromatic half of the camera, hence all videos are PAN only. Videos are packaged and delivered with a video mpeg-4 file, plus all image frames with accompanying video metadata and a frame index file. Video Product Metadata Field Value Sample _permissions Assets available for the item which the authenticated user has permission to download. array geometry Geographic boundary of the item's footprint, formatted as a GeoJSON polygon. json id Globally unique item identifier. string acquired Timestamp that the item was captured. datetime camera_id Camera used for imaging. string item_type Name of the item type. string provider Name of the item provider (e.g. \"planetscope\", \"rapideye\"). string published Timestamp that the item was published to the Planet API. datetime publishing_stage Stage of publishing for an item. SkySatVideo items will be first published and remain in \"finalized\" stage. string quality_category Metric for image quality. To qualify for \"standard\" image quality an image must meet a variety of quality standards, for example: sun altitude greater than or equal to 10 degrees, off nadir view angle less than 20 degrees, and saturated pixels fewer than 20%. If the image does not meet these criteria it is considered \"test\" quality. string satellite_azimuth Angle from true north to the satellite vector at the time of imaging, averaged across the full SkySatCollect, projected on the horizontal plane in degrees (0 - 360). double satellite_id Globally unique satellite identifier. string strip_id The unique identifier of the image stripe that the item came from. string sun_azimuth The angle of the sun, as seen by the observer, measured clockwise from the north (0 - 360). double sun_elevation The angle of the sun above the horizon (0 - 90). double updated Timestamp that the item record was last updated. datetime view_angle The satellite's across-track, off-nadir viewing angle. Positive numbers denote east, negative numbers denote west (-25 - +25). double Available Asset Types Asset Name Description video_file Video mp4 file of all overlapping basic l1a panchromatic frames video_frames Compressed folder with all basic l1a panchromatic frames and accompanying RPCs that make up the video file video_metadata json document describing the composite location of the video capture, as well as time, elevation angle, and azimuth angle at the start and end of the collection","tags":"data-api","url":"https://developers.planet.com/docs/data/skysatvideo","loc":"https://developers.planet.com/docs/data/skysatvideo"},{"title":"Using Planet Tile Services in ArcGIS Online","text":"Planet basemaps are added to ArcGIS Online (AGOL) by using either of the following Planet tile service protocols: WMTS XYZ Complete details about each of these tile services is available in, Tile Services Overview . Note : For all Planet tile services, you must be authenticated for the specific requested resource. If you do not have the correct permissions, the tile request results in a 404 error. Authentication is achieved by providing a valid api_key as a query parameter in all tile requests. WMTS Tile Service Web Map Tile Service (WMTS) URL Structure: https://api.planet.com/basemaps/v1/mosaics/wmts?api_key={api-key} To add a WMTS layer to ArcGIS Online: Click Add , then select Add Layer from Web . From the dropdown, select WMTS OGC Web Service . Insert URL following the structure given above, then click Get Layers . Select the desired basemap from the dropdown and click Add Layer . XYZ Tile Service The XYZ Tile Service URL structure for mosaics and scenes: https://tiles{0-3}.planet.com/basemaps/v1/planet-tiles/{mosaic_name}/gmap/{level}/{col}/{row}.png?api_key={api-key} When accessing a mosaic by using the XYZ tile service, the URL includes the mosaic name. For example: https://tiles1.planet.com/basemaps/v1/planet-tiles/global_monthly_2019_12_mosaic/gmap/{level}/{col}/{row}.png?api_key={api-key} XYZ Service URL structure for individual Scenes: https://tiles{0-3}.planet.com/data/v1/{item_type}/{item_id}/{level}/{col}/{row}.png?api_key={api-key} In this case, the URL includes both the item type and the item ID of the desired scenes. To view multiple scenes, include a comma separated list of item IDs in the URL. For example: https://tiles1.planet.com/data/v1/PSScene3Band/20200516_171114_50_2271,20200516_171112_30_2271,20200516_171110_11_2271/{level}/{col}/{row}.png?api_key={api-key} To add an XYZ layer to ArcGIS Online: Click Add , then select Add Layer from Web . From the dropdown, select Tile Layer . Insert URL following the structure given above, then click Add Layer . Overzoom in ArcGIS To zoom past the limit set by ArcGIS Online maps, add a zmax=< numeric value > parameter in the tile services URL. The zmax value provides the ability to zoom past the native resolution of Basemaps. For example: https://api.planet.com/basemaps/v1/series/431b62a0-eaf9-45e7-acf1-d58278176d52/wmts?api_key=THEIR_KEY&zmax=3","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/using-planet-tile-services-in-arcgis-online/","loc":"https://developers.planet.com/docs/planetschool/using-planet-tile-services-in-arcgis-online/"},{"title":"API Mechanics","text":"Authentication The Planet API uses Basic HTTP Authentication and requires that you have a Planet API key. Currently, anyone can sign up for a free account on our main website . The free account gives you access to imagery from anywhere in the world at 3-5 m/px resolution. Once you're signed up, you can find your API key in your account settings . Authenticate by setting username to your API key. **Authentication Via Basic HTTP with Python import os # import os module to access enviornmental modules import requests os.environ['PL_API_KEY']='12345' # pass in your API key PLANET_API_KEY = os.getenv('PL_API_KEY') # Setup the API Key from the `PL_API_KEY` environment variable BASE_URL = \"https://api.planet.com/analytics/\" session = requests.Session() #setup a session session.auth = (PLANET_API_KEY, \"\") #authenticate session with user name and password, pass in an empty string for the password res = session.get(BASE_URL) #make a get request to the Data API print(res.status_code) # test response print(res.text) # print response body Authentication Via cURL curl -u {api-key}: https://api.planet.com/analytics/ Pagination The Planet Analytics API paginates responses to limit the results, making them easier to work with. The JSON response will contain 250 detections maximum by default. The first GET request will yield the first page along with links representing the location of the next page. Following the next link will return another page of results. To get more results we link the rel of next . For a more detailed guide on accessing and paginating through our analytic feeds check out this jupyter notebook . Rate Limiting To improve the experience for all of our users, Planet uses rate limiting to prevent overloading the system. If handled correctly, rate limiting errors can be a normal and useful part of working with the API. When a rate limit has been exceeded, the Planet API responds with an HTTP 429 response code. When this occurs, we recommend implementing retry with an exponential backoff . An exponential backoff means that you wait for exponentially longer intervals between each retry of a single failing request. The following rate limits are currently in place: Activation endpoint - 5 requests per second, per API key. Download endpoint - 5 requests per second, per API key. Compute operation endpoints - 5 requests per second, per API key. Other endpoints - 10 requests per second, per API key. Maximum Payload Size When sending a POST request to the Planet API, the server will accept a maximum payload size of 1 megabyte. Errors Whenever an error occurs, whether it be the fault of the user or an internal system, an error object will be returned. HTTP response codes of 4xx suggest a bad request. If you receive a 4xx response, we recommend reviewing the API reference docs for more context to help you troubleshoot. 5xx errors suggest a problem on Planet's end, so if you receive a 5xx error, please contact support .","tags":"analytics","url":"https://developers.planet.com/docs/analytics/api-mechanics/","loc":"https://developers.planet.com/docs/analytics/api-mechanics/"},{"title":"API Mechanics","text":"Authentication The Planet API uses Basic HTTP Authentication and requires that you have a Planet API key. Currently, anyone can sign up for a free account on our main website . The free account gives you access to imagery from anywhere in the world at 3-5 m/px resolution. Once you're signed up, you can find your API key in your account settings . Authenticate by setting username to your API key. **Authentication Via Basic HTTP with Python import os # import os module to access enviornmental modules import requests os.environ['PL_API_KEY']='12345' # pass in your API key PLANET_API_KEY = os.getenv('PL_API_KEY') # Setup the API Key from the `PL_API_KEY` environment variable BASE_URL = \"https://api.planet.com/tasking/v2/orders\" session = requests.Session() #setup a session session.auth = (PLANET_API_KEY, \"\") #authenticate session with user name and password, pass in an empty string for the password res = session.get(BASE_URL) #make a get request to the Data API print(res.status_code) # test response print(res.text) # print response body Authentication Via cURL curl -u {api-key}: https://api.planet.com/tasking/v2/orders Rate Limiting To improve the experience for all of our users, Planet uses rate limiting to prevent overloading the system. If handled correctly, rate limiting errors can be a normal and useful part of working with the API. When a rate limit has been exceeded, the Planet API responds with an HTTP 429 response code. When this occurs, we recommend implementing retry with an exponential backoff . An exponential backoff means that you wait for exponentially longer intervals between each retry of a single failing request. The following rate limits are currently in place: Activation endpoint - 5 requests per second, per API key. Download endpoint - 5 requests per second, per API key. Compute operation endpoints - 5 requests per second, per API key. Other endpoints - 10 requests per second, per API key. Maximum Payload Size When sending a POST request to the Planet API, the server will accept a maximum payload size of 1 megabyte. Errors Whenever an error occurs, whether it be the fault of the user or an internal system, an error object will be returned. HTTP response codes of 4xx suggest a bad request. If you receive a 4xx response, we recommend reviewing the API reference docs for more context to help you troubleshoot. 5xx errors suggest a problem on Planet's end, so if you receive a 5xx error, please contact support .","tags":"tasking","url":"https://developers.planet.com/docs/tasking/api-mechanics/","loc":"https://developers.planet.com/docs/tasking/api-mechanics/"},{"title":"API Responses","text":"Subscriptions Endpoint: api.planet.com/analytics/subscriptions/ Example: curl --header \"Authorization: api-key ${PL_API_KEY}\" https://api.planet.com/analytics/subscriptions/ The Subscriptions endpoint returns all of the Subscriptions that are enabled for a particular api_key. Each item within this response describes a specific Subscription including its spatial area of interest as well as its temporal start-time and end-time. The Subscription dictates over what time period and area a particular computer vision operation will be performed. Table 1: Subscriptions endpoint Metadata Field Description Sample created Timestamp when the subscription was created (in UTC) 2019-03-08T18:11:57.488Z description Description of the Subscription as entered by the Planet Analytics Admin Building Detection in New Cairo id UUID for the subscription f301b8c9-04e1-49f6-ab31-24a8c25edbd5 feedID UUID for the Feed 1ce86055-cad0-4960-bdf3-32763c17f19b startTime Starting time of the time window for the subscription 2019-01-01T00:00:00.000Z endTime End time of the time window for the subscription. If the subscription does not have an end time, this field will not be surfaced. 2019-01-31T00:00:00.000Z geometry Polygon coordinates to the spatial extent of the subscription {\"type\": \"Polygon\", \"coordinates\": [ [ [ 103.849296569824, 1.2513119542594 ], [ 103.880882263184, 1.2513119542594 ], [ 103.880882263184, 1.27293604010387 ], [ 103.849296569824, 1.27293604010387 ], [ 103.849296569824, 1.2513119542594 ] ] ] } links Links to the individual subscription that the item refers to, the resulting collection of analytic results from the subscription, the feed operation that is associated with the subscription and to the subscriptions endpoint \"rel\": \"self\" }, { \"href\": \"https://api.planet.com/analytics/collections/f301b8c9-04e1-49f6-ab31-24a8c25edbd5/items\", \"rel\": \"results\" }, { \"href\": \"https://api.planet.com/analytics/feeds/e2ee4fca-e998-46fc-abe4-2ccaa7b7d285\", \"rel\": \"feed\" }, { \"href\": \"https://api.planet.com/analytics/subscriptions\", \"rel\": \"subscriptions\" } ], title Title of the subscription as entered by the Planet Analytics Admin Demo_Subscription_Singapore updated Last update time to the results associated with a subscription 2019-04-10T04:40:20.261Z Feeds Endpoint: api.planet.com/analytics/feeds/ Example: curl --header \"Authorization: api-key ${PL_API_KEY}\" https://api.planet.com/analytics/feeds/ The Feeds endpoint returns all of the Feeds that are enabled for a particular api_key. Each item within this response describes a specific feed including the source of imagery on which the feed operates. The Feeds describe the particular computer vision operation that will be performed when applied to the source imagery. The table below contains descriptions of the properties of each collection of responses returned by the feeds endpoint. Table 2: Feeds endpoint Metadata Field Description Sample created Timestamp when the feed was created (in UTC) 2019-03-08T18:11:57.488Z description Description of the feed as entered by the Planet Analytics Admin Ship detections from rectified PlanetScope imagery id UUID for the feed f35f37ce-4ba9-4b0d-b7d7-b687834223c3 links Links to the individual feed and to the collection of feeds [ { \"href\": \"https://api.planet.com/analytics/feeds/f35f37ce-4ba9-4b0d-b7d7-b687834223c3\", \"rel\": \"self\" }, { \"href\": \"https://api.planet.com/analytics/feeds\", \"rel\": \"feeds\" } ] source Description of the source on which the respective feed operates. Includes source bundle, item type and query filter parameters { \"config\": { \"bundle\": \"visual\", \"query\": { \"filter\": { \"config\": [\"true\"], \"field_name\": \"ground_control\", \"type\": \"StringInFilter\" }, \"item_types\": [\"PSScene3Band\"] } }, \"type\": \"image\" } target Defines the type of output for the feed. For an object detection based feed, this would be a collection. For a segmentation based feed, this would be a mosaic with an associated series_id indicating the UUID of the resulting Planet mosaic Vector output: { \"type\": \"collection\" } Or for Raster output { \"config\": { \"series_id\": \"431b62a0-eaf9-45e7-acf1-d58278176d52\" }, \"type\": \"mosaic\" } title Title of the feed as entered by the Planet Analytics Admin Ship Detections updated Timestamp of the last update from the feed (in UTC) 2019-04-11T17:51:39.771Z Collections Endpoint: api.planet.com/analytics/collections/ Example: curl --header \"Authorization: api-key ${PL_API_KEY}\" https://api.planet.com/analytics/collections/ The Collections endpoint returns all of the results from different Subscriptions that are enabled for a particular api_key. Each result within the collection describes a result of running a particular feed over the spatial area of interest as well as its temporal start-time and end-time defined in the Subscription. Below is a description of the properties of each collection of results returned by the collections endpoint. Table 3: Collections endpoint Metadata Field Description Sample created Timestamp when the result was created (in UTC) 2019-03-08T18:11:57.488Z description Description of the Collection as entered by the Planet Analytics Admin Building Detection in New Cairo id UUID for the result 1ce86055-cad0-4960-bdf3-32763c17f19b title Title of the Collection as entered by the Planet Analytics Admin New Cairo Buildings links Links to the collections endpoint, to the specific collection of results this result belongs to and to all of the results generated within this collection of results [ { \"href\": \"https://api.planet.com/analytics/collections/0c400b73-17e9-43be-884a-c30851d79ca3\", \"rel\": \"self\" }, { \"href\": \"https://api.planet.com/analytics/collections/0c400b73-17e9-43be-884a-c30851d79ca3/items\", \"rel\": \"items\" }, { \"href\": \"https://api.planet.com/analytics/collections\", \"rel\": \"collections\" } ] Collections for Raster Results Endpoint: api.planet.com/analytics/collections/{collection ID}/items Example: curl --header \"Authorization: api-key ${PL_API_KEY}\" https://api.planet.com/analytics/collections/27c0df67-572d-4036-95d6-489decf36aa9/items Each result in a raster-based feature collection references a quad from the analytic feed over which an operation has been executed. The result references the target quad through the [links][target-quad] property. This link allows the user to download a two-band GEOTIFF corresponding to the quad. The first band contains the results of the analytic operations as a binary mask with a value of 0 indicating the absence of a detection and value of 255 indicating the presence of a detection for each pixel in the source quad. For example, a building detection feed would produce a value of 0 where it does not detect buildings and a value of 255 where it does detect buildings.The second band is the alpha channel passed through from the source mosaic quad with a value of 255 indicating valid pixels and a value of 0 indicating invalid pixels. Table 4: Raster-Based Results Metadata Field Description Sample created Timestamp when the result was created (in UTC) 2019-03-08T18:11:57.488Z geometry The spatial extent of the resulting quad's area. { \"type\": \"Polygon\", \"coordinates\": [ [ [ 103.849296569824, 1.2513119542594 ], [ 103.880882263184, 1.2513119542594 ], [ 103.880882263184, 1.27293604010387 ], [ 103.849296569824, 1.27293604010387 ], [ 103.849296569824, 1.2513119542594 ] ] ] } id Result identifier 50e7d65b-9ec6-4ec1-8f46-c80bcbfffb2b links: self Link for the result (self) { \"href\": \"https://api.planet.com/analytics/collections/2d28b64b-1561-4a6f-8294-1a85aac2e3f6/items/50e7d65b-9ec6-4ec1-8f46-c80bcbfffb2b\", \"rel\": \"self\" } Links: source-quad Link to the source quad which is the imagery used to generate the detection output \"rel\": \"source-quad\" } Links: target-quad Link to the target quad which is the analytic output file { \"href\": \"https://api.planet.com/analytics/collections/2d28b64b-1561-4a6f-8294-1a85aac2e3f6/items/50e7d65b-9ec6-4ec1-8f46-c80bcbfffb2b/resources/target-quad\", \"rel\": \"target-quad\" } observed Date-time at which the source imagery was captured. 2019-03-20T07:57:18.186039Z source_mosaic_name The source mosaic upon which derivation is made. This is the unique identifier that can be used to source the mosaic from the Planet Mosaics WMTS service. global_monthly_2018_07_mosaic source_quad_id Unique identifier of the original mosaic quad upon which the detection operation is executed, described as X-Y tile identifiers (More info on Page 16 of Planet Basemaps Product Specification) 434-1216 target_mosaic_name Unique name of mosaic for querying the Planet Mosaics WMTS service or Planet Mosaics API. sif-b8ee0ab1-4500-485d-80b1-a24d92ee4cd5-2018-07-01 target_quad_id Raster output of the detection, described in UUID format. 434-1216 Collections for Vector-Based Results - Scene Imagery - Object Detection Endpoint: api.planet.com/analytics/collections/{collection ID}/items Example: curl --header \"Authorization: api-key ${PL_API_KEY}\" https://api.planet.com/analytics/collections/886b4dbb-b878-4f6b-b000-0d96cbf71d4d/items Each Item in a vector-based feature collection references an instance of a detected object. The Analytics API provides the location coordinates of the object along with metadata associated with it. Table 5: Vector based model detections on scenes Metadata Field Description Sample created Time stamp when the item was created in UTC (check) 2019-03-27T14:14:52.896Z geometry The bounding box coordinates of the detection / result. { \"type\": \"Polygon\", \"coordinates\": [ [ [ 103.849296569824, 1.2513119542594 ], [ 103.880882263184, 1.2513119542594 ], [ 103.880882263184, 1.27293604010387 ], [ 103.849296569824, 1.27293604010387 ], [ 103.849296569824, 1.2513119542594 ] ] ] } id Item identifier df7d8723-996a-4085-a714-e145a56ac5d9 link: Self Link to the item in the feature collection https://api.planet.com/analytics/collections/886b4dbb-b878-4f6b-b000-0d96cbf71d4d/items/df7d8723-996a-4085-a714-e145a56ac5d9 link: source-image-info Link to the source image metadata in which the item was detected https:/api.planet.com/analytics/collections/886b4dbb-b878-4f6b-b000-0d96cbf71d4d/items/df7d8723-996a-4085-a714-e145a56ac5d9/resources/source-image-info model_id Unique identifier of the computer vision model used to create this item 01D3FJCDHEZ1JS56150B7YR8VT model_version Time stamp indicating the version of to the computer vision model used to create this item 2019-03-29T21:01:06Z object_area_m2 The area of item's physical footprint, described in square meters. 21899.365647766444 object_diagonal_m Diagonal length of the item's physical footprint, described in meters 216.4834894839776 object_length Length of item's physical footprint, described in meters 178.2395839691162 object_width Width of the item's physical footprint, described in meters 122.86477088928223 source_item_id Unique ID of the source asset that the item was derived from, described as string. 20190320_075718_0f35 source_asset_type Type of asset derived from the source item, described as analytic or visual. visual source_item_type The class of spacecraft and/or processing level of an item upon which derivation is made. PSScene3Band observed Date-time at which the source imagery was captured. 2019-03-20T07:57:18.186039Z score Confidence of detection resulting in the item in the range [0.0, 1.0] with a value of 1.0 indicating full confidence 0.9995234 source_cloud_cover Average percentage of cloud cover in the source asset from which the object was detected 0.1 xmax_px location of the detection along the horizontal axes in pixel coordinates 2076 xmin_px location of the detection along the horizontal axes in pixel coordinates 2020 ymax_px location of the detection along the vertical axes in pixel coordinates 3047 ymin_px location of the detection along the vertical axes in pixel coordinates 2969 Collections for Vector-Based Results - Mosaic Imagery - Change Detection Endpoint: api.planet.com/analytics/collections/{collection ID}/items Example: curl --header \"Authorization: api-key ${PL_API_KEY}\" https://api.planet.com/analytics/collections/acd47acd-1301-4baf-8315-5a745824ae09/items Each Item in a vector-based feature collection for roads & building change references an instance of a newly constructed building or road. The Analytics API provides the location coordinates of an aggregation of 8x8 pixel grid cells containing the object (or \"change cells\", along with metadata associated with it. Each result references a quad from the analytic feed over which an operation has been executed, specifically the most recent mosaic after which the change has occurred. The result references the source quad through the [links][source-quad] property. Table 6: Vector based model detections on mosaics Metadata Field Description Sample created Timestamp when the result was created (in UTC) 2020-04-08T18:11:57.488Z geometry The coordinates of the aggregation of 8x8 pixel grid cells containing the change { \"type\": \"Polygon\", \"coordinates\": [ [ [ 103.849296569824, 1.2513119542594 ], [ 103.880882263184, 1.2513119542594 ], [ 103.880882263184, 1.27293604010387 ], [ 103.849296569824, 1.27293604010387 ], [ 103.849296569824, 1.2513119542594 ] ] ] } id Result identifier acd47acd-1301-4baf-8315-5a745824ae09 links: self Link for the result (self) { \"href\": \"https://api.planet.com/analytics/collections/acd47acd-1301-4baf-8315-5a745824ae09/items/acd47acd-1301-4baf-8315-5a745824ae09\", \"rel\": \"self\" } links: source-quad Link to the source quad which is the imagery used to generate the detection output { \"href\": \"https://api.planet.com/analytics/collections/acd47acd-1301-4baf-8315-5a745824ae09/items/acd47acd-1301-4baf-8315-5a745824ae09/resources/source-quad\", \"rel\": \"source-quad\" } date_after Date of the most recent time period, corresponding to date at which the change was detected \"2020-03-01 00:00:00 +0000 UTC\" date_before Estimated date of time period before the change event. This is fixed to 2 months prior to date_after. The true change event may be earlier in some cases \"2019-11-01T00:00:00Z\" object_area_m2 The area of the item's physical footprint, described in square meters. The area is smaller than the area of the change cell 458.7873390337813 observed Date-time at which the source imagery (source_mosaic_after) was captured. For Change Detection it corresponds to the same date as date_after (legacy) \"2020-03-01T00:00:00Z\" source_mosaic_after Mosaic name (not the series name) for the most recent source imagery upon which derivation is made. This is the unique identifier that can be used to source the mosaic from the Planet Mosaics WMTS service global_monthly_2020_03_mosaic source_mosaic_before Mosaic name (not the series name) for the source imagery two time periods prior from the most recent mosaic upon which derivation is made. This is the unique identifier that can be used to source the mosaic from the Planet Mosaics WMTS service global_monthly_2019_11_mosaic source_quad_id X-Y identifier of the image quad in the mosaic grid (More info on Page 16 of Planet Basemaps Product Specification). For Change Detection, it corresponds to the source_mosaic_after quad \"1848-793\"","tags":"analytics","url":"https://developers.planet.com/docs/analytics/apiresponse","loc":"https://developers.planet.com/docs/analytics/apiresponse"},{"title":"Data Overview","text":"Planet's Data API is a RESTful API interface to Planet's complete imagery catalog. It enables programmatic support for searching all Planet imagery by metadata. How To Become A Planet Developer As with all Planet APIs, using the Data API requires that you have a Planet API key: if you don't already have a Planet account, you can sign up for Planet's Developer Program . Once you're signed up, you can find your API key in your account settings . For more information, check out our quickstart guide for API users. Learn More When you're ready to dive deeper into using Planet's Data API, you'll find a collection of guides and tutorials on Planet School . You may be interested in this Python tutorial: Getting Started with Data API Search & Download . Citing Planet Data From a concept in our garage, to operating the largest fleet of Earth-imaging satellites, many people have invested time and energy in developing and enabling access to Planet's unique data feed. Please cite Planet when using our imagery and tools. To cite Planet data in publications, please include the following copyright notice: \"Image © 20xx Planet Labs PBC\" (where xx denotes the year of the content used) @Misc{, author = {Planet Labs PBC}, organization = {Planet}, title = {Planet Application Program Interface: In Space for Life on Earth}, year = {2018--}, url = \"https://api.planet.com\" }","tags":"data-api","url":"https://developers.planet.com/docs/apis/data/","loc":"https://developers.planet.com/docs/apis/data/"},{"title":"Getting Started with Planet APIs","text":"API Access To use any Planet API, you'll need an API key. API keys are available to all registered users with active Planet accounts. Find your API Key Once you're signed up, log in to your account at planet.com/account to get your API key. Find the API key field under your account information, as seen here: Account Profile page: click \"API key\" to copy your API key to the clipboard Planet's API Ecosystem Planet's platform is made up of a collection of APIs. These include: Data API - allows you to search Planet's complete catalog of data Orders API - raster tools for creating analysis-ready data with Planet's imagery archive Subscriptions API - allows you to subscribe to continuous cloud delivery of imagery and metadata collections Analytics API - gives you access to derived analytic products like Planet Analytic Feeds Basemaps API - give you access to Planet's mosaiced basemap services Tile Services - XYZ and WMTS tile map services for use in your favorite GIS or mapping client Tasking API - API for creating and managing your SkySat point collection orders Reports API - API which systematically reports download usage for internal processing and analysis You can read more about each API and find complete docs and API reference guides here . Accessing the Planet catalog With the Data API , you can download individual scenes, one at a time. You can also do a quick search or a saved search and filter those results, get stats on those images and preview them as thumbnails. When you're ready to go beyond searching and downloading an individual scene, use the Orders API to order bundles of assets for download, send bundles to your cloud account, and manipulate results with tools to prepare them for analysis before downloading. Finally, when you want to connect your catalog sources to a data processing pipeline, use the Subscriptions API to monitor for change and run tools on new data when it is available. Quickstart: Search & Download Imagery If you're new to Planet's APIs and just want to search for and download an image, then start with the Data API . A Python-based Jupyter Notebook is available here if you'd like to interactively try out searching & downloading with the Data API (recommended). Otherwise, if you prefer to do it from scratch, keep reading for a step-by-step walk through of the entire process. Conducting an image search Related: \"Searching for Imagery with Data API\" on Planet School Searching for imagery in an Area of Interest while specifying our desired Item and Asset types Define an Area of Interest (AOI) and save it as a GeoJSON file Create search filters to specify the type of data you want to see Use the Data API to conduct a 'quick search' of the Planet catalog Extract the item ID of the image you would like to download from the quick search response body Use that Item ID to list available assets for this item (more details on Items & Assets can be found in the docs) Activating & downloading the image Related: \"Downloading Imagery withData API\" on Planet School The Data API does not pre-generate assets, so they are not always immediately availiable to download. In order to download an asset, we first have to activate it. Once an asset has been activated, a temporary download link will become available. Call the \"activate\" link for your desired asset to begin the activation process Poll the \"_self\" link for the asset to check the status value: an asset will change from inactive to active when it's ready for download. The payload of the \"_self\" link you used above will now include a location value: make a GET request against that URL to begin downloading the image Data API Alternatives Want a simpler download process with more delivery options ? How about applying raster processing to your data. Meet Orders . Want continuous cloud delivery with a single API Call ? Meet Subscriptions .","tags":"quickstart","url":"https://developers.planet.com/quickstart/apis","loc":"https://developers.planet.com/quickstart/apis"},{"title":"ArcGIS One Minute to Integrations","text":"Get started with common tasks using Planet GIS integrations with the following series of videos. To learn more about Planet ArcGIS Pro, QGIS, and Google Earth Engine integrations, visit this page . ArcGIS ArcGIS Pro: Search & Preview Planet Imagery ArcGIS Pro: Stream & Download Planet Basemaps (NICFI) ArcGIS Pro: Identify Source Scene in Planet Basemap ArcGIS Pro: Define AOI for High-Res Tasking","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/arcgis-one-minute-to-integrations/","loc":"https://developers.planet.com/docs/planetschool/arcgis-one-minute-to-integrations/"},{"title":"Analyzing a Flood Event in ArcGIS Pro","text":"To follow along with this guide, check out the complete tutorial here .","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/analyzing-a-flood-event-in-arcgis-pro/","loc":"https://developers.planet.com/docs/planetschool/analyzing-a-flood-event-in-arcgis-pro/"},{"title":"Beginners ArcGIS Pro Workflow","text":"Introduction This tutorial will cover basic raster operations in ArcGIS Pro. In this workflow you will: Mosaic two basemap quads Clip the mosaic to a polygon feature class Create an NDVI raster Before you start You will need ESRI ArcGIS Pro or ArcMap to perform the raster operations demonstrated in this tutorial. Additionally, you'll need at least an ArcGIS Pro Basic lisence to use the necessary tools. More information on ESRI license requirements can be found here . You will also need to have previously downloaded at least two basemap quads from Planet. Information on downloading basemap quads from Planet's Basemaps Viewer web application can be found here . Finally, you will also need a polygon feature class that will be used to clip the mosaic you create. While this is a simple tutorial, it is recommended that you have basic familiarity with GIS concepts. 1. Mosaic Basemap Quads After downloading the two basemaps quads and creating a new project in ArcGIS Pro, click the Add Data button on the Map ribbon to add the basemap quads and clip feature class to your project. Next, navigate to the Analysis ribbon and go to Raster Functions . ESRI has extensive documentation on the Raster Functions toolset if you are interested in learning more. Under Data Management click Mosaic Rasters to open the tool dialog box. Alternatively, you can find the tool using the search bar atop the raster Raster Functions pane. With the Mosaic Rasters tool dialog open, select your basemap quads for the Raster parameter. Under Operation , select Max . To learn more about any tool in ArcGIS Pro, click the question mark in the upper right-hand corner of the tool dialog. After clicking Create new layer at the bottom of the tool dialog box, your new mosaic image will appear in the map view. 2. Clip Mosaic Next, you will clip your newly created mosaic to the polygon feature class. From the Raster Functions pane select the Clip tool that is also located under Data Management . In the following tool dialog box, select the mosaic for the Raster parameter, a Clipping Type of \"Outside\" (this will remove pixels outside of the polygon clip feature class), and select the polygon feature class for the Clipping Geometry parameter. Be sure to check the box next to Use input features for clipping geometry , which will insure that the mosaic is clipped to the input feature class. After clicking Create new layer at the bottom of the tool dialog box, your newly clipped mosaic will appear in the Map view. Nice work! You have successfully mosaiced two basemap quads and clipped the mosaic. 3. Create NDVI Raster Finally, you will calculate NDVI (Normalized Difference Vegetation Index) and create a new raster with these values. I. NDVI Overview NDVI, developed by a NASA scientist named Compton Tucker in 1977, is commonly used to assess whether an area contains live green vegetation or not. It can show the difference between water and plants, bare soil and grass, whether plants are under stress, and what lifecycle stage a crop is in. It compares how much more near-infrared light is reflected by chlorophyll vs visible red light and is given as the following equation: II. Calculating NDVI in ArcGIS Pro There are a number of ways to calculate NDVI in ArcGIS Pro. In this tutorial, you'll be utilizing the native NDVI tool which is located in the Raster Functions pane. In the following tool dialog box, select the clipped image for the Raster parameter. Under Visible Band ID , select 3 . Under Infrared Band ID , select 4 For this basemap, band 3 is the red band, and band 4 is the near-infrared band. Optionally, check the box next to Scientific Output , which will produce NDVI values between -1 and 1. After clicking Create new layer at the bottom of the tool dialog box, your new NDVI raster will appear in the Map view. You may wish to adjust the symbology of the raster. Nice work! You have successfully created an NDVI raster from the clipped mosaic!","tags":"nicfi","url":"https://developers.planet.com/docs/nicfi/beginners-arcgis-pro-workflow/","loc":"https://developers.planet.com/docs/nicfi/beginners-arcgis-pro-workflow/"},{"title":"Area order creation","text":"The Planet Tasking API is a REST based API, which can be integrated into any service, regardless of the language used. Below are some examples of how to integrate the most commonly used aspects of the Tasking API Stereo orders creation, editing and cancellation. The creation, editing and deletion of Area orders follows the same rules as normal orders except, of course, for the geometry. Area Geometry The creation of an Area order requires a GeoJSON object with a given type of \"Polygon\" and an array of coordinates representing the polygon that will comprise the area that you want to be captured, e.g. Polygon { \"type\": \"Polygon\", \"coordinates\": [ [ [ //some coordinates ], [ //some coordinates ], [ //some coordinates ] ] ] } The area, measured in KM 2 , of the provided polygon should be less than your maximum allowed KM 2 for a single Tasking Order. For assistance in the creation and validation of GeoJSON polygons you can find many resources on the internet, for example https://geojson.io/. Area order creation As mentioned, the difference between an area order and a point order is the GeoJSON object that defines the AOI (area of interest) of the order as shown below: curl --request POST --url 'https://api.planet.com/tasking/v2/orders/' \\ --header 'accept: application/json' \\ --header 'authorization: api-key <YOUR_API_KEY>' \\ --header 'content-type: application/json' \\ --data '{ 'name': 'Area Order 01', 'geometry': { 'type': 'Polygon', 'coordinates': [ [ [ -111.02062225341797, 39.58637603706183 ], [ -110.9095573425293, 39.58637603706183 ], [ -110.9095573425293, 39.670992062375056 ], [ -111.02062225341797, 39.670992062375056 ], [ -111.02062225341797, 39.58637603706183 ] ] ] } } The response is much the same as a standard Order request .","tags":"tasking","url":"https://developers.planet.com/docs/tasking/examples/area","loc":"https://developers.planet.com/docs/tasking/examples/area"},{"title":"Assured Tasking Order creation","text":"The Planet Tasking API is a REST based API, which can be integrated into any service, regardless of the language used. Assured Tasking Orders are one of the varieties of Tasking Orders that can be created via the Tasking API. The creation of an Assured Tasking Order follows the same rules as normal orders , but with a couple of extra steps along the way. Request imaging windows Assured Tasking allows the creation of a Tasking Order that is \"assured\" to take place at a given time and date of a satellite passing over the provided geo-coordinate. To do this, we first query the Tasking API to retrieve the available imaging windows that will satisfy the provided geo-coordinates and timeframe. This is done by calling the tasking/v2/imaging-windows/ endpoint of the Tasking API: curl --request POST \\ --url https://api.planet.com/tasking/v2/imaging-windows/ \\ --header 'authorization: api-key <YOUR_API_KEY>' \\ --header 'content-type: application/json' \\ --data '{ \"start_time\": \"2020-07-24T00:52Z\", \"end_time\": \"2020-07-26T00:52Z\", \"geometry\": { \"coordinates\": [ 61.874999999998835, 48.69096039092497 ], \"type\": \"Point\" }, \"pl_number\": \"<PL-YourPlanetNumber>\", \"product\": \"Assured Tasking\", \"satellite_elevation_angle_min\": 60, \"satellite_elevation_angle_max\": 90 }' The required fields for requesting the available imaging windows are: geometry : a GeoJSON object pl_number : your Planet Number, which begins with PL product : here, the product is Assured Tasking The request also includes the optional satellite_elevation_angle_min and satellite_elevation_angle_max fields, in this case set to 60° and 90° , respectively. These angles define the desired orientation of the satellite when it takes the image. Note that the more restrictive the angle, the lower the likelihood that the Tasking Order succeeds. The response body is empty, instead we have to look into the response headers for the location field, which contains a url path with a search_id that we then use in a GET request to the same endpoint: curl --request GET \\ --url 'https://api.planet.com/tasking/v2/imaging-windows/?search_id=<SEARCH_ID>' \\ --header 'authorization: api-key <YOUR_API_KEY>' \\ --header 'content-type: application/json' This request returns an array of available imaging windows: { \"count\": 2, \"next\": null, \"previous\": null, \"results\": [ { \"id\": \"b964e2a8-0a8b-4a83-a05d-8ac025c0f799\", \"assured_tasking_tier\": \"STANDARD\", \"geometry\": { \"geojson\": { \"type\": \"Point\", \"coordinates\": [ 61.874999999998835, 48.69096039092497 ] }, \"geometry\": { \"type\": \"Point\", \"coordinates\": [ 61.875, 48.69096 ] } }, \"start_time\": \"2020-07-24T06:48:56.333000Z\", \"end_time\": \"2020-07-24T06:50:03.528000Z\", \"start_off_nadir\": 31.22424, \"end_off_nadir\": 31.23145, \"created_time\": \"2020-07-23T15:41:06.820966Z\" }, { \"id\": \"6891485e-3c9a-475b-8504-081d086b5fcd\", \"assured_tasking_tier\": \"STANDARD\", \"geometry\": { \"geojson\": { \"type\": \"Point\", \"coordinates\": [ 61.874999999998835, 48.69096039092497 ] }, \"geometry\": { \"type\": \"Point\", \"coordinates\": [ 61.875, 48.69096 ] } }, \"start_time\": \"2020-07-24T06:27:33.841000Z\", \"end_time\": \"2020-07-24T06:28:41.827000Z\", \"start_off_nadir\": 31.22825, \"end_off_nadir\": 31.22892, \"created_time\": \"2020-05-23T15:41:06.828251Z\" } ] } Creating an Assured Tasking Order Each of these windows represents a time period that a satellite will be passing over the provided geo-coordinates. Taking one of these windows, we can then create an Assured Tasking Order that includes the id of the selected window. NOTE The geo-coordinates provided to the tasking/v2/imaging-windows/ request MUST also be used in the creation of the Order, otherwise the order is rejected. No start_time or end_time should be provided, as these are taken from the selected imaging window. curl --request POST --url 'https://api.planet.com/tasking/v2/orders/' \\ --header 'accept: application/json' \\ --header 'authorization: api-key <YOUR_API_KEY>' \\ --header 'content-type: application/json' \\ --data '{ 'name': 'Assured Tasking Order 01', 'geometry': { 'type': 'Point', 'coordinates': [ 61.874999999998835, 48.69096039092497 ] }, 'imaging_window': '6891485e-3c9a-475b-8504-081d086b5fcd' }","tags":"tasking","url":"https://developers.planet.com/docs/tasking/examples/assured","loc":"https://developers.planet.com/docs/tasking/examples/assured"},{"title":"Band math supported numpy math routines","text":"The bandmath raster processing tool supports the following subset of mathematical functions of the Python numpy package: add log can_cast subtract log10 promote_types multiply sinh dtype divide cosh logical_and maximum tanh logical_or minimum fft logical_not sin ifft logical_xor cos fft2 greater_equal tan ifft2 less_equal arcsin fftn equal arccos ifftn not_equal arctan bitwise_and array_equal prod bitwise_or histogram sum bitwise_xor histogram2d abs invert histogramdd sqrt left_shift where exp right_shift nan_to_num","tags":"orders","url":"https://developers.planet.com/apis/orders/bandmath-numpy-routines/","loc":"https://developers.planet.com/apis/orders/bandmath-numpy-routines/"},{"title":"NICFI Basemaps in Google Earth Engine","text":"Overview The Planet and NICFI Basemaps for Tropical Forest Monitoring Google Earth Engine (GEE) Integration hosts NICFI Basemaps in GEE. You can access NICFI Basemaps in GEE the same way as other GEE datasets. Access NICFI Basemaps in Google Earth Engine To access the NICFI Basemaps in GEE: Sign up and accept the terms at, NICFI Satellite Data Program . When you have created and logged in to a NICFI Planet account, access Basemaps in GEE by navigating to Account Settings . In the Access NICFI Data in Google Earth Engine section, click Add to Earth Engine . In the EE Image Collection dialog, enter the email associated with your GEE account. Note : The email associated with your GEE account might differ from the email used for your Planet account. The three EE Image Collections are: Tropical Africa Tropical Asia Tropical Americas Note : Each user is only permitted to register one email to the NICFI program. If you edit your account (email, collections, and so on) GEE access might be revoked from the previously registered email. Get started with NICFI Basemaps in GEE .","tags":"integrations-gee","url":"https://developers.planet.com/docs/integrations/gee/nicfi/","loc":"https://developers.planet.com/docs/integrations/gee/nicfi/"},{"title":"Creating a Mosaic in Python","text":"Creating a composite image from multiple PlanetScope scenes In this guide, you'll learn how to create a composite image (or mosaic) from multiple PlanetScope scenes that cover an area of interest (AOI). You'll need GDAL (Geospatial Data Abstraction Library) and its python bindings installed to run the commands below. First, let's use Planet Explorer to travel to stunning Yosemite National Park. You can see below that I've drawn an area of interest around Mount Dana on the eastern border of Yosemite. I want an image that depicts the mountain on a clear summer day, so I've narrowed my data search in Planet Explorer to scenes with less than 5% cloud cover, captured in July and August 2016. As you can see in the animated gif above, my search yielded a set of three PlanetScope scenes, all taken on August 20, 2016. Together these scenes cover 100% of my area of interest. As I roll over each item in Planet Explorer, I can see that the scenes' rectangular footprints extend far beyond Mount Dana. All three scenes overlap slightly, and one scene touches only a small section at the bottom of my AOI. Still, they look good to me, so I'm going to submit an order for the visual assets. After downloading, moving, and wrangling the data, I'm ready to create a composite image from the three scenes. First, though, I'll use gdalinfo to inspect the spatial metadata of the scenes. In [ ]: ! gdalinfo data/175322.tif ! gdalinfo data/175323.tif ! gdalinfo data/175325.tif The three scenes have the same coordinate systems and the same number of bands, so we can go ahead and use the gdal_merge.py utility to stitch them together. In areas of overlap, the utility will copy over parts of the previous image in the list of input files with data from the next image. The -v flag in the command below allows us to see the output of the mosaicing operations as they are done. In [ ]: ! gdal_merge.py -v data/175322.tif data/175323.tif data/175325.tif -o output/mtdana-merged.tif We can see in the verbose output above that the mosaicing operation is fairly simple: the utility script is basically copying a range of pixels for each band in each scene over to the designated output file. We can use gdalinfo to inspect the metadata of the merged raster file we created. In [ ]: ! gdalinfo output/mtdana-merged.tif The merged raster is a large GeoTiff file, so we're going use gdal_translate , another GDAL utility, to convert it to a PNG and set the output image to a percentage of the original. That will make it easier for us to view in this notebook. In [ ]: ! gdal_translate -of \"PNG\" -outsize 10 % 0 % output/mtdana-merged.tif output/mtdana-merged.png Now let's view the merged image. In [1]: from IPython.display import Image Image ( filename = \"output/mtdana-merged.png\" ) Out[1]: Success! Wait... this is definitely a composite image from our three PlanetScope scenes, but it's not really what we want. We'd much rather have a composite image that is cropped to the boundaries of our AOI. We can use gdalwarp to clip the raster to our area of interest (defined by a geojson file). In [ ]: ! gdalwarp -of GTiff -cutline data/mt-dana-small.geojson -crop_to_cutline output/mtdana-merged.tif output/mtdana-cropped.tif Again, we'll use gdal_translate to convert the GeoTiff to a smaller PNG so that it's easier to view the cropped image. In [ ]: ! gdal_translate -of \"PNG\" -outsize 10 % 0 % output/mtdana-cropped.tif output/mtdana-cropped.png In [1]: from IPython.display import Image Image ( filename = \"output/mtdana-cropped.png\" ) Out[1]: Success! A cropped, composite image of Mount Dana in Yosemite! Who wants to go for a hike?","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/creating-a-mosaic-in-python/","loc":"https://developers.planet.com/docs/planetschool/creating-a-mosaic-in-python/"},{"title":"How to Try Beta Features","text":"In the bottom left hand corner, click on the Settings icon, which will open up a modal on the left hand side with Preferences and Labs. When you click Labs, you will see a list of different experimental features that are provisionally available in Planet Explorer. Feedback in these tools is welcome. To turn one of these beta features (Labs) on, click on the toggle button. When the toggle button is switched to on , the button is teal, and when switched to off the button turns white. You can toggle these Labs on and off anytime you like.","tags":"apps-explorer","url":"https://developers.planet.com/docs/apps/explorer/beta-features/","loc":"https://developers.planet.com/docs/apps/explorer/beta-features/"},{"title":"Bulk POST and GET examples","text":"The Planet Tasking API is a REST based API, which can be integrated into any service, regardless of the language used. Below are some examples of how to integrate the most commonly used aspects of the Tasking API Bulk endpoint. Bulk Statuses Before going into the various aspects of Bulk creation, editing and cancellation, we will first look at the different statuses that can be attributed to a bulk operation. A bulk operation can have one of the following statuses: PENDING : The bulk request has been received but work has yet to start on processing the payload. RUNNING : Work has starting on processing the payload. COMPLETE : The processing of the payload has finished. Bulk Create POSTing to the bulk endpoint allows up to 1000 Tasking Orders to be created in a single, asynchronous, request. When putting together the bulk tasking order request you can optionally specify your own bulk tasking order ID beforehand, but it must be a UUID string otherwise it will be rejected. If no UUID is provided, one will be generated and returned as part of the response header location field (see below) This example also only creates point orders, but any order type can be created via a bulk request. curl --request POST --url 'https://api.planet.com/tasking/v2/bulk/' \\ --header 'accept: application/json' \\ --header 'authorization: api-key <YOUR_API_KEY>' \\ --header 'content-type: application/json' \\ --data '{ \"id\": \"example_uuid_string\", \"order_payloads\": [ { \"name\": \"Bulk order 1\", \"geometry\": { \"type\": \"Point\", \"coordinates\": [32.142035, -0.487188] } }, { \"name\": \"Bulk order 2\", \"geometry\": { \"type\": \"Point\", \"coordinates\": [52.142035, 13.487188] } }, { \"name\": \"Bulk order 3\", \"geometry\": { \"type\": \"Point\", \"coordinates\": [181, 40] } } ] }' There is no payload as part the response when the request is successful, and the response code is a 202 , which denotes an asynchronous response. Included in the headers of the response is a location field which contains the URL that can be used for requesting the status of bulk order which is a GET request to the same endpoint, but this time appending the UUID that is used to identify the original bulk POST request to the URL: curl --request GET --url 'https://api.planet.com/tasking/v2/bulk/example_uuid_string' \\ --header 'accept: application/json' \\ --header 'authorization: api-key <YOUR_API_KEY>' \\ This time the response, when successful, will return with a response code of 200 and a JSON payload that will look similar to the following: { \"id\": \"example_uuid_string\", \"start_time\": \"2020-03-20T13:27:28.501032Z\", \"end_time\": \"2020-03-20T13:27:30.317499Z\", \"operation_type\": \"CREATE\", \"payload_count\": 3, \"status\": \"COMPLETE\", \"processing_payload_count\": 0, \"failed_payload_count\": 1, \"successful_payload_count\": 2 } Note the operation_type is set to CREATE and that the status is COMPLETE . In this example the two tasking orders that comprised the original bulk tasking order POST request were successfully ingested, so there is no need to go further. However, if there are any tasking orders that are still in processing or maybe even failed for some reason then a more detailed response can be requested, using the same URL as the previous GET request but with /payloads appended to the URL: curl --request GET --url 'https://api.planet.com/tasking/v2/bulk/example_uuid_string/payloads' \\ --header 'accept: application/json' \\ --header 'authorization: api-key <YOUR_API_KEY>' This will return a list of all the payloads in the original bulk POST, with the extra provided detail: { \"count\": 3, \"next\": null, \"previous\": null, \"results\": [ { \"id\": \"921be80b-b351-4e2b-afba-3384aa0b63e9\", \"bulk_process\": \"BulkProcess object (d722f658-cf66-4d00-8d3c-e286d5ca77ee)\", \"order_id\": \"493d3e9e-176d-4617-b932-d7961f60949e\", \"payload\": { \"name\": \"Bulk order 1\", \"altitude\": 0, \"end_time\": \"2020-05-30T23:00:00Z\", \"geometry\": { \"type\": \"Point\", \"coordinates\": [ 32.142035, -0.487188 ] }, \"start_time\": \"2020-04-28T00:00:00Z\" } }, { \"id\": \"a1b4fd59-1b80-4fff-b670-659a64c0ba1e\", \"bulk_process\": \"BulkProcess object (d722f658-cf66-4d00-8d3c-e286d5ca77ee)\", \"order_id\": \"178631b4-f23e-46e6-a77b-789cc164fdbe\", \"payload\": { \"name\": \"Bulk order 2\", \"altitude\": 0, \"end_time\": \"2020-05-30T23:00:00Z\", \"geometry\": { \"type\": \"Point\", \"coordinates\": [ 32.142032, -0.487199 ] }, \"start_time\": \"2020-04-28T00:00:00Z\" } }, { \"id\": \"6fdf32db-a385-4034-8e13-c6b312ce297f\", \"bulk_process\": \"BulkProcess object (d722f658-cf66-4d00-8d3c-e286d5ca77ee)\", \"payload\": { \"name\": \"Bulk order 3\", \"altitude\": 0, \"end_time\": \"2020-05-30T23:00:00Z\", \"geometry\": { \"type\": \"Point\", \"coordinates\": [ 181, 40 ] }, \"start_time\": \"2020-04-28T00:00:00Z\" }, \"error\": \"{\\\"geometry\\\":[\\\"Geometry longitude coordinate needs to be within -180.0 and 180.0\\\"]}\" } ] } Bulk Edit The Bulk edit endpoint allows the editing of multiple Tasking Orders in a single request, negating the need to make multiple requests for multiple Tasking Orders. The request for bulk editing Tasking Orders is very much the same as the one for bulk creation, but with the inclusion of the operation_type field, which is an optional parameter that defaults to CREATE (which is why we didn't include it in the bulk create example) but can also be set to EDIT and CANCEL (the cancel example is further down). Things to be aware of - This will only work for Tasking Orders that are in the system. Because of this each, Tasking Order to be edited must be identified by its ID. - Fields that are not present in the order payloads are left alone. - The operation_type must be set as EDIT - A UUID for the bulk process is optional. - The process is asynchronous. - The editing of Tasking Orders via bulk follow the same rules as defined here A curl request would look similar to this: curl --request POST --url 'https://api.planet.com/tasking/v2/bulk/' \\ --header 'accept: application/json' \\ --header 'authorization: api-key <YOUR_API_KEY>' \\ --header 'content-type: application/json' \\ --data '{ 'order_payloads': [ { 'id': 'order_UUID', 'start_time': '2021-04-29T00:00:00Z' }, { 'id': 'order_UUID_2', 'end_time': '2021-05-29T00:00:00Z' }], 'operation_type': 'EDIT' }' As with the Bulk creation workflow, there is no payload as part the response when the request is successful, and the response code is a 202 , which denotes an asynchronous response. Included in the headers of the response is a location field which contains the URL that can be used for requesting the status of bulk edit which is a GET request to the same endpoint, but this time appending the UUID that is used to identify the original bulk POST request to the URL: curl --request GET --url 'https://api.planet.com/tasking/v2/bulk/example_uuid_string' \\ --header 'accept: application/json' \\ --header 'authorization: api-key <YOUR_API_KEY>' \\ This time the response, when successful, will return with a response code of 200 and a JSON payload that will look similar to the following: { \"id\": \"5d11a1ed-4179-45f8-a9b4-65bc40c4bf64\", \"start_time\": \"2021-03-19T14:28:51.141569Z\", \"end_time\": null, \"operation_type\": \"EDIT\", \"payload_count\": 2, \"status\": \"RUNNING\", \"processing_payload_count\": 2, \"failed_payload_count\": 0, \"successful_payload_count\": 0 } Note that the operation_type is EDIT , reflecting the type of the original bulk request. Bulk Cancel Bulk cancellation allows multiple Tasking Orders that exist in the system to be cancelled with a single POST request, with the following caveat: only Tasking Orders with the statuses PENDING and IN_PROGRESS may be cancelled Things to be aware of - This will only work for Tasking Orders that are in the system. Because of this each Tasking Order to be cancelled must be identified by its ID. - The operation_type must be set as CANCEL - A UUID for the bulk process is optional - The process is asynchronous A curl request would look similar to this: curl --request POST --url 'https://api.planet.com/tasking/v2/bulk/' \\ --header 'accept: application/json' \\ --header 'authorization: api-key <YOUR_API_KEY>' \\ --header 'content-type: application/json' \\ --data '{ 'order_payloads': [ { 'id': 'order_UUID' }, { 'id': 'order_UUID_2' }], 'operation_type': 'CANCEL' }' As with the Bulk creation workflow, there is no payload as part the response when the request is successful, and the response code is a 202 , which denotes an asynchronous response. Included in the headers of the response is a location field which contains the URL that can be used for requesting the status of bulk edit which is a GET request to the same endpoint, but this time appending the UUID that is used to identify the original bulk POST request to the URL: { \"id\": \"7ed1516b-e65b-4886-a82d-5237b5738dd3\", \"start_time\": \"2021-03-19T15:18:22.131747Z\", \"end_time\": \"2021-03-19T15:18:22.850360Z\", \"operation_type\": \"CANCEL\", \"payload_count\": 2, \"status\": \"COMPLETE\", \"processing_payload_count\": 0, \"failed_payload_count\": 0, \"successful_payload_count\": 2 } Note that the operation_type is CANCEL , reflecting the type of the original bulk request.","tags":"tasking","url":"https://developers.planet.com/docs/tasking/examples/bulk","loc":"https://developers.planet.com/docs/tasking/examples/bulk"},{"title":"Calculate Changes in Water Levels","text":"Overview The purpose of this tutorial is to use Planet imagery to calculate an approximate percentage change in reservoir water levels. How To Get Started Before we start our analysis we need to ensure we have the required packages and Planet satellite images. Requirements Software & Python Libraries You will need: Python 3 GDAL scipy & numpy skimage requests OpenCV imutils The Planet CLI (optional) Your Planet API Key How to Export Planet API Key and Install Packages To export your Planet API Key to your environment: export PLANET_API_KEY=a3a64774d30c4749826b6be445489d3b # (not a real key) You can find GDAL installation instructions here . For installation of scipy & numpy, see this page . To install the Python libraries, do: $ python -m pip install requests $ python -m pip install opencv-python $ python -m pip install scikit-image $ python -m pip install imutils # optionally: $ python -m pip install planet Once installation is complete, you're ready to start with Step 1 below. A note about Planet Imagery Product Compatability: this tutorial is compatable with all ItemTypes & Asset Types. Download Images at Two Time Points First, let's download images of the same Reservoir in California, 2 weeks apart. You can use the Data API to search for, activate & download these images, or optionally you can use the planet CLI. How to Download Images with Planet CLI To use the CLI, do: $ planet data download --item-type REOrthoTile --asset-type visual --string-in id 20160707_195146_1057917_RapidEye-1 $ planet data download --item-type REOrthoTile --asset-type visual --string-in id 20160722_194930_1057917_RapidEye-2 You now have the two Planet 'visual' GeoTIFF format images in your current directory. N.B.: As this is just an example, we are using Planet's 'visual' asset type. If we wanted a more accurate measurement we would use the higher bit-depth 'analytic' product. Use QGIS to Select Common Window to Compare Our scenes don't overlap perfectly, and for the calculation to be accurate we'd prefer they did. The GDAL Warp command enables us to do this crop. With QGIS we can find the overlapping rectangle between the two scenes. Move your mouse to where you estimate the corners might be, and take note of the numbers from the 'coordinates' box on the bottom menu bar. Crop Images With GDAL Warp Command We then run the following bash commands: gdalwarp -te 547500 4511500 556702 4527000 1057917_2016-07-07_RE1_3A_Visual.tif 20160707.tif gdalwarp -te 547500 4511500 556702 4527000 1057917_2016-07-22_RE2_3A_Visual.tif 20160722.tif Find the Water In order to find the water we want to extract the blue hues within the image. Using OpenCV, we convert the BGR colorspace to HSV and create a threshold to extract the blue water. As you can see below, the mask we created differentiates the water from the land. Create a Mask Using Threshold import cv2 as cv a = cv.imread('20160707.tif') b = cv.imread('20160722.tif') hsv_a = cv.cvtColor(a, cv.COLOR_BGR2HSV) hsv_b = cv.cvtColor(b, cv.COLOR_BGR2HSV) low = np.array([55, 0, 0]) high = np.array([118, 255, 255]) inner_a = cv.inRange(hsv_a, low, high) inner_b = cv.inRange(hsv_b, low, high cv.imwrite('inner_a.png', inner_a) cv.imwrite('inner_b.png', inner_b) Mask A Mask B Cleaning up the Mask Using Erosion and Dilation We currently have some noise in our mask that we can eliminate using two morphological operations, erosion and dilation. The purpose of these operations to ensure we have a clear separation between the background and foreground, or land and water. kernel = np.ones((5,5),np.uint8) erosion_a = cv.erode(inner_a,kernel,iterations = 2) erosion_b = cv.erode(inner_b,kernel,iterations = 2) innerA = cv.dilate(erosion_a,kernel,iterations = 1) innerB = cv.dilate(erosion_b,kernel,iterations = 1) cv.imwrite('innerA.png', innerA) cv.imwrite('innerB.png', innerB) Mask A Mask B Watershed Algorithm In order to calculate the changes in water levels we need to know the area of the water in the image. We will use a segmentation technique so we only focus on the water and ignore everything else. The watershed algorithm returns a numpy array of labels with unique values corresponding to the pixel value. from scipy import ndimage from skimage.feature import peak_local_max from skimage.segmentation import watershed import numpy as np eucl_a = ndimage.distance_transform_edt(innerA) eucl_b = ndimage.distance_transform_edt(innerB) localMaxA = peak_local_max(eucl_a, indices=False, labels=innerA) localMaxB = peak_local_max(eucl_b, indices=False, labels=innerB) markers_a = ndimage.label(localMaxA, structure=np.ones((3, 3)))[0] markers_b = ndimage.label(localMaxB, structure=np.ones((3, 3)))[0] labels_a = watershed(-eucl_a, markers_a, mask=innerA) labels_b = watershed(-eucl_b, markers_b, mask=innerB) Calculating Area Using Contours and Overlaying Mask Once we have our labels, we loop over each unique label and look for the values that correspond with the foreground, or water. After applying those values to our mask, we then grab the contour of each object in our mask in order to perform our calculations on it. By adding the area of each individual contour to the total area, we are able to approximate the area of the water in our image. Note : I added lines to fill the contours and save the image for visualization purposes but this isn't necessary for our calculation. Python Function to Find Area def get_area(labels, inner_mask, img): area = 0 for label in np.unique(labels): if label== 0: continue mask = np.zeros(inner_mask.shape, dtype=\"uint8\") mask[labels == label] = 255 contours = cv.findContours(mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE) contours = imutils.grab_contours(contours) cv.fillPoly(img, pts=contours, color=(0,255,255)) a = cv.contourArea(contours[0]) area+=a cv.imwrite('mask.png', img) return area area_a = get_area(labels_a, innerA, a) area_b = get_area(labels_b, innerB, b) Image A Image B Apply Function to get Area and Water Change After we apply our function to both planet images, we now know the approximate change in water reservoir water levels between the times both these images were captured. area_a = mask_img(labels_a, innerA, a) area_b = mask_img(labels_b, innerB, b) water_level_diff = area_b/float(area_a) Output Area A = 1164765.0 Area B = 1120738.5 Water Level Difference = 0.9622013882628685 Percent change = -3.7798611737131504% Data Visualization Section Our last step is to plot a bar chart to represent the difference in water levels. from bokeh.io import output_file, show from bokeh.plotting import figure import bokeh.plotting as bk dates = ['2016-07-13', '2016-09-10'] pixels = [area_a, area_b] plt = figure(x_range=dates, plot_height=275, title=\"Reservoir Pixels\", toolbar_location=None, tools=\"\") plt.vbar(x=dates, top=pixels, width=0.3, fill_color=\"#cfe31e\") plt.xgrid.grid_line_color = None plt.y_range.start = 0 plt.xaxis.axis_label = \"Date\" plt.yaxis.axis_label = \"Sum(Pixels)\" #saves as a html file bk.save(plt) show(plt) Water Changes Questions or comments about this guide? Join the conversation at Planet Community .","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/calculate-changes-in-water-levels/","loc":"https://developers.planet.com/docs/planetschool/calculate-changes-in-water-levels/"},{"title":"Calculate an NDVI in Python","text":"Normalized Difference Vegetation Index (NDVI), developed by a NASA scientist named Compton Tucker in 1977, is commonly used to assess whether an area contains live green vegetation or not. It can show the difference between water and plants, bare soil and grass, whether plants are under stress, and what lifecycle stage a crop is in. It compares how much more near-infrared light is reflected by the vegetation vs visible red light: In this guide we will perform a basic NDVI calculation in python, using Planet's 4-Band imagery. You will need, Python 2.7 or 3 Rasterio Numpy matplotlib retrying requests Your Planet API Key To export your Planet API Key to your environment: export PLANET_API_KEY=a3a64774d30c4749826b6be445489d3b # (not a real key) You can find Numpy installation instructions here . To install the Python libraries, do: pip install rasterio pip install matplotlib pip install retrying pip install requests Once installation is complete, you're ready to start with Step 1 below. A note about Planet Imagery Product Compatability: this tutorial is compatable with only analytic and basic_analytic asset types of the following ItemTypes: PSOrthoTile REOrthoTile PSScene Download a 4-Band image First, download a 4-band Planetscope image of agricultural land in Toledo, Spain (id: 20161218_101700_0e0d). You can do this using the Planet API, or with Planet Explorer , by filtering for '4 Band PlanetScope scene' (PSScene) or 'Planetscope ortho tile' (PSOrthoTile), and downloading an 'analytic' asset. Using the Planet CLI: planet data download --item-type PSScene --asset-type analytic,analytic_xml --string-in id 20161218_101700_0e0d You now have a file called '20161228_101647_0e26_3B_AnalyticMS.tif' in your directory. Thumbnail preview of the 4-band scene Extract the Visible Red and NIR bands In a python script, open the image and extract just the Red and Near-infrared bands, numbers 3 and 4. import rasterio import numpy image_file = \"20161228_101647_0e26_3B_AnalyticMS.tif\" # Load red and NIR bands - note all PlanetScope 4-band images have band order BGRN with rasterio.open(image_file) as src: band_red = src.read(3) with rasterio.open(image_file) as src: band_nir = src.read(4) Normalize to Top of Atmosphere Reflectance Converting the pixel values to TOA Reflectance makes the analysis more accurate, and comparable with other scenes. Load the TOA Reflectance coefficients from the metadata XML asset. from xml.dom import minidom xmldoc = minidom.parse(\"20161218_101700_0e0d_3B_AnalyticMS_metadata.xml\") nodes = xmldoc.getElementsByTagName(\"ps:bandSpecificMetadata\") # XML parser refers to bands by numbers 1-4 coeffs = {} for node in nodes: bn = node.getElementsByTagName(\"ps:bandNumber\")[0].firstChild.data if bn in ['1', '2', '3', '4']: i = int(bn) value = node.getElementsByTagName(\"ps:reflectanceCoefficient\")[0].firstChild.data coeffs[i] = float(value) Multiply the band values by the TOA Reflectance coefficients. # Multiply by corresponding coefficients band_red = band_red * coeffs[3] band_nir = band_nir * coeffs[4] Perform the NDVI calculation Next we perform the NDVI calculation through subtraction and division of the pixel values. # Allow division by zero numpy.seterr(divide='ignore', invalid='ignore') # Calculate NDVI ndvi = (band_nir.astype(float) - band_red.astype(float)) / (band_nir + band_red) Save the NDVI image Finally we output these new pixel values to a new image file, making sure we mirror the GeoTIFF spatial metadata: # Set spatial characteristics of the output object to mirror the input kwargs = src.meta kwargs.update( dtype=rasterio.float32, count = 1) # Create the file with rasterio.open('ndvi.tif', 'w', **kwargs) as dst: dst.write_band(1, ndvi.astype(rasterio.float32)) Apply a color map Applying a color map can help to visually distinguish vegetation. For more color map options check out the docs for matplotlib . import matplotlib.pyplot as plt plt.imsave(\"ndvi_cmap.png\", ndvi, cmap=plt.cm.summer) Questions or comments about this guide? Join the conversation at Planet Community .","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/calculate-an-ndvi-in-python/","loc":"https://developers.planet.com/docs/planetschool/calculate-an-ndvi-in-python/"},{"title":"Code of Conduct","text":"Last updated: September 2020 TL;DR: All attendees, sponsors, partners, volunteers and staff at our event are required to agree with the following code of conduct. Organizers will enforce this code throughout the event. We expect cooperation from all participants to ensure a safe environment for everybody. What To Do If You Witness or are Subject to Unacceptable Behavior If you are being harassed, notice that someone else is being harassed, or have any other concerns relating to harassment, please contact a member of the event staff immediately. At in-person events, event staff can be identified by staff badges and/or shirts, and an organizer can be found at the event registration area. At all events, including online (virtual), you may also report an incident here . Quick Version Planet is dedicated to providing a safe and comfortable environment and harassment-free experience for everyone, regardless of the following: gender gender identity and expression age sexual orientation disability physical appearance body size race ethnicity nationality religion political views technology choices We do not tolerate harassment of event participants in any form. Sexual language and imagery is not appropriate for any associated event venue, including talks, workshops, parties, online forums (e.g., GitHub or Gitter) and other online media. Event participants violating these rules may be sanctioned or expelled from the event without a refund (if applicable) at the discretion of the event organizers. The Less Quick Version Harassment includes offensive verbal comments related to gender, gender identity and expression, age, sexual orientation, disability, physical appearance, body size, race, ethnicity, religion, technology choices, sexual images in public spaces, deliberate intimidation, stalking, following, harassing photography or recording, sustained disruption of talks or other events, inappropriate physical contact, and unwelcome sexual attention. Participants asked to stop any harassing behavior are expected to comply immediately. Sponsors of the event are also subject to the anti-harassment policy. In particular, sponsors should not use sexualised images, activities, or other material. Event staff (including volunteers) should not use sexualised clothing/uniforms/costumes, or otherwise create a sexualised environment. If a participant engages in harassing behavior, the event organizers may take any action they deem appropriate, including warning the offender or expulsion from the event with no refund. If you are being harassed, notice that someone else is being harassed, or have any other concerns, please contact a member of event staff immediately. Event staff will be happy to help participants contact venue security or local law enforcement, provide escorts, or otherwise assist those experiencing harassment to feel safe for the duration of the event. We value your attendance. If a participant engages in harassing behavior, the event organisers may take any action they deem appropriate. This includes, but is not limited to, warning the offender, expulsion from the event with no refund (if applicable), or reporting their behavior to local law enforcement. We expect participants to follow these rules at all event venues and event-related social events.","tags":"pages","url":"https://developers.planet.com/docs/pages/code-of-conduct/","loc":"https://developers.planet.com/docs/pages/code-of-conduct/"},{"title":"How To Compare Basemaps","text":"Comparing basemaps side by side allows you to visually inspect change between two time periods. Choose Basemaps for Comparison To start comparing basemaps side by side, click on the Compare button on the lower right hand corner of the map. It is the second button from the top. From there, you will see a split screen. You can now select one basemap to inspect on the left side of the screen and another basemap to inspect on the right side of the screen. You can find a list of your available basemaps in the menu on the left hand side. To compare basemaps, select a basemap from this list by clicking on it and drag it into the split screen. You will see basemap's date listed at the bottom of each panel in the split screen. Please Note: You can only compare basemaps for the same area. Inspect and Zoom Once you have selected the two basemaps you'd like to compare, you can zoom and pan around the basemap and both panels of the split screen will mirror your movements. You can zoom either with your mouse or trackpad or by clicking the \"+\" and \"-\" buttons on the map.","tags":"apps-basemapsviewer","url":"https://developers.planet.com/docs/apps/basemapsviewer/compare-basemaps/","loc":"https://developers.planet.com/docs/apps/basemapsviewer/compare-basemaps/"},{"title":"How To Identify Contributing Scenes","text":"Once you have selected a basemap from the menu on the left-hand side, you can inspect a more granular area in more detail by reviewing contributing scenes. A scene is a single image captured by a PlanetScope satellite. Many scenes together compose a mosaic. Define an Area To define an area, you can either select a point, draw an area, or upload a geometry. These options can be found in the upper left hand corner of the modal once you have selected a basemap. Select a Point Selecting a Point is the default option. You can click on the map and a pin will be dropped onto the map. If you'd like to change the pin's location, click on another part on the map. Draw an Area You can choose to draw an area rather than clicking on a single point. You will see three options in the top header of the left hand toolbar. The second option is to Draw Area . Select Draw Area and then draw an area on the map by holding down your mouse until you have the desired polygon. Upload File You can also choose to upload a geometry. You will see three options in the top header of the left hand toolbar. The third option is to Upload File . Select Upload File and then upload a geojson file from your computer. Review Contributing Scenes and Related Quads Once you select a point, you will see a menu of contributing scenes in the left hand toolbar. Underneath the scenes, you will also see related basemap quads that are available for download. If you click into the basemap quad, you will see all of the contributing scenes to that quad. If you selected an area, either by drawing an area or uploading a file, you will see a list of basemap quads in the left hand menu. You can click into the basemap quad to see the contributing scenes to that quad. As you look through the list of scenes in the menu, you will see the scene outline appear on the map. View and Download Scenes If you would like to see a particular scene in more detail, you can click on the scene and you will be taken into the Planet Explorer application. If you have access to view and download that scene, you will be able to see the scene on the map and \"Order\" the scene for download. For more information on that process, check out the Explorer User Guide: https://developers.planet.com/docs/apps/explorer/how-to-order-download/","tags":"apps-basemapsviewer","url":"https://developers.planet.com/docs/apps/basemapsviewer/contributing-scenes/","loc":"https://developers.planet.com/docs/apps/basemapsviewer/contributing-scenes/"},{"title":"GeoJSON and Areas of Interest (AOIs)","text":"Planet Explorer and the Planet Data API accept geometry in GeoJSON format. This guide explains some of the basics of working with GeoJSON. Creating Geometry We often use the tool GeoJSON.io to create geometry. The GeoJSON.io GUI You can search by place name. Then graphically draw a polygon: And export the GeoJSON, to upload to Planet Explorer, or use in your Data API query. Simplifying Geometry A common trap is using highly complex geometry. Querying the Data API with complex geometry can significantly increase search response times, and Planet Explorer limits you to a 1MB file. MapShaper.org is a tool that 'simplifies' your geometry to get around these issues. Simply upload your GeoJSON file, click 'Simplify' in the top right corner -> Apply -> move the slider to until the number of vertices has reduced, but the shape is sufficiently maintained. Export the new simplified geometry, to use it to search the Planet archive again. Converting Shapefile to GeoJSON Compress your .shp and all associated files into a .zip file. Drag this .zip file onto the mapshaper.org homepage. Click 'Import', then 'Export' in the top right corner, and select 'GeoJSON'. Planet GeoJSON Specifications Planet has the following GeoJSON requirements: EPSG:4326 Projection No self-intersections Planet supports the following GeoJSON specifications: Polygon Point MultiPolygon MultiPoint Feature Collection Objects Questions or comments about this guide? Join the conversation at Planet Community .","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/geojson-and-areas-of-interest-aois/","loc":"https://developers.planet.com/docs/planetschool/geojson-and-areas-of-interest-aois/"},{"title":"Delivery","text":"The Subscriptions API supports delivery to Amazon S3, Microsoft Azure Blob Storage, Google Cloud Storage, or Oracle Cloud Storage. Activation and processing for direct download is not currently supported. For any cloud storage delivery option, you will need to create an cloud storage account with both write and delete access. When creating a subscription or order with bucket delivery, Planet will check the bucket permissions linked to your token by first attempting to deliver a file named planetverify.txt and then immediately deleting it. If Planet has the adequate permissions, you should not expect to see this file. If you do see this file in your buckets, we recommend that you review your permissions to ensure that Planet has both write and delete access. Cloud Credential Security When creating a subscription, a user must input their credentials for successful cloud delivery of Planet data. This poses a potential security risk. For secure handling of cloud service credentials in the request, please ensure that access is limited to the desired delivery path with no read/write access for any other storage locations or cloud services. Delivery Schema The schema for Subscriptions API delivery below. Note that this schema varies slightly from the delivery schema of the Orders API. \"delivery\": { \"type\": \"cloud-storage-provider\", \"parameters\": { \"parameter1-name\": \"p1-value\", \"parameter2-name\": \"p2-value\" } } Supported Delivery Options Delivery to Amazon S3 For Amazon S3 delivery you will need an AWS account with GetObject , PutObject , and DeleteObject permissions. Parameters aws_access_key_id (required): AWS credentials. aws_secret_access_key (required): AWS credentials. bucket (required): The name of the bucket that will receive the order output. aws_region (required): The region where the bucket lives in AWS. Example Request \"delivery\": { \"type\": \"amazon_s3\", \"parameters\": { \"bucket\": \"foo-bucket\", \"aws_region\": \"us-east-2\", \"aws_access_key_id\": \"\", \"aws_secret_access_key\": \"\" } } Delivery to Microsoft Azure For Microsoft Azure delivery you will need an Azure account with read , write , delete , and list permissions. Parameters account (required): Azure account name. container (required): The name of the container which will receive the order output. sas_token (required): Azure Shared Access Signature token . Token should be specified without a leading '?'. (I.e. \"sv=2017-04-17u0026si=writersr=cu0026sig=LGqc\" rather than \"?sv=2017-04-17u0026si=writersr=cu0026sig=LGqc\") storage_endpoint_suffix (optional): To deliver your order to a sovereign cloud a storage_endpoint_suffix should be set appropriately for your cloud. The default is \"core.windows.net\". Example Request \"delivery\": { \"type\": \"azure_blob_storage\", \"parameters\": { \"account\": \"accountname\", \"container\": \"containername\", \"sas_token\": \"sv=2017-04-17u0026si=writersr=cu0026sig=LGqc\", \"storage_endpoint_suffix\": \"core.windows.net\" } } Delivery to Google Cloud Storage For Google Cloud Storage delivery you will need an GCS account with write and delete permissions. Preparing Your Google Cloud Storage Credentials The Google Cloud Storage delivery option requires in a single-line base64 version of your service account credentials for use by the credentials parameter. To download your service account credentials in JSON format (not P12) and encode them as a base64 string, you can use a command line operation such as: cat my_creds.json | base64 | tr -d '\\n' Parameters credentials (required): GCS credentials. bucket (required): The name of the GCS bucket which will receive the order output. Example Request \"delivery\": { \"type\": \"google_cloud_storage\", \"parameters\": { \"bucket\": \"your-gcs-bucket\", \"credentials\": \"c29tZWNyZWRzZm9yeW91cmdjc2J1Y2...\" } } Delivery to Oracle Cloud Storage For Oracle Cloud Storage delivery you need an Oracle account with read , write , and delete permissions. For authentication you need a Customer Secret Key which consists of an Access Key/Secret Key pair. Parameters customer_access_key_id (required): Customer Secret Key credentials. customer_secret_key (required): Customer Secret Key credentials. bucket (required): The name of the bucket that will receive the order output. region (required): The region where the bucket lives in Oracle. namespace (required): Object Storage namespace name. Example Request \"delivery\": { \"type\": \"oracle_cloud_storage\", \"parameters\": { \"bucket\": \"foo-bucket\", \"namespace\": \"ORACLE_NAMESPACE\", \"region\": \"us-sanjose-1\", \"customer_access_key_id\": \"YOUR_ACCESS_ID\", \"customer_secret_key\": \"YOUR_SECRET_KEY\", } } Delivery Layout When data is delivered to your cloud storage solution for your Subscription, we will deliver your files in accordance with the following layout scheme: <subscription_id>/<item_id>/... For example, if we're delivering the file 20170716_144316_1041_3B_AnalyticMS.tif for item 20170716_144316_1041 as output for subscription 0ee41665-ab3b-4faa-98d1-25738cdd579c , the file will be delivered to the path: 0ee41665-ab3b-4faa-98d1-25738cdd579c/20170716_144316_1041/20170716_144316_1041_3B_AnalyticMS.tif .","tags":"subscriptions","url":"https://developers.planet.com/docs/subscriptions/delivery/","loc":"https://developers.planet.com/docs/subscriptions/delivery/"},{"title":"GEE Order and Delivery","text":"Ordering and Delivering to GEE Delivery to GEE follows a similar structure as delivery to a cloud-storage bucket from the Delivery to Cloud Storage . Delivering to GEE requires that you already have the images and the image ids. Use either the Planet Data API , the Planet Explorer , or either of the Planet GIS integrations . To use the integration, your organization must have download quota. To set up a download quota, Contact Sales . Also, the GEE ImageCollection being delivered must already exist. Create an ImageCollection by using the Earth Engine code editor or CLI. Supported Item and Asset Types Item Type Supported Order Bundles Limitations PSScene analytic_8b_sr_udm2, analytic_sr_udm2, analytic_8b_udm2, analytic_udm2, visual SkySatScene analytic, analytic_udm2, analytic_sr_udm2, visual, pansharpened_udm2, panchromatic_dn_udm2 SkySatCollect analytic, analytic_udm2, analytic_sr_udm2, visual, pansharpened_udm2, panchromatic_dn_udm2 SkySatCollects may take an hour per item to ingest See Items & Assets for more information. Supported Raster Operations The Planet GEE Delivery Integration supports the clip and harmonization order operations. The clip operation can reduce the download quota consumption by reducing the size of the imagery order. The option to harmonize improves the spectral consistency across three generations of Planet Doves (Dove Classics, Dove-R, SuperDove) by approximately matching a Sentinel-2 spectral response. Harmonization is only available for surface reflectance PlanetScope Scenes (PSScene) bundles. All other order operations are unsupported at this time. Placing an order with another operation in a delivery request results in the following response. { \"message\": \"Unable to accept order: GEE delivery does not support tools\" } Example GEE delivery payloads The following payload delivers PSScene analytic_8b_sr_udm2 images to the Planet GEE account. analytic_8b_sr_udm2 is an orders bundle type that delivers a surface reflectance corrected PlanetScope image. Specify the following two GEE fields in the delivery node: - Project - Collection Project The fields must correspond to the GEE Cloud Project, and collection to the GEE Image Collection that will receive the images. The Orders REST URL https://api.planet.com/compute/ops/orders/v2 Simple delivery { \"name\": \"PSScene 8-band order Miami\", \"products\": [{ \"item_ids\": [ \"20220118_154923_68_2424\" ], \"item_type\": \"PSScene\", \"product_bundle\": \"analytic_8b_sr_udm2\" }], \"delivery\": { \"google_earth_engine\": { \"project\": \"your-cloud-project-name\", \"collection\": \"your-image-collection-name\", \"notifications\": { \"email\": true } } } } Delivery with clip and harmonization applied { \"name\": \"PSScene 8-band order Miami\", \"products\": [{ \"item_ids\": [ \"20220118_154923_68_2424\" ], \"item_type\": \"PSScene\", \"product_bundle\": \"analytic_8b_sr_udm2\" }], \"tools\": [{ \"harmonize\": { \"target_sensor\": \"Sentinel-2\" } },{ \"clip\": { \"aoi\": { \"type\": \"Polygon\", \"coordinates\": [ [ [-80.176302, 25.758621], [-80.140075, 25.758621], [-80.140075, 25.802288], [-80.176302, 25.802288], [-80.176302, 25.758621] ] ] } } }], \"delivery\": { \"google_earth_engine\": { \"project\": \"your-cloud-project\", \"collection\": \"your-image-collection\", \"notifications\": {\"email\": true} } } } Example GEE delivery response Example API response { \"_links\": { \"_self\": \"https://api.planet.com/compute/ops/orders/v2/9aedcc50-6e29-4880-8dcf-7f168214cca3\" }, \"created_on\": \"2022-02-01T23:04:14.251Z\", \"delivery\": { \"google_earth_engine\": { \"collection\": \"your-image-collection\", \"credentials\": \"<REDACTED>\", \"project\": \"your-cloud-project\" } }, \"error_hints\": [], \"id\": \"9aedcc50-6e29-4880-8dcf-7f168214cca3\", \"last_message\": \"Preparing order\", \"last_modified\": \"2022-02-01T23:04:14.251Z\", \"name\": \"PSScene 8-band order Miami\", \"products\": [ { \"item_ids\": [ \"20220118_154923_68_2424\" ], \"item_type\": \"PSScene\", \"product_bundle\": \"analytic_8b_sr_udm2\" } ], \"state\": \"queued\", \"tools\": [ { \"harmonize\": { \"target_sensor\": \"Sentinel-2\" } }, { \"clip\": { \"aoi\": { \"coordinates\": [ [ [ -80.176302, 25.758621 ], [ -80.140075, 25.758621 ], [ -80.140075, 25.802288 ], [ -80.176302, 25.802288 ], [ -80.176302, 25.758621 ] ] ], \"type\": \"Polygon\" } } } ] } Delivery success To check on order status, pull the URL in the API response that was provided after order submission. When the order status is Success , the images are available in your EE image collection. If required, refresh the EE assets to view the new images. { \"\\_links\": { \"\\_self\": \"https://ordersv2.next.prod.planet-labs.com/compute/ops/orders/v2/4711cf34-1e88-4d99-877c-a25d62418b64\", \"results\": [ { \"delivery\": \"success\", \"expires_at\": \"2020-06-25T02:31:11.591Z\", \"location\": \"projects/your_cloud_project_name/assets/your_ee_image_collection_name/20180716_163210_103c_3B_AnalyticMS_SR\", \"name\": \"PSScene4Band/20180716_163210_103c_3B_AnalyticMS_SR.tif\" }, { \"delivery\": \"success\", \"expires_at\": \"2020-06-25T02:32:02.502Z\", \"location\": \"projects/your_cloud_project_name/assets/your_ee_image_collection_name/20180716_162019_0f1a_3B_AnalyticMS_SR\", \"name\": \"PSScene4Band/20180716_162019_0f1a_3B_AnalyticMS_SR.tif\" }, { \"delivery\": \"success\", \"expires_at\": \"2020-06-25T02:32:29.749Z\", \"location\": \"projects/your_cloud_project_name/assets/your_ee_image_collection_name/20180716_162016_0f1a_3B_AnalyticMS_SR\", \"name\": \"PSScene4Band/20180716_162016_0f1a_3B_AnalyticMS_SR.tif\" }, { \"delivery\": \"success\", \"expires_at\": \"2020-06-25T02:32:56.820Z\", \"location\": \"projects/your_cloud_project_name/assets/your_ee_image_collection_name/20180716_163212_103c_3B_AnalyticMS_SR\", \"name\": \"PSScene4Band/20180716_163212_103c_3B_AnalyticMS_SR.tif\" }, { \"delivery\": \"success\", \"expires_at\": \"2020-06-25T02:31:37.810Z\", \"location\": \"projects/your_cloud_project_name/assets/your_ee_image_collection_name/20180716_163213_103c_3B_AnalyticMS_SR\", \"name\": \"PSScene4Band/20180716_163213_103c_3B_AnalyticMS_SR.tif\" }, { \"delivery\": \"success\", \"expires_at\": \"2020-06-25T02:31:25.155Z\", \"location\": \"projects/your_cloud_project_name/assets/your_ee_image_collection_name/20180716_163211_103c_3B_AnalyticMS_SR\", \"name\": \"PSScene4Band/20180716_163211_103c_3B_AnalyticMS_SR.tif\" }, { \"delivery\": \"success\", \"expires_at\": \"2020-06-25T02:31:35.339Z\", \"location\": \"projects/your_cloud_project_name/assets/your_ee_image_collection_name/20180716_162018_0f1a_3B_AnalyticMS_SR\", \"name\": \"PSScene4Band/20180716_162018_0f1a_3B_AnalyticMS_SR.tif\" }, { \"delivery\": \"success\", \"expires_at\": \"2020-06-25T02:32:19.476Z\", \"location\": \"projects/your_cloud_project_name/assets/your_ee_image_collection_name/20180716_162017_0f1a_3B_AnalyticMS_SR\", \"name\": \"PSScene4Band/20180716_162017_0f1a_3B_AnalyticMS_SR.tif\" } ] }, \"created_on\": \"2020-06-24T02:27:30.935Z\", \"delivery\": { \"google_earth_engine\": { \"collection\": \"your_ee_image_collection_name\", \"project\": \"your_cloud_project_name\" } }, \"error_hints\": [], \"id\": \"4711cf34-1e88-4d99-877c-a25d62418b64\", \"last_message\": \"Delivery completed\", \"last_modified\": \"2020-06-24T02:34:18.645Z\", \"name\": \"PS Cropland Delivery to GEE\", \"products\": [ { \"item_ids\": [ \"20180716_163213_103c\", \"20180716_163212_103c\", \"20180716_163211_103c\", \"20180716_163210_103c\", \"20180716_162019_0f1a\", \"20180716_162018_0f1a\", \"20180716_162017_0f1a\", \"20180716_162016_0f1a\" ], \"item_type\": \"PSScene4Band\", \"product_bundle\": \"analytic_sr\" } ], \"state\": \"success\" } Use a Google Service Account Imprortant : When creating an order, you must input your credentials for successful delivery of Planet data to cloud storage. This introduces a potential security risk. For secure delivery to cloud storage, limit access to the required delivery path without read/write access for any other storage locations or cloud services. Use your own Google Service Account (SA) to deliver images to GEE. Using your Google SA, provides a dedicated queue for orders. When using the default SA from Planet, orders compete with other orders in the queue. Each SA has approximately 3000 queue depth limit when delivering to GEE. Creating a Service Account Managing Service Accounts provides more details. Considerations: Enroll your SA to Earth Engine by using the sign up page Assign GEE Writer IAM Roles to your Service Account. See Step 3 for more details Using your Service Account To submit your GEE Delivery Order with your own Service Account, add a new credentials field to your payload. { \"name\": \"Miami 8-band Image - BYOS\", \"products\": [ { \"item_ids\": [ \"20220118_154923_68_2424\" ], \"item_type\": \"PSScene\", \"product_bundle\": \"analytic_8b_sr_udm2\" } ], \"delivery\": { \"google_earth_engine\": { \"project\": \"your_cloud_project_name\", \"collection\": \"your_ee_image_collection_name\", \"credentials\": \"<base64 credential>\" } } } Planet recommends using a command line tool such as base64 to encode your credentials. Avoid using online tools that can expose your credentials. Leave the Credentials field blank.","tags":"integrations-gee","url":"https://developers.planet.com/docs/integrations/gee/delivery/","loc":"https://developers.planet.com/docs/integrations/gee/delivery/"},{"title":"Planet Developer Program","text":"Interested in hacking against Planet's Platform? Want to take our APIs for a spin and see how you might intergrate Planet into your existing geospatial workflows? Need a stack of Planet imagery to develop a time series analysis script against? The Developer Program might be just what you are looking for. This program gives \"broad, but shallow\" access to Planet's platform and data: if accepted, you'll receive an API key with access to Planetscope data via our public APIs, along with the ability to search for and download data from a selection of AOIs (areas of interest) around the globe. Program access is good for 90 days following activation of your account. Who this developer program is for Access to the Developer Program is limited to users interested in trying Planet's platform for the purpose of evaluating Planet's APIs and related developer tools: data access is limited and does not fully represent the complete Planet catalog. If you are a student or researcher interested in Planet data, the Education & Research Program may be more suitable. If you are interested in commercial use of Planet's platform and data, this program is not for you - but we'd love to help you out: get in touch . Access Details APIs Your Developer Program account's API key will include access to the following APIs: Data API : search Planet's imagery catalog Tile Services API : XYZ & WMTS tile map services of Planet basemaps Orders API : construct toolchains & place orders for imagery You will also be able to use our open-source Python library & CLI to access the same APIs. Imagery During the program your API key will allow you to search for and download the following imagery types using Planet's APIs: * 3-band PlanetScope Scenes * 4-band PlanetScope Scenes * 8-band PlanetScope Scenes * Landsat 8 Scenes * Sentinel-1 GRD Scenes Additionally, Developer Program users can access the following basemaps using the Tile Services API: * Global Monthly * Global Quarterly * Oregon Monthly Normalized Analytic Note: Basemap availability is limited to the TOI described below. AOIs You will be able to search for and download imagery within a collection of small AOIs covering a variety of locations (including urban, rural, agricultural, and coastal regions) around the globe. Eligible AOIs are subject to change over time, but include the areas shown on the map below (you may need to zoom in): Tip: If you aren't concerned with geographic specifics, and only want to quickly search for data within any AOI, try San Francisco's Golden Gate Park: { \"type\": \"Feature\", \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [-122.511034, 37.771597], [-122.510605, 37.763998], [-122.459021, 37.766033], [-122.457733, 37.76549], [-122.452755, 37.766372], [-122.454557, 37.775125], [-122.465973, 37.773836], [-122.511034, 37.771597] ] ] }, \"properties\": { \"name\": \"golden_gate_park\" } } For a geospatial listing of AOIs currently available in the Developer Program, reference aois.geojson . TOI Currently, the Time of Interest (TOI) window for the Developer Program is Aug 31 2018-Mar 30 2019 . This means that for the datasets listed above, and within any geography that intersects with the AOIs listed above, you may search for and download data within this TOI's window of time.","tags":"pages","url":"https://developers.planet.com/docs/pages/planet-developer-program/","loc":"https://developers.planet.com/docs/pages/planet-developer-program/"},{"title":"Discover Planet Basemaps in ArcGIS","text":"Overview Planet's Basemaps are composed of Planet's \"best\" PlanetScope or SkySat images over a specific time of interest to provide a near-cloud-free look at an area of interest. To learn more about the imagery specifications of Planet Basemap products, please see our Basemaps Product Spec Search for Basemaps Basemaps in the Planet ArcGIS Add-In are organized into three categories: One off, Series & All. The One off filter catalogs Basemaps that don't belong to a time-series, i.e., they were purchased and produced for a single AOI/TOI. The Series filter catalogs Basemaps that belong to a time-series. Planet produces time-series Basemaps for many intervals, the most common are \"monthly\" and \"weekly\" Basemaps. The All filter is a catch-all for One Off and Series Basemaps. The All filter also has a text filter that allows you to filter Basemaps using keywords (e.g., \"PS Tropical\"). Additionally, all Basemaps can be filtered by \"Surface Reflectance only,\" which if applied, will limit results only to basemaps that have been atmospherically corrected for surface reflectance values and includes near infrared spectral information. Learn more about SR correction on PlanetScope data here . Stream Planet Basemaps Planet ArcGIS Add-In users can stream Basemaps into ArcGIS as a single Basemap or as part of a time-series. To stream a Basemap as a time-series, select each Basemap instance from the Basemaps search results panel, then select \"Explore Selected\". This will create a single \"layer\" in your ArcGIS Pro table of contents with the name of your Basemap series and the selected time interval. Selecting the Basemap layer in your table of contents will open a new ribbon that is only accessible when working with Planet Basemaps, called Planet Basemap Tools. The Planet Basemap Tools ribbon has controls that enable you to adjust visualization parameters and animate through the time intervals for your Planet Basemaps. If the Basemap you are streaming is a surface reflectance Basemap, you will have processing options to stream the Basemap in false color like color infrared or as a spectral index visualization like ndvi, and have a few select color ramp options that can be applied to each processing option. Identify Basemap Source Scene Some Planet Basemap users may want to be able to identify the contributing source scene for a specific location in a Planet Basemap so that they can view metadata about the pixels such as their specific collection date. The Planet Inspector panel in the Planet ArcGIS Add-In allows users to do just that: select a location in a Planet Basemap and identify the source scene for that location. To use the Planet Inspector tool, first open the Planet Basemap that you'd like to inspect and make sure you have the Basemap selected in your ArcGIS Pro table of contents. If you have a Basemap Series added to your ArcGIS Pro Map, make sure that the series is on the specific temporal instance that you'd like to inspect using the Planet Basemap Tools ribbon. Then zoom to the area that you'd like to \"inspect\". Next select the Planet Inspector icon from the Planet Imagery ribbon, and click the pencil icon on the panel that appears. This will enable your cursor for inspection. Simply click a location on the selected Basemap that you'd like to inspect. The tool will return the Planet imagery scene that contributed to that specific location in the Basemap. By default you should be able to view the specific date and UTC time that the image was collected. If your account has permissions to access that source image, you can select the gear icon next to the image in the Planet Inspector panel and click \"Query sceneID\" . This will open the image into the Planet Search Panel where you can further explore its metadata, stream the preview layer or download the image. Download Basemaps Planet Basemaps are distributed as a grid of GeoTIFF files which are called \"Basemap quads\" or simply \"quads\". If your Planet Basemaps subscription includes download quota, you will be able to use the Planet ArcGIS Add-In to download a subset of or your entire Basemap's quads. To download a Basemap, first select the Basemap instance or instances (you can select more than one Basemap of the same time series) you'd like to download from the Basemaps Panel search results, then select \"Order\" from the bottom-right of the panel. The Order Basemap Panel presents user's with three options: * Download Complete Basemap(s) * Download Specific AOI from Basemap(s) * Create streaming connection(s) Option 1: Download Complete Basemap(s) This should only be used for Basemaps of a size that can be managed on a single desktop computer. Generally, surface reflectance Planet Basemaps are ~120MB per visual ~35MB per quad. If you select to download a Basemap with more than 500 quads, you will be prompted with a warning message about the size, continue if it is an acceptable download size. Option 2. Download Specific AOI from Basemap(s) To download a subset of your Basemap(s) based on an area of interest, select option 2. Then use the draw tools to define your area of interest. Once you AOI is set, select \"Find Quads\" . This will query Planet's Basemaps API to find all the quads across the Basemap instances you selected for download. Select the quads you'd like to download and then select \"Next\" . Provide a name for your download and click \"Submit Order\" to complete your Basemap quad order. To open your order for download, navigate to the Orders Panel and select \"download\" option next to the name of your Basemap Quad order.","tags":"integrations-arcgis","url":"https://developers.planet.com/docs/integrations/arcgis/discover-basemaps/","loc":"https://developers.planet.com/docs/integrations/arcgis/discover-basemaps/"},{"title":"Discover Planet Basemaps in QGIS","text":"Overview Planet's Basemaps are composed of Planet's \"best available\" PlanetScope or SkySat imagery scenes mosaiced together over a specific time of interest to provide a near-cloud-free view of an area of interest. To learn more about the imagery specifications of Planet Basemap products, please see Planet's Basemaps Product Spec . Search for Basemaps Basemaps in the Planet QGIS Plugin are organized into three categories: One-off, Series & All. The One-off filter catalogs Basemaps that don't belong to a time-series, i.e., they were purchased and produced for a single AOI/TOI. The Series filter catalogs Basemaps that belong to a time-series. Planet produces time-series Basemaps for many intervals, the most common are \"monthly\" and \"weekly\" Basemaps. The All filter is a catch-all for One Off and Series Basemaps. The All filter also has a text filter that allows you to filter Basemaps using keywords (e.g., \"PS Tropical\"). Additionally, all Basemaps can be filtered by \"Surface Reflectance only,\" which if applied, will limit results only to Basemaps that have been atmospherically corrected for surface reflectance values and include additional spectral information like near-infrared. Learn more about SR correction on PlanetScope data here . Stream Planet Basemaps Planet QGIS Plugin users can stream Basemaps into QGIS as a single Basemap or as part of a time-series. To stream a Basemap as a time-series, select each Basemap instance from the Basemaps search results panel, then select \"Explore Selected\". This will create a single \"layer\" in your QGIS table of contents, which will include a time-slider that allows you to animate through the time-series. If the Basemap you are streaming is a surface reflectance Basemap, you will have a processing option drop-down menu below the Basemap layer, which enables you to stream the Basemap in false color like color infrared or as a spectral index visualization like NDVI. There are also a number of select color ramp options to complete your visualization. Identify Basemap Source Scene Some Planet Basemap users may want to be able to identify the contributing \"source\" scene for a specific location in a Planet Basemap so that they can view metadata about the pixels such as their specific collection date. The Planet Inspector panel in the Planet QGIS Plugin allows users to do just that: select a location on a Planet Basemap and identify the source scene for that location. To use the Planet Inspector tool, first open the Planet Basemap that you'd like to inspect and make sure you have the Basemap selected in your QGIS Layers panel. If you have a Basemap Series added to your QGIS Map, make sure that the series is on the specific temporal instance that you'd like to inspect. Zoom to the area that you'd like to inspect for more detail. Then select the Planet Inspector icon from the Planet QGIS Plugin panel, and click the \"wand\" icon on the panel that appears. This will enable your cursor for inspection. To use, simply click a location on the selected Basemap that you'd like to inspect. The tool will return the Planet imagery scene that contributed to that specific location in the Basemap. By default you should be able to view the specific date and UTC time that the image was collected. If your account has permissions to access that source imagery scene, you can select the gear icon next to the image in the Planet Inspector panel and click \"Open in Explorer\". This will open the image into the Planet QGIS Search Panel where you can further explore its metadata, stream the preview layer or download the image. Order & Download Basemaps Planet Basemaps are distributed as a grid of GeoTIFF files which are called \"Basemap quads\" or simply \"quads\". If your Planet Basemaps subscription includes download quota, you will be able to use the Planet QGIS Plugin to download a subset of or your entire Basemap's quads. To download a Baseamp, first select the Basemap instance or instances (you can select more than one Basemap of the same time series) you'd like to download from the Basemap search results, then select \"Order\" from the bottom-right of the Basemaps Panel. The Order Basemap Panel presents user's with three options: * Download Complete Basemap(s) * Download Specific AOI from Basemap(s) * Create streaming connection(s) Option 1: Download Complete Basemap(s) This should only be used for Basemaps of a size that can be managed on a single desktop computer. Generally, surface reflectance Basemaps are ~120MB per visual ~35MB per quad. If you select to download a Basemap with more than 500 quads, you will be prompted with a warning message about the size. Continue if it is an acceptable download size. Option 2. Download Specific AOI from Basemap(s) To download a subset of your Basemap(s) based on an area of interest, select option 2. Then use the draw tools to define your area of interest. Once your AOI is set, select \"Find Quads\" . This will query Planet's Basemaps API to find all the quads across the Basemap instances you selected for download. Select the quads you'd like to download and then select \"Next\" . Provide a name for your download. Selecting the option to \"create virtual layer\" will generate a mosaiced .vrt layer for your Basemap quads. To open your download, navigate to the Orders Panel and select \"download\" option next to the name of your Basemap Quad order. Option 3. Create Streaming Connection(s) You can also establish a XYZ tile connection to your QGIS catalog for your Planet Basemap(s). Open your QGIS \"Browser\" panel to locate your \"XYZ Tile\" connections. XYZ tiles are a protocol that describes how a mapping client (like QGIS) can access tiled imagery. E.g., OpenStreetMap is usually available as a XYZ tile connection by default in most versions of QGIS. You can learn more about Planet's XYZ tile services here . When establishing a streaming connection, you will have options to specify a processing option, which will apply a spectral index or false color visualization to your SR Basemap. Setting a processing option will apply that visualization as a default for your streaming connection, however, you will still be able to change to a different processing option when you add the streaming connection to your map (and you remain logged in the Planet Plugin). You can also specify a Min/Max zoom level that you'd like to set your Basemap streaming service to. Setting a min/max zoom level will restrict pixel rendering to only those zoom levels.","tags":"integrations-qgis","url":"https://developers.planet.com/docs/integrations/qgis/discover-basemaps/","loc":"https://developers.planet.com/docs/integrations/qgis/discover-basemaps/"},{"title":"Discover Imagery in ArcGIS","text":"Overview The search, stream and download capabilities for Planet imagery are organized in the Planet Imagery Search Panel in ArcGIS that can be pulled up by selecting the Image Search icon from the Planet Imagery ribbon. The Image Search Panel includes images acquired by Planet's SkySat, PlanetScope, and RapidEye constellations. It also includes open imagery archives like images acquired from LandSat and Sentinel satellites. Search for imagery To search for imagery, the only required field is an area of interest (aoi), or alternatively a specific Image ID. On the Planet Imagery Search Panel there are multiple options for selecting an area of interest: e.g., selecting the current map extent, the extent of all active layers in your Pro map, drawing a specific area of interest, or using a selected feature to define a polygon aoi. Once an area of interest has been set, you can directly search for Planet imagery within ArcGIS. To further refine your search results, select the \"Filters\" tab to the left of the \"Search\" button on the Search Panel. This will open a new panel just for refining your imagery search filters. For example, you can specify a min/max cloud cover threshold, spectral bands, a time of interest, a specific satellite constellation, etc. Once you are happy with your filters, simply press \"<- Back\" from the top-left and \"Search\" from the Imagery Search Panel. This will display a list of images that match your search criteria. Imagery search results are grouped by date and product type. You can explore your search results even further by selecting the drop down arrows left of each result. This will show each individual image that is included in that set of date and product results. Hover over each image result to see a pop-up window containing the image's full metadata. Additionally by selecting the configure results metadata card above the search results, you can adjust the default metadata fields that are displayed for each individual image so that you can inspect each result in greater detail and display the metadata most important to your curation. Version 2.2 image search updates In 2.2, you won't see PSScene3Band or PSScene4Band imagery types anymore in the Imagery Search Panel filters. Instead, you'll be able to search for 3, 4, and 8-band PlanetScope imagery using PlanetScope Scene and applying spectral band filters. Search for PlanetScope imagery by bands In the new image search panel, you'll be able to search for PlanetScope imagery by selecting \"PlanetScope Scene\". To filter your results to see images that have at least 4 spectral bands (vis, NIR) select the \"Near-infrared (NIR)\" check-box under the \"PlanetScope Only Filters\". Applying this filter returns images that have at least visible and near-infrared bands, but may also have coastal blue, green II, yellow and red edge bands. To filter your results to only 8-band PlanetScope images, select the \"Coastal blue, green II, yellow, red edge\". Once applied, this returns only PlanetScope images that have 8 spectral bands. Note that you cannot select \"Coastal blue, green II, yellow, red edge\" without also selecting \"Near-infrared (NIR)\" because NIR data is included in 8-band images. Search for PlanetScope imagery by other filters You can further refine your search using the \"Instrument Filters\" to see PlanetScope images specific to PlanetScope satellite sensors like Dove Classics, Dove Rs, and Super Doves. Earliest Dove Classic (PS2) imagery available on July, 2014 to April 29, 2022. Earliest Dove R (PS2.SD) imagery available is on March, 2019 to April 22, 2022. Earliest Super Dove (PSB.SD) imagery available is mid-March, 2020 to current monitoring. Under \"Advanced Filters\", you'll find additional filtering options such as \"Include only surface reflectance\" that, once applied, only return PlanetScope (or SkySat) images that have a surface reflectance asset. Save search Users executing a similar imagery search many times may be interested in saving that search so that it is easier to recreate. Planet ArcGIS Add-In users can now save their search, which preserves their search filters including their AOI, by selecting the save icon above the search results. Give your search a name and specify if you'd like to remove the start or end date. Removing the end-date, for example, ensures your saved search applies to new imagery as it becomes available. Save Searches are portable across the Planet Platform. i.e., Saving a search in ArcGIS will allow you to access that same saved search in Planet Explorer, and vice versa. Updating saved searches to PlanetScope Scene For saved searches created using legacy item types like PSSscene4Band or PSScene3Band you will be prompted to update to the new PlanetScope scene item type. If your saved search was created for 4-band images, updating to PlanetScope scene applies the \"Near-infrared (NIR)\" filter. Stream preview imagery For each search result, you can stream preview images into Pro by selecting the \"Add images to map\" icon right of each search result. We refer to these image tiles as \"previews\" because they are \"browse\" quality tile layers that are not full-resolution or full-bit depth and don't contain any multi-spectral information. Users can also stream multiple results to their ArcGIS Pro map as preview layers by selecting each result and then clicking the \"Add all preview layers to the map\" icon above the search results. Order and download imagery ArcGIS Add-In users can download Planet imagery directly within ArcGIS Pro. Ordering and downloading imagery will provide access to full bit-depth, multi-spectral geotiff(s) for your selected imagery scenes. To place an Imagery Order, select the images you'd like to download from the Image Search panel using the check-boxes left of each image. Then select \"Order\" from the bottom-right of the Imagery Search Panel. This will pop open an Order Imagery window in ArcGIS Pro. This will pop open an Order Imagery window in ArcGIS Pro. This window will walk you through 3 steps to download your images. This order checkout process is new to the Add-In with V2.1. Step 1.) Name your Order. Give your order a name, and optionally if the default asset selection on the right hand side is what you'd like to order, you can go ahead and click Order and be done at Step 1. Step 2.) Select Assets. Select from a list of \"rectified assets,\" or expand the \"Show More\" drop down list to select \"unrectified\" assets. Step 3.) Tools and Review. Review your order by screening the selected thumbnails, and optionally select to \"clip\" your images to your AOI(s). Clip in the ArcGIS Add-In now supports arbitrary polygons as well as multipolygons, so long as the vertices count is less than 500. Once an order has been placed you can monitor your order and download it (once available for download) from the Planet Order Status Panel. The Order Status Panel will include orders for imagery scenes and Basemap quads. Once an imagery scene is available for download a \"Download\" button will be available for the Order. If you've already downloaded an order before, there will be an option to \"Re-Download\" . You can also \"Open order folder\" which will open the file location you originally downloaded the imagery to. The Order Status Panel in 2.1+ will also include metadata about your order, including the Order ID, which will link out to the Planet's Order Status page where you can find even more details about your Order Status and inspect issues if any occur. Add imagery to your map Once your order has finished processing you can download or \"add to map\". Adding to map using the button provided in the Order Status Panel will automatically render your data in true color RGB.","tags":"integrations-arcgis","url":"https://developers.planet.com/docs/integrations/arcgis/discover-imagery/","loc":"https://developers.planet.com/docs/integrations/arcgis/discover-imagery/"},{"title":"Discover Planet Imagery in QGIS","text":"Overview Planet QGIS Plugin users can search, stream, and download Planet imagery in the Planet Imagery Search Panel in QGIS. Access the panel by selecting the magnifying glass icon from the Planet QGIS Plugin Toolbar. The Imagery Search Panel includes images acquired by Planet's SkySat, PlanetScope, and RapidEye constellations. It also includes open imagery archives, such as images acquired from LandSat and Sentinel satellites. Search for imagery To search for imagery, the only required field is an area of interest (AOI) or, alternatively, a specific Image ID. On the Planet Imagery Search Panel, there are multiple options for selecting an AOI. For example, you can select the current map extent or the extent of all active layers in your QGIS map, draw a specific area of interest, or use a selected feature to define a polygon AOI. Once an AOI has been set, you can directly search for Planet imagery within QGIS. To further refine your search results, select the \"Filter Results\" tab to the left of the \"Search\" button on the Search Panel. Filter Results is a new panel just for refining your imagery search filters. For example, you can specify a min/max cloud cover threshold, spectral bands, a time of interest, or a specific satellite instrument. Once you are happy with your filters, simply press \"<- Back\" from the top-left and then \"Search\" from the Imagery Search Panel. Doing so returns a list of images that match your search criteria. Version 2.2 image search updates Note In version 2.2 of the Planet QGIS Plugin, you won't see PSScene3Band or PSScene4Band imagery types anymore in the Imagery Search Panel filters. Instead, you'll be able to search for 3-, 4-, and 8-band PlanetScope imagery using PlanetScope Scene, and applying spectral band filters. Search by bands In the new image search panel, you can search for PlanetScope imagery by selecting \"PlanetScope Scene.\" To filter your results to see images that have at least four spectral bands (visual plus NIR), select the \"Near-infrared (NIR)\" check-box under the \"PlanetScope Only Filters.\" Applying this filter returns images that have at least visible and near-infrared bands, but may also have coastal blue, green II, yellow and red-edge bands. To filter your results to images that have all eight bands, select the \"Coastal blue, green II, yellow, red edge.\" Once applied, only 8-band PlanetScope images are returned. Note You cannot select \"Coastal blue, green II, etc\" without also selecting \"Near-infrared (NIR),\" because NIR data is included in 8-band images. Search by other filters You can further refine your search using the \"Instrument Filters\" to see PlanetScope images specific to PlanetScope satellite sensors, such as Dove Classic, Dove R, and Super Dove. Earliest Dove Classic (PS2) imagery available on July, 2014 to April 29, 2022. Earliest Dove R (PS2.SD) imagery available is on March, 2019 to April 22, 2022. Earliest Super Dove (PSB.SD) imagery available is mid-March, 2020 to current monitoring. Under \"Advanced Filters,\" you'll find additional filtering options such as \"Include only surface reflectance\" that, once applied, only return PlanetScope (or SkySat) images that have a surface reflectance asset. Save search Planet QGIS Plugin users can save their search by selecting the save icon above the search results. Saving a search preserves search filters and the search AOI. This may be helpful and save time if you find that you're repeating the same search. Give your search a name and specify if you'd like to remove the start or end date. Removing the end date ensures your saved search applies to new imagery as it becomes available. Removing the start date will provide access to everything your account has access to up until the set end date. Save searches are portable across the Planet Platform. Saving a search in QGIS allows you to access that same saved search in Planet Explorer and Planet APIs, and vice versa. Updating saved searches to PlanetScope Scene For saved searches created using legacy item types, such as PSSscene4Band and PSScene3Band, you are prompted to update to the new PlanetScope scene item type. If your saved search was created for 4-band images, updating to PlanetScope scene applies the \"Near-infrared (NIR)\" filter. Updating is optional but to get the benefits of the new PlanetScope scene bands and radiometric improvements, it's encouraged! Inspect search results Imagery search results are grouped by date and product type. You can explore your search results even further by selecting the drop-down arrows to the left of each result. The drop-down list shows each individual image included in that date and product result group. Pro Tip By selecting the settings gear icon above the search results, you can adjust the default metadata fields displayed for each individual image. These settings allow you to inspect each result in greater detail and display the metadata most important to your curation. Stream preview imagery Planet QGIS Plugin users can place preview images and multiple results into the QGIS map. To stream preview images into your QGIS map: select the \"Add preview layer to map\" icon to the right of each search result. We refer to these image tiles as \"previews,\" because they are \"browse\" quality tile layers, are not full-resolution or full-bit depth, and don't contain any multispectral information. To stream multiple results into your QGIS map as preview layers: select each result, then click the \"Add all preview layers to the map\" icon above the search results. Download imagery Planet QGIS Plugin users can download Planet imagery directly within their QGIS workflows. Ordering and downloading imagery provide access to full bit-depth, multispectral GeoTIFF(s) for your selected imagery scenes. Note The order checkout process is new to the Add-In with V2.1. To access the Imagery Order window in QGIS: Select the images you'd like to download from the Image Search panel using the check-boxes left of each image. Select \"Order\" from the bottom-right of the Imagery Search Panel. The Order Imagery window opens and walks you through three steps to download your images: Step 1. Name your Order. Give your order a name. If the default asset selection on the right is what you'd like to order, click Order to skip steps 2 and 3. Step 2. Select Assets. Select from a list of \"rectified assets,\" or expand the \"Show More\" drop-down list to select \"unrectified\" assets. Step 3. Tools and Review. Review your order by screening the selected thumbnails, and optionally select to \"clip\" your images to your AOI(s). Note As of V2.1, the Clip feature in the Planet QGIS Plugin supports arbitrary polygons as well as multipolygons, so long as the vertices count is less than 500. Clipping is not supported on unrectified assets. Once an order has been placed, you can monitor your order and download it (once available for download) from the Order Status Panel. The Order Status Panel will include orders for imagery scenes and Basemap quads. Once an imagery scene is available for download, a \"Download\" button will be available for the Order. If you've already downloaded an order before, there is an option to \"Re-Download\" . You can also select \"Open order folder,\" which opens the file location you originally downloaded the imagery to. The Order Status Panel in 2.1+ also includes metadata about your order, including the Order ID, which links out to the Planet's Order Status page. The Order Status page provides more details about your order status and any issues.","tags":"integrations-qgis","url":"https://developers.planet.com/docs/integrations/qgis/discover-imagery/","loc":"https://developers.planet.com/docs/integrations/qgis/discover-imagery/"},{"title":"How To Download Basemap Quads","text":"A basemap quad is a single square GeoTIFF, many of which together comprise a mosaic. In Basemap Viewer, you can download quads one at a time. Define an Area To inspect a smaller area in greater detail, you can either select a point, draw an area, or upload a geometry. These options can be found in the upper left hand corner of the modal once you have selected a basemap. Select a Point Selecting a Point is the default option. You can click on the map and a pin will be dropped onto the map. If you'd like to change the pin's location, click on another part on the map. Draw an Area You can choose to draw an area rather than clicking on a single point. You will see three options in the top header of the left hand toolbar. The second option is to Draw Area . Select Draw Area and then draw an area on the map by holding down your mouse until you have the desired polygon. Upload File You can also choose to upload a geometry. You will see three options in the top header of the left hand toolbar. The third option is to Upload File . Select Upload File and then upload a geojson file from your computer. Download Basemap Quads Once you have defined your area of interest (either by selecting a point, drawing an area, or uploading a file), you will see a list of quads in the left hand menu. Click on the quad you are interested in. Once you click on the quad, you will see the coordinates of your selected location and the ID of your selected quad. Next to the ID, you will see three icons. The second icon in the shape of an arrow is the Download icon. Click on the second Download icon to download the tif. It should automatically download onto your computer.","tags":"apps-basemapsviewer","url":"https://developers.planet.com/docs/apps/basemapsviewer/download-basemaps/","loc":"https://developers.planet.com/docs/apps/basemapsviewer/download-basemaps/"},{"title":"Downloading Quads from a Mosaic using Basemaps API","text":"Overview The purpose of this tutorial is to provide a user-friendly way to use Planet's Basemaps API to download all quads to a folder in their directory. How To Get Started Before we jump into downloading the quads, let's quickly review the required packages for utilizing this tutorial. Imports requests os json Your Planet API Key urllib.request Setup Session Using Basemaps API The first step is to setup a session to access the basemaps API. The basemaps API can be used to download full mosaics, or in our case, to download individual parts of the mosaic known as quads. Create Session to Access API In order to access the basemaps API, we need a Planet API key for successful authentication. In this case, the API key is saved to a config file and imported into the python script, but feel free to use your API key directly in the notebook if you are following along. import requests import config #setup API KEY PLANET_API_KEY = '' # <= insert API key here #setup Planet base URL API_URL = \"https://api.planet.com/basemaps/v1/mosaics\" #setup session session = requests.Session() #authenticate session.auth = (config.PLANET_API_KEY, \"\") #<= change to match variable for API Key if needed Send Request and Check Status Code When sending the request, we will provide one parameter. Assuming we know the name of the mosaic, we can include those details in the request to access the corresponding metadata. After sending the request, let's check the status code to ensure it was successful. #set params for search using name of mosaic parameters = { \"name__is\" :\"nsw_ps_1month_date_ramp_L15_mosaic\" # <= customize to your use case } #make get request to access mosaic from basemaps API res = session.get(API_URL, params = parameters) #response status code print(res.status_code) 200 Access Mosaic MetaData The metadata for each mosaic is necessary to access the quads. Specifically, we need to extract the mosaic id and bbox to search for the quads within our area of interest. In this tutorial we are using the AOI from the entire mosaic to download all quads, but those values can be customized for your use case. Further Examine the JSON Object import json #print metadata for mosaic mosaic = res.json() print(json.dumps(mosaic, indent=2)) { \"_links\": { \"_self\": \"https://api.planet.com/basemaps/v1/mosaics?api_key=PLANET_API_KEY\" }, \"mosaics\": [ { \"_links\": { \"_self\": \"https://api.planet.com/basemaps/v1/mosaics/e8cd50a5-e9dc-4278-a8f3-1c2475b452c5?api_key=PLANET_API_KEY\", \"quads\": \"https://api.planet.com/basemaps/v1/mosaics/e8cd50a5-e9dc-4278-a8f3-1c2475b452c5/quads?api_key=PLANET_API_KEY&bbox={lx},{ly},{ux},{uy}\", \"tiles\": \"https://tiles.planet.com/basemaps/v1/planet-tiles/nsw_ps_1month_date_ramp_L15_mosaic/gmap/{z}/{x}/{y}.png?api_key=PLANET_API_KEY\" }, \"bbox\": [ 141, -38, 154, -28 ], \"coordinate_system\": \"EPSG:3857\", \"datatype\": \"byte\", \"first_acquired\": \"2017-08-25T00:00:00.000Z\", \"grid\": { \"quad_size\": 2048, \"resolution\": 4.777314267823516 }, \"id\": \"e8cd50a5-e9dc-4278-a8f3-1c2475b452c5\", \"item_types\": [ \"PSScene3Band\" ], \"last_acquired\": \"2017-09-25T00:00:00.000Z\", \"level\": 15, \"name\": \"nsw_ps_1month_date_ramp_L15_mosaic\", \"product_type\": \"basemap\", \"quad_download\": true } ] } Get ID and Bbox Values from Mosaic #get id mosaic_id = mosaic['mosaics'][0]['id'] #get bbox for entire mosaic mosaic_bbox = mosaic['mosaics'][0]['bbox'] #converting bbox to string for search params string_bbox = ','.join(map(str, mosaic_bbox)) print('Mosaic id: '+ mosaic_id) print('Mosaic bbox: '+ string_bbox) Mosaic id: e8cd50a5-e9dc-4278-a8f3-1c2475b452c5 Mosaic bbox: 141,-38,154,-28 Search for Mosaic Quads using AOI Now that we have the required metadata, we can send a request to the API for the mosaic's quads. Each quad comes with a download link that we use to save them to our local directory. Setup Request for Quads to Basemaps API We will provide two parameters, a string of bbox values and minimal set to \"True\". The bbox values are required to send the request. The minimal parameter is optional, but we included it because it hides the metadata we don't need for this use case. Lastly, we include the mosaic id in the request url to access quads for this specific mosaic. #search for mosaic quad using AOI search_parameters = { 'bbox': string_bbox, 'minimal': True } #accessing quads using metadata from mosaic quads_url = \"{}/{}/quads\".format(API_URL, mosaic_id) res = session.get(quads_url, params=search_parameters, stream=True) print(res.status_code) 200 Quads Metadata The quad response object contains the download link and bbox values for each portion of the grid. Each quad also has a unique identifier which we will use to name the quads as we save them to our local directory. quads = res.json() items = quads['items'] #printing an example of quad metadata print(json.dumps(items[0], indent=2)) { \"_links\": { \"download\": \"https://api.planet.com/basemaps/v1/mosaics/e8cd50a5-e9dc-4278-a8f3-1c2475b452c5/quads/3794-1715/full?api_key=PLANET_API_KEY\" }, \"bbox\": [ 153.45703125, -28.07198030177986, 153.544921875, -27.994401411046145 ], \"id\": \"3794-1715\", \"percent_covered\": null } Download Quads to Local Directory The final step to this tutorial is taking the download link from the metadata and saving those files to your local directory by id number. We do this by iterating over the json object and using urllib to retrieve the file via the download link. import os import urllib.request #iterate over quad download links and saving to folder by id for i in items: link = i['_links']['download'] name = i['id'] name = name + '.tiff' DIR = 'quads/' # <= a directory i created, feel free to customize filename = os.path.join(DIR, name) #checks if file already exists before s if not os.path.isfile(filename): urllib.request.urlretrieve(link, filename) Conclusion After a few simple steps, we now have a folder full of quads within our local directory. Check out our Planet Basemaps API Documentation to learn more. If you'd like to access the full .py script, follow this link . Questions or comments about this guide? Join the conversation at Planet Community .","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/downloading-quads-from-a-mosaic-using-basemaps-api/","loc":"https://developers.planet.com/docs/planetschool/downloading-quads-from-a-mosaic-using-basemaps-api/"},{"title":"Downloading Imagery with Data API","text":"Overview This API Quickstart Guide will walk you through how to download your first image from the Planet Data API. See guide \"Getting Started\" guide for instructions on using this guide and acquiring a Planet API key. See Step 1: Searching for Imagery for a guide to searching for images in the Planet API. Downloading a large amount of imagery from our API can be tricky, when you're done with this tutorial you may want to check out: Large AOI Best Practices . Accessing a Single Item In the last section, we learned how to search for items that interest us. Items are identified by their ItemType and ItemId, here is one of the items from our Guide to Searching for Imagery . ItemType: REOrthoTile ItemId: 20160707_195147_1057916_RapidEye-1 An easy way to visualize this item before we download it would be to extract its geometry coordinates and view its footprint in geojson.io: curl -L -H \"Authorization: api-key $PL_API_KEY\" \\ 'https://api.planet.com/data/v1/item-types/REOrthoTile/items/20160707_195147_1057916_RapidEye-1' \\ | jq '.geometry' | geojsonio Asset Types In general, a single satellite image can be provided in many different formats for different use cases. Some users might want color corrected products that can be viewed on the web, some might want raw image data for scientific purposes. In the Planet Data API, these different item options are called Assets and items usually have multiple asset types. We can see what asset types are availiable for a certain item by adding /assets to the item url. curl -L -H \"Authorization: api-key $PL_API_KEY\" \\ 'https://api.planet.com/data/v1/item-types/REOrthoTile/items/20160707_195147_1057916_RapidEye-1/assets' \\ | jq 'keys' [ \"analytic\", \"analytic_xml\", \"udm\", \"visual\", \"visual_xml\" ] Asset Activation An important thing to know about the API is that it does not pre-generate Assets so they are not always immediately availiable to download. You can see that the visual asset for this item has the status \"inactive\", so we need to activate it. curl -L -H \"Authorization: api-key $PL_API_KEY\" \\ 'https://api.planet.com/data/v1/item-types/REOrthoTile/items/20160707_195147_1057916_RapidEye-1/assets/' \\ | jq .visual.status \"inactive\" Depending on the amount of Assets you want to activate, the activation step can take time to complete. A best practice is to activate your desired items and then periodically check the status until it becomes \"active\". In practice, you will probably need to activate several assets at a time. But for now, let's just activate one: examples/activation.py import os import requests item_id = \"20160707_195147_1057916_RapidEye-1\" item_type = \"REOrthoTile\" asset_type = \"visual\" # setup auth session = requests.Session() session.auth = (os.environ['PL_API_KEY'], '') # request an item item = \\ session.get( (\"https://api.planet.com/data/v1/item-types/\" + \"{}/items/{}/assets/\").format(item_type, item_id)) # extract the activation url from the item for the desired asset item_activation_url = item.json()[asset_type][\"_links\"][\"activate\"] # request activation response = session.post(item_activation_url) print response.status_code ➜ python examples/activation.py 204 # HTTP 204: Success, No Content to show Asset Downloading Let's check on our asset ➜ curl -L -H \"Authorization: api-key $PL_API_KEY\" \\ 'https://api.planet.com/data/v1/item-types/REOrthoTile/items/20160707_195147_1057916_RapidEye-1/assets/' \\ | jq .visual.status \"active\" # perfect Now that the visual asset is active, we can finally get to the good stuff, downloading the image. When an asset is active the direct link to download is present on the asset object in the \"location\" field: ➜ curl -L -H \"Authorization: api-key $PL_API_KEY\" \\ 'https://api.planet.com/data/v1/item-types/REOrthoTile/items/20160707_195147_1057916_RapidEye-1/assets/' \\ | jq .visual.location \"https://api.planet.com/data/v1/download?token=eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJwUDNCNU9aYVFKUnN2WGsydmF3UVpLL2ZWci9DZWk0bG82OGJuT2NRR2laZ01EcFBTUnpsSWdHNGlZM2R5YTZWQ2xHdDROeFBka29Kb295a1BvdktPUT09IiwiaXRlbV90eXBlX2lkIjoiUkVPcnRob1RpbGUiLCJ0b2tlbl90eXBlIjoidHlwZWQtaXRlbSIsImV4cCI6MTQ3Mzc1MDczOCwiaXRlbV9pZCI6IjIwMTYwNzA3XzE5NTE0N18xMDU3OTE2X1JhcGlkRXllLTEiLCJhc3NldF90eXBlIjoidmlzdWFsIn0.lhRgqIggvnRoCgUVX3hgaNYDQIdU09wVaImxv3a_vuGjfzC7_OteYeViboeiZYBH2_eMdWT5ZWDz2BZiAWkXlQ\" You can CURL that direct link or copy it into a web browser to download the image. ➜ curl -L -H \"Authorization: api-key $PL_API_KEY\" \\ 'https://api.planet.com/data/v1/download?token=eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJwUDNCNU9aYVFKUnN2WGsydmF3UVpLL2ZWci9DZWk0bG82OGJuT2NRR2laZ01EcFBTUnpsSWdHNGlZM2R5YTZWQ2xHdDROeFBka29Kb295a1BvdktPUT09IiwiaXRlbV90eXBlX2lkIjoiUkVPcnRob1RpbGUiLCJ0b2tlbl90eXBlIjoidHlwZWQtaXRlbSIsImV4cCI6MTQ3Mzc1MDczOCwiaXRlbV9pZCI6IjIwMTYwNzA3XzE5NTE0N18xMDU3OTE2X1JhcGlkRXllLTEiLCJhc3NldF90eXBlIjoidmlzdWFsIn0.lhRgqIggvnRoCgUVX3hgaNYDQIdU09wVaImxv3a_vuGjfzC7_OteYeViboeiZYBH2_eMdWT5ZWDz2BZiAWkXlQ' \\ > redding.tiff You should now be the proud owner of a brand new visual RapidEye asset. high res tiff Next Guide: Best practices when working with large AOIs","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/downloading-imagery-with-data-api/","loc":"https://developers.planet.com/docs/planetschool/downloading-imagery-with-data-api/"},{"title":"Early Access Program","text":"Planet's Subscriptions API Early Access Program is available to select Planet customers interested in testing and sharing feedback on our Beta API. If you're interested in participating, please reach out to your Account Manager or submit a request to support. Overview Program Timeline The Early Access Program begins on July 30th, 2020 . Hour-long feedback sessions, in exchange for early access, will be scheduled for the week of August 31st, 2020 . Following feedback and implementation, the Subscriptions API will be made generally available to all customers later in the year. Program Details Cost : There is no cost to use the Subscriptions API in Early Access Beta, or upon General Availability. All Planet customers will have access to the Subscriptions API when fully released. Quota : We are able to offer quota credits for Subscriptions API testing, for those customers who request it. Weekly Release Notes Over the course of the Early Access period we may make changes to the API based on feedback from Early Access customers. During this period, Early Access customers can expect weekly release notes from the Subscriptions API Product Team, which will announce upcoming changes and additive features or improvements. Any breaking API changes will be announced at least 2 full business days before they are put into production.","tags":"subscriptions","url":"https://developers.planet.com/docs/subscriptions/eap/","loc":"https://developers.planet.com/docs/subscriptions/eap/"},{"title":"This is an example webinar","text":"if we need to add webinars to their own pages we can do that here by tags : webinar and it will show up in the NICFI Users Resource Page","tags":"nicfi","url":"https://developers.planet.com/docs/nicfi/this-is-an-example-webinar/","loc":"https://developers.planet.com/docs/nicfi/this-is-an-example-webinar/"},{"title":"Examples","text":"The Planet Tasking API is a REST based API, which can be integrated into any service, regardless of the language used. Authentication The Planet API uses Basic HTTP Authentication and requires that you have a Planet API key. To obtain an API key for Planet's high resolution tasking, please contact a Planet sales representative. Once you have an API key, it should be added into the headers of any request made to the Tasking API endpoints. If using curl then the following would be an example of this: --header 'authorization: api-key <YOUR_API_KEY>' An example of Basic HTTP Authentication with Python is included below: import os # import os module to access enviornmental modules import requests from requests.auth import HTTPBasicAuth # import helper functions to make Basic request to Planet API PLANET_API_KEY = os.getenv('PL_API_KEY') # Setup the API Key from the `PL_API_KEY` environment variable BASE_URL = 'https://api.planet.com/tasking/v2/orders/' if PLANET_API_KEY is None: PLANET_API_KEY = '12345' #pass in your API key auth = HTTPBasicAuth(PLANET_API_KEY, '') # HTTPBasicAuth() wants a username & password; you can pass an empty string for the password res = requests.get(url=BASE_URL, auth=auth) print(res.status_code) # make a request to the Tasking API and test response Formatting All requests and responses use the JSON format, and uses snake_case as the naming convention. Headers The only header, apart from the Authorization header as mentioned above, that is required is the content-type, which should look like this: --header 'Content-Type: application/json' GeoJSON All the geographical coordinate definitions in the Tasking API follow the GeoJson format Version The current version of the API can be found via the url https://api.planet.com/tasking/v2/version.txt","tags":"tasking","url":"https://developers.planet.com/docs/tasking/examples","loc":"https://developers.planet.com/docs/tasking/examples"},{"title":"FAQ","text":"Google Earth Engine Delivery Frequently Asked Questions Ordering Questions Do I need download quota to deliver imagery to Earth Engine? Yes, delivery to GEE requires and consumes download quota. Which raster operations are supported by Planet's GEE Delivery Integration? The Planet GEE Delivery tool supports both the clip and harmonization orders operation tools. Note : Harmonization is only available for surface reflectance PlanetScope Scenes (PSScene) bundles. What is the Max Order size to GEE? The max order size depends on your Orders plan and how much quota you have for download. Max order size can range from 500 to 2000 assets per order. What is an appropriate scale for Planet GEE Delivery Integration usage? With the default Planet Service Account, the ingest queue can fill up with large orders. Planet recommends a limit of approximately 1000 assets delivered per organization, per day. There is also an option to bring their own service account for a dedicated queue with greater scalability. Some personal Google accounts are capped at 250 Gb (the limit is set by Google). Do I have to pay for Google Cloud Storage to use the GEE Delivery Integration? The Planet Delivery Integration sends imagery directly to your GEE account. It does not require you to set up or pay for cloud storage. Which Planet Items and Assets are supported by the GEE Delivery Integration? Item Type Supported Order Bundles Limitations PSScene analytic_8b_sr_udm2, analytic_sr_udm2, analytic_8b_udm2, analytic_udm2, visual The harmonization order operation can only be used on PSScene SR assets PSScene4Band analytic, analytic_sr, analytic_udm2, analytic_sr_udm2 SkySatScene analytic, analytic_udm2, analytic_sr_udm2, visual, pansharpened_udm2, panchromatic_dn_udm2 SkySatCollect analytic, analytic_udm2, analytic_sr_udm2, visual, pansharpened_udm2, panchromatic_dn_udm2 SkySatCollects may take an hour per item to ingest Are Planet Basemaps supported? Basemaps are not currently supported. What happens to images that are ordered twice to the same Image Collection? Planet GEE Delivery Integration overwrites image assets ordered to the same image collection. Download quota is deducted. Why is my delivery to GEE taking longer than my Orders API request? There is a hand-off from the Planet API to the GEE API. The following are approximate estimates of how long orders take: 15 minutes for PlanetScope assets 30 minutes for SkySat assets However, these Note : The estimated order time depends on several factors, including order size and network traffic to GEE. Estimations are not assured by a Planet SLA. What permissions must be granted to the Planet Service Account for delivery to Earth Engine? To write to an EE account, the Planet Google Service Account (SA) must have the EE Resource Writer IAM role. The Resource Writer role provides read/write access to an EE Cloud Project. Create a separate Cloud Project account without Read access for sensitive or proprietary data. Data Questions How are the UDM2 bands organized when delivered to an EE image collection? Planet's GEE Delivery Integration appends UDM bands to each image in your Image Collection. So for example, if you ordered a PSScene4Band Item Type with the analytic_sr_udm bundle, your resulting image would have 12 bands (4 spectral, 8 UDM bands). Bands Description B1 Blue B2 Green B3 Red B4 NIR Q1 Clear Map Q2 Snow Map Q3 Shadow Map Q4 Light Haze Map Q5 Heavy Haze Map Q6 Cloud Map Q7 Confidence Map Q8 Usable Pixels Note that PSScene 8-bands are ordered as: Bands Description B1 Coastal blue B2 Blue B3 Green II B4 Green B5 Yellow B6 Red B7 Red edge B8 NIR To learn more about the UDM2 bands, see Planet's Dev Docs here . How does ingesting imagery to GEE change Planet data? The following are examples of how GEE delivery changes Planet data: EE constructs image pyramids during ingest by using the GEE default Mean pyramiding scheme since datasets are continuous. Ingesting imagery to GEE reprojects your images to Maps Mercator EPSG:3857. More information on the GEE imagery upload processes is available at, Image Upload . Other Questions How can I test the Planet GEE Delivery Integration? To test the GEE Delivery Integration, sign up at the Planet Developer Program . Planet will provideyou with the API and enough download quota for the integration. Students or researchers can apply for data access by using the Education and Researh Program . Planet accounts with download quota can use the GEE Delivery Integration.","tags":"integrations-gee","url":"https://developers.planet.com/docs/integrations/gee/faq","loc":"https://developers.planet.com/docs/integrations/gee/faq"},{"title":"Frequently Asked Questions","text":"Developer Program I signed up for the Developer Program. What is included? Developer Program users can see previews of Planet's imagery, anywhere around the world. Your Planet Account is open for 90 days. Within 90 days, you can stream up to 10,000 daily scene tiles and 10,000 basemap tiles. Once you run out of tiles in your trial, you will see a watermark and will only be able to preview thumbnails with limited zoom on the map. You can see how many tile views you have used by referencing the My Usage tab under Settings. You receive a notification when you've used 80% of your tiles. To download your usage report, go to the Usage tab on your account page. In addition to previewing Planet's imagery catalog all over the world, check out full-resolution scenes (we call this \"hosted data\"). This will give you a better sense of resolution. You can use bandmath and color balancing tools on this data. Go to the My Hosted Data tab on the left-hand toolbar and click on Demo Data to take a look at these examples. Searching for Imagery When do I start consuming tiles? When you log into Planet Explorer, a 2018 Planet Basemap loads as a reference for navigation, which does not consume tiles. You start to consume tiles once you have clicked on an image. How do I check how much quota I have left in my plan? You can check your tile view quota and how much remaining budget you have from your Planet Account page. Planet recommends that you check at the end of the month to see how much of your quota is used. When uploading an area of interest (AOI) file, what projection should I use? Projecting data is a key component of successfully combining your data and the imagery found in Planet Explorer. Upload a Shapefile, WKT, GeoJSON, or KML file. Make sure your data is in WGS 84 (SRID/EPSG:4326). How do I upload files with complicated areas of interest (AOI)? When you import a file and define an area of interest, files with multi-polygons or polygons with over 500 vertices must be simplified to order imagery. Planet Explorer guides you through the order process so that you can define your area of interest and select which shapes you would like to use for your area of interest. You can can simplify your area of interest by selecting one of the auto-generated options. Supported file types include shapefile, GeoJSON, JSON, Keyhole Markup Language (KML), Well Known Text (WKT), GPX, DBF, SHX, PRJ, and ZIP files. What does the error \"Invalid Geometry\" mean when uploading an AOI file to the Explorer? The error \"invalid geometry\" means that the projection of your file is not in WGS 84 (commonly referred to as latitude/longitude). The way to fix this error is to re-project your data into WGS 84 (SRID/EPSG: 4326) projection. How can I find SuperDove imagery? If you would like to view SuperDove imagery, first draw your area of interest. When you see the search panel, click on Filters and select the grouping called Other Attributes . Under Instrument Filter , select PSB.SD as the instrument filter. Why can't I find PSScene3Band and PSScene4Band in Explorer anymore? There is a new way to search for PlanetScope Scenes. Now, instead of searching for PSScene3Band or PSScene4Band separately, you can search for PSScene and select the band capabilities you need separately. Band filters include a filter for NIR (\"4-band\"), as well as Coastal Blue, Green II, Yellow, Red-Edge (\"8-band\"). What are the default search filters in Planet Explorer? By default, you will see PlanetScope imagery that has at least NIR capabilities (\"4-band\"), as this is the most common use case. This includes imagery from Planet's Dove-Classic, Dove-R, and Super-Dove constellations, but is not inclusive of Planet's entire archive because some imagery from Dove-Classic does not have NIR capabilities. Earliest PS2 imagery available on July, 2014 to April 29, 2022. Earliest PS2.SD imagery available is on March, 2019 to April 22, 2022. Earliest PSB.SD imagery available is mid-March, 2020 to current monitoring. How do I filter results to view only Coastal Blue, Green II, Yellow, Red-Edge capabilities? If you would like to see imagery that has \"8-band\" capabilities, go to the PlanetScope filters section and select Coastal Blue, Green II, Yellow, Red-Edge . This selection shows imagery captured by our Super-Dove constellations. How do I filter results to view Planet's entire PlanetScope archive? Planet Explorer will default to having the NIR band filter selected, to show only imagery that includes NIR capabilities (which is the majority of Planet's catalog). If you would like to see Planet's entire PlanetScope catalog, make sure that PSScene is selected under Imagery and unselect the NIR band capability under Planetscope filters. This will be relevant to you if you are looking for older imagery, deep into the archive. How does searching and filtering impact what I see when I'm ready to order imagery? What you filter on will impact the options you see when ordering. When you are ordering imagery, you will see a menu of available assets based on the capabilities of the imagery you selected; the menu shows only those assets that are in common for all of the imagery that you selected. For example: If you filter on PSScene and NIR capabilities, you should expect to see Visual and Surface-Reflectance 4-band assets, with the Surface-Reflectance 4-band asset chosen by default at order time. If you filter on PSScene and Coastal Blue, Yellow, Green II capabilities, you should expect to see Visual, Surface-Reflectance 4-band, Surface-Reflectance 8-band, TOAR 4-band, TOAR 8-band assets at order time. The Surface-Reflectance 4-band asset is chosen by default, but you can adjust this according to your use case. Ordering Hosted Data in Explorer Why do I have to order hosted data to get full bit-depth daily scenes in Explorer? How is that different from what I already see in Explorer? When you order hosted data for analysis in Explorer, it contains information beyond the visual attributes (like spectral bands). We process and host the full-resolution, full bit-depth spectral data upon a customer's request. These scenes are different from the search results that you preview in Explorer, which is a compressed JPEG that we add to our imagery catalog, for every image we take everyday. We primarily use the JPEG in Explorer so that you can zoom around and view imagery quickly and efficiently, all over the world. If you would like to inspect a specific area, you can order a scene with more capabilities for further analysis. Can I order any type of scene for analysis in Explorer? Currently, PlanetScope Scenes, RapidEye Orthotile, SkySat Scenes and SkySat Collects are supported. If you order other types of imagery, the order will not go through. We are not currently supporting Landsat or Sentinel data in this feature. Does ordering a scene for analysis in Explorer cost money? Yes, customers will be charged quota for ordering hosted data. If you order hosted data and then download the same scene within 30 days, you will only be charged quota one time. My order for hosted data failed. What should I do? If your order for hosted data fails, try again. If that doesn't work, contact support by submitting a request so that we can troubleshoot. Please make sure to let us know that your order was for hosted data. Tasking a High-Resolution Image I clicked on the link to task a high-resolution image, but I can't log in. What should I do? If your organization has not purchased a plan to task high-resolution imagery, you will not be able to log in to the Tasking Dashboard. Please contact sales to add this capability to your plan or to learn more. If your organization has purchased a tasking plan, but you cannot log in, you must request access. Please click Get Help on the Tasking Dashboard login page to be redirected.","tags":"apps-explorer","url":"https://developers.planet.com/docs/apps/explorer/faqs/","loc":"https://developers.planet.com/docs/apps/explorer/faqs/"},{"title":"Filtering and pagination","text":"The Planet Tasking API is a REST based API, which can be integrated into any service, regardless of the language used. Below are some examples of how to use filters to narrow the responses from the Tasking API /orders and /captures endpoints and how to pagniate when then response contains a large number of elements. Filtering Filtering in the Tasking API is a part of the GET requests made to the /orders and /captures endpoints. The filtering options are mostly similar for each endpoint, so we will be concentrating on the /orders endpoint in these examples. A full list of all the filters available can be found in the Tasking API Reference . Filters in the Tasking API are AND operations, which means that each filter parameter is joined with the previous parameters to narrow down the returned results. The following example request to the tasking/v2/orders endpoint shows two filters (status & name__icontains) as well as pagination and ordering rules for the returned results: https://api.planet.com/tasking/v2/orders/?status=FULFILLED&name__icontains=Order&limit=50&offset=0&ordering=-updated_time,-created_time","tags":"tasking","url":"https://developers.planet.com/docs/tasking/examples/filters","loc":"https://developers.planet.com/docs/tasking/examples/filters"},{"title":"How To Find Basemaps","text":"You will see a menu on the left hand side, with a list of all of the basemaps you have access to. Filter by Cadence You can filter these basemaps based on cadence (i.e. daily, weekly, monthly, quarterly). If a basemap does not fall into a regular cadence, it will be listed under the \"Other\" filter. Search by Location You can search for a basemap by typing in a location into the search bar at the top of the screen.","tags":"apps-basemapsviewer","url":"https://developers.planet.com/docs/apps/basemapsviewer/find-basemap/","loc":"https://developers.planet.com/docs/apps/basemapsviewer/find-basemap/"},{"title":"Beginners GDAL Workflow","text":"Introduction In this tutorial, you will do the following: Mosaic Basemap Quads Clip to an AOI Perform NDVI on the clipped mosaic Before Steps Before we dive into this tutorial, you will need to have downloaded at least 2 quads from an area of your choice. In order to do this, please refer to this tutorial here for using the GUI or here for using API. You will also need to have a polygon feature class for your area of interest which we will use for the clipping section. If you do not have ready, please use the following website to create one easily. Along with the above, you will also need GDAL (Geospatial Data Abstraction Library) and its python bindings installed to run the commands below 1. Mosaic Basemap Quads After downloading the quads from an area of your choice, running the following command will give you the spatial metadata of the quads. !gdalinfo data/L15-0697E-0963N.tif The response should look like below: Driver: GTiff/GeoTIFF Files: L15-0697E-0963N.tif Size is 4096, 4096 Coordinate System is: PROJCS[\"WGS 84 / Pseudo-Mercator\", GEOGCS[\"WGS 84\", DATUM[\"WGS_1984\", SPHEROID[\"WGS 84\",6378137,298.257223563, AUTHORITY[\"EPSG\",\"7030\"]], AUTHORITY[\"EPSG\",\"6326\"]], PRIMEM[\"Greenwich\",0, AUTHORITY[\"EPSG\",\"8901\"]], UNIT[\"degree\",0.0174532925199433, AUTHORITY[\"EPSG\",\"9122\"]], AUTHORITY[\"EPSG\",\"4326\"]], PROJECTION[\"Mercator_1SP\"], PARAMETER[\"central_meridian\",0], PARAMETER[\"scale_factor\",1], PARAMETER[\"false_easting\",0], PARAMETER[\"false_northing\",0], UNIT[\"metre\",1, AUTHORITY[\"EPSG\",\"9001\"]], AXIS[\"X\",EAST], AXIS[\"Y\",NORTH], EXTENSION[\"PROJ4\",\"+proj=merc +a=6378137 +b=6378137 +lat_ts=0.0 +lon_0=0.0 +x_0=0.0 +y_0=0 +k=1.0 +units=m +nadgrids=@null +wktext +no_defs\"], AUTHORITY[\"EPSG\",\"3857\"]] Origin = (-6398696.510913709178567,-1174072.754290983080864) Pixel Size = (4.777314267160000,-4.777314267160000) Metadata: AREA_OR_POINT=Area Image Structure Metadata: COMPRESSION=LZW INTERLEAVE=BAND Corner Coordinates: Upper Left (-6398696.511,-1174072.754) ( 57d28'49.69\"W, 10d29'16.12\"S) Lower Left (-6398696.511,-1193640.634) ( 57d28'49.69\"W, 10d39'38.19\"S) Upper Right (-6379128.632,-1174072.754) ( 57d18'16.87\"W, 10d29'16.12\"S) Lower Right (-6379128.632,-1193640.634) ( 57d18'16.87\"W, 10d39'38.19\"S) Center (-6388912.571,-1183856.694) ( 57d23'33.28\"W, 10d34'27.20\"S) Band 1 Block=512x512 Type=UInt16, ColorInterp=Blue Overviews: 2048x2048, 1024x1024, 512x512 Band 2 Block=512x512 Type=UInt16, ColorInterp=Green Overviews: 2048x2048, 1024x1024, 512x512 Band 3 Block=512x512 Type=UInt16, ColorInterp=Red Overviews: 2048x2048, 1024x1024, 512x512 Band 4 Block=512x512 Type=UInt16, ColorInterp=Undefined Overviews: 2048x2048, 1024x1024, 512x512 Band 5 Block=512x512 Type=UInt16, ColorInterp=Alpha Overviews: 2048x2048, 1024x1024, 512x512 This command gives you some basic information into the metadata of your quads. For example, it tells you how many bands your quad has (4 bands + alpha) and in what projection it is in (WGS84). Now that we have inspected the tiff files with the above command, we will run the following command to stitch them together. !gdal_merge.py -v data/L15-0697E-0963N.tif data/L15-0698E-0963N.tif -o output/merged.tif The -v flag in the command allows us to see the output of the mosaicing operations as they are done. We can see in the verbose output above that the mosaicing operation is fairly simple: the utility script is basically copying a range of pixels for each band in each scene over to the designated output file. Processing file 1 of 2, 0.000% completed in 0 minutes. Filename: L15-0697E-0963N.tif File Size: 4096x4096x5 Pixel Size: 4.777314 x -4.777314 UL:(-6398696.510914,-1174072.754291) LR:(-6379128.631675,-1193640.633529) Copy 0,0,4096,4096 to 0,0,4096,4096. Copy 0,0,4096,4096 to 0,0,4096,4096. Copy 0,0,4096,4096 to 0,0,4096,4096. Copy 0,0,4096,4096 to 0,0,4096,4096. Copy 0,0,4096,4096 to 0,0,4096,4096. Processing file 2 of 2, 50.000% completed in 0 minutes. Filename: L15-0698E-0963N.tif File Size: 4096x4096x5 Pixel Size: 4.777314 x -4.777314 UL:(-6379128.631675,-1174072.754291) LR:(-6359560.752437,-1193640.633529) Copy 0,0,4096,4096 to 4096,0,4096,4096. Copy 0,0,4096,4096 to 4096,0,4096,4096. Copy 0,0,4096,4096 to 4096,0,4096,4096. Copy 0,0,4096,4096 to 4096,0,4096,4096. Copy 0,0,4096,4096 to 4096,0,4096,4096. Let's run gdalinfo again to see the spatial metadata of the mosaiced file. Driver: GTiff/GeoTIFF Files: merged.tif Size is 8192, 4096 Coordinate System is: PROJCS[\"WGS 84 / Pseudo-Mercator\", GEOGCS[\"WGS 84\", DATUM[\"WGS_1984\", SPHEROID[\"WGS 84\",6378137,298.257223563, AUTHORITY[\"EPSG\",\"7030\"]], AUTHORITY[\"EPSG\",\"6326\"]], PRIMEM[\"Greenwich\",0, AUTHORITY[\"EPSG\",\"8901\"]], UNIT[\"degree\",0.0174532925199433, AUTHORITY[\"EPSG\",\"9122\"]], AUTHORITY[\"EPSG\",\"4326\"]], PROJECTION[\"Mercator_1SP\"], PARAMETER[\"central_meridian\",0], PARAMETER[\"scale_factor\",1], PARAMETER[\"false_easting\",0], PARAMETER[\"false_northing\",0], UNIT[\"metre\",1, AUTHORITY[\"EPSG\",\"9001\"]], AXIS[\"X\",EAST], AXIS[\"Y\",NORTH], EXTENSION[\"PROJ4\",\"+proj=merc +a=6378137 +b=6378137 +lat_ts=0.0 +lon_0=0.0 +x_0=0.0 +y_0=0 +k=1.0 +units=m +nadgrids=@null +wktext +no_defs\"], AUTHORITY[\"EPSG\",\"3857\"]] Origin = (-6398696.510913709178567,-1174072.754290983080864) Pixel Size = (4.777314267160000,-4.777314267160000) Metadata: AREA_OR_POINT=Area Image Structure Metadata: INTERLEAVE=PIXEL Corner Coordinates: Upper Left (-6398696.511,-1174072.754) ( 57d28'49.69\"W, 10d29'16.12\"S) Lower Left (-6398696.511,-1193640.634) ( 57d28'49.69\"W, 10d39'38.19\"S) Upper Right (-6359560.752,-1174072.754) ( 57d 7'44.06\"W, 10d29'16.12\"S) Lower Right (-6359560.752,-1193640.634) ( 57d 7'44.06\"W, 10d39'38.19\"S) Center (-6379128.632,-1183856.694) ( 57d18'16.87\"W, 10d34'27.20\"S) Band 1 Block=8192x1 Type=UInt16, ColorInterp=Gray Band 2 Block=8192x1 Type=UInt16, ColorInterp=Undefined Band 3 Block=8192x1 Type=UInt16, ColorInterp=Undefined Band 4 Block=8192x1 Type=UInt16, ColorInterp=Undefined Band 5 Block=8192x1 Type=UInt16, ColorInterp=Undefined As you can see above, the size of the merged raster has changed from 4096,4096 to 8192,4096. 2. Clip to an AOI Now that we have succesfully mosaiced the quads, we will now clip the merged file to our exact area of interest. For this step, we will run the following command: !gdalwarp -of GTiff -cutline data/clip_aoi.geojson -crop_to_cutline output/merged.tif output/merged_cropped.tif 3. Perform NDVI on the clipped mosaic For the NDVI calculation, we will be taking a look at the 3rd and 4rth band of the merged file. Jut as a note: the band rendering for analytic quads are the following: Band 1: Blue Band 2: Green Band 3: Red Band 4: NIR Band 5: Alpha from osgeo import gdal import numpy as np g = gdal.Open(\"merged.tif\") if g is None: raise IOError(\"Couldn't open merged.tif\") b3 = g.GetRasterBand(3).ReadAsArray().astype(np.float32) b4 = g.GetRasterBand(4).ReadAsArray().astype(np.float32) ndvi = (b4 - b3) / (b4 + b3) ndvi = ndvi.astype(np.float32) drv = gdal.GetDriverByName(\"GTiff\") dst_ds = drv.Create(\"output_file.tif\", g.RasterXSize, g.RasterYSize, 1, gdal.GDT_Float32, options=[\"COMPRESS=LZW\"]) dst_ds.GetRasterBand(1).WriteArray(ndvi) dst_ds = None Good Job! You have finished the workflow!","tags":"nicfi","url":"https://developers.planet.com/docs/nicfi/beginners-gdal-workflow/","loc":"https://developers.planet.com/docs/nicfi/beginners-gdal-workflow/"},{"title":"Google Earth Engine One Minute to Integrations","text":"Get started with common tasks using Planet GIS integrations with the following series of videos. To learn more about Planet ArcGIS Pro, QGIS, and Google Earth Engine integrations, visit this page . Earth Engine Order to & Analyze Imagery in Google Earth Engine Pivot Center NDVI Analysis in Google Earth Engine Analyze Planet Imagery from Earth Engine in QGIS","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/google-earth-engine-one-minute-to-integrations/","loc":"https://developers.planet.com/docs/planetschool/google-earth-engine-one-minute-to-integrations/"},{"title":"Using Google Earth Engine & Planet to generate NDVI data","text":"","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/using-google-earth-engine-planet-to-generate-ndvi-data/","loc":"https://developers.planet.com/docs/planetschool/using-google-earth-engine-planet-to-generate-ndvi-data/"},{"title":"Using Planet in GEE","text":"Using Planet in Google Earth Engine Setting Band Combinations Set band combinations to visualize the Planet map layer. True color settings produce a natural visualization. False color visualizations reveal and enhance spectral data otherwise invisible to the human eye. For example, re-ordering the near-infrared, green and red bands from 8-band imagery emphasizes the near-infrared features that can highlight vegetation health. For more information on Planet spectral bands, see the Band order and sensor frequency table at Understanding PlanetScope Instruments . Visualizing 8-band Imagery True Color The following example displays the natural red, green, and blue bands from the imagery: Map.addLayer(imageCollection, {\"opacity\":1,\"bands\":[\"B6\",\"B4\",\"B2\"],\"min\":405.79,\"max\":4499.71,\"gamma\":2.331}) False Color Infrared In the following example, by ordering near infrared, green, and red bands you can create a false color infrared display that highlights the near-infrared data in the imagery. False color infrared is useful for seeing differences in vegetation. Map.addLayer(imageCollection, {\"opacity\":1,\"bands\":[\"B8\",\"B4\",\"B6\"],\"min\":405.79,\"max\":4499.71,\"gamma\":2.331}) Band Math NDVI on 8-band Imagery Map.addLayer(image.normalizedDifference(['B8', 'B6']).rename('NDVI'), {min: -1, max: 1, palette: ['blue', 'white', 'green']}); Working with Cloud Masks: UDM2 Visualizing Usable Pixels Ordering a Planet analytic_sr_udm2 appends the Usable Data Mask 2.0 ( UDM2 bands to PlanetScope images, resulting in a twelve band image in Earth Engine. Map.addLayer(image.select('Q8'), {min: 0, max: 1, palette: ['black', 'white']});","tags":"integrations-gee","url":"https://developers.planet.com/docs/integrations/gee/gee/","loc":"https://developers.planet.com/docs/integrations/gee/gee/"},{"title":"GDAL & QGIS: installation & setup","text":"Installation & Setup Windows Users If you're running Windows, use the OSGEO4W Installer to download & install a variety of free & open source geospatial tools, including GDAL & QGIS. Visit http://trac.osgeo.org/osgeo4w , and follow the Quick Start for OSGeo4W Users steps: Download & run the appropriate network installer for your system During the setup process, make sure to select both the \"GDAL\" package and \"QGIS\" to be installed. TIP: if you run into issues after the initial run of the installer, re-run the OSGEO4W installer & repeat steps 2-5 above. It's possible that some dependencies will not be installed on the first run. Once installation is complete, you'll use the OSGeo4W Shell to access command line utilities like GDAL. This shell is automatically installed after completing the above. Mac Users If you're running Mac OS X, KyngChaos is a good way to get installable packages for both QGIS & GDAL. To install QGIS, download the QGIS version listed under Current from http://www.kyngchaos.com/software/qgis : Here, the \"Current\" version available for download is QGIS 2.18.13-1 To install, right-click the installer file and select Open . A security warning will pop up, but you can continue the installation safely (for more information, see the 'Install Note' at the top of this page ). Follow a similar process to install GDAL from http://www.kyngchaos.com/software/frameworks . Under GDAL Complete , select the download for the GDAL version beginning with \"2\". Here, the 2.x version available for download is GDAL 2.1 Right-click the downloaded file & select Open to begin the installation. After the installation is complete, there's one more step required to enable GDAL's command line tools. To finish setup, open your terminal and type the following at the prompt: echo 'export PATH=/Library/Frameworks/GDAL.framework/Programs:$PATH' >> ~/.bash_profile Hit enter after that line, and type the following: source ~/.bash_profile After you hit enter again, setup is complete. Linux Users For most users, your Linux distribution's default repository is likely to have a relatively recent version of GDAL. Feel free to simple use that package, or read on for more specific information: Ubuntu & Linux Mint Users As of October 2017, Ubuntu's default ( Universe ) repositories have GDAL 1.11. To check what version of gdal is currently available to you, run the following command: sudo apt-cache policy gdal-bin To install that version, do: sudo apt-get install gdal-bin Alternatively, if you are running an LTS (12.04, 14.04, or 16.04) you can use the ubuntugis-unstable PPA to install GDAL 2+. If you prefer this option, run the following instead: sudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable sudo apt-get update sudo apt-get install gdal-bin CentOS Users In order to install GDAL, you'll need to use the EPEL repository. Follow the instructions for your CentOS version here to do that. For example: for CentOS 7, assuming epel-release-7-10 is the relevant EPEL release, you would do: su -c 'rpm -Uvh http://download.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-10.noarch.rpm' Once you've added the EPEL repository, run the following command: sudo yum install gdal Everyone Else You can also build GDAL yourself, by compiling from source. Detailed instructions on this are available at http://trac.osgeo.org/gdal/wiki/BuildingOnUnix All Users Before going on, let's verify that the setup process completed successfully. If QGIS has installed successfully, you should be able to find a newly-installed program, QGIS Desktop , on your system: To confirm GDAL installation, open a terminal and type the following command: ogrinfo Windows users: remember, you'll use the OSGeo4W Shell here. If all went well, you should get output similar to this: Usage: ogrinfo [--help-general] [-ro] [-q] [-where restricted_where|@filename] [-spat xmin ymin xmax ymax] [-geomfield field] [-fid fid] [-sql statement|@filename] [-dialect sql_dialect] [-al] [-rl] [-so] [-fields={YES/NO}] [-geom={YES/NO/SUMMARY}] [-formats] [[-oo NAME=VALUE] ...] [-nomd] [-listmdd] [-mdd domain|`all`]* [-nocount] [-noextent] datasource_name [layer [layer ...]] FAILURE: No datasource specified. If, however, you get an error that says command not found , go back and review the installation steps for your operating system.","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/gdal-qgis-installation-setup/","loc":"https://developers.planet.com/docs/planetschool/gdal-qgis-installation-setup/"},{"title":"Getting started with GDAL","text":"Introduction As with most data, being able to query, transform, and visualize geospatial data makes your work easier and your data more useful to you. If you're new to working with and using geospatial data, though, the world of geo-tools available can be overwhelming. In this tutorial, we'll learn about a powerful, widely-used, and broadly applicable Free & Open Source Software (FOSS) tool that will empower you to do more with your data. GDAL GDAL , also known as GDAL/OGR , is a library of tools used for manipulating geospatial data. GDAL works on both raster and vector data types, and is an incredible useful tool to be familiar with when working with geospatial data. While the GDAL library can be used programmatically, GDAL also includes a CLI ( C ommand L ine I nterface). For the purposes of this tutorial, we will be focusing on the CLI only. Some common uses you may have for GDAL include: quickly getting basic information about a dataset, converting between geospatial file types, clipping one dataset against another, and more. We'll walk through a few demos of these and other common use-cases later on in the examples section. A note about names Traditionally, the name \"GDAL\" was used to refer to the raster-related half of the library, while \"OGR\" referred to the vector part. You may commonly hear people use both \"GDAL\" and \"GDAL/OGR\" to refer to this library - but in all cases, the toolset being referenced is the same. Installation Visit this page for installation & setup instructions. When you're finished, come back to this page to learn more. Commonly-used commands Once you've verified GDAL has been installed successfully, let's take a look at the different CLI commands you will use in this tutorial: ogrinfo Get information about a vector dataset gdalinfo Get information about a raster dataset ogr2ogr Convert vector data between file formats gdal_translate Convert raster data between file formats There are other commands available, but these four are the most common. We'll start by learning some of the most-common ways you might use these commands. Examples Because GDAL is a CLI, all of your interaction with it will be via your command line (or Terminal). For Windows users who followed this tutorial's installation instructions , you'll use the OSGeo4W Shell here. If you need a refresher course on types of geospatial data, check out this tutorial. Working with vector data GDAL can read dozens of file types. To see a full list of the vector data filetypes supported by your current GDAL installation, do: ogrinfo --formats In the following examples, we'll use GeoJSON files -- but you could also read KML, Shapefile, Geopackage, and more. Exploring data To get basic information about your dataset, do: ogrinfo mydata.geojson Which will return something like this: INFO: Open of `mydata.geojson' using driver `GeoJSON' successful. 1: mydata (Polygon) What this tells you: Your dataset, mydata.geojson , has one layer of data, called mydata , which contains Polygon features. To learn more about that layer of Polygon features, do: ogrinfo -so mydata.geojson mydata Which will return something like his: INFO: Open of `mydata.geojson' using driver `GeoJSON' successful. Layer name: mydata Geometry: Polygon Feature Count: 1 ExtentV: (-86.484375, 18.979026) - (-14.414062, 52.482780) Layer SRS WKT: GEOGCS[\"WGS 84\", DATUM[\"WGS_1984\", SPHEROID[\"WGS 84\",6378137,298.257223563, AUTHORITY[\"EPSG\",\"7030\"]], AUTHORITY[\"EPSG\",\"6326\"]], PRIMEM[\"Greenwich\",0, AUTHORITY[\"EPSG\",\"8901\"]], UNIT[\"degree\",0.0174532925199433, AUTHORITY[\"EPSG\",\"9122\"]], AUTHORITY[\"EPSG\",\"4326\"]] What this tells you: There is 1 feature (a single polygon) in this dataset's layer The Extent (bounding box) of the dataset is given as a coordinate pair The SRS (spatial reference) of this dataset, printed as WKT ( W ell- K nown T ext) Converting data One of the most convenient features of GDAL is its ability to quickly and painlessly convert data between file types. In fact, even if you use GDAL for nothing else, data conversion alone is worth the price of admission. To convert a vector dataset from one format to another, the basic command pattern is: ogr2ogr -f <output format> <destination filename> <source filename> To see a list of valid output formats, do: ogr2ogr --formats Note: the formats supported by a given GDAL instance can vary, depending on the installation process -- but generally, support for common filetypes like Shapefile, GeoJSON, etc. will always be available. Let's say we have a shapefile, mydata.shp , which we'd like to convert to a GeoJSON dataset. To do this, we would run: ogr2ogr -f GeoJSON myconverteddata.geojson mydata.shp Working with raster data Just as we learned that GDAL can read and write dozens of vector data types, the same is true for raster data. To see a full list of the raster data filetypes supported by your current GDAL installation, do: gdalinfo --formats For the following examples, we'll use GeoTIFF data for demonstration purposes. Exploring data To get information about your dataset, do: ogrinfo mydata.tif Which will return something like this: Driver: GTiff/GeoTIFF Files: mydata.tif Size is 8879, 4392 Coordinate System is: PROJCS[\"WGS 84 / UTM zone 38N\", GEOGCS[\"WGS 84\", DATUM[\"WGS_1984\", SPHEROID[\"WGS 84\",6378137,298.257223563, AUTHORITY[\"EPSG\",\"7030\"]], AUTHORITY[\"EPSG\",\"6326\"]], PRIMEM[\"Greenwich\",0, AUTHORITY[\"EPSG\",\"8901\"]], UNIT[\"degree\",0.0174532925199433, AUTHORITY[\"EPSG\",\"9122\"]], AUTHORITY[\"EPSG\",\"4326\"]], PROJECTION[\"Transverse_Mercator\"], PARAMETER[\"latitude_of_origin\",0], PARAMETER[\"central_meridian\",45], PARAMETER[\"scale_factor\",0.9996], PARAMETER[\"false_easting\",500000], PARAMETER[\"false_northing\",0], UNIT[\"metre\",1, AUTHORITY[\"EPSG\",\"9001\"]], AXIS[\"Easting\",EAST], AXIS[\"Northing\",NORTH], AUTHORITY[\"EPSG\",\"32638\"]] Origin = (494265.000000000000000,2729640.000000000000000) Pixel Size = (3.000000000000000,-3.000000000000000) Metadata: AREA_OR_POINT=Area TIFFTAG_DATETIME=2017:10:03 06:53:18 Image Structure Metadata: COMPRESSION=LZW INTERLEAVE=PIXEL Corner Coordinates: Upper Left ( 494265.000, 2729640.000) ( 44d56'35.92\"E, 24d40'52.01\"N) Lower Left ( 494265.000, 2716464.000) ( 44d56'36.12\"E, 24d33'43.62\"N) Upper Right ( 520902.000, 2729640.000) ( 45d12'23.78\"E, 24d40'51.54\"N) Lower Right ( 520902.000, 2716464.000) ( 45d12'23.07\"E, 24d33'43.14\"N) Center ( 507583.500, 2723052.000) ( 45d 4'29.72\"E, 24d37'17.79\"N) Band 1 Block=256x256 Type=UInt16, ColorInterp=Red NoData Value=0 Overviews: 2960x1464, 987x488, 329x163 Band 2 Block=256x256 Type=UInt16, ColorInterp=Green NoData Value=0 Overviews: 2960x1464, 987x488, 329x163 Band 3 Block=256x256 Type=UInt16, ColorInterp=Blue NoData Value=0 Overviews: 2960x1464, 987x488, 329x163 Band 4 Block=256x256 Type=UInt16, ColorInterp=Undefined NoData Value=0 Overviews: 2960x1464, 987x488, 329x163 What this tells you: Converting data We can also use GDAL to convert raster data from one file format to another, just as we learned to do with vector data. To convert a raster dataset from one format to another, the basic command pattern is: gdal_translate -of <output format> <source filename> <destination filename> Note! this command is similar, but not quite the same, as ogr2ogr : notice the output format is indicated by -of , and the ordering of source & destination filenames is reversed from the ogr2ogr command. To see a list of valid output formats, do: gdal_translate --formats As an example, let's transform a GeoTIFF raster dataset mydata.tif into a georeferenced PNG. To do that, we would run: gdal_translate -of png mydata.tif myconverteddata.png","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/getting-started-with-gdal/","loc":"https://developers.planet.com/docs/planetschool/getting-started-with-gdal/"},{"title":"How to Get Help","text":"In the top navigation, on the upper right hand corner of the webpage, you will see help, app switcher, and account icons. Help Dropdown The first icon, which looks like a question mark will display a list of help resources, including Planet's Help Center, this User Guide, our Changelog, and Terms of Service. You can also take a tour of the Explorer application for contextual help and submit feedback. The Help Center button opens the Planet Support website in a new tab or browser window, linked here: Planet Support . This page contains White Papers & Guides , Frequently Asked Questions , Help , Community Pages and a link to Contact Sales . This page can be a great resource for questions not answered in this User Guide. The What's New section is an updated list of all engineering changes made to Explorer. The Terms link will open a popup window with links to Terms of Service , Privacy Policy , and various links to data agencies & companies used in the creation of the Planet Explorer basemap & data. App Switcher The second icon which looks like an app library will display a list of available applications that you can navigate to. When clicked on, the links in this list will open a new tab or browser window (depending on your personal settings).","tags":"apps-explorer","url":"https://developers.planet.com/docs/apps/explorer/how-to-get-help/","loc":"https://developers.planet.com/docs/apps/explorer/how-to-get-help/"},{"title":"Planet Hack 2021","text":"How to Participate Use this repo's issue tracker to introduce yourself , pitch a project idea , or form a team . Use this Gitter room to chat with other Planet Hack 2021 hackers Note that team formation can happen anytime in the days leading up to Planet Hack - but hacking should not begin until Thursday, October 14th ! Accessing Planet Data All participants in Planet Hack 2021 are eligible for free access to Planet's high-resolution, analysis-ready mosaics of the world's tropics via the NICFI Data Program . To access data, sign up for a free Planet account at https://www.planet.com/nicfi/ . Learn more and discover additional resources at https://developers.planet.com/nicfi/ . Code of Conduct All attendees, sponsors, partners, volunteers and staff are required to agree with our Event Code of Conduct . If you experience or witness an incident and wish to make a report, use this form . FAQs I don't know anything about Planet data or satellite imagery in general, where should I start? You may find this Introduction to Geospatial Data useful, as well as this Satellite Imagery Overview For a quickstart guide to usings Planet's platform & APIs, see here To browse our collection of self-guided tutorials, check out Planet School When is Planet Hack? Hacking officially kicks off 12:01am Anywhere on Earth (AOE) Thursday October 14th , and ends at 11:59pm Anywhere on Earth (AOE) Sunday, October 17th . Tell me about demos, again? One of the best parts of any hackathon is the opportunity to see what everyone has been working on: demos are a fun way to show-and-tell what you worked on during the previous week. Think of a demo as a Planet Hack-specific lightning talk, and not necessarily a serious high-production-value finished-project demonstration. To take even more of the pressure off, we use pre-recorded videos to give you as many takes as you need to nail your demo down. Follow Planet Hack 2021, demo videos will be showcased in a gallery here on developers.planet.com . Remember, a demo video is not expected to be polished and flawless: think of this as recording yourself giving a casual lightning talk. Each team/project may submit a video of up to 15 minutes length telling about their project and what they did during Planet Hack. Slides are optional but encouraged, as is showing coding or project demos. To submit your demo: Each team/hacker should fill out this form before 11:59pm AoE on October 17th . Who can attend? Anyone interested in exploring and experimenting with Planet's platform, APIs, and unique dataset. You don't have to be a developer or engineer to \"hack\": data scientists, geospatial pros, curious hobbyists and more are all invited. Can I get started early? Brainstorming, discussion, and team formation is encouraged to begin early. Actual hacking, however, should begin on October 14th. Sounds great, what do I do next? Head on over to the issue tracker and introduce yourself ! I have a question that's not answered here! Reach out to us via developers@planet.com .","tags":"events","url":"https://developers.planet.com/docs/events/planet-hack-2021/","loc":"https://developers.planet.com/docs/events/planet-hack-2021/"},{"title":"How to Analyze Imagery","text":"You can analyze imagery in the browser by taking measurements, comparing imagery side by side, enhancing pixels, applying spectral visualizations, and creating a timelapse. Measurement tools can be found on the map. All other analysis tools can be found in the toolbar on the right hand side. Take Measurements You can measure the distance between two points, the area within a polygon or the bearing of a drawn line. The measure tools are on the bottom right hand corner of the map, below the Draw an AOI button. If you float over this icon, you will see these available tools: The first icon from the left (a compass icon) is the Measure Bearing tool, which allows you to measure the bearing between two points on the map. When you click on two points, the results are displayed on the map until you clear them. If required, continue to create sets of points and calculate their bearing. Note : You can create multiple types of measurements on the map. For example, if you create a bearing measurement, and then choose to create an area measurement, both continue to be visible on the map and are managed as individual measurements. Using the Measure Area tool, you can measure, download, edit, save or delete drawn geometries and measurements including the area of interest (AOI). The last icon (a ruler icon) is the Measure Distance tool. When prompted, Click to create segments . To create a segment: 1. Hold shift to draw free-hand. 2. Click twice in the same location to end. 3. After you create one or more segments, double click to end the line measurements. The line turns white, and a final distance is displayed. You can create multiple measurements on the map. Comparing imagery You can compare sets of Planet imagery from different days, months, and quarters side by side. In the toolbar on the right hand side, you will see the Compare icon at the top of the stack. When you click the Compare icon, the map view changes, and you see a prompt to Drag & Drop Images to Compare. Click and drag any image from the left pane, and release when on top of the map view. You can see the information box in the top center describes the image that has been added to the map view. Repeat again with a second image from the list in the left pane. Now you can see two images have been added to the map view, and a slider bar is visible in the middle of the map view. The image on the left side of the slider icon corresponds with the tile description at the top left, and similarly for the image on the right side and the corresponding tile description on the top right. By clicking on the slider icon and moving the mouse left or right, the map interface changes, and you can compare the two images that have been stacked one atop the other. The icon in the top middle indicates that you can swap the imagery overlay (so that the bottom image becomes the top image). To swap the image on the map view with a new image, simply click and drag a new image to the map view, and drop in the proper quadrant to replace the image you don't want to compare anymore. When comparing imagery, there are two tool icons in the bottom left stack - Slide and Opacity . Slide This is the default option selected as you choose the Compare tool. This controls the slider bar allowing you to view two images stacked atop each other. Opacity If you choose the Opacity option, you will see the top left image along with an Opacity slider bar at the bottom of the map view. As you slide the Opacity bar to the right, the top image will fade, and the features of the bottom image will start to become visible. Enhance Pixels You can enhance Planet's data to adjust for contrast, brightness, and saturation. Data Guideline You can use pixel enhancements with our basemaps (surface reflectance basemaps work best) as well as with daily scenes (you must order hosted data). Select enhancement Select enhancements from the right-hand toolbar. The enhance button is the second icon from the top. The tooltip should read Enhance imagery . To enhance imagery, you can choose from pre-set filters or adjust more granularly to your own liking. Preset modes include: Auto enhancement: recommended for most use cases Snow: recommended for icy and snowy areas that are typically washed out Desert: recommended for desert areas that are typically washed out Custom enhancement filters allow you to adjust for contrast, brightness, and saturation. Adjust by moving the slider to the right or the left. You can also adjust for contrast, brightness, and saturation by adjusting points on the histogram. Turn the histogram toggle on and click on the points to adjust. If you enhance imagery via the histogram, you may use the sliders on top of your histogram adjustments for post-processing. Apply Spectral Visualizations Select visualizations from the right-hand toolbar. The visualizations button is the third icon from the top. The tooltip should read Perform spectral analysis . If you would like advanced tools to analyze the imagery beyond the Red-Blue-Green spectrum, you can use the spectral visualization tools. These tools take advantage of the spectral band information that Planet captures. Data Guideline You can use spectral visualizations with surface reflectance basemaps as well as with daily scenes (you must order hosted data). Choose your Visualization The visualization tools are located in the toolbar on the right hand side. When you click on the third icon in the toolbar, you will see a menu of visualizations to choose from. The menu of visualizations includes: RGB: Red Green Blue CIR: Color-infrared NDVI: Normalized Difference Vegetation Index NDWI: Normalized Difference Water Index (please note that Planet calculates NDWI using NIR rather than SWIR) VARI: Visible Atmospherically Resistant Index MSAVI2: Modified Soil Adjusted Vegetation Index MTVI2: Modified Triangular Vegetation Index Changing the color ramp: If you click CIR, your basemap visualization will change automatically to be color infrared. If you click NDVI, NDWI, VARI, MSAVI2, or MTVI2 you will have the option to select your color ramp in a pop-up in the bottom left-hand corner. Click the edit tool in the upper right hand corner of the pop-up. Click the carrot indicator to view your options. Once you have selected a color ramp, you can save your preferences by clicking \"Save\". Your imagery will then reflect the color ramp you chose. To view any other indices or band combinations that we do not feature yet, submit your request by clicking the link that reads \"Not finding the index that meets your needs? Give Feedback\". This will take you to a Google Form where you can tell us more about what you would like to see. We may follow up with you if we have additional questions. Try Demo Data for Pixel Enhancement and Spectral Visualizations If you are not ready to order hosted data for your area and time of interest or if you do not yet have access to surface reflectance basemaps, you can try out our tools using Planet's demo data. Basemaps : If you are not currently viewing a Surface Reflectance Basemap, you will see a notification that prompts you to switch to a Surface Reflectance Basemap when you click on a tool in the toolbar. If your organization has purchased access to multiple Surface Reflectance Basemaps, you will see a list view. If your organization has not purchased any Surface Reflectance Basemaps, you will have the option to view a demo Surface Reflectance Basemap. You can also purchase a Surface Reflectance basemap online with your credit card by clicking Purchase . Daily Scenes : To try demo data, go to the left hand navigation and click on the third icon down. The tooltip reads Access your hosted data for analysis. Once you click on the icon, you will see a fly out with the option to choose My Folders and Demo Data. Click on Demo Data to see a list of Folders. Folders are organized by examples relevant to industry and geographic areas. Once you find a Folder that sounds interesting to you, click on the Folder to view the imagery in the Folder. Click on the image and go to the tools in the right-hand toolbar to apply visualizations or enhancements. Create a Timelapse If you would like to compare multiple images over time, you can create a timelapse in the Stories application. Click the Stories icon in the right hand toolbar, at the bottom of the stack. When you click the icon, a pop-up opens with a link to the Planet Stories application. In Stories, you can make timelapses of multiple images. You can also publish your timelapses on the Planet website or on your own website or social media account.","tags":"apps-explorer","url":"https://developers.planet.com/docs/apps/explorer/how-to-analyze-imagery/","loc":"https://developers.planet.com/docs/apps/explorer/how-to-analyze-imagery/"},{"title":"How to Search for Imagery","text":"This section overviews the Planet Explorer imagery search options. You can search for the latest imagery over your area of interest by panning and zooming to the location, uploading a GEOJSON file for your AOI, or drawing a shape on the map. Using the search bar You can search for any location or a specific area of interest (AOI) by using the search box (similar to a search engine) located at the top left of the page. Type a location in the Search Bar. The map view zooms to that location and an Area-of-Interest (AOI) and a bounding box appears in the map. After you have a bounding box drawn, the search results appear in a panel on the left side of the page. Creating an Area of Interest (AOI) on the map You can search for imagery by specifying an area on the map, either by drawing a geometry or uploading a GEO file. Supported file types include shapefile, GeoJSON, JSON, Keyhole Markup Language (KML), Well Known Text (WKT), GPX, DBF, SHX, PRJ, and ZIP files. The map tools are available on the bottom right corner of the page. Hover over the Area-of-Interest (AOI) icon to view a tooltip to Draw or upload a geometry . Click the tool to view the options menu to create an AOI. The tooltip changes when you float over each icon in the group. The following tools are available: File importer uploads a geo file into Planet Explorer. Click the Upload Tool to open a file system browser window and navigate to your file. You can upload more than one file to Planet Explorer, but if multiple polygons are found, Planet Explorer automatically simplifies the shape of your geometry. Supported file types include shapefile, GeoJSON, JSON, Keyhole Markup Language (KML), Well Known Text (WKT), GPX, DBF, SHX, PRJ, and ZIP files. Constrained Circular AOI draws a circle with a maximum area of 50,000 sq. km. The area varies by the latitude of the center coordinate. Constrained Rectangular AOI draws a rectangle with a maximum area of 50,000 sq. km. The area varies by the latitude of the center coordinate. Custom AOI draws a polygon of your choice. Circular AOI draws a circle of any size. Rectangular AOI draws a rectangle of any size. Selecting on the Time Slider & using the Imagery Picker Tools If you select a Basemap or create a search for imagery, a timeline slider bar appears at the bottom of the page. The dots in the slider indicate time intervals. Viewing Basemaps To access your Basemaps, click the Access your Basemaps icon from the toolbar on the left side of your screen. The Intervals option allows you to select the following options: Quarterly Basemap changes the time slider to show three-month increments of each year. Monthly Basemap changes the time slider show each month of the year. Weekly Basemap changes the time slider to show each week of the year. This also includes bi-weekly basemaps. Daily Imagery creates a prompt to Click on the map to search for daily imagery by drawing an area of interest (AOI). You can deselect a Basemap either by entering Command+Click for Mac or Control+Click for PC or by clicking on the Basemap name. If you go into the drawer to see your basemaps, you will see a list of basemap series you have access to. You can click into each series to see the mosaics. The basemaps card shows two action buttons: The compass allows a user to zoom directly to the basemap. The eye shows a preview of the basemap on the map. Note : If you do not have access to imagery, an option to purchase access is available. Sharing your session If you want to share your session, click the Share this Session icon on the bottom right corner of the page. Click Copy to to copy and share the link. Anyone with this link can view your entire session: your area of interest, your search filters, and your current selections.","tags":"apps-explorer","url":"https://developers.planet.com/docs/apps/explorer/how-to-search-imagery/","loc":"https://developers.planet.com/docs/apps/explorer/how-to-search-imagery/"},{"title":"How to View Imagery","text":"After you define an area of interest (AOI), a panel appears on the left side of your Planet Explorer page. Here you can search for data using filters, date ranges, and imagery types. You will see a few places in the application where you can view data: Preview scenes in the archive, where you can view and/or order. Basemaps your organization has access to. Hosted data that you have ordered. Navigation In each of these drawers, you will see actions that you can take. When you preview scenes in the archive, you can filter your selections. Once you do that, you will see results organized by dates. Each of these result cards show three action buttons: The shopping cart quickly adds all images from a specific date to an order. The eye pulls up a preview of all images from a specific date on the map. X items > navigates to the scene level on a specific date to allow for more granular selections. Once you click on the X items > button, you will see a list of satellite strips taken on that date and evaluate whether there are any overlaps to avoid. You can click into each strip to see individual scenes and make selections from there. At the strip level, you will see three action buttons: The shopping cart quickly adds all images from that strip to an order. The eye pulls up a preview of all images from that strip on the map. The double square locks the footprint of the entire strip on the map. If you click into the strip, you will see a list of scenes in that strip. The scene level card shows two action buttons: The double square locks the footprint of the scene on the map. The eye shows how many scenes have been selected for preview in the strip. Cadence Options You can choose your imagery cadence with the following options: Daily imagery appear in Scenes Other cadences appear in Basemaps Filters Options You can change your Filter settings to narrow your image results or make updates. Filters are grouped according to imagery capabilities, PlanetScope filters, environmental conditions, and other attributes. The groups are collapsible for easy navigation. After you select your filters, click Apply Filters . To start and begin with new filters, elect Clear Filters . NOTE To use filters with environmental conditions, enter the exact values or use the slider. Date Ranges You can select the date range for your imagery search results. Select the Dates icon and select the date ranges to filter your search for one or more date ranges. The days are UTC by default. To easily compare results that are months apart, select multiple date ranges. You can enter one range, then click Add another range to enter a second range. You can add as many ranges as you need. Click Done to display the imagery within each range. When you click Dates , an interactive Edit Date Ranges window appears. You have the option to remove the current date range or add additional dates of interest. To make changes, click Done in the bottom right corner. Search Results After you select your filters, the list of search results display imagery based on your parameters. Each search result represents a group of available imagery. Each search result appears as a thumbnail image and includes the date of the image, the percentage of area coverage for your area of interest, and the pixel resolution. If the image is partially over-rectified, an icon notification appears. Partially rectified imagery is considered test quality. If you click the arrow from the search result, the tooltip displays View Details . This expands the grouping and displays all images taken on that date and grouped by satellite. You will see an icon with the instrument filter as shorthand for each satellite constellation. You can inspect imagery more granularly at this step by selecting and deselecting entire groups of imagery or single images. You can click the view details symbol to the right of the date to see metadata about that specific image. Overlay Layers Toggle The toolstack tools located on the bottom right hand corner of the screen include an overlay toggle button. Use this button to adjust what you see on the map. If you click the Street Labels toggle, you can turn the text labels on and off on the map. If the indicator is teal, the toggle is on. If you click the Satellite View toggle, you can turn the contextual satellite layer on and off on the map. NOTE The contextual layer does not affect the number of tiles streamed. Zoom Tools The Zoom tools stack at the bottom right hand of the page enable you to navigate throughout your map view. The + and - allow you to zoom out. If you hover over these arrows, the current zoom level displays. The current zoom level and how it translates into meters and pixels appears at the bottom of the screen. The globe pictograph gives you context about where you are looking. The teal dot represents your current focus. Additional zoom tools allow you to quickly zoom into an area of interest or out to the whole world. From left to right, the tools are: Zoom to area of interest is also called the rubberband zoom. This option allows you to draw a rectangle to zoom into an area. The rectangle is not permanent and is an indicator of what extent to zoom into. Zoom out to World enables you to zoom back to the largest zoom level.","tags":"apps-explorer","url":"https://developers.planet.com/docs/apps/explorer/how-to-view-imagery/","loc":"https://developers.planet.com/docs/apps/explorer/how-to-view-imagery/"},{"title":"How to Generate Planet Image Quick-looks","text":"Image Quick-looks (QL) are basically downsampled or lower resolution images that can be generated to offer a very rapid, lightway and easy-to-handle option to view satellite sensored data without downloading the original, large datasets. They have been used traditionally in the industry, e.g. by RapidEye customers, to assess cloud coverage and pixel usability on acquisitions before ordering. In this tutorial, you will learn two simple options to generate Image QL from PlanetScope scenes using our APIs and open source geospatial tools. Side note: Planet's scenes are considerably smaller in size than those from traditional sensors such as Landsat, Sentinel and even RapidEye. Therefore, QL are not generated as an standard asset on our catalog. Instead, Planet provides lightweight metadata assets that are useful for assessing image quality and pixel usability, such as the UDM and UDM2 assets, prior to download. Head to this tutorial if you want to check out how to work with those products. Content Environment set up QL with Planet's raster toolkit QL in Planet's QGIS integration 1. Environment set up We will be using: Planet CLI V1 jq QGIS v3.6+ Our Area of Interest in Savoy, France. Note Planet V1 SDK and CLI are branched from the main development branch. So be sure to grab the latest V1 branch, which is currently https://github.com/planetlabs/planet-client-python/tree/1.5.2, and can be cloned at the commandline with a call to git clone --depth 1 --branch 1.5.2 git@github.com:planetlabs/planet-client-python.git . Before using the Planet CLI, make sure you are authenticated to access Planet APIs. You can do that either by setting an environment variable named PL_API_KEY or initializing at the commandline. planet init where you enter you Planet credentials (the same email and password you use to log on to Planet Explorer or your account page). 2. QL with Planet's Raster Toolkit Using the Planet's Orders API, you have a your disposal a large set of raster operations that can be applied to the data before downloading it, essentially letting you process and arrange your image to your desired output all before downloading. For this exercise, we will use the Reproject raster tool to downsample PlanetScope 3-Band scenes from their original 3m GSD to a coarser spatial resolution. This is the fastest and more scalable approach there is since Planet will do all the processing on our more than 1000 VMs. Note: This approach counts agains your allocated download quota. So, let's start! a. Define your scene ID list . Using the Planet CLI, let's do a Data API search over the Savoy AOI for PSScene scenes acquired first week of April, 2020 and check how many scenes we get: planet data search --geom examples/savoy.geojson --item-type PSScene \\ --date acquired gte 2022-03-01 \\ --date acquired lte 2022-03-07 | jq '.features | length' Now, let's repeat the step above but instead of using jq to only count items, let's print all the scenes' IDs, concatenate them into a comma-separated string and copy the result: planet data search --geom examples/savoy.geojson --item-type PSScene \\ --date acquired gte 2022-03-01 \\ --date acquired lte 2022-03-07 | jq -r '.features | map(.id) | join(\",\")' You'll copy and use these IDs when you submit an order. b. Submit order . Let's make a Planet order using the Reproject raster tool. When using the Planet CLI, the tool (or tools chain) need to be passed as a .json file in the arguments list. Let's create one of those that contains the following JSON object: [ { \"reproject\": { \"projection\": \"EPSG:3857\", \"kernel\": \"cubic\", \"resolution\": \"60.0\" } } ] Note: See that in this step we need to define our output dataset's resolution and projection as well as the kernel used for pixel processing. The Reproject tool, as its name defines it, is mainly used for changing image's projections. However, since we are also able to change pixel size, we can use it for our exercise. You have to take into account that we are not using the projection specific to the images we are downsampling but a global Mercator projection and hence the resulting QL might not be as accurately ground-locked as the original images. You can also use the projection specific to each image you are processing by checking on its metadata. Now, let's use the CLI to submit an order using the Orders API. For input IDs we use the PSScene IDs copied on step 2.a . We need to define the bundle or asset type we want to download, our order name and pass the name of our tools JSON file. planet orders create --item-type PSScene --bundle visual \\ --id \"YOUR-COMMA-SEPARATED-LIST-OF-IDS\" \\ --name QL-tutorial-demo --tools examples/reproject.json | jq . This should output a JSON object containing our order's metadata. c. Check order status . On the previous response, you can see that our order status is queued . That means our order has been received by the server and has been put on the processing waiting-list. The orders computing servers will automatically start processing your order as space in the processing engines becomes available so this should not take more than a couple of seconds. Once the order starts being processed though, it will depend on the number of bundles you are requesting and the operations to apply to determine how long your order will take to process. We can always check the order status by sending the below request using our own order-id (from the previous step) planet orders get \"YOUR-ORDER-ID\" | jq '\"Name: \" + .name + \". Status: \" + .state' d. Download order . Once an order's status has changed to success , we can go ahead and download it with the below command: planet -v orders download \"YOUR-ORDER-ID\" --dest ql-demo-orders --quiet Note: All of the previous steps can be streamlined and automated using a Python script, which allows for more scalability and less human interaction. Now, we can visualise our QL on QGIS or any other GIS software. 3. QL in Planet's QGIS integration This solution technically does not generate image QL but it essentially provides you with the same functionalities a QL does. Planet's integration to QGIS is the easiest and more practical way for you to preview images directly on your GIS workspace. Moreover, the images are streamed at native resolution so you can see features and do visual inspection with the highest spatial detail, hence, rendering the concept of QL obsolete. Let's do it! a. Get Planet Explorer . Open a QGIS workspace and navigate to the QGIS Pluging manager: Plugins > Manage and install plugins...> All . Search for Planet_Explorer and click on Install Plugin once it shows up. Info The plugin can be found on QGIS's market place from version 3.6 on. Once installed, the plugin will be added to your QGIS panels on the top left side. Click on the Planet logo to open and authenticate using your Planet registered Email and Password. b. Define your scene ID list Now that you are logged in, we can proceed to define the images we want to preview by doing a search. We can replicate the search done in step 2.a . For that, we will need to load our Savoy AOI onto our workspace and select the geometry using the Feature Selection tool. On the Planet Explorer tab, click on Selection on the Area of interest section and then on Single Feature to select your layer as AOI to search in. On the Filters section, tick the box for PlanetScope 3-band and define your Date Range by using the date picker tool. Hit Search . If you already have a list, such as the one we got on step 2.a , you can skip the filter set up above and simply paste your list of the Item IDs (comma separated) input field. Info There are many more filters you can use to narrow your filter criteria. If you want to know more about using the QGIS integration, see this tutorial for a more complete overview. c. Add images to workspace A list of results will appear on the bottom part of the tab. If you hover on the results, you will get footprints displayed in your Map extent. You can also click on Settings for more options. Clicking on Add preview layer to map will stream the full resolution images on your current Map. And that is it! In three simple steps you have added full resolution images to your GIS workspace which you can use in conjunction to other ancillary data to assess image usability and make decisions before ordering large image datasets.","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/how-to-generate-planet-image-quick-looks/","loc":"https://developers.planet.com/docs/planetschool/how-to-generate-planet-image-quick-looks/"},{"title":"Satellite Imagery","text":"Quickstart Guide to Satellite Imagery So you've downloaded your first Planet image. There's something on your computer that came from space. Cool! So now what? Well, first things first: look at it! If you open it in Windows Picture Viewer (WPV) or Apple's Preview, the image may look totally black. Don't worry, it's not broken! That's just an analytic file appropriate for scientific applications, and WPV & Preview expect 8- or 16-bit images . The values in the analytic file can be scaled in a program like Photoshop or GIMP, or opened and scaled in GIS software like QGIS. But if you want something that looks like what you expect out of the box, download the visual file instead. Fig. 1: Analytic file on the left. Visual on the right. So now that you can see something, you may wonder what you're looking at. Well, imaging satellites have digital cameras attached to telescopes - like a sports photojournalist's setup, but in space! Credit: Wikipedia These cameras are fancier than cell phone cameras, but the pixels you see when you zoom into a selfie are the same type of thing you see when you zoom into a satellite image. They represent the intensity of light reflected off the objects the camera was pointed at. As an aside, Planet's cofounders actually launched a cell phone to the edge of the atmosphere, and recent phone sats even captured photos! The main difference between Planet's cameras and a photojournalist's is that our camera is sitting in space and pointing at the ground. Oh, and it's surrounded by lots of electronics to help it understand where it is, stay there, and transmit images to the ground. Because we know where the satellite is pointing and the height of the orbit, we know that each pixel represents a specific place and covers 3 to 5 meters on the ground - depending on the orbit and the length of the telescope. This helps us put images on a map, like what you see in Google Maps. Anyway, an image contains some combination of bands, or data \"layers\", that represent each of the different wavelengths of light recorded by the sensor. Planet's satellites record red, green, blue, and near-infrared (NIR) light reflecting off the ground. Even though our eyes don't see it, near-infrared (NIR) light provides extremely helpful information! Our RapidEye images capture NIR as well as red edge information, which falls between \"pure\" red and NIR. People are most familiar with RGB images, because that's what we see out in the world. You can see where visible light appears in the electromagnetic spectrum in the figure below. Fig. 2 Electromagnetic spectrum (Credit: NASA ) This image of San Francisco shows that Golden Gate Park reflects a lot of green light and absorbs red and blue light (which makes it look green to us). Seafoam along the western coast reflects red, green AND blue light (which makes it look white to us). Fig. 3 Planet image of San Francisco. Other satellites and instruments record light in different parts of the electromagnetic spectrum, including ultraviolet or thermal infrared. Bees can even see ultraviolet light! Fig. 4 What a bee sees vs. what we see. Interestingly, chlorophyll reflects a lot of near-infrared (NIR) light, which means it's useful for highlighting plants. Water absorbs NIR light, so it's easy to distinguish green water from green plants. Check out the image below - it alternates between a normal RGB image and a false-color image created with NIR, red and blue bands. That green lake in the upper left looks a lot like the green forest NE of center - except when you look at the false color image: the lake looks black, while the dense forest is dark red. As you might imagine, this is really useful for agricultural applications - like checking crop health (more chlorophyll = healthier growth) - or tracking deforestation. Fig. 5: Standard RapidEye RGB image near Santa Cruz vs. false color with NIR Other materials reflect different wavelengths of light in different ways. The graphs below show the spectral signatures of different features you might see in a satellite image (see Figs. 6 & 7). We can use these spectral signatures to classify different types of features on the ground. The graphs below show the amount of light reflected off a particular surface at a particular wavelength of light. So what can you actually see in our imagery? Look for patterns across a landscape? Measure urban growth? Track fires, sandstorms, floods? Do you know what to look for? This NASA guide offers useful tips for visually inspecting and interpreting images - no code necessary! The most interesting thing about our imagery is the fact that it is updated so often. Because we have so many satellites in space (137 at the time of writing, but we're launching more soon), we can image the same place frequently. Once our full constellation is launched later this year, we'll be imaging the entire world every day. So we'll be able to watch crops grow, buildings appear, or deforestation spread - all as it happens. No one has been able to do that in such detail before, so we're very excited about the possibilities. So have at it! You've got access to all our data for California through our OpenCalifornia initiative, and there's a lot to explore. Submit a request if you need any help or have feedback, and please let us know how you use the data.","tags":"images","url":"https://developers.planet.com/docs/images/satellite-imagery/","loc":"https://developers.planet.com/docs/images/satellite-imagery/"},{"title":"Remote Sensing Indices","text":"Dynamically rendering false-color indices Planet's Surface Reflectance Basemap products are also available in false-color visualizations to support a wider range of analysis. Currently the following seven band combinations and indices available via Tile Service: Red-Green-Blue (RGB) Color-infrared (CIR) Normalized Difference Vegetation Index (NDVI) Normalized Difference Water Index (NDWI) Visual Atmosphere Resistance Index (VARI) Modified Soil-adjusted Vegetation Index (MSAVI2) Modified Triangular Vegetation Index (MTVI2) Triangular Greenness Index (TGI) NOTE: False-color indices and band math visualizations are available only on Surface Reflectance basemaps. Remote Sensing Indices & Legends Index Formula Legend URL Parameters NDVI \\(\\frac{ir - r}{ir + r}\\) ?proc=ndvi NDWI \\(\\frac{g - ir}{g + ir}\\) ?proc=ndwi MSAVI2 \\(\\frac{2 * ir + 1 - \\sqrt{(2 * ir + 1)&#94;2 - 8(ir - r)}}{2}\\) ?proc=msavi2 MTVI2 \\(\\frac{1.5 * ( 1.2 * (ir - g) - 2.5 * (r - g)}{\\sqrt{(2 * ir + 1) &#94; 2 - (6 * ir -5 * \\sqrt{r})} - .5}\\) ?proc=mtvi2 VARI \\(\\frac{g - r}{g + r - b}\\) ?proc=vari TGI \\(\\frac{(120 * (r - b)) - (190 * (r - g))}{2}\\) ?proc=tgi","tags":"basemaps","url":"https://developers.planet.com/docs/basemaps/tile-services/indices","loc":"https://developers.planet.com/docs/basemaps/tile-services/indices"},{"title":"Understanding PlanetScope Instruments","text":"PlanetScope imagery products are derived from three cohorts of satellites, with instrument IDs of PS2 , PS2.SD , and PSB.SD . Planet achieved Mission 1 after the successful launch of 88 Dove satellites in February 2017 and the successful launch of a further 48 Dove satellites in July 2017. This groundbreaking feat enabled Planet to image the world's land mass, roughly 200Mkm2, every single day in 4 spectral bands: blue, green, red and near-infrared (NIR). As of August, 2021, Planet has been able to refresh all the original Dove satellites with the next generation of Doves. Planet keeps a near-daily cadence and has added four additional bands: green I, red edge, yellow and coastal blue. The PSB.SD instrument The newest PSB.SD instrument consists of the next-generation \"PSBlue\" telescope with a larger 47 megapixel sensor and the same filter response as PS2.SD below, in the Red, Green, Blue and NIR bands. The PSB.SD payloads extend this capability so that in addition to the four bands that are identical to the PS2.SD spectral bands below (Red, Green, Blue, and NIR), there are four additional bands. These additional bands are Red Edge, Green I, Yellow, and Coastal Blue. Red Edge is meant to be interoperable with Sentinel-2 band 5. Please refer to the table below in this section to see the absorption range for each band. Band Name Wavelength (fwhm) Interoperable with Sentinel-2 1 Coastal Blue 443 (20) Yes - with Sentinel-2 band 1 2 Blue 490 (50) Yes - with Sentinel-2 band 2 3 Green I 531 (36) No equivalent with Sentinel-2 4 Green 565 (36) Yes - with Sentinel-2 band 3 5 Yellow 610 (20) No equivalent with Sentinel-2 6 Red 665 (31) Yes - with Sentinel-2 band 4 7 Red Edge 705 (15) Yes - with Sentinel-2 band 5 8 NIR 865 (40) Yes - with Sentinel-2 band 8a Please refer to this CSV for spectral response within absorption ranges. There is a new, larger sensor on the PSB.SD payload, meaning that the framing of scene products are larger in both directions when compared to PS2.SD and Dove Classic scene products. Each frame consists of eight stripes, as seen below. In order to generate the final 8-band image, we stack together a number of consecutive frames on either side of a given frame. Earliest imagery available is mid-March, 2020 to current monitoring. The PS2.SD instrument The PS2.SD instrument is composed of the same \"PS2\" telescope and the same 2D frame detector as used in PS2 ( see below ). The Bayer pattern filter and pass-band filters in the PS2 satellites have been replaced with a high-performance butcher-block filter. The PS2.SD filter is made up of 4 individual pass-band filters that separate the light into each of the blue, green, red, and NIR channels. The choice of the pass-band filters for PS2.SD match closely with, and are interoperable with, those of Sentinel-2. We've named this new instrument PS2.SD . Each frame acquired by the PS2.SD instrument consists of 4 stripes, as seen below. In order to generate the final 4-band image, we stack together a number of consecutive frames on either side of a given frame. Earliest imagery available is on March, 2019 to April 22, 2022. The PS2 instrument The PS2 satellites carry instruments consisting of a telescope we call \"PS2\" paired with a 2D frame detector having 6600 pixels across by 4400 lines down. The detector has a Bayer pattern filter separating the wavelengths of light into blue, green, and red channels. On top of the Bayer pattern filter is a \"2-stripe\" filter. The top half blocks the NIR wavelengths, thus allowing only the blue, green, and red light to pass through. The bottom half allows only the NIR wavelengths of light to pass through. The result is that each frame acquired by the PS2 instrument consists of a top half that is an RGB image and a bottom half that is an NIR image (as seen below). The RGB half of each frame is then combined with the NIR half of the adjacent frame in order to generate the resulting 4-band image. Earliest imagery available on July, 2014 to April 29, 2022. Band order and sensor frequency Depending on the scene product requested—3-band, 4-band, or 8-band—imagery can come back from a combination of different sensors. The following table provides the frequencies of the imagery returned from the three sensors. Band Order and Sensor Frequency Imagery Frequency of Order Returned from PlanetScope Sensors Bands Ordered Imagery from PS2 Imagery from PS2.SD Imagery from PSB.SD 3-band Band 1 = Red Red: 590 - 670 nm Red: 650 - 682 nm Red: 650 - 680 nm Band 2 = Green Green: 500 - 590 nm Green: 547 - 585 nm Green: 547 - 585 nm Band 3 = Blue Blue: 455 - 515 nm Blue: 464 - 517 nm Blue: 465 - 515 nm 4-band Band 1 = Blue Blue: 455 - 515 nm Blue: 464 - 517 nm Blue: 465 - 515 nm Band 2 = Green Green: 500 - 590 nm Green: 547 - 585 nm Green: 547 - 585 nm Band 3 = Red Red: 590 - 670 nm Red: 650 - 682 nm Red: 650 - 680 nm Band 4 = Near-infrared NIR: 780 - 860 nm NIR: 846 - 888 nm NIR: 845 - 885 nm 8-band Band 1 = Coastal Blue n/a n/a Coastal Blue 431 - 452 nm Band 2 = Blue Blue: 465 - 515 nm Band 3 = Green I Green I: 513 - 549 nm Band 4 = Green Green: 547 - 583 nm Band 5 = Yellow Yellow: 600 - 620 nm Band 6 = Red Red: 650 - 680 nm Band 7 = Red Edge Red Edge: 697 - 713 nm Band 8 = Near-infrared NIR: 845 - 885 nm","tags":"data-api","url":"https://developers.planet.com/docs/apis/data/sensors/","loc":"https://developers.planet.com/docs/apis/data/sensors/"},{"title":"Planet Integrations","text":"Planet's Integrations meet you where you are by making it easier to access Planet imagery in your workflows. Planet's GIS Integrations with ArcGIS Pro and QGIS Planet's GIS Integrations offer an embedded UI experience within your GIS software that enables you to discover, preview, stream and download Planet imagery & Basemaps directly from your GIS. Access these integrations by installing the Planet ArcGIS Pro Add-In or the Planet QGIS Plugin Use the search panels for imagery and Basemaps to discover the images best fit for your application, directly in your GIS Quickly preview images and stream Basemaps using Planet's tile services to inspect imagery without downloading data Leverage the Basemap tools to visualize change, and identify source metadata for any Basemap pixels Download imagery or Basemaps directly from your GIS Task for high resolution SkySat imagery directly within your GIS maps Planet's GEE Delivery Integration Planet's GEE Delivery Integration offers users a way to send supported Planet imagery types directly to GEE using Planet's Orders API. Directly send supported imagery types to GEE via Planet's Orders API Apply supported Orders API operations to delivery payloads like clip Leverage a default Planet service account, or bring your own to manage your delivery queue","tags":"integrations","url":"https://developers.planet.com/docs/integrations/planet-integrations/","loc":"https://developers.planet.com/docs/integrations/planet-integrations/"},{"title":"Get started with Planet CLI: searching for data","text":"Find complete documentation and examples for Planet's CLI at developers.planet.com/docs/pythonclient .","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/get-started-with-planet-cli-searching-for-data/","loc":"https://developers.planet.com/docs/planetschool/get-started-with-planet-cli-searching-for-data/"},{"title":"An Introduction to Cloud Optimized GeoTIFFS (COGs) Part 2: Converting Regular GeoTIFFs into COGs","text":"For the purpose of this demonstration, we will place a simple order to the Orders API that will return us some Non Cloud Optimized GeoTIFFs. First, we'll use the Data API to do a quick search of the Planet catalog for PSScene items, filtering by a specific AOI and TOI. We will take the item id's returned from that search to submit a simple order to the Orders API. We'll download an analytic bundle containing the GeoTIFFs, udms, and xml files, focusing our attention on just the GeoTIFFs so we can inspect them and convert them to COGs. Import Dependencies In [3]: import requests import os from requests.auth import HTTPBasicAuth import json import pathlib from rio_cogeo.cogeo import cog_translate from rio_cogeo.profiles import cog_profiles Authentication In [4]: ## Get Planet API key stored as an environment variable on your system PLANET_API_KEY = os . getenv ( 'PLANET_API_KEY' ) ## HTTP Basic Authentication planet_auth = HTTPBasicAuth ( PLANET_API_KEY , '' ) In [5]: # set content type to json headers = { 'content-type' : 'application/json' } Create a Search with Planet's Data API In [6]: # Quick Search endpoint BASE_URL = \"https://api.planet.com/data/v1\" quick_search_url = \" {} /quick-search\" . format ( BASE_URL ) print ( quick_search_url ) https://api.planet.com/data/v1/quick-search In [7]: ## Search for items that intersect the specified geometry. The AOI is centered around midtown Manhattan geom_filter = { \"type\" : \"GeometryFilter\" , \"field_name\" : \"geometry\" , \"config\" : { \"type\" : \"Polygon\" , \"coordinates\" : [ [ [ - 73.98674011230469 , 40.7555146258563 ], [ - 73.93670082092285 , 40.7555146258563 ], [ - 73.93670082092285 , 40.80542887583346 ], [ - 73.98674011230469 , 40.80542887583346 ], [ - 73.98674011230469 , 40.7555146258563 ] ] ] } } # Apply a date range filter for imagery. Return all imagery aquired after May 11th, 2021 and on or before # May 17th, 2021 date_range_filter = { \"type\" : \"DateRangeFilter\" , \"field_name\" : \"acquired\" , \"config\" : { \"gt\" : \"2021-05-11T00:00:00Z\" , \"lte\" : \"2021-05-17T00:00:00Z\" } } #Apply a range filter looking at imagery that has cloud cover less than 20 percent range_filter = { \"type\" : \"RangeFilter\" , \"field_name\" : \"cloud_cover\" , \"config\" : { \"lte\" : 0.2 } } # Filter imagery with an AOI around midtown Manhattan aquired after May 10th, 2021 and on or before May 13th, 2021 # with less than 20 percent cloud coverage combined_filters = { \"type\" : \"AndFilter\" , \"config\" : [ geom_filter , date_range_filter , range_filter ] } In [8]: print ( json . dumps ( combined_filters , indent = 2 )) { \"type\": \"AndFilter\", \"config\": [ { \"type\": \"GeometryFilter\", \"field_name\": \"geometry\", \"config\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ -73.98674011230469, 40.7555146258563 ], [ -73.93670082092285, 40.7555146258563 ], [ -73.93670082092285, 40.80542887583346 ], [ -73.98674011230469, 40.80542887583346 ], [ -73.98674011230469, 40.7555146258563 ] ] ] } }, { \"type\": \"DateRangeFilter\", \"field_name\": \"acquired\", \"config\": { \"gt\": \"2021-05-11T00:00:00Z\", \"lte\": \"2021-05-17T00:00:00Z\" } }, { \"type\": \"RangeFilter\", \"field_name\": \"cloud_cover\", \"config\": { \"lte\": 0.2 } } ] } In [9]: # Create the request object for PSScene Imagery search_request_4Band = { \"item_types\" : [ \"PSScene\" ], \"filter\" : combined_filters } In [10]: search_result_4Band = \\ requests . post ( quick_search_url , auth = planet_auth , json = search_request_4Band ) print ( json . dumps ( search_result_4Band . json (), indent = 1 )) { \"_links\": { \"_first\": \"https://api.planet.com/data/v1/searches/a6a765f52fcb49e39386f3007fdea4b9/results?_page=eyJwYWdlX3NpemUiOiAyNTAsICJzb3J0X2J5IjogInB1Ymxpc2hlZCIsICJzb3J0X2Rlc2MiOiB0cnVlLCAic29ydF9zdGFydCI6IG51bGwsICJzb3J0X2xhc3RfaWQiOiBudWxsLCAic29ydF9wcmV2IjogZmFsc2UsICJxdWVyeV9wYXJhbXMiOiB7fX0%3D\", \"_next\": \"https://api.planet.com/data/v1/searches/a6a765f52fcb49e39386f3007fdea4b9/results?_page=eyJwYWdlX3NpemUiOiAyNTAsICJzb3J0X2J5IjogInB1Ymxpc2hlZCIsICJzb3J0X2Rlc2MiOiB0cnVlLCAic29ydF9zdGFydCI6ICIyMDIxLTA1LTEyVDIzOjU5OjMyLjAwMDAwMFoiLCAic29ydF9sYXN0X2lkIjogIjIwMjEwNTEyXzE0NTYzNF83NV8yMjM1IiwgInNvcnRfcHJldiI6IGZhbHNlLCAicXVlcnlfcGFyYW1zIjoge319\", \"_self\": \"https://api.planet.com/data/v1/searches/a6a765f52fcb49e39386f3007fdea4b9/results?_page=eyJwYWdlX3NpemUiOiAyNTAsICJzb3J0X2J5IjogInB1Ymxpc2hlZCIsICJzb3J0X2Rlc2MiOiB0cnVlLCAic29ydF9zdGFydCI6IG51bGwsICJzb3J0X2xhc3RfaWQiOiBudWxsLCAic29ydF9wcmV2IjogZmFsc2UsICJxdWVyeV9wYXJhbXMiOiB7fX0%3D\" }, \"features\": [ { \"_links\": { \"_self\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210515_145754_03_245c\", \"assets\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210515_145754_03_245c/assets/\", \"thumbnail\": \"https://tiles.planet.com/data/v1/item-types/PSScene/items/20210515_145754_03_245c/thumb\" }, \"_permissions\": [ \"assets.analytic:download\", \"assets.analytic_dn:download\", \"assets.analytic_dn_xml:download\", \"assets.analytic_sr:download\", \"assets.analytic_xml:download\", \"assets.basic_analytic:download\", \"assets.basic_analytic_dn:download\", \"assets.basic_analytic_dn_nitf:download\", \"assets.basic_analytic_dn_rpc:download\", \"assets.basic_analytic_dn_rpc_nitf:download\", \"assets.basic_analytic_dn_xml:download\", \"assets.basic_analytic_dn_xml_nitf:download\", \"assets.basic_analytic_nitf:download\", \"assets.basic_analytic_rpc:download\", \"assets.basic_analytic_rpc_nitf:download\", \"assets.basic_analytic_xml:download\", \"assets.basic_analytic_xml_nitf:download\", \"assets.basic_udm:download\", \"assets.basic_udm2:download\", \"assets.udm:download\", \"assets.udm2:download\" ], \"geometry\": { \"coordinates\": [ [ [ -74.37268412366183, 40.859446283772684 ], [ -74.42776593697927, 40.669786898778845 ], [ -74.0116429878091, 40.59898584160791 ], [ -73.95524731926979, 40.788094482224984 ], [ -74.37268412366183, 40.859446283772684 ] ] ], \"type\": \"Polygon\" }, \"id\": \"20210515_145754_03_245c\", \"properties\": { \"acquired\": \"2021-05-15T14:57:54.037986Z\", \"anomalous_pixels\": 0, \"clear_confidence_percent\": 97, \"clear_percent\": 100, \"cloud_cover\": 0, \"cloud_percent\": 0, \"columns\": 13261, \"epsg_code\": 32618, \"ground_control\": true, \"gsd\": 4.1, \"heavy_haze_percent\": 0, \"instrument\": \"PSB.SD\", \"item_type\": \"PSScene\", \"light_haze_percent\": 0, \"origin_x\": 548364, \"origin_y\": 4523346, \"pixel_resolution\": 3, \"provider\": \"planetscope\", \"published\": \"2021-05-16T02:53:35Z\", \"publishing_stage\": \"finalized\", \"quality_category\": \"standard\", \"rows\": 9545, \"satellite_azimuth\": 109.8, \"satellite_id\": \"245c\", \"shadow_percent\": 0, \"snow_ice_percent\": 0, \"strip_id\": \"4481598\", \"sun_azimuth\": 122.8, \"sun_elevation\": 57.3, \"updated\": \"2021-05-16T10:02:42Z\", \"view_angle\": 1, \"visible_confidence_percent\": 75, \"visible_percent\": 100 }, \"type\": \"Feature\" }, { \"_links\": { \"_self\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210515_145751_73_245c\", \"assets\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210515_145751_73_245c/assets/\", \"thumbnail\": \"https://tiles.planet.com/data/v1/item-types/PSScene/items/20210515_145751_73_245c/thumb\" }, \"_permissions\": [ \"assets.analytic:download\", \"assets.analytic_dn:download\", \"assets.analytic_dn_xml:download\", \"assets.analytic_sr:download\", \"assets.analytic_xml:download\", \"assets.basic_analytic:download\", \"assets.basic_analytic_dn:download\", \"assets.basic_analytic_dn_nitf:download\", \"assets.basic_analytic_dn_rpc:download\", \"assets.basic_analytic_dn_rpc_nitf:download\", \"assets.basic_analytic_dn_xml:download\", \"assets.basic_analytic_dn_xml_nitf:download\", \"assets.basic_analytic_nitf:download\", \"assets.basic_analytic_rpc:download\", \"assets.basic_analytic_rpc_nitf:download\", \"assets.basic_analytic_xml:download\", \"assets.basic_analytic_xml_nitf:download\", \"assets.basic_udm:download\", \"assets.basic_udm2:download\", \"assets.udm:download\", \"assets.udm2:download\" ], \"geometry\": { \"coordinates\": [ [ [ -74.33131600482537, 41.00269427575604 ], [ -74.38662597145866, 40.81303664055583 ], [ -73.96954443048755, 40.74217839692822 ], [ -73.91294381869535, 40.93129014515558 ], [ -74.33131600482537, 41.00269427575604 ] ] ], \"type\": \"Polygon\" }, \"id\": \"20210515_145751_73_245c\", \"properties\": { \"acquired\": \"2021-05-15T14:57:51.738548Z\", \"anomalous_pixels\": 0, \"clear_confidence_percent\": 99, \"clear_percent\": 100, \"cloud_cover\": 0, \"cloud_percent\": 0, \"columns\": 13263, \"epsg_code\": 32618, \"ground_control\": true, \"gsd\": 4.1, \"heavy_haze_percent\": 0, \"instrument\": \"PSB.SD\", \"item_type\": \"PSScene\", \"light_haze_percent\": 0, \"origin_x\": 551730, \"origin_y\": 4539273, \"pixel_resolution\": 3, \"provider\": \"planetscope\", \"published\": \"2021-05-16T02:53:35Z\", \"publishing_stage\": \"finalized\", \"quality_category\": \"standard\", \"rows\": 9542, \"satellite_azimuth\": 109.8, \"satellite_id\": \"245c\", \"shadow_percent\": 0, \"snow_ice_percent\": 0, \"strip_id\": \"4481598\", \"sun_azimuth\": 123.1, \"sun_elevation\": 57.2, \"updated\": \"2021-05-16T06:47:52Z\", \"view_angle\": 1, \"visible_confidence_percent\": 76, \"visible_percent\": 100 }, \"type\": \"Feature\" }, { \"_links\": { \"_self\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210514_145807_70_2455\", \"assets\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210514_145807_70_2455/assets/\", \"thumbnail\": \"https://tiles.planet.com/data/v1/item-types/PSScene/items/20210514_145807_70_2455/thumb\" }, \"_permissions\": [ \"assets.analytic:download\", \"assets.analytic_dn:download\", \"assets.analytic_dn_xml:download\", \"assets.analytic_sr:download\", \"assets.analytic_xml:download\", \"assets.basic_analytic:download\", \"assets.basic_analytic_dn:download\", \"assets.basic_analytic_dn_nitf:download\", \"assets.basic_analytic_dn_rpc:download\", \"assets.basic_analytic_dn_rpc_nitf:download\", \"assets.basic_analytic_dn_xml:download\", \"assets.basic_analytic_dn_xml_nitf:download\", \"assets.basic_analytic_nitf:download\", \"assets.basic_analytic_rpc:download\", \"assets.basic_analytic_rpc_nitf:download\", \"assets.basic_analytic_xml:download\", \"assets.basic_analytic_xml_nitf:download\", \"assets.basic_udm:download\", \"assets.basic_udm2:download\", \"assets.udm:download\", \"assets.udm2:download\" ], \"geometry\": { \"coordinates\": [ [ [ -74.24446662789185, 40.8059426626398 ], [ -74.30175541923639, 40.615109164051304 ], [ -73.88166825754688, 40.541004593103835 ], [ -73.82304346424415, 40.73219629803683 ], [ -74.24446662789185, 40.8059426626398 ] ] ], \"type\": \"Polygon\" }, \"id\": \"20210514_145807_70_2455\", \"properties\": { \"acquired\": \"2021-05-14T14:58:07.707762Z\", \"anomalous_pixels\": 0, \"clear_confidence_percent\": 97, \"clear_percent\": 100, \"cloud_cover\": 0, \"cloud_percent\": 0, \"columns\": 13441, \"epsg_code\": 32618, \"ground_control\": true, \"gsd\": 4.1, \"heavy_haze_percent\": 0, \"instrument\": \"PSB.SD\", \"item_type\": \"PSScene\", \"light_haze_percent\": 0, \"origin_x\": 559062, \"origin_y\": 4517490, \"pixel_resolution\": 3, \"provider\": \"planetscope\", \"published\": \"2021-05-15T05:55:18Z\", \"publishing_stage\": \"finalized\", \"quality_category\": \"standard\", \"rows\": 9695, \"satellite_azimuth\": 277, \"satellite_id\": \"2455\", \"shadow_percent\": 0, \"snow_ice_percent\": 0, \"strip_id\": \"4478204\", \"sun_azimuth\": 122.9, \"sun_elevation\": 56.9, \"updated\": \"2021-05-15T08:12:01Z\", \"view_angle\": 2.9, \"visible_confidence_percent\": 68, \"visible_percent\": 100 }, \"type\": \"Feature\" }, { \"_links\": { \"_self\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210514_145805_22_2455\", \"assets\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210514_145805_22_2455/assets/\", \"thumbnail\": \"https://tiles.planet.com/data/v1/item-types/PSScene/items/20210514_145805_22_2455/thumb\" }, \"_permissions\": [ \"assets.analytic:download\", \"assets.analytic_dn:download\", \"assets.analytic_dn_xml:download\", \"assets.analytic_sr:download\", \"assets.analytic_xml:download\", \"assets.basic_analytic:download\", \"assets.basic_analytic_dn:download\", \"assets.basic_analytic_dn_nitf:download\", \"assets.basic_analytic_dn_rpc:download\", \"assets.basic_analytic_dn_rpc_nitf:download\", \"assets.basic_analytic_dn_xml:download\", \"assets.basic_analytic_dn_xml_nitf:download\", \"assets.basic_analytic_nitf:download\", \"assets.basic_analytic_rpc:download\", \"assets.basic_analytic_rpc_nitf:download\", \"assets.basic_analytic_xml:download\", \"assets.basic_analytic_xml_nitf:download\", \"assets.basic_udm:download\", \"assets.basic_udm2:download\", \"assets.udm:download\", \"assets.udm2:download\" ], \"geometry\": { \"coordinates\": [ [ [ -74.19832042788863, 40.95974534147435 ], [ -74.25591563689633, 40.76891583288914 ], [ -73.83476372219397, 40.69473031056543 ], [ -73.77595107651916, 40.88592501691234 ], [ -74.19832042788863, 40.95974534147435 ] ] ], \"type\": \"Polygon\" }, \"id\": \"20210514_145805_22_2455\", \"properties\": { \"acquired\": \"2021-05-14T14:58:05.229202Z\", \"anomalous_pixels\": 0, \"clear_confidence_percent\": 98, \"clear_percent\": 100, \"cloud_cover\": 0, \"cloud_percent\": 0, \"columns\": 13443, \"epsg_code\": 32618, \"ground_control\": true, \"gsd\": 4.1, \"heavy_haze_percent\": 0, \"instrument\": \"PSB.SD\", \"item_type\": \"PSScene\", \"light_haze_percent\": 0, \"origin_x\": 562794, \"origin_y\": 4534599, \"pixel_resolution\": 3, \"provider\": \"planetscope\", \"published\": \"2021-05-15T05:55:18Z\", \"publishing_stage\": \"finalized\", \"quality_category\": \"standard\", \"rows\": 9693, \"satellite_azimuth\": 277.1, \"satellite_id\": \"2455\", \"shadow_percent\": 0, \"snow_ice_percent\": 0, \"strip_id\": \"4478204\", \"sun_azimuth\": 123.2, \"sun_elevation\": 56.9, \"updated\": \"2021-05-15T08:12:01Z\", \"view_angle\": 3, \"visible_confidence_percent\": 69, \"visible_percent\": 100 }, \"type\": \"Feature\" }, { \"_links\": { \"_self\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210514_154816_78_227b\", \"assets\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210514_154816_78_227b/assets/\", \"thumbnail\": \"https://tiles.planet.com/data/v1/item-types/PSScene/items/20210514_154816_78_227b/thumb\" }, \"_permissions\": [ \"assets.analytic:download\", \"assets.analytic_dn:download\", \"assets.analytic_dn_xml:download\", \"assets.analytic_sr:download\", \"assets.analytic_xml:download\", \"assets.basic_analytic:download\", \"assets.basic_analytic_dn:download\", \"assets.basic_analytic_dn_nitf:download\", \"assets.basic_analytic_dn_rpc:download\", \"assets.basic_analytic_dn_rpc_nitf:download\", \"assets.basic_analytic_dn_xml:download\", \"assets.basic_analytic_dn_xml_nitf:download\", \"assets.basic_analytic_nitf:download\", \"assets.basic_analytic_rpc:download\", \"assets.basic_analytic_rpc_nitf:download\", \"assets.basic_analytic_xml:download\", \"assets.basic_analytic_xml_nitf:download\", \"assets.basic_udm:download\", \"assets.basic_udm2:download\", \"assets.udm:download\", \"assets.udm2:download\" ], \"geometry\": { \"coordinates\": [ [ [ -74.11165238530299, 40.88022844171581 ], [ -74.16965097087387, 40.688244984254446 ], [ -73.74516771292764, 40.612673868851914 ], [ -73.68540002302983, 40.80549464933756 ], [ -74.11165238530299, 40.88022844171581 ] ] ], \"type\": \"Polygon\" }, \"id\": \"20210514_154816_78_227b\", \"properties\": { \"acquired\": \"2021-05-14T15:48:16.780257Z\", \"anomalous_pixels\": 0, \"clear_confidence_percent\": 96, \"clear_percent\": 100, \"cloud_cover\": 0, \"cloud_percent\": 0, \"columns\": 13575, \"epsg_code\": 32618, \"ground_control\": true, \"gsd\": 4.1, \"heavy_haze_percent\": 0, \"instrument\": \"PSB.SD\", \"item_type\": \"PSScene\", \"light_haze_percent\": 0, \"origin_x\": 570162, \"origin_y\": 4525842, \"pixel_resolution\": 3, \"provider\": \"planetscope\", \"published\": \"2021-05-15T04:46:54Z\", \"publishing_stage\": \"finalized\", \"quality_category\": \"standard\", \"rows\": 9775, \"satellite_azimuth\": 278.5, \"satellite_id\": \"227b\", \"shadow_percent\": 0, \"snow_ice_percent\": 0, \"strip_id\": \"4478803\", \"sun_azimuth\": 142.4, \"sun_elevation\": 63.8, \"updated\": \"2021-05-15T10:14:08Z\", \"view_angle\": 5, \"visible_confidence_percent\": 75, \"visible_percent\": 100 }, \"type\": \"Feature\" }, { \"_links\": { \"_self\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210513_152348_101f\", \"assets\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210513_152348_101f/assets/\", \"thumbnail\": \"https://tiles.planet.com/data/v1/item-types/PSScene/items/20210513_152348_101f/thumb\" }, \"_permissions\": [ \"assets.analytic:download\", \"assets.analytic_dn:download\", \"assets.analytic_dn_xml:download\", \"assets.analytic_sr:download\", \"assets.analytic_xml:download\", \"assets.basic_analytic:download\", \"assets.basic_analytic_dn:download\", \"assets.basic_analytic_dn_nitf:download\", \"assets.basic_analytic_dn_rpc:download\", \"assets.basic_analytic_dn_rpc_nitf:download\", \"assets.basic_analytic_dn_xml:download\", \"assets.basic_analytic_dn_xml_nitf:download\", \"assets.basic_analytic_nitf:download\", \"assets.basic_analytic_rpc:download\", \"assets.basic_analytic_rpc_nitf:download\", \"assets.basic_analytic_xml:download\", \"assets.basic_analytic_xml_nitf:download\", \"assets.basic_udm:download\", \"assets.basic_udm2:download\", \"assets.udm:download\", \"assets.udm2:download\" ], \"geometry\": { \"coordinates\": [ [ [ -73.9672324650034, 40.81564535503385 ], [ -73.67655740377553, 40.76608458487274 ], [ -73.69766539333473, 40.69454427012009 ], [ -73.98863012303238, 40.744440151313285 ], [ -73.97149039187175, 40.803480093216486 ], [ -73.97080263288335, 40.803362226135754 ], [ -73.9672324650034, 40.81564535503385 ] ] ], \"type\": \"Polygon\" }, \"id\": \"20210513_152348_101f\", \"properties\": { \"acquired\": \"2021-05-13T15:23:48.063258Z\", \"anomalous_pixels\": 0.08, \"clear_confidence_percent\": 94, \"clear_percent\": 96, \"cloud_cover\": 0.04, \"cloud_percent\": 2, \"columns\": 8772, \"epsg_code\": 32618, \"ground_control\": true, \"gsd\": 3.8, \"heavy_haze_percent\": 0, \"instrument\": \"PS2\", \"item_type\": \"PSScene\", \"light_haze_percent\": 0, \"origin_x\": 585384, \"origin_y\": 4518807, \"pixel_resolution\": 3, \"provider\": \"planetscope\", \"published\": \"2021-05-14T02:53:45Z\", \"publishing_stage\": \"finalized\", \"quality_category\": \"standard\", \"rows\": 4381, \"satellite_azimuth\": 277.5, \"satellite_id\": \"101f\", \"shadow_percent\": 2, \"snow_ice_percent\": 0, \"strip_id\": \"4475303\", \"sun_azimuth\": 132.6, \"sun_elevation\": 60.7, \"updated\": \"2021-05-14T06:59:42Z\", \"view_angle\": 4, \"visible_confidence_percent\": 76, \"visible_percent\": 98 }, \"type\": \"Feature\" }, { \"_links\": { \"_self\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210513_152347_101f\", \"assets\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210513_152347_101f/assets/\", \"thumbnail\": \"https://tiles.planet.com/data/v1/item-types/PSScene/items/20210513_152347_101f/thumb\" }, \"_permissions\": [ \"assets.analytic:download\", \"assets.analytic_dn:download\", \"assets.analytic_dn_xml:download\", \"assets.analytic_sr:download\", \"assets.analytic_xml:download\", \"assets.basic_analytic:download\", \"assets.basic_analytic_dn:download\", \"assets.basic_analytic_dn_nitf:download\", \"assets.basic_analytic_dn_rpc:download\", \"assets.basic_analytic_dn_rpc_nitf:download\", \"assets.basic_analytic_dn_xml:download\", \"assets.basic_analytic_dn_xml_nitf:download\", \"assets.basic_analytic_nitf:download\", \"assets.basic_analytic_rpc:download\", \"assets.basic_analytic_rpc_nitf:download\", \"assets.basic_analytic_xml:download\", \"assets.basic_analytic_xml_nitf:download\", \"assets.basic_udm:download\", \"assets.basic_udm2:download\", \"assets.udm:download\", \"assets.udm2:download\" ], \"geometry\": { \"coordinates\": [ [ [ -73.94812826450752, 40.878764123248295 ], [ -73.6572588318352, 40.82925512193429 ], [ -73.67849350656874, 40.757712754345924 ], [ -73.96957614635204, 40.80758194147197 ], [ -73.95238977660173, 40.866711484404455 ], [ -73.95165876186178, 40.86658634858055 ], [ -73.94812826450752, 40.878764123248295 ] ] ], \"type\": \"Polygon\" }, \"id\": \"20210513_152347_101f\", \"properties\": { \"acquired\": \"2021-05-13T15:23:47.058198Z\", \"anomalous_pixels\": 0.08, \"clear_confidence_percent\": 95, \"clear_percent\": 95, \"cloud_cover\": 0.03, \"cloud_percent\": 3, \"columns\": 8770, \"epsg_code\": 32618, \"ground_control\": true, \"gsd\": 3.8, \"heavy_haze_percent\": 0, \"instrument\": \"PS2\", \"item_type\": \"PSScene\", \"light_haze_percent\": 0, \"origin_x\": 586911, \"origin_y\": 4525833, \"pixel_resolution\": 3, \"provider\": \"planetscope\", \"published\": \"2021-05-14T02:53:45Z\", \"publishing_stage\": \"finalized\", \"quality_category\": \"standard\", \"rows\": 4378, \"satellite_azimuth\": 277.5, \"satellite_id\": \"101f\", \"shadow_percent\": 2, \"snow_ice_percent\": 0, \"strip_id\": \"4475303\", \"sun_azimuth\": 132.7, \"sun_elevation\": 60.6, \"updated\": \"2021-05-14T06:59:42Z\", \"view_angle\": 4, \"visible_confidence_percent\": 75, \"visible_percent\": 97 }, \"type\": \"Feature\" }, { \"_links\": { \"_self\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210513_150713_64_1067\", \"assets\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210513_150713_64_1067/assets/\", \"thumbnail\": \"https://tiles.planet.com/data/v1/item-types/PSScene/items/20210513_150713_64_1067/thumb\" }, \"_permissions\": [ \"assets.analytic:download\", \"assets.analytic_dn:download\", \"assets.analytic_dn_xml:download\", \"assets.analytic_sr:download\", \"assets.analytic_xml:download\", \"assets.basic_analytic:download\", \"assets.basic_analytic_dn:download\", \"assets.basic_analytic_dn_nitf:download\", \"assets.basic_analytic_dn_rpc:download\", \"assets.basic_analytic_dn_rpc_nitf:download\", \"assets.basic_analytic_dn_xml:download\", \"assets.basic_analytic_dn_xml_nitf:download\", \"assets.basic_analytic_nitf:download\", \"assets.basic_analytic_rpc:download\", \"assets.basic_analytic_rpc_nitf:download\", \"assets.basic_analytic_xml:download\", \"assets.basic_analytic_xml_nitf:download\", \"assets.basic_udm:download\", \"assets.basic_udm2:download\", \"assets.udm:download\", \"assets.udm2:download\" ], \"geometry\": { \"coordinates\": [ [ [ -74.24868126954468, 40.738094335373525 ], [ -74.20771604517796, 40.59348951919248 ], [ -73.92144378585328, 40.63976411448478 ], [ -73.96201579685065, 40.785054430186705 ], [ -74.24868126954468, 40.738094335373525 ] ] ], \"type\": \"Polygon\" }, \"id\": \"20210513_150713_64_1067\", \"properties\": { \"acquired\": \"2021-05-13T15:07:13.643492Z\", \"anomalous_pixels\": 0, \"clear_confidence_percent\": 97, \"clear_percent\": 95, \"cloud_cover\": 0, \"cloud_percent\": 4, \"columns\": 9256, \"epsg_code\": 32618, \"ground_control\": true, \"gsd\": 3.7, \"heavy_haze_percent\": 0, \"instrument\": \"PS2.SD\", \"item_type\": \"PSScene\", \"light_haze_percent\": 0, \"origin_x\": 563436, \"origin_y\": 4515417, \"pixel_resolution\": 3, \"provider\": \"planetscope\", \"published\": \"2021-05-14T02:47:44Z\", \"publishing_stage\": \"finalized\", \"quality_category\": \"standard\", \"rows\": 7162, \"satellite_azimuth\": 258.3, \"satellite_id\": \"1067\", \"shadow_percent\": 1, \"snow_ice_percent\": 0, \"strip_id\": \"4475043\", \"sun_azimuth\": 126, \"sun_elevation\": 58.1, \"updated\": \"2021-05-14T08:59:15Z\", \"view_angle\": 4.1, \"visible_confidence_percent\": 85, \"visible_percent\": 96 }, \"type\": \"Feature\" }, { \"_links\": { \"_self\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210513_150715_17_1067\", \"assets\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210513_150715_17_1067/assets/\", \"thumbnail\": \"https://tiles.planet.com/data/v1/item-types/PSScene/items/20210513_150715_17_1067/thumb\" }, \"_permissions\": [ \"assets.analytic:download\", \"assets.analytic_dn:download\", \"assets.analytic_dn_xml:download\", \"assets.analytic_sr:download\", \"assets.analytic_xml:download\", \"assets.basic_analytic:download\", \"assets.basic_analytic_dn:download\", \"assets.basic_analytic_dn_nitf:download\", \"assets.basic_analytic_dn_rpc:download\", \"assets.basic_analytic_dn_rpc_nitf:download\", \"assets.basic_analytic_dn_xml:download\", \"assets.basic_analytic_dn_xml_nitf:download\", \"assets.basic_analytic_nitf:download\", \"assets.basic_analytic_rpc:download\", \"assets.basic_analytic_rpc_nitf:download\", \"assets.basic_analytic_xml:download\", \"assets.basic_analytic_xml_nitf:download\", \"assets.basic_udm:download\", \"assets.basic_udm2:download\", \"assets.udm:download\", \"assets.udm2:download\" ], \"geometry\": { \"coordinates\": [ [ [ -74.27631322948251, 40.834882218188305 ], [ -74.23519958613848, 40.6902935056587 ], [ -73.94853801714905, 40.73659466447457 ], [ -73.98913398299976, 40.88191007766607 ], [ -74.27631322948251, 40.834882218188305 ] ] ], \"type\": \"Polygon\" }, \"id\": \"20210513_150715_17_1067\", \"properties\": { \"acquired\": \"2021-05-13T15:07:15.171792Z\", \"anomalous_pixels\": 0, \"clear_confidence_percent\": 97, \"clear_percent\": 96, \"cloud_cover\": 0, \"cloud_percent\": 3, \"columns\": 9256, \"epsg_code\": 32618, \"ground_control\": true, \"gsd\": 3.7, \"heavy_haze_percent\": 0, \"instrument\": \"PS2.SD\", \"item_type\": \"PSScene\", \"light_haze_percent\": 0, \"origin_x\": 561015, \"origin_y\": 4526142, \"pixel_resolution\": 3, \"provider\": \"planetscope\", \"published\": \"2021-05-14T00:46:59Z\", \"publishing_stage\": \"finalized\", \"quality_category\": \"standard\", \"rows\": 7162, \"satellite_azimuth\": 258.4, \"satellite_id\": \"1067\", \"shadow_percent\": 2, \"snow_ice_percent\": 0, \"strip_id\": \"4475043\", \"sun_azimuth\": 126.1, \"sun_elevation\": 58.1, \"updated\": \"2021-05-14T06:54:57Z\", \"view_angle\": 4.1, \"visible_confidence_percent\": 86, \"visible_percent\": 97 }, \"type\": \"Feature\" }, { \"_links\": { \"_self\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210512_152647_0f15\", \"assets\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210512_152647_0f15/assets/\", \"thumbnail\": \"https://tiles.planet.com/data/v1/item-types/PSScene/items/20210512_152647_0f15/thumb\" }, \"_permissions\": [ \"assets.analytic:download\", \"assets.analytic_dn:download\", \"assets.analytic_dn_xml:download\", \"assets.analytic_sr:download\", \"assets.analytic_xml:download\", \"assets.basic_analytic:download\", \"assets.basic_analytic_dn:download\", \"assets.basic_analytic_dn_nitf:download\", \"assets.basic_analytic_dn_rpc:download\", \"assets.basic_analytic_dn_rpc_nitf:download\", \"assets.basic_analytic_dn_xml:download\", \"assets.basic_analytic_dn_xml_nitf:download\", \"assets.basic_analytic_nitf:download\", \"assets.basic_analytic_rpc:download\", \"assets.basic_analytic_rpc_nitf:download\", \"assets.basic_analytic_xml:download\", \"assets.basic_analytic_xml_nitf:download\", \"assets.basic_udm:download\", \"assets.basic_udm2:download\", \"assets.udm:download\", \"assets.udm2:download\" ], \"geometry\": { \"coordinates\": [ [ [ -73.99031432008931, 40.71563074078843 ], [ -74.28470047757162, 40.76572808145461 ], [ -74.26330870557332, 40.83794830174201 ], [ -73.96909651736247, 40.78806000415319 ], [ -73.97325723237714, 40.77427147969483 ], [ -73.97270260764692, 40.77417710815058 ], [ -73.99031432008931, 40.71563074078843 ] ] ], \"type\": \"Polygon\" }, \"id\": \"20210512_152647_0f15\", \"properties\": { \"acquired\": \"2021-05-12T15:26:47.88976Z\", \"anomalous_pixels\": 0.04, \"clear_confidence_percent\": 97, \"clear_percent\": 99, \"cloud_cover\": 0.02, \"cloud_percent\": 0, \"columns\": 8870, \"epsg_code\": 32618, \"ground_control\": true, \"gsd\": 3.9, \"heavy_haze_percent\": 0, \"instrument\": \"PS2\", \"item_type\": \"PSScene\", \"light_haze_percent\": 0, \"origin_x\": 560370, \"origin_y\": 4521030, \"pixel_resolution\": 3, \"provider\": \"planetscope\", \"published\": \"2021-05-13T03:52:53Z\", \"publishing_stage\": \"finalized\", \"quality_category\": \"standard\", \"rows\": 4450, \"satellite_azimuth\": 275.2, \"satellite_id\": \"0f15\", \"shadow_percent\": 0, \"snow_ice_percent\": 1, \"strip_id\": \"4471821\", \"sun_azimuth\": 133.9, \"sun_elevation\": 60.8, \"updated\": \"2021-05-13T10:05:35Z\", \"view_angle\": 2, \"visible_confidence_percent\": 83, \"visible_percent\": 100 }, \"type\": \"Feature\" }, { \"_links\": { \"_self\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210512_152646_0f15\", \"assets\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210512_152646_0f15/assets/\", \"thumbnail\": \"https://tiles.planet.com/data/v1/item-types/PSScene/items/20210512_152646_0f15/thumb\" }, \"_permissions\": [ \"assets.analytic:download\", \"assets.analytic_dn:download\", \"assets.analytic_dn_xml:download\", \"assets.analytic_sr:download\", \"assets.analytic_xml:download\", \"assets.basic_analytic:download\", \"assets.basic_analytic_dn:download\", \"assets.basic_analytic_dn_nitf:download\", \"assets.basic_analytic_dn_rpc:download\", \"assets.basic_analytic_dn_rpc_nitf:download\", \"assets.basic_analytic_dn_xml:download\", \"assets.basic_analytic_dn_xml_nitf:download\", \"assets.basic_analytic_nitf:download\", \"assets.basic_analytic_rpc:download\", \"assets.basic_analytic_rpc_nitf:download\", \"assets.basic_analytic_xml:download\", \"assets.basic_analytic_xml_nitf:download\", \"assets.basic_udm:download\", \"assets.basic_udm2:download\", \"assets.udm:download\", \"assets.udm2:download\" ], \"geometry\": { \"coordinates\": [ [ [ -73.97180216210324, 40.77909355282157 ], [ -74.2664028997079, 40.82920836979391 ], [ -74.24494457232056, 40.9014498359252 ], [ -73.95041760834685, 40.8515053377512 ], [ -73.95462404176209, 40.837566369819605 ], [ -73.95418063640875, 40.83749092855522 ], [ -73.97180216210324, 40.77909355282157 ] ] ], \"type\": \"Polygon\" }, \"id\": \"20210512_152646_0f15\", \"properties\": { \"acquired\": \"2021-05-12T15:26:46.883127Z\", \"anomalous_pixels\": 0.03, \"clear_confidence_percent\": 97, \"clear_percent\": 99, \"cloud_cover\": 0.01, \"cloud_percent\": 0, \"columns\": 8872, \"epsg_code\": 32618, \"ground_control\": true, \"gsd\": 3.9, \"heavy_haze_percent\": 0, \"instrument\": \"PS2\", \"item_type\": \"PSScene\", \"light_haze_percent\": 0, \"origin_x\": 561855, \"origin_y\": 4528092, \"pixel_resolution\": 3, \"provider\": \"planetscope\", \"published\": \"2021-05-13T03:52:53Z\", \"publishing_stage\": \"finalized\", \"quality_category\": \"standard\", \"rows\": 4450, \"satellite_azimuth\": 275.2, \"satellite_id\": \"0f15\", \"shadow_percent\": 0, \"snow_ice_percent\": 1, \"strip_id\": \"4471821\", \"sun_azimuth\": 134, \"sun_elevation\": 60.8, \"updated\": \"2021-05-13T10:02:56Z\", \"view_angle\": 2, \"visible_confidence_percent\": 84, \"visible_percent\": 100 }, \"type\": \"Feature\" }, { \"_links\": { \"_self\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210512_152222_1014\", \"assets\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210512_152222_1014/assets/\", \"thumbnail\": \"https://tiles.planet.com/data/v1/item-types/PSScene/items/20210512_152222_1014/thumb\" }, \"_permissions\": [ \"assets.analytic:download\", \"assets.analytic_dn:download\", \"assets.analytic_dn_xml:download\", \"assets.analytic_sr:download\", \"assets.analytic_xml:download\", \"assets.basic_analytic:download\", \"assets.basic_analytic_dn:download\", \"assets.basic_analytic_dn_nitf:download\", \"assets.basic_analytic_dn_rpc:download\", \"assets.basic_analytic_dn_rpc_nitf:download\", \"assets.basic_analytic_dn_xml:download\", \"assets.basic_analytic_dn_xml_nitf:download\", \"assets.basic_analytic_nitf:download\", \"assets.basic_analytic_rpc:download\", \"assets.basic_analytic_rpc_nitf:download\", \"assets.basic_analytic_xml:download\", \"assets.basic_analytic_xml_nitf:download\", \"assets.basic_udm:download\", \"assets.basic_udm2:download\", \"assets.udm:download\", \"assets.udm2:download\" ], \"geometry\": { \"coordinates\": [ [ [ -74.26377944125522, 40.78881729693007 ], [ -74.26223488612236, 40.79419481984668 ], [ -74.26182616840805, 40.794127621628235 ], [ -74.25812651031767, 40.80743674430642 ], [ -73.9650773180917, 40.75902034579338 ], [ -73.9832184062908, 40.694830255120195 ], [ -73.9854670243336, 40.68708009397012 ], [ -74.27872461673279, 40.73534199669171 ], [ -74.26377944125522, 40.78881729693007 ] ] ], \"type\": \"Polygon\" }, \"id\": \"20210512_152222_1014\", \"properties\": { \"acquired\": \"2021-05-12T15:22:22.564228Z\", \"anomalous_pixels\": 0, \"clear_confidence_percent\": 97, \"clear_percent\": 100, \"cloud_cover\": 0.02, \"cloud_percent\": 0, \"columns\": 8819, \"epsg_code\": 32618, \"ground_control\": true, \"gsd\": 3.8, \"heavy_haze_percent\": 0, \"instrument\": \"PS2\", \"item_type\": \"PSScene\", \"light_haze_percent\": 0, \"origin_x\": 560901, \"origin_y\": 4517646, \"pixel_resolution\": 3, \"provider\": \"planetscope\", \"published\": \"2021-05-13T03:45:31Z\", \"publishing_stage\": \"finalized\", \"quality_category\": \"standard\", \"rows\": 4377, \"satellite_azimuth\": 102.5, \"satellite_id\": \"1014\", \"shadow_percent\": 0, \"snow_ice_percent\": 0, \"strip_id\": \"4472149\", \"sun_azimuth\": 132.8, \"sun_elevation\": 60.6, \"updated\": \"2021-05-13T09:53:59Z\", \"view_angle\": 3, \"visible_confidence_percent\": 77, \"visible_percent\": 100 }, \"type\": \"Feature\" }, { \"_links\": { \"_self\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210512_152221_1014\", \"assets\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210512_152221_1014/assets/\", \"thumbnail\": \"https://tiles.planet.com/data/v1/item-types/PSScene/items/20210512_152221_1014/thumb\" }, \"_permissions\": [ \"assets.analytic:download\", \"assets.analytic_dn:download\", \"assets.analytic_dn_xml:download\", \"assets.analytic_sr:download\", \"assets.analytic_xml:download\", \"assets.basic_analytic:download\", \"assets.basic_analytic_dn:download\", \"assets.basic_analytic_dn_nitf:download\", \"assets.basic_analytic_dn_rpc:download\", \"assets.basic_analytic_dn_rpc_nitf:download\", \"assets.basic_analytic_dn_xml:download\", \"assets.basic_analytic_dn_xml_nitf:download\", \"assets.basic_analytic_nitf:download\", \"assets.basic_analytic_rpc:download\", \"assets.basic_analytic_rpc_nitf:download\", \"assets.basic_analytic_xml:download\", \"assets.basic_analytic_xml_nitf:download\", \"assets.basic_udm:download\", \"assets.basic_udm2:download\", \"assets.udm:download\", \"assets.udm2:download\" ], \"geometry\": { \"coordinates\": [ [ [ -74.24642450408183, 40.84954759450063 ], [ -74.24422493235842, 40.857209447972046 ], [ -74.2439205716801, 40.85715947303992 ], [ -74.24021864656655, 40.87052161618214 ], [ -73.94680155826984, 40.822092047902586 ], [ -73.96539574753778, 40.75641215980805 ], [ -73.96721598053044, 40.7501503494916 ], [ -74.26063715285925, 40.79839904931422 ], [ -74.24642450408183, 40.84954759450063 ] ] ], \"type\": \"Polygon\" }, \"id\": \"20210512_152221_1014\", \"properties\": { \"acquired\": \"2021-05-12T15:22:21.558644Z\", \"anomalous_pixels\": 0, \"clear_confidence_percent\": 97, \"clear_percent\": 100, \"cloud_cover\": 0.01, \"cloud_percent\": 0, \"columns\": 8816, \"epsg_code\": 32618, \"ground_control\": true, \"gsd\": 3.8, \"heavy_haze_percent\": 0, \"instrument\": \"PS2\", \"item_type\": \"PSScene\", \"light_haze_percent\": 0, \"origin_x\": 562368, \"origin_y\": 4524663, \"pixel_resolution\": 3, \"provider\": \"planetscope\", \"published\": \"2021-05-13T03:45:31Z\", \"publishing_stage\": \"finalized\", \"quality_category\": \"standard\", \"rows\": 4377, \"satellite_azimuth\": 102.6, \"satellite_id\": \"1014\", \"shadow_percent\": 0, \"snow_ice_percent\": 0, \"strip_id\": \"4472149\", \"sun_azimuth\": 132.9, \"sun_elevation\": 60.5, \"updated\": \"2021-05-13T09:53:59Z\", \"view_angle\": 3, \"visible_confidence_percent\": 83, \"visible_percent\": 100 }, \"type\": \"Feature\" }, { \"_links\": { \"_self\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210512_145636_96_2235\", \"assets\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210512_145636_96_2235/assets/\", \"thumbnail\": \"https://tiles.planet.com/data/v1/item-types/PSScene/items/20210512_145636_96_2235/thumb\" }, \"_permissions\": [ \"assets.analytic:download\", \"assets.analytic_dn:download\", \"assets.analytic_dn_xml:download\", \"assets.analytic_sr:download\", \"assets.analytic_xml:download\", \"assets.basic_analytic:download\", \"assets.basic_analytic_dn:download\", \"assets.basic_analytic_dn_nitf:download\", \"assets.basic_analytic_dn_rpc:download\", \"assets.basic_analytic_dn_rpc_nitf:download\", \"assets.basic_analytic_dn_xml:download\", \"assets.basic_analytic_dn_xml_nitf:download\", \"assets.basic_analytic_nitf:download\", \"assets.basic_analytic_rpc:download\", \"assets.basic_analytic_rpc_nitf:download\", \"assets.basic_analytic_xml:download\", \"assets.basic_analytic_xml_nitf:download\", \"assets.basic_udm:download\", \"assets.basic_udm2:download\", \"assets.udm:download\", \"assets.udm2:download\" ], \"geometry\": { \"coordinates\": [ [ [ -73.96312166532697, 40.830271317535875 ], [ -74.01369495117122, 40.65484329783307 ], [ -73.62890814829333, 40.589951153223076 ], [ -73.57724701927319, 40.76487012699357 ], [ -73.96312166532697, 40.830271317535875 ] ] ], \"type\": \"Polygon\" }, \"id\": \"20210512_145636_96_2235\", \"properties\": { \"acquired\": \"2021-05-12T14:56:36.963261Z\", \"anomalous_pixels\": 0, \"clear_confidence_percent\": 90, \"clear_percent\": 99, \"cloud_cover\": 0, \"cloud_percent\": 0, \"columns\": 12234, \"epsg_code\": 32618, \"ground_control\": true, \"gsd\": 3.8, \"heavy_haze_percent\": 0, \"instrument\": \"PSB.SD\", \"item_type\": \"PSScene\", \"light_haze_percent\": 0, \"origin_x\": 583380, \"origin_y\": 4520436, \"pixel_resolution\": 3, \"provider\": \"planetscope\", \"published\": \"2021-05-12T23:59:32Z\", \"publishing_stage\": \"finalized\", \"quality_category\": \"test\", \"rows\": 8765, \"satellite_azimuth\": 182.3, \"satellite_id\": \"2235\", \"shadow_percent\": 0, \"snow_ice_percent\": 1, \"strip_id\": \"4471165\", \"sun_azimuth\": 123.7, \"sun_elevation\": 56.7, \"updated\": \"2021-05-13T04:07:19Z\", \"view_angle\": 0.1, \"visible_confidence_percent\": 72, \"visible_percent\": 100 }, \"type\": \"Feature\" }, { \"_links\": { \"_self\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210512_145634_75_2235\", \"assets\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20210512_145634_75_2235/assets/\", \"thumbnail\": \"https://tiles.planet.com/data/v1/item-types/PSScene/items/20210512_145634_75_2235/thumb\" }, \"_permissions\": [ \"assets.analytic:download\", \"assets.analytic_dn:download\", \"assets.analytic_dn_xml:download\", \"assets.analytic_sr:download\", \"assets.analytic_xml:download\", \"assets.basic_analytic:download\", \"assets.basic_analytic_dn:download\", \"assets.basic_analytic_dn_nitf:download\", \"assets.basic_analytic_dn_rpc:download\", \"assets.basic_analytic_dn_rpc_nitf:download\", \"assets.basic_analytic_dn_xml:download\", \"assets.basic_analytic_dn_xml_nitf:download\", \"assets.basic_analytic_nitf:download\", \"assets.basic_analytic_rpc:download\", \"assets.basic_analytic_rpc_nitf:download\", \"assets.basic_analytic_xml:download\", \"assets.basic_analytic_xml_nitf:download\", \"assets.basic_udm:download\", \"assets.basic_udm2:download\", \"assets.udm:download\", \"assets.udm2:download\" ], \"geometry\": { \"coordinates\": [ [ [ -73.92236344663175, 40.96908603516853 ], [ -73.97315169812276, 40.79371037759496 ], [ -73.58757474423084, 40.728758751865044 ], [ -73.53570650228487, 40.903663685448315 ], [ -73.92236344663175, 40.96908603516853 ] ] ], \"type\": \"Polygon\" }, \"id\": \"20210512_145634_75_2235\", \"properties\": { \"acquired\": \"2021-05-12T14:56:34.752349Z\", \"anomalous_pixels\": 0, \"clear_confidence_percent\": 97, \"clear_percent\": 100, \"cloud_cover\": 0, \"cloud_percent\": 0, \"columns\": 12235, \"epsg_code\": 32618, \"ground_control\": true, \"gsd\": 3.8, \"heavy_haze_percent\": 0, \"instrument\": \"PSB.SD\", \"item_type\": \"PSScene\", \"light_haze_percent\": 0, \"origin_x\": 586626, \"origin_y\": 4535886, \"pixel_resolution\": 3, \"provider\": \"planetscope\", \"published\": \"2021-05-12T23:59:32Z\", \"publishing_stage\": \"finalized\", \"quality_category\": \"test\", \"rows\": 8760, \"satellite_azimuth\": 183.1, \"satellite_id\": \"2235\", \"shadow_percent\": 0, \"snow_ice_percent\": 0, \"strip_id\": \"4471165\", \"sun_azimuth\": 124, \"sun_elevation\": 56.7, \"updated\": \"2021-05-13T04:26:53Z\", \"view_angle\": 0.1, \"visible_confidence_percent\": 76, \"visible_percent\": 100 }, \"type\": \"Feature\" } ], \"type\": \"FeatureCollection\" } Submit an Order with the Planet Orders API In [14]: # Item id's for PSScene Imagery obtained from our search. We can now use these item id's in # preparing our order item_selection = [ feature [ 'id' ] for feature in search_result_4Band . json ()[ 'features' ]] item_selection Out[14]: ['20210515_145754_03_245c', '20210515_145751_73_245c', '20210514_145807_70_2455', '20210514_145805_22_2455', '20210514_154816_78_227b', '20210513_152348_101f', '20210513_152347_101f', '20210513_150713_64_1067', '20210513_150715_17_1067', '20210512_152647_0f15', '20210512_152646_0f15', '20210512_152222_1014', '20210512_152221_1014', '20210512_145636_96_2235', '20210512_145634_75_2235'] In [13]: # Base Order URL planet_orders_url = 'https://api.planet.com/compute/ops/orders/v2' In [15]: # Prepare a simple order def prepare_simple_order ( order_name , item_list , item_type , bundle_selection ): order_request = { \"name\" : order_name , \"products\" :[ { \"item_ids\" : item_list , \"item_type\" : item_type , \"product_bundle\" : bundle_selection } ] } return order_request In [16]: def submit_simple_order ( order_name , order_items , base_order_url , auth , item_type , bundle_selection ): # Prepare the order request order_request = prepare_simple_order ( order_name , order_items , item_type , bundle_selection ) print ( json . dumps ( order_request , indent = 2 )) # Place the order order_response = requests . post ( base_order_url , json . dumps ( order_request ), auth = auth , headers = headers ) print ( order_response ) return order_response In [ ]: order_response = submit_simple_order ( \"analytic_order\" , item_selection , planet_orders_url , planet_auth , \"PSScene\" , \"analytic\" ) In [ ]: # Append current order id to the base orders URL. Replace with your own order id current_order_url = planet_orders_url + '/' + 'cb363b75-b4e4-46f1-8d32-0ef87afb6215' In [ ]: order_response = requests . get ( current_order_url , auth = planet_auth ) In [ ]: order_results = order_response . json ()[ \"_links\" ][ \"results\" ] order_results Conversion to COGs In [17]: # Create a directory to store the regular geotiffs from our order results def download_geotiffs ( order_results , directory_name ): # Create a directory to store regular geotiffs inside your current working directory regular_geotiff_folder = pathlib . Path . cwd () / directory_name try : regular_geotiff_folder . mkdir ( parents = True , exist_ok = False ) print ( \"Directory to store regular geotiffs has been made\" ) except FileExistsError : print ( \"Directory to store regular geotiffs already exists\" ) # get all the analytic image result names order_names = [ order [ 'name' ] for order in order_results if order [ 'name' ] . endswith ( 'AnalyticMS.tif' )] # get the locations for the analytic images order_locations = [ order [ 'location' ] for order in order_results if order [ 'name' ] . endswith ( 'AnalyticMS.tif' )] for order_name , order_location in zip ( order_names , order_locations ): geotiff_file_path = pathlib . Path . joinpath ( regular_geotiff_folder ) . joinpath ( order_name ) geotiff_file_path . parent . mkdir ( parents = True , exist_ok = True ) geotiff_download = requests . get ( order_location , allow_redirects = True ) open ( geotiff_file_path , 'wb' ) . write ( geotiff_download . content ) In [18]: # Create another directory to store COGs after conversion def cog_convert ( geotiff_directory , order_id , cog_directory_name , item_type ): cog_path = pathlib . Path . cwd () / cog_directory_name try : cog_path . mkdir ( parents = True , exist_ok = False ) print ( \"Directory to store newly created cogs has been made\" ) except FileExistsError : print ( \"Directory to store newly created cogs already exists\" ) geotiff_file_path = pathlib . Path . cwd () / geotiff_directory / order_id / item_type for filename in os . listdir ( geotiff_file_path ): src_path = pathlib . Path . joinpath ( geotiff_file_path ) . joinpath ( filename ) dst_path = pathlib . Path . joinpath ( cog_path ) . joinpath ( filename ) cog_translate ( src_path , dst_path , cog_profiles . get ( \"deflate\" )) In [19]: def cog_conversion_from_order ( planet_orders_url , order_id , item_type , planet_auth , original_tiff_path , cog_path ): # Get the user's current order id and append to the base order URL current_order_url = planet_orders_url + '/' + order_id # Get array of results from the current order order_response = requests . get ( current_order_url , auth = planet_auth ) . json () order_results = order_response [ \"_links\" ][ \"results\" ] # From the order results, download our GeoTIFFs and store in directory download_geotiffs ( order_results , original_tiff_path ) # Convert this directory of GeoTIFFs to COGs and store in separate directory cog_convert ( original_tiff_path , order_id , cog_path , item_type ) In [ ]: cog_conversion_from_order ( planet_orders_url , \"edc43923-3ecd-4ee4-932a-e19360522af9\" , \"PSScene\" , planet_auth , \"geotiff\" , \"cog\" ) Inspecting and Converting GeoTIFFs and COGs Using rio-cogeo rio-cogeo is a rasterio plugin for the creation and validation of COGs. It is a pretty neat tool! It has both a CLI and an API to work with. Below we will use the command line to take one of our non cloud optimzed GeoTIFFs from our submitted order and learn more about the details of the format. We can then use the plugin to convert it into a COG and inspect the data and compare the differences. For the GeoTIFF below, we can see that it is internally tiled and has multiple overviews. However, its offset values for the IFD of the main image as well as the first overview illustrate that the internal structure of the GeoTIFF is not stored as contigious blocks as highlighted in the diagram earlier in this tutorial. Therefore, it is not a valid COG. Ordinary GeoTIFF command: rio cogeo info COG command: rio cogeo create Now, let's go look at the converted COG version of this GeoTIFF from our Cogs directory that we created. We can now see that the IFDs and the image data are stored contigously making it a valid COG. Converting GeoTIFFs and COGs Using GDAL The GDAL command line interface can also be used to quickly create a COG. You need to specify the form of compression used(LZW or Deflate) and also require internal tiling to be present. To create a set of overviews, you can use the gdaladdo command. This command would need to be executed before gdal_translate to create a valid COG. Up Next In the next tutorial, we will provide an introduction to Google Cloud and Dynamic Web Tiling with COGs!","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/an-introduction-to-cloud-optimized-geotiffs-cogs-part-2-converting-regular-geotiffs-into-cogs/","loc":"https://developers.planet.com/docs/planetschool/an-introduction-to-cloud-optimized-geotiffs-cogs-part-2-converting-regular-geotiffs-into-cogs/"},{"title":"An Introduction to Cloud Optimized GeoTIFFS (COGs) Part 3: Dynamic Web Tiling with Titiler","text":"Here we are going to take a set of COGs we generated from the Introduction to COGs tutorial and place them on Google Cloud to be publicly ingestible. First, we will demonstrate how to upload sample COGs to a bucket in Google Cloud Storage and make them publicly readable. We can then stream the COG from its online location and read into QGIS Desktop or the cogeo.com/map tool. Uploading COGs to Google Cloud Storage Creating a Bucket A bucket serves as a container to store your data. In our case, this is where we will store our collection of COGs. For the purpose of this demonstration, when creating the bucket we did not enforce public access prevention because we want our COGs accessible to the internet. We also set access control to be Uniform Bucket Access. Please select the best options for your use case. Making Objects Within Bucket Publicly Readable Now we want to make our sample COGs readable to the public internet. To do so, we need go to Permissions, add allUsers as a new member, and set the role to be Storage Object Viewer To learn more about bucket creation and access control specifications that best suits your particular use case, refer to https://cloud.google.com/storage/docs/how-to to learn more about working with Google Cloud Storage. Streaming Our COGs Now that we have stored our COGs online in a newly created storage bucket, we can now start streaming these COGs from their online locations and take a look! Using cogeo.com/map cogeo.com has a great mapping tool that you can use to display any COG that is stored online. This tool basically turns COGs into web tiles through the underlying web tiling service called tiles.rdnt.io. By entering the public url into the search bar, you can inspect your COG, zoom around, and share it with others. Using QGIS Desktop You can also take the public url and stream your COG directly in QGIS Desktop. To do this, first open the Data Source Manager by clicking on the icon on the top left of your screen. Select the Raster dialog from the list of options. Select 'Protocol: HTTP(S), cloud,etc' and set type to be HTTP/HTTPS/FTP. Paste the public url for the COG below. Click save and close the Data Manager to begin viewing your COG in QGIS. Dynamic Tiling with TiTiler TiTiler is dynamic tile server built on top of rio-tiler, the FastAPI web framework and Rasterio/GDAL. We will use TiTiler to serve up the tiles from our sample COG locally on our machine and explore some of the default COG endpoints of the application. You can install and begin running the application locally by: pip install uvicorn titiler.application uvicorn titiler.application.main:app Now that we our application running locally on our machine, let's explore some of the default cog endpoints and take a look at the responses we get. In [1]: import requests import json from folium import Map , TileLayer from io import BytesIO import rasterio % pylab inline Populating the interactive namespace from numpy and matplotlib In [2]: titiler_endpoint = \"http://127.0.0.1:8000\" # Two sample COGs - one being a PSScene analytic image and the other being a PSOrthoTile visual image # from the Google Cloud storage bucket analytic_cog_url = \"https://storage.googleapis.com/sample-cogs/20210514_145807_70_2455_3B_AnalyticMS.tif\" visual_cog_url = \"https://storage.googleapis.com/sample-cogs/cog/4478204_1857918_2021-05-14_2455_RGB_Visual.tif\" In [3]: def submit_request ( BASE_URL , endpoint , url ): r = requests . get ( f \" { BASE_URL } / { endpoint } \" , params = { \"url\" : url , } ) . json () return r COG Validation Endpoint We saw multiple possibilities of validating COGs in the previous tutorial. TiTiler itself also has a validation endpoint in the application where you can confirm if your GeoTIFF is a COG and get back some info.Let's make a GET request to the /cog/validate endpoint and check it out. Here we get a similar breakdown of the COG information we found out using rio cogeo in the previous tutorial. We can verify that both of our GeoTIFFs are indeed COGs that have internal tiling and multiple overviews. Analytic In [4]: analytic_cog_validation = submit_request ( titiler_endpoint , \"cog/validate\" , analytic_cog_url ) print ( json . dumps ( analytic_cog_validation , indent = 4 )) { \"Path\": \"https://storage.googleapis.com/sample-cogs/20210514_145807_70_2455_3B_AnalyticMS.tif\", \"Driver\": \"GTiff\", \"COG\": true, \"Compression\": \"DEFLATE\", \"ColorSpace\": null, \"COG_errors\": null, \"COG_warnings\": null, \"Profile\": { \"Bands\": 4, \"Width\": 13795, \"Height\": 9952, \"Tiled\": true, \"Dtype\": \"uint16\", \"Interleave\": \"PIXEL\", \"AlphaBand\": false, \"InternalMask\": false, \"Nodata\": 0.0, \"ColorInterp\": [ \"blue\", \"green\", \"red\", \"undefined\" ], \"ColorMap\": false, \"Scales\": [ 1.0, 1.0, 1.0, 1.0 ], \"Offsets\": [ 0.0, 0.0, 0.0, 0.0 ] }, \"GEO\": { \"CRS\": \"EPSG:32618\", \"BoundingBox\": [ 558549.0, 4488015.0, 599934.0, 4517871.0 ], \"Origin\": [ 558549.0, 4517871.0 ], \"Resolution\": [ 3.0, -3.0 ], \"MinZoom\": 9, \"MaxZoom\": 15 }, \"Tags\": { \"Image Metadata\": { \"AREA_OR_POINT\": \"Area\", \"OVR_RESAMPLING_ALG\": \"NEAREST\", \"TIFFTAG_DATETIME\": \"2021:05:14 14:58:07\" }, \"Image Structure\": { \"COMPRESSION\": \"DEFLATE\", \"INTERLEAVE\": \"PIXEL\", \"LAYOUT\": \"COG\" } }, \"IFD\": [ { \"Level\": 0, \"Width\": 13795, \"Height\": 9952, \"Blocksize\": [ 512, 512 ], \"Decimation\": 0 }, { \"Level\": 1, \"Width\": 6898, \"Height\": 4976, \"Blocksize\": [ 512, 512 ], \"Decimation\": 2 }, { \"Level\": 2, \"Width\": 3449, \"Height\": 2488, \"Blocksize\": [ 512, 512 ], \"Decimation\": 4 }, { \"Level\": 3, \"Width\": 1725, \"Height\": 1244, \"Blocksize\": [ 512, 512 ], \"Decimation\": 8 }, { \"Level\": 4, \"Width\": 863, \"Height\": 622, \"Blocksize\": [ 512, 512 ], \"Decimation\": 16 }, { \"Level\": 5, \"Width\": 432, \"Height\": 311, \"Blocksize\": [ 512, 512 ], \"Decimation\": 32 } ] } Visual In [5]: visual_cog_validation = submit_request ( titiler_endpoint , \"cog/validate\" , visual_cog_url ) print ( json . dumps ( visual_cog_validation , indent = 4 )) { \"Path\": \"https://storage.googleapis.com/sample-cogs/cog/4478204_1857918_2021-05-14_2455_RGB_Visual.tif\", \"Driver\": \"GTiff\", \"COG\": true, \"Compression\": \"LZW\", \"ColorSpace\": null, \"COG_errors\": null, \"COG_warnings\": null, \"Profile\": { \"Bands\": 4, \"Width\": 8000, \"Height\": 8000, \"Tiled\": true, \"Dtype\": \"uint8\", \"Interleave\": \"PIXEL\", \"AlphaBand\": true, \"InternalMask\": false, \"Nodata\": null, \"ColorInterp\": [ \"red\", \"green\", \"blue\", \"alpha\" ], \"ColorMap\": false, \"Scales\": [ 1.0, 1.0, 1.0, 1.0 ], \"Offsets\": [ 0.0, 0.0, 0.0, 0.0 ] }, \"GEO\": { \"CRS\": \"EPSG:32618\", \"BoundingBox\": [ 571500.0, 4511500.0, 596500.0, 4536500.0 ], \"Origin\": [ 571500.0, 4536500.0 ], \"Resolution\": [ 3.125, -3.125 ], \"MinZoom\": 10, \"MaxZoom\": 15 }, \"Tags\": { \"Image Metadata\": { \"AREA_OR_POINT\": \"Area\", \"TIFFTAG_DATETIME\": \"2021:05:14 14:58:05\" }, \"Image Structure\": { \"COMPRESSION\": \"LZW\", \"INTERLEAVE\": \"PIXEL\", \"PREDICTOR\": \"2\" } }, \"IFD\": [ { \"Level\": 0, \"Width\": 8000, \"Height\": 8000, \"Blocksize\": [ 512, 512 ], \"Decimation\": 0 }, { \"Level\": 1, \"Width\": 2667, \"Height\": 2667, \"Blocksize\": [ 128, 128 ], \"Decimation\": 3 }, { \"Level\": 2, \"Width\": 889, \"Height\": 889, \"Blocksize\": [ 128, 128 ], \"Decimation\": 9 }, { \"Level\": 3, \"Width\": 297, \"Height\": 297, \"Blocksize\": [ 128, 128 ], \"Decimation\": 27 } ] } COG Metadata Endpoint Let's make a GET request to the /cog/metadata endpoint to gather some basic info and summary statistics of our COG. This includes its bounding box and some summary statistics for each band. If we look at the statistics for each band, we can see a list of histogram bins followed by a list of min and max values within each bin. We can also see what the percentage of valid pixels(pixels that have data) is. Analytic In [6]: analytic_cog_metadata = submit_request ( titiler_endpoint , \"cog/metadata\" , analytic_cog_url ) print ( json . dumps ( analytic_cog_metadata , indent = 4 )) { \"bounds\": [ -74.30860815002872, 40.53685919989149, -73.81522948934723, 40.80976203894409 ], \"band_metadata\": [ [ \"1\", {} ], [ \"2\", {} ], [ \"3\", {} ], [ \"4\", {} ] ], \"band_descriptions\": [ [ \"1\", \"blue\" ], [ \"2\", \"green\" ], [ \"3\", \"red\" ], [ \"4\", \"nir\" ] ], \"dtype\": \"uint16\", \"nodata_type\": \"Nodata\", \"colorinterp\": [ \"blue\", \"green\", \"red\", \"undefined\" ], \"statistics\": { \"1\": { \"percentiles\": [ 4360.0, 13800.0 ], \"min\": 3938.0, \"max\": 26652.0, \"std\": 2341.320555374775, \"histogram\": [ [ 276041.0, 160988.0, 35882.0, 13784.0, 6338.0, 2998.0, 1467.0, 1224.0, 630.0, 48.0 ], [ 3938.0, 6209.4, 8480.8, 10752.2, 13023.6, 15295.0, 17566.4, 19837.800000000003, 22109.2, 24380.600000000002, 26652.0 ] ], \"valid_percent\": 0.6599395297699594 }, \"2\": { \"percentiles\": [ 2934.0, 12597.0 ], \"min\": 2511.0, \"max\": 28000.0, \"std\": 2369.768493399677, \"histogram\": [ [ 255953.0, 184757.0, 36119.0, 12970.0, 5020.0, 2172.0, 1153.0, 768.0, 436.0, 52.0 ], [ 2511.0, 5059.9, 7608.8, 10157.7, 12706.6, 15255.5, 17804.4, 20353.3, 22902.2, 25451.100000000002, 28000.0 ] ], \"valid_percent\": 0.6599395297699594 }, \"3\": { \"percentiles\": [ 1470.0, 11610.0 ], \"min\": 201.0, \"max\": 34013.0, \"std\": 2593.153965697304, \"histogram\": [ [ 224014.0, 220647.0, 39380.0, 10102.0, 2977.0, 1291.0, 828.0, 136.0, 9.0, 16.0 ], [ 201.0, 3582.2, 6963.4, 10344.599999999999, 13725.8, 17107.0, 20488.199999999997, 23869.399999999998, 27250.6, 30631.8, 34013.0 ] ], \"valid_percent\": 0.6599395297699594 }, \"4\": { \"percentiles\": [ 579.0, 10380.0 ], \"min\": 400.0, \"max\": 59997.0, \"std\": 2686.2309341992127, \"histogram\": [ [ 364818.0, 131684.0, 2855.0, 29.0, 3.0, 0.0, 2.0, 7.0, 0.0, 2.0 ], [ 400.0, 6359.7, 12319.4, 18279.1, 24238.8, 30198.5, 36158.2, 42117.9, 48077.6, 54037.299999999996, 59997.0 ] ], \"valid_percent\": 0.6599395297699594 } }, \"driver\": \"GTiff\", \"width\": 13795, \"count\": 4, \"height\": 9952, \"nodata_value\": 0.0, \"overviews\": [ 2, 4, 8, 16, 32 ] } Visual In [7]: visual_cog_metadata = submit_request ( titiler_endpoint , \"cog/metadata\" , visual_cog_url ) print ( json . dumps ( visual_cog_metadata , indent = 4 )) { \"bounds\": [ -74.15301677654034, 40.74879573187055, -73.85303951686923, 40.97653527298751 ], \"band_metadata\": [ [ \"1\", {} ], [ \"2\", {} ], [ \"3\", {} ], [ \"4\", {} ] ], \"band_descriptions\": [ [ \"1\", \"\" ], [ \"2\", \"\" ], [ \"3\", \"\" ], [ \"4\", \"\" ] ], \"dtype\": \"uint8\", \"nodata_type\": \"Alpha\", \"colorinterp\": [ \"red\", \"green\", \"blue\", \"alpha\" ], \"statistics\": { \"1\": { \"percentiles\": [ 11.0, 228.0 ], \"min\": 1.0, \"max\": 255.0, \"std\": 56.33194131240483, \"histogram\": [ [ 121371.0, 166191.0, 206460.0, 154249.0, 136366.0, 103685.0, 69008.0, 46261.0, 25548.0, 19437.0 ], [ 1.0, 26.4, 51.8, 77.19999999999999, 102.6, 128.0, 153.39999999999998, 178.79999999999998, 204.2, 229.6, 255.0 ] ], \"valid_percent\": 1.0 }, \"2\": { \"percentiles\": [ 22.0, 205.0 ], \"min\": 1.0, \"max\": 255.0, \"std\": 43.83467679790805, \"histogram\": [ [ 32003.0, 172722.0, 333226.0, 212381.0, 129629.0, 77624.0, 44244.0, 25481.0, 13016.0, 8250.0 ], [ 1.0, 26.4, 51.8, 77.19999999999999, 102.6, 128.0, 153.39999999999998, 178.79999999999998, 204.2, 229.6, 255.0 ] ], \"valid_percent\": 1.0 }, \"3\": { \"percentiles\": [ 20.0, 195.0 ], \"min\": 1.0, \"max\": 253.0, \"std\": 44.000460084001745, \"histogram\": [ [ 72105.0, 289202.0, 259686.0, 176497.0, 109431.0, 67298.0, 37426.0, 20460.0, 10577.0, 5894.0 ], [ 1.0, 26.2, 51.4, 76.6, 101.8, 127.0, 152.2, 177.4, 202.6, 227.79999999999998, 253.0 ] ], \"valid_percent\": 1.0 } }, \"driver\": \"GTiff\", \"width\": 8000, \"count\": 4, \"height\": 8000, \"overviews\": [ 3, 9, 27 ] } GeoJson Info Endpoint If we make a GET request to the /cog/info.geojson endpoint, we can also get back the GeoJson feature for the COG as well. In [8]: cog_geojson = submit_request ( titiler_endpoint , \"cog/info.geojson\" , analytic_cog_url ) print ( json . dumps ( cog_geojson , indent = 4 )) { \"type\": \"Feature\", \"geometry\": { \"coordinates\": [ [ [ -74.30860815002872, 40.80976203894409 ], [ -74.30860815002872, 40.53685919989149 ], [ -73.81522948934723, 40.53685919989149 ], [ -73.81522948934723, 40.80976203894409 ], [ -74.30860815002872, 40.80976203894409 ] ] ], \"type\": \"Polygon\" }, \"properties\": { \"band_metadata\": [ [ \"1\", {} ], [ \"2\", {} ], [ \"3\", {} ], [ \"4\", {} ] ], \"band_descriptions\": [ [ \"1\", \"blue\" ], [ \"2\", \"green\" ], [ \"3\", \"red\" ], [ \"4\", \"nir\" ] ], \"dtype\": \"uint16\", \"nodata_type\": \"Nodata\", \"colorinterp\": [ \"blue\", \"green\", \"red\", \"undefined\" ], \"driver\": \"GTiff\", \"width\": 13795, \"count\": 4, \"height\": 9952, \"nodata_value\": 0.0, \"overviews\": [ 2, 4, 8, 16, 32 ], \"dataset\": \"https://storage.googleapis.com/sample-cogs/20210514_145807_70_2455_3B_AnalyticMS.tif\" } } In [9]: cog_geojson = submit_request ( titiler_endpoint , \"cog/info.geojson\" , visual_cog_url ) print ( json . dumps ( cog_geojson , indent = 4 )) { \"type\": \"Feature\", \"geometry\": { \"coordinates\": [ [ [ -74.15301677654034, 40.97653527298751 ], [ -74.15301677654034, 40.74879573187055 ], [ -73.85303951686923, 40.74879573187055 ], [ -73.85303951686923, 40.97653527298751 ], [ -74.15301677654034, 40.97653527298751 ] ] ], \"type\": \"Polygon\" }, \"properties\": { \"band_metadata\": [ [ \"1\", {} ], [ \"2\", {} ], [ \"3\", {} ], [ \"4\", {} ] ], \"band_descriptions\": [ [ \"1\", \"\" ], [ \"2\", \"\" ], [ \"3\", \"\" ], [ \"4\", \"\" ] ], \"dtype\": \"uint8\", \"nodata_type\": \"Alpha\", \"colorinterp\": [ \"red\", \"green\", \"blue\", \"alpha\" ], \"driver\": \"GTiff\", \"width\": 8000, \"count\": 4, \"height\": 8000, \"overviews\": [ 3, 9, 27 ], \"dataset\": \"https://storage.googleapis.com/sample-cogs/cog/4478204_1857918_2021-05-14_2455_RGB_Visual.tif\" } } TileJson Endpoint Now, let's make a GET request to the /cog/[{TileMatrixSetId}]/tilejson.json endpoint where the TileMatrixSetId refers to the public url of our COG. This endpoint will return a MapBox TileJson document, a json specification for talking about tilesets and optional metadata associated with them. Analytic In [10]: tile_json_analytic = submit_request ( titiler_endpoint , \"cog/tilejson.json\" , analytic_cog_url ) print ( json . dumps ( tile_json_analytic , indent = 4 )) { \"tilejson\": \"2.2.0\", \"name\": \"sample-cogs/20210514_145807_70_2455_3B_AnalyticMS.tif\", \"version\": \"1.0.0\", \"scheme\": \"xyz\", \"tiles\": [ \"http://127.0.0.1:8000/cog/tiles/WebMercatorQuad/{z}/{x}/{y}@1x?url=https%3A%2F%2Fstorage.googleapis.com%2Fsample-cogs%2F20210514_145807_70_2455_3B_AnalyticMS.tif\" ], \"minzoom\": 9, \"maxzoom\": 15, \"bounds\": [ -74.30860815002872, 40.53685919989149, -73.81522948934723, 40.80976203894409 ], \"center\": [ -74.06191881968797, 40.67331061941779, 9 ] } Visual In [11]: tile_json_visual = submit_request ( titiler_endpoint , \"cog/tilejson.json\" , visual_cog_url ) print ( json . dumps ( tile_json_visual , indent = 4 )) { \"tilejson\": \"2.2.0\", \"name\": \"sample-cogs/cog/4478204_1857918_2021-05-14_2455_RGB_Visual.tif\", \"version\": \"1.0.0\", \"scheme\": \"xyz\", \"tiles\": [ \"http://127.0.0.1:8000/cog/tiles/WebMercatorQuad/{z}/{x}/{y}@1x?url=https%3A%2F%2Fstorage.googleapis.com%2Fsample-cogs%2Fcog%2F4478204_1857918_2021-05-14_2455_RGB_Visual.tif\" ], \"minzoom\": 10, \"maxzoom\": 15, \"bounds\": [ -74.15301677654034, 40.74879573187055, -73.85303951686923, 40.97653527298751 ], \"center\": [ -74.00302814670479, 40.86266550242903, 10 ] } COG Viewer Endpoint Let's go to the /cog/viewer endpoint to view our selected COG. Enter the url of the chosen COG. Once you hit apply, Titiler will recreate the tiles dynamically on the fly. Layer Selection Let's take a look at the left side-panel. The layers dropdown menu allows us to specify which band we want to look at. Raster Data Histograms The panel also provides a histogram to visualize the distribution of pixel values, where each bin represents the frequency of pixels that fall within the range of the bin. We can also visualize this raster histogram after we stream our COG into QGIS. To do this, right click on the layer name and select Properties from the context menu. From the Raster Layer Properties dialog, choose the histogram option. We can see that the output mirrors the distributions displayed from the /cog/viewer endpoint in TiTiler and the summary statistics obtained from our previous request to the /cog/metadata endpoint. Displaying Tiles Using Folium and Leaflet We can also use the python library folium to visualize our COG in an interactive Leaflet map. We can refer back to the tilejson document and extract the values from the bounding box to instantiate the Map object. We will use the url of the COG to create the TileLayer and add it to the map. In [12]: tileset = tile_json_analytic [ \"tiles\" ][ 0 ] tileset Out[12]: 'http://127.0.0.1:8000/cog/tiles/WebMercatorQuad/{z}/{x}/{y}@1x?url=https%3A%2F%2Fstorage.googleapis.com%2Fsample-cogs%2F20210514_145807_70_2455_3B_AnalyticMS.tif' In [13]: left , bottom , right , top = tile_json_analytic [ \"bounds\" ][ 0 ], tile_json_analytic [ \"bounds\" ][ 1 ], tile_json_analytic [ \"bounds\" ][ 2 ], tile_json_analytic [ \"bounds\" ][ 3 ] In [14]: m = Map ( location = (( bottom + top ) / 2 , ( left + right ) / 2 ), zoom_start = 10 , tiles = \"Stamen Terrain\" ) tile_layer = TileLayer ( tiles = tileset , attr = \"Sample COG\" ) tile_layer . add_to ( m ) Out[14]: <folium.raster_layers.TileLayer at 0x7ff74e527d60> In [15]: m Out[15]: Make this Notebook Trusted to load map: File -> Trust Notebook","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/an-introduction-to-cloud-optimized-geotiffs-cogs-part-3-dynamic-web-tiling-with-titiler/","loc":"https://developers.planet.com/docs/planetschool/an-introduction-to-cloud-optimized-geotiffs-cogs-part-3-dynamic-web-tiling-with-titiler/"},{"title":"An Introduction to Cloud Optimized GeoTIFFS (COGs) Part 1: Overview","text":"So....What actually is a TIFF file anyway? TIFF stands for Tag Image File Format, a format for storing raster graphic images. It was designed to establish a general consensus on a common scanned image file format. TIFF Header The header of a TIFF file contains things like the TIFF version and where to find the first Image File Directory in the file. Image File Directories and Data What Makes a GeoTIFF Different? A GeoTIFF file has some additional tags containing information about where the image exists on earth. his includes things like map projections, coordinate systems, datums, etc. Basically lots of interesting geodspatial relevant info that provides a spatial reference. What is a Cloud Optimized GeoTIFF, and why is it important? A cloud optimized GeoTiff, or COG, is a type of GeoTIFF file that has been formatted to work on the cloud. So why is this format so important? The Why - Analyze Problems on a Global Scale - Handle Exponential Growth of Data - Allow Efficient Streaming of Data - Reduce Data Duplication - Democratizing Data Science - Make Geospatial Data More Accessible and Available The How Cloud Optimized GeoTIFFs are the gold standard format for storing raster data in cloud storage. Why? Well, it comes down to how the format is structured internally. COGs fundamentally depend on technology that work in conjunction with each other. The manner in which pixels are organized (internal tiling, overviews, compression) makes it easier for users to access parts of the data corresponding to their particular area of interest, without needing to download the entire file first. Organization Internal Tiling In a COG, pixels are stored in tiles. This creates the ability to access just the part of a file that is needed because all relevant information is stored together in each tile. Overviews Overviews form zoomed out, or lower resolution, versions of the original image. This is what is refered to as downsampling . You increase the size of the cells in the grid, making the image smaller and have less detail. A GeoTIFF file will often have multiple overviews, each with a different zoom level Overviews are really useful when a client wants to quickly render an image of the whole file. This can be done very efficiently because the client doesn't need to request the original resolution image, but can instead request one of the overviews that are available to obtain a quick preview of the image very fast. Visualizing Overviews Using Rasterio Here we will visualize the overviews of the blue, green, and red bands of two sample COGs with an AOI centered around midtown Manhattan. In [1]: import rasterio import os import matplotlib.pyplot as plt from rasterio.plot import show import numpy as np % matplotlib inline In [17]: def generate_overviews ( image ): with rasterio . open ( image ) as src : # Iterate over the blue, green, and red bands for band in src . indexes [: - 1 ]: # Get list of overview levels for the band cog_overview = src . overviews ( band ) # Iterate over each level in reverse order for i in range ( len ( cog_overview ) - 1 , - 1 , - 1 ): overview_image = src . read ( band , out_shape = ( int ( src . height / cog_overview [ i ]), int ( src . width / cog_overview [ i ]))) # Apply a boolean mask to convert all 0 values in the array to nan overview_image = overview_image . astype ( float ) overview_image [ np . where ( overview_image == 0 )] = np . nan # Plot each overview plt . figure ( figsize = ( 20 , 15 )) plt . xlabel ( \"Columns\" , fontsize = 20 ) plt . ylabel ( \"Rows\" , fontsize = 20 ) plt . title ( 'Overview: Band: {} -- Zoom Level {} -- Modified height: {} , Modified Width: {} ' . format ( band , cog_overview [ i ], overview_image . shape [ 0 ], overview_image . shape [ 1 ]), fontsize = 20 ) plt . imshow ( overview_image ) plt . show () In [18]: # Can replace with any sample COG of your choosing analytic_image = os . getcwd () + '/20210514_145807_70_2455_3B_AnalyticMS.tif' visual_image = os . getcwd () + '/' + '4478803_1857818_2021-05-14_227b_RGB_Visual.tif' Let's take a look at the analytic image. For each band, we are taking a decimated read of the image at the different overviews, or zoom factors(often seen in factors of 2). We can see the image transition from from a quite detailed view to a progressively coarser, less refined resolution. The visual effects become most noticeable at the highest overview level. In [19]: overviews = generate_overviews ( analytic_image ) Now let's look at the visual image.As you take a decimated read of the image at each overview (in this case factors of 3), you can really notice the difference in resolution as you increase the zoom levels. In [20]: overviews = generate_overviews ( visual_image ) overviews Overall COG Structure The diagrams presented below contrast how the IFDs and the actual data they reference are mapped out in the memory of the file. This is an important distinction between a normal GeoTIFF and a COG. In a regular GeoTIFF, the locations of where things can be stored is pretty fluid. However, for a COG to be a COG, the IFDs are structured at the beginning of the file, acting essentially as a very useful table of contents. For a COG, the IFDs are very important because they contain information about the tile offsets and tile byte counts for every tile. So because the IFDs are stored at the very beginning of file and contain information on the offset and byte count of each tile, you are able to quickly get a mapping of where each tile begins in the file, as well as its size. By knowing where each tile is located in the file, you are able toquickly get just the parts of the file you need. Ordinary TIFF/GeoTIFF Structure Here we can see that the IFDs are scattered throughout the file and not at the beginning like a COG as illustrated above. HTTP GET Range Request The organizational features mentioned above go hand in hand when a client is making a GET request to a server. If the server has an Accept Range: Bytes in its response header, clients can specify a range of bytes when making a request, getting only the parts of the data, in this case the TIFF file, that they actually need rather than needing to wait for the entire file to finish downloading. The overviews make it possible to preview the image quickly by reducing the amount of range requests made. You only need to get the values from the overview rather than all of the pixels from the raw image. This is why if you look at a COG compared to a regular GeoTIFF in a tool like cogeo, the performance difference is notable. With the COG, you'll be able to load the image faster and zoom in and out much smoother than you would if you were working with a regular GeoTIFF. With the GeoTIFF, the entire image needs to finish downloading before the tiles can be generated for viewing. Next Steps In the next tutorial, we will use Planet's Data API and Orders API to download some Regular GeoTIFFs and show how to convert them into COGs!","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/an-introduction-to-cloud-optimized-geotiffs-cogs-part-1-overview/","loc":"https://developers.planet.com/docs/planetschool/an-introduction-to-cloud-optimized-geotiffs-cogs-part-1-overview/"},{"title":"Introduction to STAC Part 1: An Overview of the Specification","text":"The goal of this tutorial is to provide an overview to the STAC specification, a breakdown of each STAC component, and how they are integrated together. What is STAC? The Spatial Temporal Asset Catalog specification was designed to establish a standard, unified language to talk about geospatial data, allowing it to more easily searchable and queryable. An overarching goal in having this common standard is to eliminate the need to puruse through APIs of many satellite providers in order to access all the needed data. STAC is simple and extensible in its design due to how it is structured. STAC is a network of json files that reference other json files, with each json file adhering to a specific core specification depending on what STAC component it is describing. This core json format can also be customized to fit differing needs, making the STAC specification highly flexible and adaptable. STAC Components The four key components of STAC include items, catalogs, collections, and the STAC API. These components can be used in isolation from one another, but ideally work best in tandem. STAC Item A STAC item is the foundational building block of STAC. It is GeoJSON supplemented with additional metadata that enables clients to traverse through catalogs. In [1]: import pystac In [2]: print ( pystac . Item . __doc__ ) An Item is the core granular entity in a STAC, containing the core metadata that enables any client to search or crawl online catalogs of spatial 'assets' - satellite imagery, derived data, DEM's, etc. Args: id (str): Provider identifier. Must be unique within the STAC. geometry (dict): Defines the full footprint of the asset represented by this item, formatted according to `RFC 7946, section 3.1 (GeoJSON) <https://tools.ietf.org/html/rfc7946>`_. bbox (List[float] or None): Bounding Box of the asset represented by this item using either 2D or 3D geometries. The length of the array must be 2*n where n is the number of dimensions. Could also be None in the case of a null geometry. datetime (datetime or None): Datetime associated with this item. If None, a start_datetime and end_datetime must be supplied in the properties. properties (dict): A dictionary of additional metadata for the item. stac_extensions (List[str]): Optional list of extensions the Item implements. href (str or None): Optional HREF for this item, which be set as the item's self link's HREF. collection (Collection or str): The Collection or Collection ID that this item belongs to. extra_fields (dict or None): Extra fields that are part of the top-level JSON properties of the Item. Attributes: id (str): Provider identifier. Unique within the STAC. geometry (dict): Defines the full footprint of the asset represented by this item, formatted according to `RFC 7946, section 3.1 (GeoJSON) <https://tools.ietf.org/html/rfc7946>`_. bbox (List[float] or None): Bounding Box of the asset represented by this item using either 2D or 3D geometries. The length of the array is 2*n where n is the number of dimensions. Could also be None in the case of a null geometry. datetime (datetime or None): Datetime associated with this item. If None, the start_datetime and end_datetime in the common_metadata will supply the datetime range of the Item. properties (dict): A dictionary of additional metadata for the item. stac_extensions (List[str] or None): Optional list of extensions the Item implements. collection (Collection or None): Collection that this item is a part of. links (List[Link]): A list of :class:`~pystac.Link` objects representing all links associated with this STACObject. assets (Dict[str, Asset]): Dictionary of asset objects that can be downloaded, each with a unique key. collection_id (str or None): The Collection ID that this item belongs to, if any. extra_fields (dict or None): Extra fields that are part of the top-level JSON properties of the Item. To learn more about STAC Item specifications: https://github.com/radiantearth/stac-spec/tree/master/item-spec STAC Catalog A Catalog is usually the starting point for navigating a STAC. A catalog.json file will contain contains links to some combination of other catalogs, collections, and/or items. This combination is quite variable and flexible depending on how the data is being organized. A catalog may only reference a group of items, it may link toother subcatalogsand no collections, or a combination of catalogs and collections, etc. We can think of it like a directory tree on a computer. STAC Catalog Relation and Media Types Self : Absolute URL to where the given json file can be found online, if possible Root : Root: URL to root catalog or collection Parent : URL to a Parent STAC Specification (could be an item, catalog, collection) Child : URL to a Child STAC Specification (item, catalog, collection) In [4]: print ( pystac . Catalog . __doc__ ) A PySTAC Catalog represents a STAC catalog in memory. A Catalog is a :class:`~pystac.STACObject` that may contain children, which are instances of :class:`~pystac.Catalog` or :class:`~pystac.Collection`, as well as :class:`~pystac.Item` s. Args: id (str): Identifier for the catalog. Must be unique within the STAC. description (str): Detailed multi-line description to fully explain the catalog. `CommonMark 0.28 syntax <http://commonmark.org/>`_ MAY be used for rich text representation. title (str or None): Optional short descriptive one-line title for the catalog. stac_extensions (List[str]): Optional list of extensions the Catalog implements. href (str or None): Optional HREF for this catalog, which be set as the catalog's self link's HREF. catalog_type (str or None): Optional catalog type for this catalog. Must be one of the values in :class`~pystac.CatalogType`. Attributes: id (str): Identifier for the catalog. description (str): Detailed multi-line description to fully explain the catalog. title (str or None): Optional short descriptive one-line title for the catalog. stac_extensions (List[str] or None): Optional list of extensions the Catalog implements. extra_fields (dict or None): Extra fields that are part of the top-level JSON properties of the Catalog. links (List[Link]): A list of :class:`~pystac.Link` objects representing all links associated with this Catalog. catalog_type (str or None): The catalog type, or None if not known. To learn more about STAC Catalog specifications: https://github.com/radiantearth/stac-spec/tree/master/catalog-spec STAC Collection A STAC Collection builds upon the STAC Catalog specification to include additional metadata about a set of items that exist as part of the collection. In [5]: print ( pystac . Collection . __doc__ ) A Collection extends the Catalog spec with additional metadata that helps enable discovery. Args: id (str): Identifier for the collection. Must be unique within the STAC. description (str): Detailed multi-line description to fully explain the collection. `CommonMark 0.28 syntax <http://commonmark.org/>`_ MAY be used for rich text representation. extent (Extent): Spatial and temporal extents that describe the bounds of all items contained within this Collection. title (str or None): Optional short descriptive one-line title for the collection. stac_extensions (List[str]): Optional list of extensions the Collection implements. href (str or None): Optional HREF for this collection, which be set as the collection's self link's HREF. catalog_type (str or None): Optional catalog type for this catalog. Must be one of the values in :class`~pystac.CatalogType`. license (str): Collection's license(s) as a `SPDX License identifier <https://spdx.org/licenses/>`_, `various`, or `proprietary`. If collection includes data with multiple different licenses, use `various` and add a link for each. Defaults to 'proprietary'. keywords (List[str]): Optional list of keywords describing the collection. providers (List[Provider]): Optional list of providers of this Collection. properties (dict): Optional dict of common fields across referenced items. summaries (dict): An optional map of property summaries, either a set of values or statistics such as a range. extra_fields (dict or None): Extra fields that are part of the top-level JSON properties of the Collection. Attributes: id (str): Identifier for the collection. description (str): Detailed multi-line description to fully explain the collection. extent (Extent): Spatial and temporal extents that describe the bounds of all items contained within this Collection. title (str or None): Optional short descriptive one-line title for the collection. stac_extensions (List[str]): Optional list of extensions the Collection implements. keywords (List[str] or None): Optional list of keywords describing the collection. providers (List[Provider] or None): Optional list of providers of this Collection. properties (dict or None): Optional dict of common fields across referenced items. summaries (dict or None): An optional map of property summaries, either a set of values or statistics such as a range. links (List[Link]): A list of :class:`~pystac.Link` objects representing all links associated with this Collection. extra_fields (dict or None): Extra fields that are part of the top-level JSON properties of the Catalog. To learn more about STAC Collection specifications: https://github.com/radiantearth/stac-spec/tree/master/collection-spec Dynamic versus Static STAC Catalogs STAC Catalogs can be static, by creating the json files and storing them either in local directories, on file servers, or stored on cloud services like Amazon Simple Storage Service (Amazon S3)or Google Cloud Storage. This makes static STAC Catalogs highly portable, reliable, providing a solid foundation for building dynamic versions through the use of APIs. STAC API This leads us to STAC APIs, the last component of the STAC specification. A STAC API is a RESTful API specification for querying STAC catalogs in a dynamic way. It is designed with a standard set of endpoints for searching catalogs, collections, and items. You can find details in the API specification here: https://github.com/radiantearth/stac-api-spec Next Steps In the next tutorial, we will demonstrate how to generate a simple, static STAC Catalog of some Planet imagery using PySTAC!","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/introduction-to-stac-part-1-an-overview-of-the-specification/","loc":"https://developers.planet.com/docs/planetschool/introduction-to-stac-part-1-an-overview-of-the-specification/"},{"title":"Introduction to STAC Part 2: Creating an Example STAC Catalog of Planet Imagery with PySTAC","text":"Announcement! STAC metadata in the Orders API is in Beta now. You no longer need to use PySTAC or other third-party solutions to create a STAC catalog of imagery. Instead of working your way through this article, we recommend trying out the Orders API STAC metadata. We will unpublish this Introduction to STAC Part 2 tutorial when Beta is complete. In this tutorial, we will highlight how to create a simple STAC catalog using the python library PySTAC. We will refer back to the catalog of items we obtained from our Planet order and the corresponding analytic assets (our COGs stored in our Google Cloud Storage bucket). Import Dependencies In [1]: import pystac import os import json import requests import urllib.request import rasterio from tempfile import TemporaryDirectory from pathlib import Path import typing Create Empty STAC Catalog Get the STAC version pystac defaults to In [2]: pystac . get_stac_version () Out[2]: '1.0.0-beta.2' In [3]: catalog = pystac . Catalog ( id = 'sample-catalog' , description = 'Simple STAC catalog.' ) In [4]: catalog Out[4]: <Catalog id=sample-catalog> Our catalog is currently empty. Let's go ahead and add some items to it. In [5]: print ( list ( catalog . get_all_items ())) print ( list ( catalog . get_children ())) [] [] Creating STAC Items from a Planet Order Setup Planet Authentication In [6]: import requests from requests.auth import HTTPBasicAuth import json ## Get Planet API key stored as an environment variable on your system PLANET_API_KEY = os . getenv ( 'PLANET_API_KEY' ) ## HTTP Basic Authentication planet_auth = HTTPBasicAuth ( PLANET_API_KEY , '' ) # set content type to json headers = { 'content-type' : 'application/json' } In [7]: # Base Order URL planet_orders_url = 'https://api.planet.com/compute/ops/orders/v2' # order id order_id = 'cb363b75-b4e4-46f1-8d32-0ef87afb6215' List containing some of the item ids from our order In [8]: item_ids = [ '20210515_145754_03_245c' , '20210514_145807_70_2455' , ] Downloading and Storing Planet Order Metadata.json for the Items In [9]: def store_item_metadata ( order_id , metadata_folder_name , item_type , item_ids ): # Get previous Planet order results with the order id associated with the order current_order = planet_orders_url + '/' + order_id order_response = requests . get ( current_order , auth = planet_auth ) order_response . status_code order_results = order_response . json ()[ '_links' ][ 'results' ] # List of metadata json file names from the selected items from the order file_names = [ file_name := order_id + '/' + item_type + '/' + item_id + '_metadata.json' for item_id in item_ids ] # Create folder to store metadata if the folder does not already exist metadata_folder = Path . cwd () / metadata_folder_name try : metadata_folder . mkdir ( parents = True , exist_ok = False ) except FileExistsError as err : print ( \"Directory already exists\" ) file_paths = [] for result in order_results : if result [ 'name' ] in file_names : json_file = result [ 'location' ] metadata_path = Path . joinpath ( metadata_folder ) . joinpath ( result [ \"name\" ]) file_paths . append ( str ( metadata_path )) metadata_path . parent . mkdir ( parents = True , exist_ok = True ) item_metadata_download = requests . get ( json_file , allow_redirects = True ) open ( metadata_path , 'wb' ) . write ( item_metadata_download . content ) In [10]: def load_item_metadata ( file ): with open ( file , \"r\" ) as f : data = json . load ( f ) return data Functionality for Creating STAC Items In order to generate PySTAC items, we will use the rasterio and shapely to extract each item's bounding box and geometry. We will also refer to each item's metadata.json file delivered from our previous Planet order to apply some additional item properties that are not part of the core STAC Item specification but often widely used. The resources below provide a great breakdown of common metadata fields and extensions to the core STAC specification that are available to us. https://github.com/radiantearth/stac-spec/tree/master/extensions https://github.com/radiantearth/stac-spec/blob/master/item-spec/common-metadata.md In [11]: from rasterio.warp import calculate_default_transform from shapely.geometry import Polygon , mapping from datetime import datetime from itertools import islice def create_STAC_Item ( tiff_path , metadata_json ): with rasterio . open ( tiff_path ) as sample_cog : bounds = sample_cog . bounds src_crs = sample_cog . crs dst_crs = 'EPSG:4326' # EPSG identifier for WGS84 coordinate system used by the geojson format left , bottom , right , top = rasterio . warp . transform_bounds ( sample_cog . crs , dst_crs , * bounds ) bbox = [ left , bottom , right , top ] # Create geojson feature geom = mapping ( Polygon ([ [ left , bottom ], [ left , top ], [ right , top ], [ right , bottom ] ])) time_acquired = datetime . strptime ( metadata_json [ \"properties\" ][ \"acquired\" ][: - 1 ], '%Y-%m- %d T%H:%M:%S. %f ' ) # Instantiate pystac item item = pystac . Item ( id = metadata_json [ \"id\" ], geometry = geom , bbox = bbox , datetime = time_acquired , properties = { }) # Use Planet metadata.json to add some common metadata to the STAC item metadata_properties = metadata_json [ \"properties\" ] # Enable item extensions item . ext . enable ( 'eo' ) item . ext . enable ( 'view' ) item . ext . enable ( 'projection' ) for key , value in islice ( metadata_properties . items (), 1 , None ): # Add some common metadata for the item not included in the core item specification if ( key == 'gsd' ): item . common_metadata . gsd = value # View Geometry Extension if ( key == 'sun_azimuth' ): item . ext . view . sun_azimuth = value if ( key == 'sun_elevation' ): item . ext . view . sun_elevation = value # Electro Optical Extension - if ( key == 'cloud_cover' ): item . ext . eo . cloud_cover = value # Projection Extension if ( key == 'epsg_code' ): item . ext . projection . epsg = value # Tuple containing spatial and temporal extent information to use later in this tutorial item_extent_info = ( bbox , geom , time_acquired ) # Returns a list containing the PySTAC Item object and a tuple # holding the bounding box, geojson polygon, and date the item was acquired return item , ( item_extent_info ) Let's create our set of STAC Items from the Planet order metadata.json files and set the asset types to be the COGs stored in our Google Cloud Storage Bucket. In [12]: def create_STAC_Items ( metadata_folder_name , planet_order_id , item_type , item_ids , storage_bucket_name ): # Store metadata store_item_metadata ( order_id , metadata_folder_name , item_type , item_ids ) metadata_directory = metadata_folder_name + '/' + order_id + '/' + item_type metadata_files = sorted ( Path ( metadata_directory ) . glob ( '*' ), reverse = True ) urls = [] urls = sorted ([ storage_bucket_name + item_id + '_3B_AnalyticMS.tif' for item_id in item_ids ], reverse = True ) # empty list to store STAC items stac_items = [] for asset_url , item_metadata in zip ( urls , metadata_files ): m = load_item_metadata ( item_metadata ) item , extent = create_STAC_Item ( asset_url , m ) item . add_asset ( key = 'analytic' , asset = pystac . Asset ( href = asset_url , title = \"4-Band Analytic\" , # indicate it is a cloud optimized geotiff media_type = pystac . MediaType . COG , roles = ([ \"analytic\" ]) ) ) stac_items . append (( item , extent )) return stac_items In [13]: item_type = 'PSScene' metadata_folder = 'catalog_metadata' storage_bucket_name = 'https://storage.googleapis.com/sample-cogs/cog/' stac_items = create_STAC_Items ( metadata_folder , order_id , item_type , item_ids , storage_bucket_name ) Directory already exists Add STAC Items to the STAC Catalog Now we can inspect the contents of our STAC Items individually and add each item to our STAC Catalog. In [14]: for index , item in enumerate ( stac_items ): catalog . add_item ( item [ 0 ]) print ( json . dumps ( item [ 0 ] . to_dict (), indent = 4 )) { \"type\": \"Feature\", \"stac_version\": \"1.0.0-beta.2\", \"id\": \"20210515_145754_03_245c\", \"properties\": { \"eo:cloud_cover\": 0, \"proj:epsg\": 32618, \"gsd\": 4.1, \"view:sun_azimuth\": 122.8, \"view:sun_elevation\": 57.3, \"datetime\": \"2021-05-15T14:57:54.037986Z\" }, \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ -74.43459546492133, 40.59496845871806 ], [ -74.43459546492133, 40.8630991753778 ], [ -73.94789184374838, 40.8630991753778 ], [ -73.94789184374838, 40.59496845871806 ], [ -74.43459546492133, 40.59496845871806 ] ] ] }, \"links\": [ { \"rel\": \"root\", \"href\": null, \"type\": \"application/json\" }, { \"rel\": \"parent\", \"href\": null, \"type\": \"application/json\" } ], \"assets\": { \"analytic\": { \"href\": \"https://storage.googleapis.com/sample-cogs/cog/20210515_145754_03_245c_3B_AnalyticMS.tif\", \"type\": \"image/tiff; application=geotiff; profile=cloud-optimized\", \"title\": \"4-Band Analytic\", \"roles\": [ \"analytic\" ] } }, \"bbox\": [ -74.43459546492133, 40.59496845871806, -73.94789184374838, 40.8630991753778 ], \"stac_extensions\": [ \"eo\", \"view\", \"projection\" ] } { \"type\": \"Feature\", \"stac_version\": \"1.0.0-beta.2\", \"id\": \"20210514_145807_70_2455\", \"properties\": { \"eo:cloud_cover\": 0, \"proj:epsg\": 32618, \"gsd\": 4.1, \"view:sun_azimuth\": 122.9, \"view:sun_elevation\": 56.9, \"datetime\": \"2021-05-14T14:58:07.707762Z\" }, \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ -74.30860815002872, 40.53685919989149 ], [ -74.30860815002872, 40.80976203894409 ], [ -73.81522948934723, 40.80976203894409 ], [ -73.81522948934723, 40.53685919989149 ], [ -74.30860815002872, 40.53685919989149 ] ] ] }, \"links\": [ { \"rel\": \"root\", \"href\": null, \"type\": \"application/json\" }, { \"rel\": \"parent\", \"href\": null, \"type\": \"application/json\" } ], \"assets\": { \"analytic\": { \"href\": \"https://storage.googleapis.com/sample-cogs/cog/20210514_145807_70_2455_3B_AnalyticMS.tif\", \"type\": \"image/tiff; application=geotiff; profile=cloud-optimized\", \"title\": \"4-Band Analytic\", \"roles\": [ \"analytic\" ] } }, \"bbox\": [ -74.30860815002872, 40.53685919989149, -73.81522948934723, 40.80976203894409 ], \"stac_extensions\": [ \"eo\", \"view\", \"projection\" ] } We can indeed verify that we have added two STAC items as children to the catalog. In [15]: print ( list ( catalog . get_all_items ())) [<Item id=20210515_145754_03_245c>, <Item id=20210514_145807_70_2455>] In [16]: catalog . describe () * <Catalog id=sample-catalog> * <Item id=20210515_145754_03_245c> * <Item id=20210514_145807_70_2455> Catalog Types STAC supports the use of both relative and absolute links in json files. To provide some standard uniformity in selecting which type to use and when, the specification encourages the use of three catalog types. Self-Contained All links are relative to allow for maximum transferability. This allows a STAC catalog to be downloaded and used locally. Links to the item assets can either be absolute links to their online locations or can be relative links to the where in the local directory they are stored. Published Published catalogs are STAC Catalogs that exist online rather than stored on a local machine. Absolute Published This is a published catalog that stores all links as absolute. Relative Published The catalog is self-contained with the exception that it contains an absolute link at the root to where it is stored online. Adding a Collection to Our Catalog As mentioned earlier, a Collection is really just an extension of a STAC Catalog. It has some additional metadata like spatial extent and temporal extent . We will describe extent in detail later in this notebook. We'll create a Collection using some other COGs from our Google Cloud Storage Bucket and demonstrate how to generate one using PySTAC. This Collection will exist as a subdirectory within our already existing STAC Catalog. Create Additional STAC Items In [17]: collection_item_ids = [ '20210513_150715_17_1067' , '20210512_152647_0f15' , '20210512_152646_0f15' , ] collection_metadata_folder = \"collection_metadata\" In [18]: collection_stac_items = create_STAC_Items ( collection_metadata_folder , order_id , item_type , collection_item_ids , storage_bucket_name ) Directory already exists In [19]: for index , collection_item in enumerate ( collection_stac_items ): print ( json . dumps ( collection_item [ 0 ] . to_dict (), indent = 4 )) { \"type\": \"Feature\", \"stac_version\": \"1.0.0-beta.2\", \"id\": \"20210513_150715_17_1067\", \"properties\": { \"eo:cloud_cover\": 0, \"proj:epsg\": 32618, \"gsd\": 3.7, \"view:sun_azimuth\": 126.1, \"view:sun_elevation\": 58.1, \"datetime\": \"2021-05-13T15:07:15.171792Z\" }, \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ -74.27891390114934, 40.687388944405484 ], [ -74.27891390114934, 40.88465957427119 ], [ -73.94518702625808, 40.88465957427119 ], [ -73.94518702625808, 40.687388944405484 ], [ -74.27891390114934, 40.687388944405484 ] ] ] }, \"links\": [], \"assets\": { \"analytic\": { \"href\": \"https://storage.googleapis.com/sample-cogs/cog/20210513_150715_17_1067_3B_AnalyticMS.tif\", \"type\": \"image/tiff; application=geotiff; profile=cloud-optimized\", \"title\": \"4-Band Analytic\", \"roles\": [ \"analytic\" ] } }, \"bbox\": [ -74.27891390114934, 40.687388944405484, -73.94518702625808, 40.88465957427119 ], \"stac_extensions\": [ \"eo\", \"view\", \"projection\" ] } { \"type\": \"Feature\", \"stac_version\": \"1.0.0-beta.2\", \"id\": \"20210512_152647_0f15\", \"properties\": { \"eo:cloud_cover\": 0.02, \"proj:epsg\": 32618, \"gsd\": 3.9, \"view:sun_azimuth\": 133.9, \"view:sun_elevation\": 60.8, \"datetime\": \"2021-05-12T15:26:47.889760Z\" }, \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ -74.28521956035253, 40.715449945504595 ], [ -74.28521956035253, 40.8380858015212 ], [ -73.96833974020785, 40.8380858015212 ], [ -73.96833974020785, 40.715449945504595 ], [ -74.28521956035253, 40.715449945504595 ] ] ] }, \"links\": [], \"assets\": { \"analytic\": { \"href\": \"https://storage.googleapis.com/sample-cogs/cog/20210512_152647_0f15_3B_AnalyticMS.tif\", \"type\": \"image/tiff; application=geotiff; profile=cloud-optimized\", \"title\": \"4-Band Analytic\", \"roles\": [ \"analytic\" ] } }, \"bbox\": [ -74.28521956035253, 40.715449945504595, -73.96833974020785, 40.8380858015212 ], \"stac_extensions\": [ \"eo\", \"view\", \"projection\" ] } { \"type\": \"Feature\", \"stac_version\": \"1.0.0-beta.2\", \"id\": \"20210512_152646_0f15\", \"properties\": { \"eo:cloud_cover\": 0.01, \"proj:epsg\": 32618, \"gsd\": 3.9, \"view:sun_azimuth\": 134, \"view:sun_elevation\": 60.8, \"datetime\": \"2021-05-12T15:26:46.883127Z\" }, \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ -74.26694023232191, 40.778899122937155 ], [ -74.26694023232191, 40.901587524162004 ], [ -73.94961769018644, 40.901587524162004 ], [ -73.94961769018644, 40.778899122937155 ], [ -74.26694023232191, 40.778899122937155 ] ] ] }, \"links\": [], \"assets\": { \"analytic\": { \"href\": \"https://storage.googleapis.com/sample-cogs/cog/20210512_152646_0f15_3B_AnalyticMS.tif\", \"type\": \"image/tiff; application=geotiff; profile=cloud-optimized\", \"title\": \"4-Band Analytic\", \"roles\": [ \"analytic\" ] } }, \"bbox\": [ -74.26694023232191, 40.778899122937155, -73.94961769018644, 40.901587524162004 ], \"stac_extensions\": [ \"eo\", \"view\", \"projection\" ] } SpatialTemporal Extents of a Collection Spatial Extent One of the key things a Collection includes is the spatial extent of the items it holds. What do we mean by spatial extent? Spatial Extent refers to the the extent of geographic space a raster covers. This is represented by the four corners of a raster image ( xmin, y min, x max, y max). Since we are items into our collection, we will need to determine the full extent of geographic space both items cover when combined. To do this, we will need to find the union of the items geojson polygons and merge them into one polygon. In [20]: from shapely.ops import unary_union import matplotlib.pyplot as plt from shapely.geometry import shape def get_spatial_extent ( polygons ): # Plot of polygons overlay plt . figure ( figsize = ( 14 , 8 )) for polygon in polygons : plt . plot ( * shape ( polygon ) . exterior . xy ) # Returns a union of the two geojson polygons for each item unioned_geometry = unary_union ( polygons ) # Plot the unified polygon x , y = shape ( unioned_geometry ) . exterior . xy plt . figure ( figsize = ( 14 , 8 )) plt . fill ( x , y , alpha = 0.5 , facecolor = 'none' , edgecolor = 'purple' , linewidth = 7 ) plt . show () # Set the bbox to be the bounds of the unified polygon and return the spatial extent of the collection return pystac . SpatialExtent ( bboxes = [ unioned_geometry . bounds ]) Temporal Extent The other type of extent that is important to a Collection is Temporal Extent. Temporal Extent refers to the extent of time over which items in the Collection were acquired from a start date to an end date. In [21]: def get_temporal_extent ( startime , endtime ): time_interval = [ startime , endtime ] temporal_extent = pystac . TemporalExtent ( intervals = [ time_interval ]) return temporal_extent Combining Spatial and Temporal Extent to Create Full Extent of the Collection In [22]: def create_full_extent ( stac_item_list ): polygons = [] datetimes = [] for index , stac_item in enumerate ( stac_item_list ): geometry = stac_item [ 1 ][ 1 ] polygons . append ( shape ( geometry )) datetime = stac_item [ 1 ][ 2 ] datetimes . append ( datetime ) # Get the spatial extent spatial_extent = get_spatial_extent ( polygons ) # Get temporal extent temporal_extent = get_temporal_extent ( min ( datetimes ), max ( datetimes )) collection_extent = pystac . Extent ( spatial = spatial_extent , temporal = temporal_extent ) return collection_extent In [23]: extent = create_full_extent ( collection_stac_items ) Create the Collection, Add STAC Items, and Set the Collection as a Child to the Catalog In [24]: collection = pystac . Collection ( id = 'nyc-images' , description = 'Planet PSScene Analytic Images Over Midtown Manhattan' , extent = extent , license = 'test' ) In [25]: collection . providers = [ pystac . Provider ( name = 'Planet' , roles = [ 'producer' , 'processor' ], url = 'https://www.planet.com' ) ] In [26]: collection_items = [ collection_stac_item [ 0 ] for collection_stac_item in collection_stac_items ] collection . add_items ( collection_items ) In [27]: collection . describe () * <Collection id=nyc-images> * <Item id=20210513_150715_17_1067> * <Item id=20210512_152647_0f15> * <Item id=20210512_152646_0f15> In [28]: catalog . add_child ( collection ) Normalize HREFS and Save Catalog We'll setup a temporary directory that will serve as the entry point for our STAC Catalog.The HREFs for all STAC links are structured according to the location of the root catalog. For the purpose of this tutorial, we are creating a self-contained catalog. Asset links will be absolute to reference the location of our COGs online. Feel free to adjust to your own use case. In [29]: tmp_dir = TemporaryDirectory () root_path = str ( Path ( tmp_dir . name ) . joinpath ( 'sample-stac' )) catalog . normalize_and_save ( root_href = root_path , catalog_type = pystac . CatalogType . SELF_CONTAINED ) Here is Our Simple STAC Created with Planet Imagery! Now we can see our entire sample Planet STAC in action! If we look below, we can see our outermost root catalog linking to the STAC Items we created at the start of this tutorial followed by our newly created STAC Collection containing three other STAC Items. In [30]: catalog . describe () * <Catalog id=sample-catalog> * <Collection id=nyc-images> * <Item id=20210513_150715_17_1067> * <Item id=20210512_152647_0f15> * <Item id=20210512_152646_0f15> * <Item id=20210515_145754_03_245c> * <Item id=20210514_145807_70_2455> And if we open our catalog.json document, we can see the root self-referencing relative link, the relative link to the two STAC items within the catalog and the relative link to the Collection.json file childed to it. In [31]: with open ( catalog . get_self_href ()) as f : print ( f . read ()) { \"id\": \"sample-catalog\", \"stac_version\": \"1.0.0-beta.2\", \"description\": \"Simple STAC catalog.\", \"links\": [ { \"rel\": \"root\", \"href\": \"./catalog.json\", \"type\": \"application/json\" }, { \"rel\": \"item\", \"href\": \"./20210515_145754_03_245c/20210515_145754_03_245c.json\", \"type\": \"application/json\" }, { \"rel\": \"item\", \"href\": \"./20210514_145807_70_2455/20210514_145807_70_2455.json\", \"type\": \"application/json\" }, { \"rel\": \"child\", \"href\": \"./nyc-images/collection.json\", \"type\": \"application/json\" } ] } And here is our collection.json that is a child to our root catalog. In [32]: with open ( collection . get_self_href ()) as f : print ( f . read ()) { \"id\": \"nyc-images\", \"stac_version\": \"1.0.0-beta.2\", \"description\": \"Planet PSScene Analytic Images Over Midtown Manhattan\", \"links\": [ { \"rel\": \"root\", \"href\": \"../catalog.json\", \"type\": \"application/json\" }, { \"rel\": \"item\", \"href\": \"./20210513_150715_17_1067/20210513_150715_17_1067.json\", \"type\": \"application/json\" }, { \"rel\": \"item\", \"href\": \"./20210512_152647_0f15/20210512_152647_0f15.json\", \"type\": \"application/json\" }, { \"rel\": \"item\", \"href\": \"./20210512_152646_0f15/20210512_152646_0f15.json\", \"type\": \"application/json\" }, { \"rel\": \"parent\", \"href\": \"../catalog.json\", \"type\": \"application/json\" } ], \"extent\": { \"spatial\": { \"bbox\": [ [ -74.28521956035253, 40.687388944405484, -73.94518702625808, 40.901587524162004 ] ] }, \"temporal\": { \"interval\": [ [ \"2021-05-12T15:26:46.883127Z\", \"2021-05-13T15:07:15.171792Z\" ] ] } }, \"license\": \"test\", \"providers\": [ { \"name\": \"Planet\", \"roles\": [ \"producer\", \"processor\" ], \"url\": \"https://www.planet.com\" } ] } STAC Validation Using STAC Validator One option to validate our STAC is to use the STACValidator python utility. We can see that every json file in our STAC meet the criteria for a valid STAC entity. In [33]: from stac_validator import stac_validator # Instantiate a STACValidate Object. Setting recursive to -1 will do a full recursive validation # for the STAC catalog stac = stac_validator . StacValidate ( catalog . get_self_href (), recursive =- 1 ) stac . run () validation_check = [ message for message in stac . message ] validation_check Out[33]: [{'version': '1.0.0-beta.2', 'path': '/tmp/tmp4cqko1fi/sample-stac/catalog.json', 'schema': ['https://schemas.stacspec.org/v1.0.0-beta.2/catalog-spec/json-schema/catalog.json'], 'valid_stac': True, 'asset_type': 'CATALOG', 'validation_method': 'recursive'}, {'version': '1.0.0-beta.2', 'path': '/tmp/tmp4cqko1fi/sample-stac/./20210515_145754_03_245c/20210515_145754_03_245c.json', 'schema': ['https://cdn.staclint.com/v1.0.0-beta.1/extension/eo.json', 'https://cdn.staclint.com/v1.0.0-beta.1/extension/view.json', 'https://cdn.staclint.com/v1.0.0-beta.1/extension/projection.json', 'https://schemas.stacspec.org/v1.0.0-beta.2/item-spec/json-schema/item.json'], 'valid_stac': True, 'asset_type': 'ITEM', 'validation_method': 'recursive'}, {'version': '1.0.0-beta.1', 'path': '/tmp/tmp4cqko1fi/sample-stac/./20210514_145807_70_2455/20210514_145807_70_2455.json', 'schema': ['https://cdn.staclint.com/v1.0.0-beta.1/extension/eo.json', 'https://cdn.staclint.com/v1.0.0-beta.1/extension/view.json', 'https://cdn.staclint.com/v1.0.0-beta.1/extension/projection.json', 'https://cdn.staclint.com/v1.0.0-beta.1/item.json'], 'valid_stac': True, 'asset_type': 'ITEM', 'validation_method': 'recursive'}, {'version': '1.0.0-beta.1', 'path': '/tmp/tmp4cqko1fi/sample-stac/./nyc-images/collection.json', 'schema': ['https://cdn.staclint.com/v1.0.0-beta.1/collection.json'], 'valid_stac': True, 'asset_type': 'COLLECTION', 'validation_method': 'recursive'}, {'version': '1.0.0-beta.1', 'path': '/tmp/tmp4cqko1fi/sample-stac/./nyc-images/./20210513_150715_17_1067/20210513_150715_17_1067.json', 'schema': ['https://cdn.staclint.com/v1.0.0-beta.1/extension/eo.json', 'https://cdn.staclint.com/v1.0.0-beta.1/extension/view.json', 'https://cdn.staclint.com/v1.0.0-beta.1/extension/projection.json', 'https://cdn.staclint.com/v1.0.0-beta.1/item.json'], 'valid_stac': True, 'asset_type': 'ITEM', 'validation_method': 'recursive'}, {'version': '1.0.0-beta.1', 'path': '/tmp/tmp4cqko1fi/sample-stac/./nyc-images/./20210512_152647_0f15/20210512_152647_0f15.json', 'schema': ['https://cdn.staclint.com/v1.0.0-beta.1/extension/eo.json', 'https://cdn.staclint.com/v1.0.0-beta.1/extension/view.json', 'https://cdn.staclint.com/v1.0.0-beta.1/extension/projection.json', 'https://cdn.staclint.com/v1.0.0-beta.1/item.json'], 'valid_stac': True, 'asset_type': 'ITEM', 'validation_method': 'recursive'}, {'version': '1.0.0-beta.1', 'path': '/tmp/tmp4cqko1fi/sample-stac/./nyc-images/./20210512_152646_0f15/20210512_152646_0f15.json', 'schema': ['https://cdn.staclint.com/v1.0.0-beta.1/extension/eo.json', 'https://cdn.staclint.com/v1.0.0-beta.1/extension/view.json', 'https://cdn.staclint.com/v1.0.0-beta.1/extension/projection.json', 'https://cdn.staclint.com/v1.0.0-beta.1/item.json'], 'valid_stac': True, 'asset_type': 'ITEM', 'validation_method': 'recursive'}] Using PySTAC We can also walk over the STAC by using the Catalog.walk() method in PySTAC. The output below shows that there are no validation errors. In [34]: for root , subcategories , items in catalog . walk (): print ( ' {} is the current root in the STAC' . format ( root . id )) print ( 'Are there any any STAC validation errors ?: {} ' . format ( root . validate ())) for subcat in subcategories : print ( ' {} is a subcatalog or collection for the current root in the STAC' . format ( subcat . id )) print ( 'Are there any STAC validation errors ?: {} ' . format ( subcat . validate ())) for item in items : print ( ' {} is a STAC Item within the current root' . format ( item . id )) print ( 'Are there any STAC validation errors ?: {} ' . format ( item . validate ())) sample-catalog is the current root in the STAC Are there any any STAC validation errors ?: None nyc-images is a subcatalog or collection for the current root in the STAC Are there any STAC validation errors ?: None 20210515_145754_03_245c is a STAC Item within the current root Are there any STAC validation errors ?: None 20210514_145807_70_2455 is a STAC Item within the current root Are there any STAC validation errors ?: None nyc-images is the current root in the STAC Are there any any STAC validation errors ?: None 20210513_150715_17_1067 is a STAC Item within the current root Are there any STAC validation errors ?: None 20210512_152647_0f15 is a STAC Item within the current root Are there any STAC validation errors ?: None 20210512_152646_0f15 is a STAC Item within the current root Are there any STAC validation errors ?: None Clear Catalog and Cleanup Temporary Directory In [35]: catalog . clear_children () catalog . clear_items () list ( catalog . get_children ()) Out[35]: [] In [36]: list ( catalog . get_items ()) Out[36]: [] In [37]: tmp_dir . cleanup ()","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/introduction-to-stac-part-2-creating-an-example-stac-catalog-of-planet-imagery-with-pystac/","loc":"https://developers.planet.com/docs/planetschool/introduction-to-stac-part-2-creating-an-example-stac-catalog-of-planet-imagery-with-pystac/"},{"title":"Items & Assets","text":"Items In the Planet API, an item is an entry in our catalog, and generally represents a single logical observation (or scene) captured by a satellite. Each item is defined by an item_type , which represents the class of spacecraft and/or processing level of the item. Assets (or products, such as visual or analytic) can be derived from the item's source data. All items have a standard (or shared) set of properties. A few examples of shared properties are: acquired - Date-time at which the imagery was captured. geometry - An item's physical footprint, described as GeoJSON. published - Date-time at which this item was added to the API. Items also have additional properties that are specific to the item_type of the item. All items of a given item_type share all properties with one another. Whenever possible, properties that are identically named between different item_types will have the same schema and semantics. For example, acquired is an RFC-3339 timestamp in all items where it appears, enabling meaningful comparisons across item_types . Planet operates the PlanetScope (PS), RapidEye (RE), and SkySatf Earth-imaging constellations. Imagery is collected and processed in a variety of formats to serve different use cases, be it mapping, deep learning, disaster response, precision agriculture, or simple temporal image analytics to create rich information products. PlanetScope satellite imagery is captured as a continuous strip of single frame images known as \"scenes.\" Scenes are derived from multiple generations of PlanetScope satellites. Older-generation of PlanetScope satellites acquired a single RGB (red, green, blue) frame or a split-frame with a RGB half and a NIR (near-infrared) half, depending on the capability of the satellite. The new generation of PlanetScope satellites (PS2.SD and PSB.SD) acquire images with a multistripe frame with bands divided between RGBNIR (PS2.SD) or RGBNIR, green I, yellow and coastal blue (PSB.SD). The older generation of PlanetScope Satellites (PS2) acquired a single RGB (reg, green, blue) frame or split frame with a RGB half and a NIR (near-infrared) half depending on the capability of the satellite. Planet offers two product lines for PlanetScope imagery: a Basic Scene product and an Ortho Scene product. The Basic Scene product is a scaled Top of Atmosphere Radiance (at sensor) and sensor-corrected product. The Basic Scene product is designed for users with advanced image processing and geometric correction capabilities. The product is not orthorectified or corrected for terrain distortions. Ortho Scenes represent the single-frame image captures as acquired by a PlanetScope satellite with additional post processing applied. Item Types An item_type represents the class of spacecraft and/or processing level of an item . All items have an associated item_type . Each item_type has a specific list of asset_types that can be derived from the item's source data. All items within an item_type group will have identical schemas with no nullified or optional properties. Items across item_types may also share identical properties, and generally have the same schema and semantics to facilitate cross item_type searching using shared properties. As an example, both REOrthoTile and PSScene items have acquired and published properties. It can be assumed that these properties have the same meaning across both item_types . Whenever possible, item data is sliced in a similar manner across item_types . Available Item Types Description PSScene PlanetScope 3, 4, and 8 band scenes captured by the Dove satellite constellation REOrthoTile RapidEye OrthoTiles captured by the RapidEye satellite constellation REScene Unorthorectified strips captured by the RapidEye satellite constellation SkySatScene SkySat Scenes captured by the SkySat satellite constellation SkySatCollect Orthorectified scene composite of a SkySat collection SkySatVideo Full motion videos collected by a single camera from any of the active SkySats Landsat8L1G Landsat8 Scenes provided by USGS Landsat8 satellite Sentinel2L1C Copernicus Sentinel-2 Scenes provided by ESA Sentinel-2 satellite Assets An asset describes a product that can be derived from an item's source data, and can be used for various analytic, visual or other purposes. Assets are generally either image data or metadata. items have many assets available for production and download, each a different representation of the same item using different processing steps. (To view all possible asset values for an item type you're interested in, select that item type, above .) As an example, an item may have a visual or an analytic asset. The visual asset is intended for display, while the analytic can be used for further processing. For a complete listing of asset_types available for each item_type , checkout the item type specifics in this section. Item Publishing Lifecycle An item's publishing stage will help you understand when the right time is to download an item, based on whether your pipeline needs to optimize for data latency or data accuracy. Publishing stage is only available for PlanetScope and SkySat items: PSScene , SkySatScene , SkySatCollect , SkySatVideo . It supports the following values, availability and prevalence of each varying by item type: preview : Lowest latency, lowest fidelity. Data is unrectified; metadata changes are expected upon subsequent republishing. standard : Standard latency, standard fidelity. Data is stable and rectified, but subject to minimal metadata changes upon republishing. finalized : Highest latency, highest fidelity. Data is stable and rectified, no additional metadata changes are expected (barring any bug fixes or new quality improvements) This field will be available for all PlanetScope and SkySat items published after June 19, 2020. By mid-July, these fields will be backfilled for the full archive. Preview Stage Applicable only to unrectifiable, open water or cloud PSScene and all SkySatScene items. \"Preview\" PSScene items typically publish couple of hours before they will be republished as \"standard\" (if they are rectifiable). \"Preview\" SkySatScene items (L1A assets) are typically published two hours before they will be rectified and republished as \"finalized\". Upon republishing to \"standard\" or \"finalized\", significant metadata changes are expected. If the data is unrectifiable, it will remain in the \"preview\" stage. Standard Stage Applicable to all rectifiable items. With the exception of unrectifiable, open water/cloudy PSScene imagery, all of PlanetScope publishing will start in the \"standard\" stage. Note: this stage is not used for SkySat publishing. All \"Standard\" PlanetScope items will be republished to a \"finalized\" stage and may be subject to minimal change upon republishing as more scenes within a strip are published. Finalized Stage Applicable to all PSScene, SkySatCollect, SkySatVideo, and rectifiable PSScene and SkySatScene items. While no further republishing or metadata changes are expected as part of standard publishing for \"finalized\" items, Planet's catalog is dynamic and we will republish items as bug fixes, new metadata fields, new asset types, and broader quality improvements are released. You can read more on our UpdateFilter feature to learn about ways we support redownloading to filter on these enhancements. For PSScene items, \"finalized\" data will be available approximately 12-24 hours after an item reaches \"standard\" stage. For SkySatScene items, \"finalized\" data wil be available approximately 2 hours after an item is published as \"preview\" All SkySatCollect and SkySatVideo items will start and end in \"finalized\" stage","tags":"data-api","url":"https://developers.planet.com/docs/apis/data/items-assets/","loc":"https://developers.planet.com/docs/apis/data/items-assets/"},{"title":"Best Practices for working with Large AOIs","text":"Overview In this guide, you'll learn more about best practices for working with a large amount of image items in the Data API. If you haven't already, see the \"Getting Started\" guide for more information on how to acquire an API key and setup your development environment. Paginate Through a Large Search When a search returns more then 250 results those results will be broken up into several pages. You must request each page seperately, below is a common pagination pattern. examples/pagination.py import os import requests session = requests.Session() session.auth = (os.environ['PLANET_API_KEY'], '') # this large search filter produces all PlanetScope imagery for 1 day very_large_search = { \"name\": \"very_large_search\", \"item_types\": [\"PSScene\"], \"filter\": { \"type\": \"DateRangeFilter\", \"field_name\": \"acquired\", \"config\": { \"gte\": \"2016-07-01T00:00:00.000Z\", \"lte\": \"2016-07-02T00:00:00.000Z\" } } } # Create a Saved Search saved_search = \\ session.post( 'https://api.planet.com/data/v1/searches/', json=very_large_search) # after you create a search, save the id. This is what is needed # to execute the search. saved_search_id = saved_search.json()[\"id\"] # What we want to do with each page of search results # in this case, just print out each id def handle_page(page): for item in page[\"features\"]: print item[\"id\"] # How to Paginate: # 1) Request a page of search results # 2) do something with the page of results # 3) if there is more data, recurse and call this method on the next page. def fetch_page(search_url): page = session.get(search_url).json() handle_page(page) next_url = page[\"_links\"].get(\"_next\") if next_url: fetch_page(next_url) first_page = \\ (\"https://api.planet.com/data/v1/searches/{}\" + \"/results?_page_size={}\").format(saved_search_id, 5) # kick off the pagination fetch_page(first_page) ➜ python examples/pagination.py 219842_2261109_2016-07-01_0c2b 219842_1962716_2016-07-01_0c2b 219842_1962713_2016-07-01_0c2b 219842_1962613_2016-07-01_0c2b 219842_1962714_2016-07-01_0c2b ... Parallelizing Requests If you need to perform a large number of API operations, such as activating many items, your request rate can be improved by sending requests in parallel. In Python this can be done using a ThreadPool. The size of the ThreadPool will define the parallelism of requests. Due to Python's architecture ThreadPools are most useful when doing I/O bound operations, like talking to an API. If the operations were CPU bound, this would not be a good idea See: GIL . Note: If you increase the request rate too much you will run into rate limiting, see the next section for how to deal with that. examples/parallelism.py import os import requests from multiprocessing.dummy import Pool as ThreadPool # setup auth session = requests.Session() session.auth = (os.environ['PLANET_API_KEY'], '') def activate_item(item_id): print \"activating: \" + item_id # request an item item = session.get( (\"https://api.planet.com/data/v1/item-types/\" + \"{}/items/{}/assets/\").format(\"PSScene\", item_id)) # request activation session.post( item.json()[\"visual\"][\"_links\"][\"activate\"]) # An easy way to parallise I/O bound operations in Python # is to use a ThreadPool. parallelism = 5 thread_pool = ThreadPool(parallelism) # Open up a file of ids that we have already retrieved from a search with open('examples/1000_PSScene_ids.txt') as f: item_ids = f.read().splitlines()[:100] # only grab 100 # In this example, all items will be sent to the `activate_item` function # but only 5 will be running at once thread_pool.map(activate_item, item_ids) ➜ python examples/parallelism.py activating: 219842_2261109_2016-07-01_0c2b activating: 217416_1962722_2016-07-01_0c2b activating: 219842_1962614_2016-07-01_0c2b activating: 217416_1761305_2016-07-01_0c2b activating: 217416_1660809_2016-07-01_0c2b ... Working with Rate Limiting If you handle them correctly, rate limiting errors will be a normal and useful part of working with the API. The Planet API responds with HTTP 429 when your request has been denied due to exceeding rate limits. The following example shows you how to identify a rate limit error and then retry with an exponential backoff. An exponential backoff means that you wait for exponentially longer intervals between each retry of a single failing request. The retrying library provides a decorator that you can add to any method to give it various types of retries. examples/rate_limiting.py import os import requests from multiprocessing.dummy import Pool as ThreadPool from retrying import retry # setup auth session = requests.Session() session.auth = (os.environ['PLANET_API_KEY'], '') # \"Wait 2&#94;x * 1000 milliseconds between each retry, up to 10 # seconds, then 10 seconds afterwards\" @retry( wait_exponential_multiplier=1000, wait_exponential_max=10000) def activate_item(item_id): print \"attempting to activate: \" + item_id # request an item item = session.get( (\"https://api.planet.com/data/v1/item-types/\" + \"{}/items/{}/assets/\").format(\"PSScene\", item_id)) # raise an exception to trigger the retry if item.status_code == 429: raise Exception(\"rate limit error\") # request activation result = session.post( item.json()[\"visual\"][\"_links\"][\"activate\"]) if result.status_code == 429: raise Exception(\"rate limit error\") print \"activation succeeded for item \" + item_id parallelism = 50 thread_pool = ThreadPool(parallelism) with open('examples/1000_PSScene_ids.txt') as f: item_ids = f.read().splitlines()[:400] # only grab 100 thread_pool.map(activate_item, item_ids) ➜ python examples/rate_limiting.py attempting to activate: 217416_1661222_2016-07-01_0c2b attempting to activate: 217416_1962721_2016-07-01_0c2b attempting to activate: 217416_1661320_2016-07-01_0c2b attempting to activate: 217416_1458713_2016-07-01_0c2b attempting to activate: 217416_1761305_2016-07-01_0c2b activation succeeded for item 217416_1761714_2016-07-01_0c2b activation succeeded for item 217416_2062808_2016-07-01_0c2b attempting to activate: 217416_1761712_2016-07-01_0c2b attempting to activate: 217416_1962820_2016-07-01_0c2b activation succeeded for item 217416_1153521_2016-07-01_0c2b","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/best-practices-for-working-with-large-aois/","loc":"https://developers.planet.com/docs/planetschool/best-practices-for-working-with-large-aois/"},{"title":"How to Manage Your Account","text":"Manage your account Select the Account icon in the top right corner to manage your account or logout. The Account icon displays a dropdown options to navigate to the Planet Account page or to Log Out . Hover over the account icon to view a tooltip that displays which account you are currently signed into. From your Planet account page, view personal account settings, update or disable your profile, change the password, review orders, receive invitations, and view the usage of organizational accounts.","tags":"apps-explorer","url":"https://developers.planet.com/docs/apps/explorer/how-to-manage-account/","loc":"https://developers.planet.com/docs/apps/explorer/how-to-manage-account/"},{"title":"How to Manage Preferences","text":"Manage Preferences You can manage preferences related to coordinate and measurement systems in the left hand navigation. Click on the Settings icon in the lower left hand corner. Click on Preferences to adjust preferences for your coordinate system and measurement system.","tags":"apps-explorer","url":"https://developers.planet.com/docs/apps/explorer/how-to-manage-preferences/","loc":"https://developers.planet.com/docs/apps/explorer/how-to-manage-preferences/"},{"title":"API Mechanics","text":"Authentication The Reports API uses Basic HTTP Authentication and requires that you have a Planet API key. Once you're signed up, you can find your API key on the My Settings page in my account . Authenticate by setting username to your API key. You can find your organizations ID in your Organization ID on the Organizations tab in my account . If you have sub organizations you may also find the ID number for those organizations on the same page. Example: Listing Reports Here, we're using a (fictional) API key \"12345\" to list available reports for an (again, fictional) Organization with ID \"0000\": With cURL curl -u 12345: https://api.planet.com/reports/v0/?org_id=0000 With Python import requests PLANET_API_KEY = 12345 BASE_URL = \"https://api.planet.com/reports/v0\" session = requests.Session() # setup a session session.auth = (PLANET_API_KEY, \"\") # authenticate session with user name and password, pass in an empty string for the password res = session.get(BASE_URL, params={\"org_id\": 0000}) # make a GET request to the Reports API to list available reports print(res.text) # print response body Permissions Users must be an organization administrator in order to list and download usage reports for a plan. Links Most Reports API responses contain a _links object that contain a list of hyperlinks to itself and related data. You are encouraged to rely on these links rather than constructing the links yourself. The most common _link is _self , which is a self reference. When an API response is paginated, _links will contain _next and _prev references. Pagination The Reports API paginates responses to limit the results, making them easier to work with. The first GET request will yield the first page along with _links representing the location of the _next page. Following the _next link will return another page of results. This process may be repeated until the _next link is no longer returned, which indicates the last page of results. The following _links are provided in the response to facilitate pagination: _self - The canonical location of the current page. _first - The initial page. _next - The page that logically follow the current page. _prev - The page that logically precedes the current page.","tags":"reports","url":"https://developers.planet.com/docs/reports/api-mechanics/","loc":"https://developers.planet.com/docs/reports/api-mechanics/"},{"title":"API Mechanics","text":"Authentication The Planet API uses Basic HTTP Authentication and requires that you have a Planet API key. Once you're signed up, you can find your API key in your account settings . Authenticate by setting username to your API key. **Authentication Via Basic HTTP with Python import os # import os module to access enviornmental modules import requests os.environ['PL_API_KEY']='12345' # pass in your API key PLANET_API_KEY = os.getenv('PL_API_KEY') # Setup the API Key from the `PL_API_KEY` environment variable BASE_URL = \"https://api.planet.com/data/v1\" session = requests.Session() #setup a session session.auth = (PLANET_API_KEY, \"\") #authenticate session with user name and password, pass in an empty string for the password res = session.get(BASE_URL) #make a get request to the Data API print(res.status_code) # test response print(res.text) # print response body Authentication Via cURL curl -u {api-key}: https://api.planet.com/data/v1/ Permissions Depending on your account type, you may be prevented from taking certain actions. Things that have permission restrictions will return a list of permissions attached to the object. As an example, free accounts can only download assets from items located in California. In this case, its list of permissions will include a download permission. If the asset is not downloadable, the download permission will be absent. If you wish, you can filter objects based on your permission level . Links Most Planet API responses contain a _links object that contain a list of hyperlinks to itself and related data. You are encouraged to rely on these links rather than constructing the links yourself. The most common _link is _self , which is a self reference. When an API response is paginated, _links will contain _next and _prev references. Pagination The Planet API paginates responses to limit the results, making them easier to work with. The first GET request will yield the first page along with _links representing the location of the _next page. Following the _next link will return another page of results. This process may be repeated until the _next link is no longer returned, which indicates the last page of results. The following _links are provided in the response to facilitate pagination: _self - The canonical location of the current page. _first - The initial page. _next - The page that logically follow the current page. _prev - The page that logically precedes the current page. Rate Limiting To improve the experience for all of our users, Planet uses rate limiting to prevent overloading the system. If handled correctly, rate limiting errors can be a normal and useful part of working with the API. When a rate limit has been exceeded, the Planet API responds with an HTTP 429 response code. When this occurs, we recommend implementing retry with an exponential backoff . An exponential backoff means that you wait for exponentially longer intervals between each retry of a single failing request. The following rate limits are currently in place: Activation endpoint - 5 requests per second, per API key. Download endpoint - 5 requests per second, per API key. Compute operation endpoints - 5 requests per second, per API key. Other endpoints - 10 requests per second, per API key. Maximum Payload Size When sending a POST request to the Planet API, the server will accept a maximum payload size of 1 megabyte. Errors Whenever an error occurs, whether it be the fault of the user or an internal system, an error object will be returned. HTTP response codes of 4xx suggest a bad request. If you receive a 4xx response, we recommend reviewing the API reference docs for more context to help you troubleshoot. 5xx errors suggest a problem on Planet's end, so if you receive a 5xx error, please contact support .","tags":"data-api","url":"https://developers.planet.com/docs/apis/data/api-mechanics/","loc":"https://developers.planet.com/docs/apis/data/api-mechanics/"},{"title":"Setting up Monitoring Orders","text":"The Planet Tasking API is a REST based API, which can be integrated into any service, regardless of the language used. Below are some examples of how to create and maintain Monitoring orders. The RRule A Monitoring order is a Tasking Order that takes images of a location over a period of time at a defined cadence. The time period, cadence and other options are defined by the provided RRule which allows flexibility and accuracy in the creation of a monitoring order. In first the example below the rrule is defined as \"FREQ=WEEKLY;COUNT=4;INTERVAL=1\" which can be broken down thusly: FREQ=WEEKLY : Defines that the Monitoring Tasking Order frequency should be orientated around calendar weeks COUNT=4 : Defines that this order should run 4 times INTERVAL=1 : States that the cadence should be every week. If this was set to 2 for example, then the cadence would be every 2 weeks. 3 would be every 3 weeks and so on. This means that the above RRule will create an order that will capture 1 image per week for 4 weeks, with the start time of the first capture being the date/time defined in the start_time parameter. But what happens if you create your Monitoring Tasking Order on a Wednesday and you want the cadence to run from Monday to Sunday but you still want to use the rest of the week you are in to take the first capture. This can be achieved using a combination of the BYDAY RRule parameter and the early_start flag in the order payload. RRule restrictions Some restrictions do apply to how the RRule format can be used to set up Monitoring Tasking Orders. The following should be taken into account when creating you order: The maximum number of monitoring instances for a single Monitoring Tasking Order is 365 The minimum length of a single monitioring instance is 1 day. RRule definitions that attempt to set a cadence < 24HR will be rejected The RRule option BYYEARDAY will be rejected The RRule option FREQ=YEARLY will be rejected The interval and count must both be > 0 Taking all of this into consideration, let's see what is involved in creating such a Monitoring Order: Creating a Monitoring Order If you are already familiar with creating a standard Tasking Order, then setting a Monitoring Order isn't much different, it just needs a couple of extra fields to be defined. (If you are not familiar with setting up a Tasking Order, you can take a look at Tasking Orders ) curl --request POST \\ --url https://api.planet.com/tasking/v2/orders/ \\ --header 'authorization: api-key <YOUR_API_KEY>' \\ --header 'content-type: application/json' \\ --data '{ \"geometry\": { \"type\": \"Point\", \"coordinates\": [ 149.44135, 28.49240 ] }, \"name\": \"Test Monitoring Order\", \"scheduling_type\": \"MONITORING\", \"rrule\": \"FREQ=WEEKLY;COUNT=4;INTERVAL=1;BYDAY=MO\", \"early_start\": true }' Note the lack of a start_time in this request. If the start_time is omitted then the system will take the current time and date as the start time. The above request would, if created on any other day than a Monday, attempt to collect 5 captures, the time of interest of the first capture spanning from the time that the order was created to the end of that week, with the next capture time of interest starting on the following Monday, which is defined by the BYDAY RRule parameter. If you want to know how your Monitoring Order is doing, you can set up email notifications so you can be automatically informed when a new capture is taken (see Notification and History ) Checking the status of your monitoring order If you want to check the status of a monitoring order programmatically, the first thing is to make a call to the tasking/v2/orders endpoint with the id of the Monitoring Order that you want to check: curl --request GET \\ --url https://api.planet.com/tasking/v2/orders/<ORDER_ID_GOES_HERE> \\ --header 'authorization: api-key <YOUR_API_KEY>' \\ --header 'content-type: application/json' The response from this request contains presenting an overview of the capture status of the order as well as the status of the Tasking Order itself: { \"id\": \"ORDER_ID\", ... ... ... \"status\": \"IN_PROGRESS\", \"capture_count\": 1, \"capture_status_queued_count\": 0, \"capture_status_processing_count\": 0, \"capture_status_published_count\": 1, \"rrule\": \"FREQ=WEEKLY;COUNT=4;INTERVAL=1;BYDAY=MO\", ... ... ... } To view the captures themselves, the following call can be made to the tasking/v2/captures endpoint, which will return all the captures for the given Tasking Order ID: curl --request GET \\ --url 'https://api.planet.com/tasking/v2/captures/?order_id=<ORDER_ID_GOES_HERE>' \\ --header 'authorization: api-key <YOUR_API_KEY>' \\ --header 'content-type: application/json'","tags":"tasking","url":"https://developers.planet.com/docs/tasking/examples/monitoring","loc":"https://developers.planet.com/docs/tasking/examples/monitoring"},{"title":"NICFI Basemaps in Google Earth Engine FAQ","text":"NICFI Basemaps in GEE FAQ Which NICFI Basemaps are available in GEE? The following Basemaps are available in GEE: PlanetScope Tropical Normalized Analytic Biannual and PlanetScope Tropical Normalized Analytic Monthly series Basemaps The following data description pages provide details on the Planet and NICFI Basemaps: Planet & NICFI Basemaps for Tropical Forest Monitoring - Tropical Africa Planet & NICFI Basemaps for Tropical Forest Monitoring - Tropical Asia Planet & NICFI Basemaps for Tropical Forest Monitoring - Tropical Americas How are the Basemaps organized in GEE? The NICFI Basemaps are organized by the major rainforest regions (Amazon, Congo, and Indonesia) into 3 regional Image Collections: Tropical Africa Tropical Asia Tropical Americas Bi-annual and monthly images are included with the same regional image collections: projects/planet-nicfi/assets/basemaps/africa projects/planet-nicfi/assets/basemaps/asia projects/planet-nicfi/assets/basemaps/americas Add a single mosaic from the collection to your map by using the following command: var imageCollection = ee.ImageCollection('projects/planet-nicfi/assets/basemaps/africa'); Map.addLayer(imageCollection.first(), {gain: 0.15, bands:[\"R\", \"G\", \"B\"]}) How do I filter the Basemaps by date? The PlanetScope Tropical Normalized Analytic Monthly series Basemaps are stored as images in the Image Collections representing a single month in time. For example, the July 2021 Normalized Analytic Basemap has a start date of 2021-07-01 and an end date on the first of the following month: 2021-08-01. Running a date filter for a specific time period within this month, will not return any results (for example, between 2021-08-02 and 2021-08-19). Note: The filterDate options use the start date and verify if it is within the date range provided. The start of the month must be included in your query. For example, the following filter returns only the Basemap for October: var filter_collection = planet_collection.filterDate ('2020-09-02', '2020-10-02') To return both September and October, use the following filter: var filter_collection = planet_collection.filterDate ('2020-09-01', '2020-10-02') Where do I find additional information about the NICFI Basemaps? Additional information on NICFI basemaps is availble in: The NICFI DATA Program User Guide The NICFI Satellite Data Program How long does it take for NICFI Basemaps to be available in GEE? NICFI monthly or bi-annual Basemaps are available in GEE within one week of publication on the Planet Platform. Can I share Basemaps with internal or external colleagues in my organization? Users are permitted to share data in compliance with the NICFI end user licensing agreement (EULA) terms. Direct access to the NICFI Basemap Image Collections in GEE is gated by Planet to ensure that a NICFI EULA is signed. The collections do not appear when searching the Public Catalog. Can I access the Basemap Source Scenes in GEE? The source scenes are not directly accessible in GEE, however, Planet has a Delivery Integration, described in the Google Earth Engine Overview for NICFI customers to deliver imagery to GEE. To identify which scene intersects a specific point in a Planet Basemap, use the inspector tool in the Planet GIS integrations ( ArcGIS & QGIS ) or use the Basemap API or the Planet Basemap viewer . Where do I go with questions or for support? For questions contact Planet Support, at support@planet.com . Additional help for using GEE is available at, Google Earth Engine Get Help .","tags":"integrations-gee","url":"https://developers.planet.com/docs/integrations/gee/nicfi/faq","loc":"https://developers.planet.com/docs/integrations/gee/nicfi/faq"},{"title":"NICFI Program Resource center","text":"Welcome to the NICFI Program Resource Center! On this page you will find important resources for using the NICFI data. Through Norway's International Climate & Forests Initiative (NICFI), anyone can now access Planet's high-resolution, analysis-ready mosaics of the world's tropics in order to help reduce and reverse the loss of tropical forests, combat climate change, conserve biodiversity, and facilitate sustainable development. In support of NICFI's mission, you can use this data for a number of projects including, but not limited to: Advance scientific research about the world's tropical forests and the critical services they provide. Implement and improve policies for sustainable forest management and land use in developing tropical forest countries and jurisdictions. Increase transparency and accountability in the tropics. Protect and improve the rights of indigenous peoples and local communities in tropical forest countries. Innovate solutions towards reducing pressure on forests from global commodities and financial markets. In short, the primary purpose of the NICFI Program is to support reducing and reversing the loss of tropical forests, contributing to combating climate change, conserving biodiversity, contributing to forest regrowth, restoration, and enhancement, and facilitating sustainable development, all of which must be Non-Commercial Use. To learn how more about the NICFI program, streaming and downloading basemaps please read the NICFI Data Program User Guide . The NICFI Data has 3 User Access Levels: Level 0 - Open and Public Good: Public view-only access of the Visual Mosaics (historical and future mosaics) through Purpose Ally sites. (Purpose Allies are entities that engage the public on forests and land use monitoring, e.g Global Forest Watch ). Level 1 - As Open as Possible: Access to download Surface Reflectance mosaics (historical and future mosaics) from the Planet Platform and via Planet's integrations. User groups include Third Party Participants e.g. those individuals and organizations using the data in pursuit of the NICFI Purpose. Level 1 users can stream and download Planet Basemaps from multiple sources. Please read through the User Guide to find the tool that is most appropriate for your needs. Level 2 - Select Partners: Strategic partners defined by Norwegian Ministry of Climate and Environment who have access to Level 1 data layers as well as the underlying scenes from Planet and selected historical archive data from Airbus back to 2002. Share your work with the world. Leverage the NICFI Social Media Playbook to showcase your efforts to combat tropical forest loss. If you need further support with the NICFI tropical forest & climate data program, please contact KSAT here: nicfi-servicedesk@ksat.no .","tags":"pages","url":"https://developers.planet.com/https://university.planet.com/page/nicfi","loc":"https://developers.planet.com/https://university.planet.com/page/nicfi"},{"title":"Notification and History","text":"Keeping track of your tasking orders past and present A Tasking Order, as it progresses through the Tasking API system, passes through a number of states as shown on the overview page . Each Tasking Order keeps a history of these transitions, and you can be notified of these transitions as they happen in real time. Tasking Order history To find out more about Tasking Order history on the Tasking Dashboard, go here However, if you are reading this you probably want to know how to do this via the API. You can review the history of your orders and their captures directly from the API using the endpoint: https://api.planet.com/tasking/v2/order-history This endpoint can accept a number of filters, which will help you find and process the history events that matter to you. The following example will request all history events that are other ORDER_CREATED or ORDER_FULFILLED: curl --request GET \\ --url 'https://api.planet.com/tasking/v2/order-history/?event_type__in=ORDER_CREATED%2CORDER_FULFILLED' \\ --header 'authorization: api-key <YOUR_API_KEY>' \\ --header 'content-type: application/json' More information about what filters can be applied to the history requests can be found in the Order History API Reference Email Notifications As your Tasking Order transitions from one state to the next, it is possible to receive notifications by email, informing you of its progress so you can be kept up-to-date without having to constantly come back to the Tasking Dashboard or having to make calls to the Tasking API to know the state of your Tasking order. The inbox to which these emails are sent is the email address of the user that the API key used in the requests refers to. It is not possible to direct these notification emails to another email address. You won't receive emails until you grant permissions for Planet to send you email notifications, and you can do this either via the Tasking Dashboard or by using the Tasking API. To achieve this using the Tasking API, it requires a POST request being made to the /v2/preferences/notifications/ endpoint: curl --request POST \\ --url https://api.planet.com/tasking/v2/preferences/notifications \\ --header 'authorization: api-key <YOUR_API_KEY>' \\ --header 'content-type: application/json' \\ --data '{ \"enabled_emails\": [ \"ORDER_CREATED\" ] }' The above POST request tells the Tasking API to send an email each time a Tasking Order is created using the same API key as what was used to set the notification permissions. Email notifications can be set up for the following events in the Tasking system: ORDER_FULFILLED, ORDER_EXPIRED, ORDER_CREATED, CAPTURE_FAILED, CAPTURE_PUBLISHED, CAPTURE_SCHEDULED, ORDER_LOCK_IN_CONFIRMED, ORDER_LOCK_IN_CANCELLATION_FAILED, ORDER_LOCK_IN_FAILED, BULK_FINISHED NOTE The POST request to the /v2/preferences/notifications endpoint works as a switch for each event in the above list. In other words, if an event is included in the request, notifications are either enabled for that event OR if that notifications were already enabled, then they stay enabled. If an event is excluded from the POST event then notifications for that event are then disabled. To see what notification preferences have been set, make a GET request to the same endpoint: curl --request GET \\ --url https://api.planet.com/tasking/v2/preferences/notifications \\ --header 'authorization: api-key <YOUR_API_KEY>' \\ --header 'content-type: application/json' This will return a response that will look similar to this: { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"enabled_emails\": [ \"ORDER_CREATED\" ] } ] } It is not possible to have different notification settings per Tasking Order, so the notifications that you choose to receive will apply to every order you create. For more information, please refer to the Notification API Reference . If you want to do the initial set up via the Tasking Dashboard, you can find out more about that and other features of the Tasking Dashboard here","tags":"tasking","url":"https://developers.planet.com/docs/tasking/notification-and-history","loc":"https://developers.planet.com/docs/tasking/notification-and-history"},{"title":"Notifications","text":"The Subscriptions API supports notifications to make it easier for you to monitor your subscriptions. Notifications give you visibility into specific events in a subscription's lifecycle. You can keep polling for subscriptions results periodically to determine the status and understand final items delivered. But webhook notifications proactively notify you when a subscription matches and delivers an item so you have confidence that you have all the expected imagery. Subscription notifications send messages in the form of notification topics. A topic is a specific event type that you can choose to be notified about. The Subscriptions API supports the following topics: delivery.success - an item is delivered. delivery.match - an item match occurred. delivery.failed - an item delivery failed. status.backfill.completed - a backfill completed. status.completed - a subscription completed. status.cancelled - a subscription was cancelled. status.pending - a subscription is pending. status.all - any and all Subscription level changes. status.suspended - a subscription has been suspended. status.failed - a subscription failed. To enable webhooks for a subscription, include a \"notifications\" object with a webhook URL and a set of notification topics in the notification. You must specify at least one topic, and a valid webhook URL (a callback where you expect to receive updates) using the scheme https (e.g.: https://host:8654/webhook/path). Responding to a Webhook Your client must acknowledge that it received data by sending a 200 OK response. Any response outside of the 200 range, including 3XX HTTP redirection codes, is a failure, indicating that you didn't receive the webhook. Planet doesn't follow redirects for webhook notifications and considers them to be an error response. Planet attempts \"best effort\" delivery. Events are sent in order, for each subscription and topic, however, we do not guarantee sequence of event delivery. In rare circumstances, you might experience delays in receiving webhooks. However, webhooks are always sent with the most recent data for the given subscription. The payload of the delivered webhook should reflect the most recent attributes for the subscription between the time of the webhook's trigger and the webhook's eventual delivery. If no 200 OK response is received, Planet attempts to deliver the event 3 times with exponential backoff. The following example creates a subscription that will notify: when a subscription filter match occurs. when that matched item is delivered. when that matched item fails to deliver. when a backfill completes. POST example POST: https://api.planet.com/subscriptions/ { \"name\": \"Example Subscription\", \"source\": { \"type\": \"catalog\", \"parameters\": { \"geometry\": { \"coordinates\": [[[139.5648193359375,35.42374884923695], [140.1031494140625,35.42374884923695], [140.1031494140625,35.77102915686019], [139.5648193359375,35.77102915686019], [139.5648193359375,35.42374884923695]]], \"type\": \"Polygon\" }, \"start_time\": \"2021-03-01T00:00:00Z\", \"end_time\": \"2023-08-31T00:00:00Z\", \"item_types\": [\"PSScene\"], \"asset_types\": [\"ortho_analytic_4b\"] } }, \"delivery\": { \"type\": \"google_cloud_storage\", \"parameters\": { \"bucket\": \"<my-bucket>\", \"credentials\": \"<my-credentials>\" } }, \"notifications\": { \"webhook\": { \"url\": \"https://example.com/post\", \"topics\": [ \"delivery.success\", \"delivery.match\", \"delivery.failed\", \"status.backfill.completed\" ] } } } Webhook Event Body Clients can expect the event body payload to contain the following attributes: schema_version : the schema version of the webhook body. subscription_id : the subscription ID that triggered the event. topic : the event topic. name : the name of the subscription. result : a string or object with the results of the event. For delivery.success , delivery.match , delivery.failed , results will be an object. All other topics will be a string. timestamp : the timestamp of the event. \"delivery.success\" topic body example { \"schema_version\": \"0.0.1\", \"subscription_id\": \"1c7fb0c8-ae1d-45db-8def-fd3a4bffba71\", \"topic\": \"delivery.success\", \"name\": \"Example subscription with delivery success notification\", \"result\": { \"delivered\": [ \"1c7fb0c8-ae1d-45db-8def-fd3a4bffba71/20201128_014059_74_1066/20201128_014059_74_1066_metadata.json\", \"1c7fb0c8-ae1d-45db-8def-fd3a4bffba71/20201128_014059_74_1066/20201128_014059_74_1066_3B_AnalyticMS.tif\" ] }, \"timestamp\": \"2021-09-21T15:33:40Z\" } \"delivery.match\" topic body example { \"schema_version\": \"0.0.1\", \"subscription_id\": \"1c7fb0c8-ae1d-45db-8def-fd3a4bffba71\", \"topic\": \"delivery.match\", \"name\": \"Example subscription with delivery match notification\", \"result\": { \"item_id\": \"20201128_014059_74_1066\" }, \"timestamp\": \"2021-09-21T15:32:49Z\" }","tags":"subscriptions","url":"https://developers.planet.com/docs/subscriptions/notifications/","loc":"https://developers.planet.com/docs/subscriptions/notifications/"},{"title":"Bounding Box Detections on Basemaps","text":"Number Description 1 Title of the Subscription. Generated manually by the Planet Account Manager. 2 Subscription Description Description of the Subscription. Each Subscription generates a description that is designed to give additional information about what the Subscription is for. 3 Date Filter. Choose the dates you wish to see. The dates you select must be within the Subscription start and end dates. 4 Toggle for Basemaps without Detections. There may be times where a Planet Basemap has zero detections. By default, the Analytic Feeds Viewer does not display these Basemaps, but you can toggle on the display of Basemaps without detections. 5 Results Sorting. Use this toggle to determine the order in which you wish to view results. Sort by date or number of detections. 6 Number of Detections within the Image. The number of detections found within the image. 7 Link to Explorer. Click this link to view imagery within the same AOI or that you have access to in Planet Explorer. 8 Scene ID. This is the unique ID for the scene that was processed for the detection. 9 Review & Export. Enables you to export detections as a geojson file. 10 Visualization Option: Heatmaps. Choose to see a heatmap of detectionsor each individual detection. 11 Visualization Option: Individual Detections. Choose to see individual detections. 12 Show all Time. This will toggle whether you see only detections for the selected time period or all time periods shown. 13 Confidence Score Filter. Use the confidence score filtering feature to show bounding box detections with higher confidence and remove false positives with lower confidence scores. 14 View Over Time. View how your area has changed over time and let Planet's detections guide you to where the most change has taken place 15 Confidence Score. A score (0 - 1.0) of how likely it is that this detection is a true positive (correct) detection 16 Detection Diagonal Length. The measurement in m of the diagonal length of the bounding box detection. This can be a good proxy for object length. 17 Image Acquisition Timestamp. The time at which the image was captured - this reflects the time that the object detected was present. 18 Location. The Latitude and Longitude of the centroid of the detection. 19 Link to Tasking Dashboard. Task a skysat to capture a high resolution image of the area. Note: You must already have access to the Tasking Dashboard Through the Review & Export flow, you'll be able to quickly cycle through change detections shown on-screen, selecting the time period where you first see the change take place. After reviewing all detections, you'll export the change detections into a clean dataset. Note: Your progress will not be saved once you leave the review flow. You'll need to review all detections or export the entire dataset. Number Description 1 Keyboard Shortcuts. Using the number keys, you can quickly select the time period which corresponds to when the change occurred. 2 Progress Bar. You'll see how many detections you've reviewed and how many more there are to go. 3 Export All. You can bypass the review flow and export all detections 4 No Change. Occasionally, you'll run into false positive change detections - select \"No Change\" when you find a detection that doesn't show change. 5 Previous Detect. Go back to the previous detection 6 Exit. Return to the main Feed Viewer display.","tags":"apps-feedviewer","url":"https://developers.planet.com/docs/apps/feedviewer/detectionbasemaps","loc":"https://developers.planet.com/docs/apps/feedviewer/detectionbasemaps"},{"title":"Object Detection on Imagery","text":"Number Description 1 Title of the Subscription. Generated manually by the Planet Account Manager. 2 Description of the Subscription. Each Subscription generates a description that is designed to give additional information about what the Subscription is for. 3 Date Filter. Choose the dates you wish to see. The dates you select must be within the Subscription start and end dates. 4 Toggle for Scenes without Detections. Use this toggle to include scenes within the subscription that resulted in 0 detections 5 Results Sorting. Use this toggle to determine the order in which you wish to view results. Sort by date or number of detections. 6 Number of Detections within the Image. The number of detections found within the image. 7 Link to Explorer. Click this link to view imagery within the same AOI or that you have access to in Planet Explorer 8 Scene ID. This is the unique ID for the scene that was processed for the detection. 9 Review & Export. Enables you to cycle through detections to quickly remove false positives and export a clean dataset. Note: Detections can take over a minute to load depending on how many there are. 10 Visualization Option: Heatmap. Choose to see a heatmap of detections. 11 Visualization Option: Individual Detections. Choose to see individual detections. 12 Show all Time. This will toggle whether you see only detections for the selected time period or all time periods shown. 13 Confidence Score Filter. Use the confidence score filtering feature to show bounding box detections with higher confidence and remove false positives with lower confidence scores. 14 Redo Search In This Area. Our viewer is able to visualize bounding boxes over Basemaps, however when looking in very large areas, it can take an exceedingly long time for them to load. Zooming into areas less than 5,000 km2 and redoing the search has shown a better experience. 15 Confidence Score. A score (0 - 1.0) of how likely it is that this detection is a true positive (correct) detection. 16 Detection Diagonal Length. The measurement in m of the diagonal length of the bounding box detection. This can be a good proxy for object length. 17 Image Acquisition Timestamp. The time at which the image was captured - this reflects the time that the object detected was present. 18 Image Item Type. The item type of the source imagery used to derive the detection per Planet's imagery specifications. 19 Cloud Cover Percentage. The percent of the imagery captured that were covered by clouds per our UDM product. 20 Location. The Latitude and Longitude of the centroid of the detection. 21 Link to Tasking Dashboard. Task a skysat to capture a high resolution image of the area. Note: You must already have access to the Tasking Dashboard. Through the Review & Export flow, you'll be able to quickly cycle through the detections shown on-screen, removing false positives along the way to ultimately export a clean dataset. Note: Your progress will not be saved once you leave the review flow. You'll need to review all detections or export the entire dataset. Number Description 1 Reject Detection. (Keyboard shortcut \"R\" or \"8\") Rejected detections will not be included in the exported dataset at the end of the Review & Export flow. 2 Keep Detection. (Keyboard shortcut \"F\" or \"5\") Kept detections will be included in the exported dataset at the end of the Review & Export flow. 3 Progress Bar. You'll see how many detections you've reviewed and how many more there are to go. 4 Export All. You can bypass the review flow and export all detections. 5 Previous Detect. Go back to the previous detection. 6 Exit. Return to the main Feed Viewer display.","tags":"apps-feedviewer","url":"https://developers.planet.com/docs/apps/feedviewer/detectionimagery","loc":"https://developers.planet.com/docs/apps/feedviewer/detectionimagery"},{"title":"Resources for Planet Users","text":"Python Library & CLI The Python package planet is an Apache 2.0-licensed Python client library and command-line interface for working with Planet's public API. To install, run pip install planet anywhere that Python 2.7 or Python 3.4+ is installed. Links: GitHub Repo PyPI Package Documentation & Examples Jupyter Notebooks The Developer Experience team at Planet has created a collection of Apache 2.0-licensed Jupyter Notebooks, along with a Docker image that makes it easy to run your own geospatially-enabled Jupyter instance. The interactive guides in this collection are designed to help Python-familiar developers explore Earth observation data, work with Planet's Public API, and learn how to extract information from Planet's archive of high-cadence satellite imagery. Links: GitHub Repo Docker Config Notebook Tutorials QGIS Plugin QGIS is the most widely-used free and open-source desktop geographic information system (GIS). Planet's Plugin for QGIS, which makes it easy for QGIS users to discover, stream and download Planet imagery, is also open source on Planet's Github . Links: Planet QGIS Plugin documentation Planet QGIS Plugin code Staccado Staccado is a Java-based catalog that implements the SpatioTemporal Asset Catalog (STAC) specification that Planet helped author. We have a number of users who maintain copies of Planet's catalog to meet security, disaster mitigation, or latency reduction requirements, and Staccato provides an ideal, standards-based solution for these use cases. Links: SpatioTemporal Asset Catalog (STAC) Staccado code Stratus Deprecated The Planet Labs Stratus GitHub project code is no longer actively maintained. The GitHub repository has been archived. Stratus, previously known as Boundless Server Enterprise (BSE), is an open source server for serving geospatial data. Stratus extends the core GeoServer project with cloud-native capabilities, enabling scalability through automatic provisioning of compute nodes. It replaces GeoServer's disk-based configuration with a shared Redis datastore that is always in sync. This code is no longer actively maintained, and the repository has been archived. links: Stratus code GeoServer Open Data In support of the International Disaster Charter , Planet make imagery of disaster areas around the globe available directly to the public, volunteers, humanitarian organizations, and other coordinating bodies. Disaster data is openly licensed under the Creative Commons: CC-BY-SA for commerical use, and CC-NC-BY for non-commerical use. Disaster Data is available to anyone with a Planet API key: learn how to get your own API key here , or learn more about Planet Disaster Data .","tags":"pages","url":"https://developers.planet.com/docs/pages/resources-for-planet-users/","loc":"https://developers.planet.com/docs/pages/resources-for-planet-users/"},{"title":"How to Order and Download Data","text":"If you have a contract with Planet, you can download imagery directly from Explorer or via Planet's APIs. If you do not have a contract with Planet, you will not be able to download imagery. Please contact sales if you would like to download imagery but don't currently have access. At the very bottom of the Search panel on the left of the screen, you will see two buttons - one for API {:} and one for Orders . Both of these buttons reference the images in the above panel that you have selected (in the case below, the 9 images from January 23, 2022 - PlanetScope Scene ) The API Button The API button will open a modal with three sections - API Key , cURL and Selected Item Ids . Each section is collapsed by default, they can be expanded via the < > icon to show the content. The content text can be easily copied by pressing the copy icon on the far right, whether you expand it or not. The cURL Request section has the text of the cURL request syntax prepared. It also has a Include Authentication toggle so that you don't expose your api key. The Selected Item Ids section simply gives you the identification numbers of the images you have selected. The Order Items Button The Order Items( n ) - where n equals the number of image sets you have selected in the panel above - button will open a new window. If you would like to download imagery, select Direct Download . Placing your Order From here, you will see a new window for completing your order. There are 4 steps to completing your order: choosing your delivery option, naming your order, selecting assets, and tools (where available) and final review. The first step requires you to choose between Direct download or Hosted analysis in Explorer to receive your order as a Cloud Optimized GeoTIFF (COG). At the second step, the Name field is required and you can choose your own naming convention here. For the third step, after you have named your order, you have two options. You can make further selections for your order or you can do an express check-out. To complete the express check-out, you can click Order on the bottom right-hand side of the screen. This will place an order for each selection displayed in the Orders Summary column. Each white box shows a summary of your selections, including item type, asset type, and any tools selected. Each white box will be placed as a separate order, and will be charged to your account accordingly. You should only do an express check-out if you are familiar with the default assets chosen and if you don't want to add any tools (such as composite or harmonization). The fourth step is making further selections for your order. To do this, click the Continue button or click on Select Assets at the top header. At the Select Assets step, you will see the item types listed that you ordered (for example, PlanetScope Scenes or SkySat Collects). Click into the item type that you wish to select assets for. Once you click on the item type (i.e. PlanetScope Scene), you will see a menu of assets to choose from. The default asset is highlighted in teal. You can unselect it by clicking on it. If you would like to order Unorthorectified assets, click + Show More and choose from the menu of Unorthorectified assets. If you choose these assets, you will receive the raw files that did not go through the rectification process. They are delivered as TIFF & RPC (rather than as a GeoTIFF and do not include geo location information.) The asset that you select will show up on the Order Summary to the right of the screen. Once you are done selecting assets, click Continue or click on the Tools & Review header at the top of the screen. At this step, you will see a list of all of the assets that you have chosen. Click on each asset to add tools (clipping, composite, or harmonization, where applicable). Your selections will be reflected in the Order Summary on the right hand side. Note Some customers have access to clipping imagery (per their contract). When you clip imagery, you only order pixels that are in the AOI you drew. Otherwise, you download the entire scene your AOI touches. If you would like to clip imagery, but don't currently see that option in the interface, please reach out to the support team. Customers who have access to clipping imagery also have access to compositing imagery. The composite tool stitches scenes together within an order to deliver fewer images with less or zero overlap. This reduces unnecessary overlaps within imagery, and consequently reduces the overall area of imagery delivered. Two ways to composite an AOI within your order are per strip or everything: The first is to composite by strip. Compositing by strip allows for consistency per strip. This choice is ideal for the GIS analyst who is doing pixel analysis and is sensitive to variability in temporal, spatial, spectral, geometric, or environmental conditions. The second is to composite all. Compositing all means that all layers are combined into one image. This choice is ideal for the quota-sensitive user who has a primarily visual use case. Seamlines or variability in environmental conditions may appear. If a customer has a composite that is larger than the stated sq km below (which changes per item type), they do not see the option to use the composite tool. The limit depends on the item type of the input scenes due to differences in resolution. High resolution (SkySatScene): Limit of 375 sq km per composite Medium resolution (PSScene, REOrthotile, Sentinel2L1C): Limit of 9,000 sq km per composite Low resolution (Landsat8L1G): Limit of 1,200,000 sq km per composite Customers will also have access to the harmonization tool for surface reflectance assets. The harmonization tool ensures consistent radiometric calibration with Sentinel-2 satellites. This helps with combining and comparing Planet data from other sources. We recommend using this option when you are downloading data from varied Planet constellations (i.e. imagery from Dove-C and Dove-R.) Downloading your Order When placing an order, there are two options for downloading your data. These options are Direct download or Hosted analysis in Explorer, which will download a Cloud Optimized GeoTIFF (COG). After selecting your download preference, continue making your order selections as described above. Once you choose Order , you will see a note pop up briefly that you will be notified by email when your imagery download is ready. The left panel will pop open automatically to the Orders tab, and you will see your order in progress. When the order is ready for download, you will get an email to the address associated with your account. Once ready, you will be able to download a .zip of your assets from the Orders section in the left hand toolbar.","tags":"apps-explorer","url":"https://developers.planet.com/docs/apps/explorer/how-to-order-download/","loc":"https://developers.planet.com/docs/apps/explorer/how-to-order-download/"},{"title":"How to Order Hosted Data","text":"Analyze Planet daily scenes in Explorer when you order hosted data. To order a scene for analysis, search for imagery according to your needs, and click Order Scenes. A dialogue box prompts you to choose between an order for download or an order for analysis in Explorer. If you would like to order your image for analysis in Explorer and download later, you must place two separate orders. Viewing Hosted Data The hosted data drawer is organized by Folders that you ordered your hosted data into. In each folder, hosted data is organized by date. At the date level, you will see two buttons: The eye pulls up a preview of all images from a specific date on the map. X items > navigates to the scene level on a specific date to allow for more granular selections. If you click the X items > button, you will see results for specific images. The hosted data imagery card shows three action buttons: The eye shows a preview of the hosted data imagery on the map. The double square locks the image footprint on the map. The download arrow downloads the Cloud Optimized Geotiff to your computer at no extra cost. Order Hosted Data for Analysis in Explorer To order a scene for analysis, complete the following steps. Search for imagery and click Order Scenes . A dialogue box prompts you to choose between an order for download or an order for analysis in Explorer. Note : If you order your image for analysis in Explorer and then download the image, you must place two separate orders. Click Hosted analysis in Explorer. Add your imagery into a Folder using the drop-down of existing Folders with the option to add a new Folder. Note : We recommend naming Folders according to location and adding the imagery into a Folder with imagery in a similar area of interest. After you select a Folder, click Place Order . Images can take at least 15 minutes to be prepared. After the images are complete, they appear in your folder. How to Find Your Hosted Data in Your Folder To find your Folder, complete the following steps. Select the Access your hosted data for analysis icon from the left side toolbar. Click the icon to choose between My Folders and Demo Data . Click My Folders to view a list of your Folders and select the Folder with your ordered imagery. Note : If your imagery is still being prepared, a status message displays Processing images . Each Folder lists your ordered images, organized by date. How to Check the Status of your Imagery in Your Folder To check the status of your imagery, go to My Orders to view the status of your imagery. If the order fails, the imagery does not appear in the list. If the status is Failed: Try to place the order again. The imagery is not supported, it will continue to fail. Planet does not support PlanetScope 3band assets, RapidEye Scenes, Landsat, and Sentinel. Contact Planet Support if you continue to have issues with failed orders. Analyze Hosted Data Select the appropriate Folder and click the daily scene that you would like to analyze. Select tools from the right-hand toolbar, such as enhancing pixels or using spectral visualizations. Quota Charges for Hosted Data When you order hosted data, quota charges will apply. Planet will process, store and host your data for as long as your account is active. To check on your quota, go to your Planet Account page. Use your orders page to view: View and download your usage report Your Quota Used to represent your charges Your Download Area to represent what you received Orders for hosted analysis and downloads Note : If you order the same scene for hosted analysis and download, your Download Area charge will double from your Quota Used number. How to Re-Order Assets for Download Hosted Data can be used as a \"quick look\" to visualize imagery and is available to download the data after the initial assessment in Explorer. Place an existing Hosted Data order from the My Orders tab. Locate your order, and click Order Again . If you clipped your Hosted Data order, the area of interest is saved and can be used again to select which assets you want to order for download. For more information about imagery orders, see the Planet Explorer FAQ","tags":"apps-explorer","url":"https://developers.planet.com/docs/apps/explorer/how-to-order-hosted-data/","loc":"https://developers.planet.com/docs/apps/explorer/how-to-order-hosted-data/"},{"title":"Ordering Basemaps","text":"You can order Basemaps—analysis-ready mosaics—through the Orders API. To read about the different kinds of Basemaps and their specifications, see the Planet Basemaps Product Specification . To discover individual Basemaps, use the Basemaps API , select them in Planet Explorer , or view your Basemaps in the Basemap Viewer . Note NICFI Basemaps can only be ordered from the Orders API by those with Level 2 NICFI access. For information on accessing NICFI Basemaps for Level 0 and 1 access, please see the NICFI DATA Program User Guide . Use the power of the Orders API to download and stream Basemaps in cases where you want to: order mosaic quads in bulk get metadata for quad and scene identification download data for analysis based on an area of interest (AoI) reproject, resample, and rescale imagery to a projected coordinate system and resolution merge quads and associated metadata to produce a single GeoTIFF file deliver data to object stores in the cloud and download cloud-optimized GeoTIFFs The following sections introduce the basics of ordering Basemaps through the Orders API: Order Basemaps by area of interest (AoI) Order Basemaps by quad IDs and deliver to cloud Customize your Basemaps with Order tools Order Type: Full or Partial Quad limit on Basemap orders If no merge tool is specified, Basemap orders may contain up to 500 quads (defined either by area or quad ID). When the merge tool is used, the merged output must be less than 425 megapixels (approximately equal to the area of 25 quads with pixel dimensions 4096x4096). Order Basemaps by area of interest (AoI) To order Basemaps based on an area of interest, you need: Your area of interest (AoI) Your Basemap name Your API Key (you can retrieve this from your account settings) Get your Basemap name Before you begin to make calls with the Orders API, you need the Basemap mosaic name for the Basemap you want to order. This ID is the value for the mosaic_name field in an order object. You can get the ID of the Basemap you want to order through several Planet interfaces. The following section describes how to get your Basemap mosaic name in Planet Explorer, a web app, or alternatively through the Basemap API call. Method 1: Get your Basemap name through Planet Explorer To pick a Basemap using Planet Explorer, select a Basemap from the dropdown menu in the lower left corner. Note If you don't have access to basemaps, you see a message confirming that in the lower right corner. Select \"Get Access\" to sign up for basemaps or speak with your customer service manager. Once you've selected a Basemap, the Explorer updates to include that Basemap in the view. Select the search icon and time cadence, for example monthly or quarterly. Then select one of the resulting Basemap mosaic names, such as \"global_monthly_2022_05_mosaic\". When you do select it, that ID is automatically copied to your clipboard. That's the value you will be passing into the Orders API. Method 2: Get your Basemap name through the Basemap API Another way to get your Basemap mosaic name is to use the Basemap APIs to retrieve the Basemap you want and the quad IDs. Get the Basemaps API URL Get the base URL you'll need to communicate with the Basemap API service: Go to the Basemap API reference. Under List Mosaics, select GET /mosaics. A dropdown UI element appears with the URL for retrieving Basemap mosaics: https://api.planet.com/basemaps/v1/mosaics This is the base URL to send a request and get a list of mosaics. Search for the mosaic name Set the Basemap API URL and your Planet API key. BASEMAP_API_URL = 'https://api.planet.com/basemaps/v1/mosaics' auth = HTTPBasicAuth(PLANET_API_KEY, '') basemapServiceResponse = requests.get(url=BASEMAP_API_URL, auth=auth) Print out the resulting Basemaps. basemaps = basemapServiceResponse.raise_for_status() if basemapServiceResponse.status_code != 204: basemaps = json.loads(basemapServiceResponse.text) print(basemaps) Pick the name from the list returned of the Basemap you want to order and use it as the mosaic_name value when ordering your Basemap, below. Creating a Basemaps order To order Basemaps through the Orders API: Create an order object that describes the Basemap you want and the area of interest (AoI) to cover. POST the Orders request. Poll for success and then download the Basemap. Example order query JSON block Create a JSON object with a name for your order and a source_type of basemaps . Include in the product field the mosaic_name of the Basemap you want to order. Provide the geometry for your Area of Interest (AoI). order_params = { \"name\": \"Basemap order with geometry\", \"source_type\": \"basemaps\", \"products\": [ { \"mosaic_name\": \"global_monthly_2022_01_mosaic\", \"geometry\":{ \"type\": \"Polygon\", \"coordinates\":[ [ [4.607406, 52.353994], [4.680005, 52.353994], [4.680005, 52.395523], [4.607406, 52.395523], [4.607406, 52.353994] ] ] } } ] } Example POST request Your REST API request must include the following values: Your Planet API key The Orders API REST URL: https://api.planet.com/compute/ops/orders/v2 A content-type header for your JSON object The order query JSON block like the one in the example above paramRes = requests.post(ORDERS_API_URL, data=json.dumps(order_params), auth=auth, headers=headers) Example result If you print the result of the example POST request above, among other validating information, you see the state of the order and the geometry to be returned. In this example, the call to print: print(paramRes.text) displays the following JSON result: { \"_links\": { \"_self\": \"https://api.planet.com/compute/ops/orders/v2/2d56741a-8751-4cbe-a8b4-28525fc5de4d\" }, \"created_on\": \"2022-07-07T22:19:22.414Z\", \"error_hints\": [], \"id\": \"2d56741a-8751-4cbe-a8b4-28525fc5de4d\", \"last_message\": \"Preparing order\", \"last_modified\": \"2022-07-07T22:19:22.414Z\", \"name\": \"basemap order with geometry\", \"products\": [ { \"geometry\": { \"coordinates\": [ [ [ 4.607406, 52.353994 ], [ 4.680005, 52.353994 ], [ 4.680005, 52.395523 ], [ 4.607406, 52.395523 ], [ 4.607406, 52.353994 ] ] ], \"type\": \"Polygon\" }, \"mosaic_name\": \"global_monthly_2022_01_mosaic\" } ], \"source_type\": \"basemaps\", \"state\": \"queued\" } Poll for success, then download When your customized Basemap is ready to download the state changes to success . You can apply a typical poll for success, such as the one described in the Orders API Notebooks on Planet Labs Github. When the success state is returned, download individual files or deliver them to an object store on the cloud. Example returned files For each quad, the files delivered include the raster imagery, metadata files, and a zip of vector files. Here is a list of files typically returned for an example such as this: File Name Bytes 1050-1374_metadata.json 906 1050-1374_ortho_udm.tif 129390 1050-1374_provenance_raster.tif 236725 1050-1374_quad.tif 36826371 1050-1374_provenance_vector.zip 22698 1050-1374_provenance_vector Files Zipped Bytes L15-1050E-1374N.dbf 590 L15-1050E-1374N.prj 425 L15-1050E-1374N.shp 63604 L15-1050E-1374N.shx 116 Example metadata The metadata file provides, among other things, details on the Basemap, the quad, the bounding box, and the link back to the individual composite scenes. { \"_links\": { \"_self\": \"https://api.planet.com/basemaps/v1/mosaics?api_key=af7c60b57fe74e3fab6997c0bd20dd8b\" }, \"mosaics\": [ { \"_links\": { \"_self\": \"https://api.planet.com/basemaps/v1/mosaics/8e14ee92-d07c-48eb-b490-8f95d275ef0e?api_key=af7c60b57fe74e3fab6997c0bd20dd8b\", \"quads\": \"https://api.planet.com/basemaps/v1/mosaics/8e14ee92-d07c-48eb-b490-8f95d275ef0e/quads?api_key=af7c60b57fe74e3fab6997c0bd20dd8b&bbox={lx},{ly},{ux},{uy}\", \"tiles\": \"https://tiles.planet.com/basemaps/v1/planet-tiles/queensland_visual_2022q2_mosaic/gmap/{z}/{x}/{y}.png?api_key=af7c60b57fe74e3fab6997c0bd20dd8b\" }, \"bbox\": [ 137.812499980916, -29.228890026438, 153.808593728694, -8.92848706138 ], \"coordinate_system\": \"EPSG:3857\", \"datatype\": \"byte\", \"first_acquired\": \"2022-04-01T00:00:00.000Z\", \"grid\": { \"quad_size\": 4096, \"resolution\": 4.777314267823516 }, \"id\": \"8e14ee92-d07c-48eb-b490-8f95d275ef0e\", \"interval\": \"3 mons\", \"item_types\": [ \"PSScene\" ], \"last_acquired\": \"2022-07-01T00:00:00.000Z\", \"level\": 15, \"name\": \"queensland_visual_2022q2_mosaic\", \"product_type\": \"timelapse\", \"quad_download\": true } ] } Order Basemaps by quad IDs and deliver to cloud A Basemap is made of a grid of GeoTIFF files called quads. You can order individual quads through the Orders API using the following steps: From the Basemaps API, get the Basemap mosaic_id and quad_ids that you want to deliver to the cloud. Create an order query JSON block that includes those IDs. POST the Orders request. Poll for success and then download the Basemap . Get your Basemaps quad IDs using the Basemap API To retrieve Basemap quads, you need the mosaic name of the Basemap (see Get your Basemap name, above). Example Basemap packet Create a JSON object that declares the Basemap you want the quad IDs for. basemap_params = { 'name__is': 'point_reyes_rolling_normalized_2020-04-30_mosaic' } Example GET request Your REST API request must include the following values: Your Planet API key The Basemap API REST URL: https://api.planet.com/basemaps/v1/mosaics A content-type header for your JSON object The order query JSON block like the one in the example above auth = HTTPBasicAuth(PLANET_API_KEY, '') BASEMAP_API_URL = 'https://api.planet.com/basemaps/v1/mosaics' headers = {'content-type': 'application/json'} basemap_params = { 'name__is': 'point_reyes_rolling_normalized_2020-04-30_mosaic' } basemapServiceResponse = requests.get(url=BASEMAP_API_URL, params=basemap_params, auth=auth, headers=headers) basemaps = basemapServiceResponse.raise_for_status() if basemapServiceResponse.status_code != 204: basemaps = json.loads(basemapServiceResponse.text) print(basemaps) Example of getting quad IDs Now that you have the Basemap, make a call to list the mosaic quads. In the reference for this call to list mosaic quads, notice the required fields are the mosaic ID and the bounding box. mosaicID = basemaps['mosaics'][0]['id'] mosaicBbox = basemaps['mosaics'][0]['bbox'] mosaicBboxStr = ','.join(map(str, mosaicBbox)) quad_params = { 'mosaic_id': mosaicID, 'bbox': mosaicBboxStr, } Build the quads URL based on the base URL. quads_url = \"{}/{}/quads\".format(BASEMAP_API_URL, mosaicID) quadServiceResponse = requests.get(url=quads_url, params=quad_params, auth=auth, headers=headers) quads = quadServiceResponse.json() items = quads['items'] Iterate over quad to get the quad IDs. quadIds = [] for i in items: quadId = i['id'] quadIds.append(quadId) Use the quadIds you just gathered to make the Orders API request to send the quads to the cloud, in the next section. Deliver Basemaps quad to the cloud In the reference, notice the required product fields are mosaic_name and quad_ids . These are the values you retrieved in the sections above. The order query JSON block should include that required information. Because this example sends the ordered quads to cloud storage, the order query JSON block should also include the cloud delivery field. Example order query JSON block order_params = { \"name\":\"basemap order with quad_ids\", \"source_type\":\"basemaps\", \"products\":[ { \"mosaic_name\":\"point_reyes_rolling_normalized_2020-04-30_mosaic\", \"quad_ids\": quadIds } ], \"delivery\":{ \"google_cloud_storage\":{ \"bucket\":\"[your-orders-delivery-bucket]\", \"credentials\":\"[base64-encoded-credentials-for-service-agent…]\", \"path_prefix\":\"[optionalsubfolder/]\" } } } Note For more details on how to prepare the credentials and base64-encode the value for credentials, see Delivery to Google Cloud Storage . Example POST request Your REST API request must include the following values: Your Planet API key The Orders API REST URL: https://api.planet.com/compute/ops/orders/v2 A content-type header for your JSON object The order query JSON block like the one in the example above paramRes = requests.post(ORDERS_API_URL, data=json.dumps(order_params), auth=auth, headers=headers) paramRes.raise_for_status() if paramRes.status_code != 204: print(paramRes.text) Poll for success, then review quads in the cloud. When your quads are uploaded to the cloud the GET request state changes to success. (You can apply a typical poll for success, such as described in the Orders API Notebooks on Planet Labs Github.) The quads were successfully delivered to the indicated cloud bucket. Visit that cloud interface to view your quads and associated metadata. Customize your Basemaps with Order tools Basemaps supports four Order API tools : merge — merge basemaps into a larger study area clip — for orders with a geometry block, clip a raster to an area of interest reproject — resample a Basemap to a new projection area bandmath — perform numpy-like operations on rasters Order Type: Full or Partial The Orders API supports two order types: full and partial. full By default, if unspecified, all orders have an order_type of full . A full Basemaps order type will fail an order if any single quad is unavailable. partial A partial order type delivers any available quads, excluding any items which are missing or which the requester lacks permissions to access. The Orders API will always deliver all or none of the scenes in the quad. It will never deliver partial quads. Example Request using order type, raster tools, and cloud delivery POST https://api.planet.com/compute/ops/orders/v2 { \"name\": \"basemap order with geometry\", \"source_type\": \"basemaps\", \"order_type\":\"partial\", \"products\": [ { \"mosaic_name\": \"global_monthly_2022_01_mosaic\", \"geometry\":{ \"type\": \"Polygon\", \"coordinates\":[ [ [4.607406, 52.353994], [4.680005, 52.353994], [4.680005, 52.395523], [4.607406, 52.395523], [4.607406, 52.353994] ] ] } } ], \"tools\": [ {\"merge\": {}}, {\"clip\": {}} ], \"delivery\":{ \"google_cloud_storage\":{ \"bucket\":\"[your-orders-delivery-bucket]\", \"credentials\":\"[base64-encoded-credentials-for-service-agent…]\", \"path_prefix\":\"[optionalsubfolder/]\" } } }","tags":"orders","url":"https://developers.planet.com/apis/orders/basemaps/","loc":"https://developers.planet.com/apis/orders/basemaps/"},{"title":"Delivery","text":"Order Layout and Order Manifest When using the Orders API, you first create an order query JSON block that describes the parameters of order: the kind of imagery you want, an area of interest (AoI) or asset ID, any tool operations you want to perform on that imagery, and any delivery instructions, such as requesting STAC as the file format for scenes or delivering the order to a cloud bucket. When the order is fulfilled, a JSON manifest is delivered that describes the available assets delivered, as well as the path to those deliverables. For each asset, a JSON metadata file is also delivered. It describes the asset and details about the imagery such as the date it was captured, with what sensors, and under what conditions. The following sections explain the order manifest, metadata, and delivery settings: Order Layout and Order Manifest The metadata.json file Review the logical structure of delivered assets and the manifest.json file Learn about the asset through the associated metadata.json file STAC Metadata Delivery to Cloud Storage Explore the SpatioTemporal Asset Catalog (STAC) format for scene orders Deliver orders to the S3, Azure, GCP, or Oracle Order Delivery Layout Your order is delivered following a logical structure of orders, imagery-name, and file types, as well as the order manifest.json file and a metadata.json file for each imagery. Delivery of scenes The default order delivery layout for scenes is organized as follows: {OrderID}/manifest.json {OrderID}/{ItemType}/{ItemID}_metadata.json {OrderID}/{ItemType}/{AssetFileName}.{AssetFileExtension} There are slight structural variations when an order is zipped or composited. When zipped, its layout takes the structure below. After it is unzipped, the resulting layout of the contents look like the layout above. {OrderID}/manifest.json {OrderID}/{ArchiveFilename}.zip When an order is composited, its layout will be organized as follows: {OrderID}/manifest.json {OrderID}/composite_udm.tif {OrderID}/composite.tif {OrderID}/{ItemID_1}_metadata.json {OrderID}/{ItemID_1}_{AssetName}_metadata.xml {OrderID}/{ItemID_2}_metadata.json {OrderID}/{ItemID_2}_{AssetName}_metadata.xml Delivery of Basemaps You can download Basemaps or have them delivered to supported Cloud Storage Providers . Each basemaps order contains delivery results with the image in COG format, sourcetrace, and UDM2 metadata. The default order delivery layout for Basemaps is organized as follows: <order_id>/{mosaic_name}/{quad_id}.tif <order_id>/{mosaic_name}/{quad_id}_metadata.json <order_id>/{mosaic_name}/{quad_id}_sourcetrace.shz <order_id>/{mosaic_name}/{quad_id}_sourcetrace.tif <order_id>/{mosaic_name}/{quad_id}_udm2.tif Zipped vector resources decompress with the metadata.json file for each imagery at the root, and the Shapefile dataset, as in: /{mosaic_name}/{quad_id_vector_1}/_metadata.json /{mosaic_name}/{quad_id_vector_2}/_metadata.json /{mosaic_name}/{quad_id_vector_1}L15-{quad_id_1}.dbf /{mosaic_name}/{quad_id_vector_1}/L15-{quad_id_1}.prj /{mosaic_name}/{quad_id_vector_1}/L15-{quad_id_1}.shp /{mosaic_name}/{quad_id_vector_1}/L15-{quad_id_1}.shx {mosaic_name}/{quad_id_vector_2}L15-{quad_id_}.dbf {mosaic_name}/{quad_id_vector_2}/L15-{quad_id_}.prj {mosaic_name}/{quad_id_vector_2}/L15-{quad_id_}.shp {mosaic_name}/{quad_id_vector_2}/L15-{quad_id_}.shx Delivery Manifests The contents of your order are described by a JSON manifest, which is delivered alongside your order. This manifest describes the locations of the order's delivered files with additional metadata, such as the size and a cryptographic hash of file contents. Manifests should be used to learn specifically to which paths data will be delivered. While the file paths referenced in the manifest may be subject to change over time, the order's manifest will always be found at the root directory of where the order data is being delivered. Its location is calculated by taking the provided path_prefix (if any) and appending the order_id , then \"manifest.json\". As an example, an order with ID 2284b95e-9e4a-4ab1-a88f-f49dd5f0d883 with a path prefix of \"ordered_data/\" would result in a manifest at the following key: data/2284b95e-9e4a-4ab1-a88f-f49dd5f0d883/manifest.json Sample manifest.json File { \"name\": \"\", \"files\": [ { \"path\": \"PSScene/20151119_025740_0c74_metadata.json\", \"media_type\": \"application/json\", \"size\": 747, \"digests\": { \"md5\": \"03571ab27a19569f095e467a79b2a8d4\", \"sha256\": \"bc46e2196cd8d8114e62893ffaebae5bb50651ef91140641118fc468814b329c\" }, \"annotations\": { \"planet/item_id\": \"20151119_025740_0c74\", \"planet/item_type\": \"PSScene\" } }, { \"path\": \"PSScene/20151119_025740_0c74_3B_AnalyticMS.tif\", \"media_type\": \"image/tiff\", \"size\": 94649460, \"digests\": { \"md5\": \"35d48007de9d0671452ac789fbd6b9e4\", \"sha256\": \"58a00ec153c203c48cd2bab8ff8059555482aa9c9c66cfa1c90d7637aa893cb6\" }, \"annotations\": { \"planet/asset_type\": \"ortho_analytic_4b\", \"planet/bundle_type\": \"analytic_udm2\", \"planet/item_id\": \"20151119_025740_0c74\", \"planet/item_type\": \"PSScene\" } }, { \"path\": \"PSScene/20151119_025740_0c74_3B_AnalyticMS_metadata.xml\", \"media_type\": \"text/xml\", \"size\": 10384, \"digests\": { \"md5\": \"73bf083f08aec24f80fea51dfaceaea9\", \"sha256\": \"a89787f7b70a9ec3535637bbe5b5b9e229bcda98cb80dae95c84dc54e0444a89\" }, \"annotations\": { \"planet/asset_type\": \"ortho_analytic_4b_xml\", \"planet/bundle_type\": \"analytic_udm2\", \"planet/item_id\": \"20151119_025740_0c74\", \"planet/item_type\": \"PSScene\" } }, { \"path\": \"PSScene/20151119_025740_0c74_3B_udm2.tif\", \"media_type\": \"image/tiff\", \"size\": 1652624, \"digests\": { \"md5\": \"eb4effb691c370297b748f573169fb3f\", \"sha256\": \"0b762e81dde1d5be92bf9a39decd98073f5a53c4a6b82eb85176a9bd459f51c7\" }, \"annotations\": { \"planet/asset_type\": \"ortho_udm2\", \"planet/bundle_type\": \"analytic_udm2\", \"planet/item_id\": \"20151119_025740_0c74\", \"planet/item_type\": \"PSScene\" } } ] } To find your ordered assets, you may assume all of these paths are relative to the manifest.json file. The final location of assets in this example order include: data/2284b95e-9e4a-4ab1-a88f-f49dd5f0d883/PSScene/20151119_025740_0c74_3B_AnalyticMS.tif data/2284b95e-9e4a-4ab1-a88f-f49dd5f0d883/PSScene/20151119_025740_0c74_3B_AnalyticMS_metadata.xml data/2284b95e-9e4a-4ab1-a88f-f49dd5f0d883/PSScene/20151119_025740_0c74_3B_udm2.tif data/2284b95e-9e4a-4ab1-a88f-f49dd5f0d883/PSScene/20151119_025740_0c74_metadata.json Why you should depend on the manifest file The manifest.json file is the last file delivered for an order, once the order is fully complete. Due to potential delay between the time when an order's files are delivered and when they are accessible for download, we recommend waiting for the manifest before you begin accessing files. The metadata.json file In addition to your requested assets, your order will include a metadata.json file. This is a copy of the item-level metadata associated with the asset from our catalog. The metadata.json file will appear in the manifest like other assets but will not have planet/bundle_type nor planet/asset_type annotations. Sample metadata.json File { \"id\":\"20220304_093300_37_2430\", \"type\":\"Feature\", \"geometry\":{ \"coordinates\":[ [ [ 6.167210381911106, 45.95660761074959 ], [ 6.106906222592715, 45.76425741356103 ], [ 6.565372737977715, 45.69159280834395 ], [ 6.628858947551485, 45.88187947653463 ], [ 6.167210381911106, 45.95660761074959 ] ] ], \"type\":\"Polygon\" }, \"properties\":{ \"acquired\":\"2022-03-04T09:33:00.375453Z\", \"anomalous_pixels\":0, \"clear_confidence_percent\":87, \"clear_percent\":63, \"cloud_cover\":0, \"cloud_percent\":0, \"ground_control\":true, \"gsd\":4.1, \"heavy_haze_percent\":0, \"instrument\":\"PSB.SD\", \"item_type\":\"PSScene\", \"light_haze_percent\":0, \"pixel_resolution\":3, \"provider\":\"planetscope\", \"published\":\"2022-03-04T22:56:32Z\", \"publishing_stage\":\"finalized\", \"quality_category\":\"test\", \"satellite_azimuth\":102.2, \"satellite_id\":\"2430\", \"shadow_percent\":2, \"snow_ice_percent\":34, \"strip_id\":\"5455214\", \"sun_azimuth\":141.5, \"sun_elevation\":30.3, \"updated\":\"2022-03-12T02:38:49Z\", \"view_angle\":5.1, \"visible_confidence_percent\":75, \"visible_percent\":100 } } STAC Metadata For scenes orders, you can also opt in to receiving additional metadata in the SpatioTemporal Asset Catalog (STAC) format. STAC provides a standardized format for a wide range of geospatial information, including satellite imagery and accompanying assets. Note This is a beta feature available only for source_type scenes orders at this time. STAC is not available for source_type basemaps . The precise version of STAC and STAC extensions used may change as the specifications are finalized and our implementation is further developed. STAC is only available with standard delivery layout format. It is not supported for the legacy_deprecated layout format. STAC files and structure Each order contains: A single STAC Catalog file at the root of the order that represents the entire order's contents. It contains references to each item type Collection in the order. filename: catalog.json A STAC Collection file for each item type in the order with references to each Item associated with that item type. filename: <item_type> _collection.json A STAC Item file for each Planet item in the order with an Asset link to each file associated with that Item. filename: <item_id> .json STAC files are provided as a self-contained catalog with relative links within the context of a specific order. Example Request To receive order links in the STAC format, add a metadata section with a stac field to the Create Order request. { \"name\": \"stac output\", \"products\": [ { \"item_ids\": [ \"20201127_075950_38_2262\", \"20210129_075502_95_2223\" ], \"item_type\": \"PSScene\", \"product_bundle\": \"analytic_udm2\" } ], \"metadata\": { \"stac\": { } } } Delivery to Cloud Storage You may choose to have your order delivered to either Amazon S3, Microsoft Azure Blob Storage, Google Cloud Storage, or Oracle Cloud Storage. For any cloud storage provider, you will need to create an account with both write and delete access. Cloud Credential Security When creating an order, a user must input their credentials for successful cloud delivery of Planet data. This poses a potential security risk. For secure handling of cloud service credentials in the request, please ensure that access is limited to the desired delivery path with no read/write access for any other storage locations or cloud services. Delivery to Amazon S3 For Amazon S3 delivery you will need an AWS account with GetObject , PutObject , and DeleteObject permissions. Parameters aws_access_key_id (required): AWS credentials. aws_secret_access_key (required): AWS credentials. bucket (required): The name of the bucket that will receive the order output. aws_region (required): The region where the bucket lives in AWS. path_prefix (optional): An optional string that will be prepended to the files delivered to the bucket. A slash ( / ) character will be treated as a \"folder\". Any other characters will be added as a prefix to the files. Example Request { \"name\": \"amazon_s3_delivery_order\", \"products\": [ { \"item_ids\": [ \"20151119_025740_0c74\", \"20151119_025741_0c74\" ], \"item_type\":\"PSScene\", \"product_bundle\":\"analytic_udm2\" } ], \"delivery\": { \"amazon_s3\": { \"bucket\": \"foo-bucket\", \"aws_region\": \"us-east-2\", \"aws_access_key_id\": \"\", \"aws_secret_access_key\": \"\", \"path_prefix\": \"folder1/prefix/\" } } The path_prefix specified above will produce a result in S3 which looks like the following: /folder1/prefix/{order_id}}/320170716_144316_1041_3B_AnalyticMS.tif Delivery to Google Cloud Storage For Google Cloud Storage delivery, you need an account with write and delete permissions. For instance, you may have set up a service account to handle calls to Planet APIs. When you did so, you would have also generated and downloaded a JSON file with that service agent's credentials. Also, you would have assigned a role to the service account —or you would have created a custom role—that gives the service agent permissions to write to your Google Cloud Storage bucket, for example storage.objects.create , storage.objects.get , and storage.objects.delete permissions. If you have such an account set up and assigned a role with the right permissions, you can then use that service agent JSON credentials file, base64-encode it, and include that output as the credentials, below. As noted above , access should be limited to the desired delivery path with no read/write access for any other storage locations or cloud services. Preparing Your Google Cloud Storage Credentials The Google Cloud Storage delivery option requires a single-line base64 version of your service account credentials for use by the credentials parameter. Download your service account credentials in JSON format (not P12) and encode them as a base64 string with a command line operation such as: cat api_service_agent_creds.json | base64 | tr -d '\\n' Parameters credentials (required): GCS credentials. bucket (required): The name of the GCS bucket which will receive the order output. path_prefix (optional): String that will be prepended to the files delivered to the bucket. A slash ( / ) character will be treated as a \"folder\"; other characters will be a prefix to the files. Example Request { \"name\":\"gcs_delivery_order\", \"products\": [ { \"item_ids\": [ \"20151119_025740_0c74\", \"20151119_025741_0c74\" ], \"item_type\":\"PSScene\", \"product_bundle\":\"analytic_udm2\" } ], \"delivery\": { \"google_cloud_storage\": { \"bucket\":\"[your-orders-delivery-bucket]\", \"credentials\":\"[base64-encoded-credentials]\", \"path_prefix\":\"[optionalsubfolder/]\" } } } Delivery to Google Earth Engine For Google Earth Engine (GEE) delivery, follow the steps found on our GEE Setup Guide . Planet's GEE Delivery Integration simplifies the process of incorporating Planet data into GEE projects by creating a direct connection between Planet's Orders API and GEE. To use the integration, users must sign up for an Earth Engine account, create a Cloud Project, enable the Earth Engine API, and grant a Google service account access to deliver data to their GEE project. Delivery to Microsoft Azure For Microsoft Azure delivery you will need an Azure account with read , write , delete , and list permissions. Parameters account (required): Azure account name. container (required): The name of the container which will receive the order output. sas_token (required): Azure Shared Access Signature token . Token should be specified with a leading '?' (i.e. \"?sv=2017-04-17u0026si=writersr=cu0026sig=LGqc\"). storage_endpoint_suffix (optional): To deliver your order to a sovereign cloud a storage_endpoint_suffix should be set appropriately for your cloud. The default is \"core.windows.net\". path_prefix (optional): String that will be prepended to the files delivered to the bucket. A slash ( / ) character will be treated as a \"folder\"; other characters will be a prefix to the files. Example Request { \"name\": \"azure_delivery_order\", \"products\":[ { \"item_ids\": [ \"20151119_025740_0c74\", \"20151119_025741_0c74\" ], \"item_type\":\"PSScene\", \"product_bundle\":\"analytic_udm2\" } ], \"delivery\":{ \"azure_blob_storage\":{ \"account\": \"accountname\", \"container\": \"containername\", \"sas_token\": \"?sv=2017-04-17u0026si=writersr=cu0026sig=LGqc\", \"storage_endpoint_suffix\": \"core.windows.net\", \"path_prefix\": \"myprefix/\" } } } Delivery to Oracle Cloud Storage For Oracle Cloud Storage delivery you need an Oracle account with read , write , and delete permissions. For authentication you need a Customer Secret Key which consists of an Access Key/Secret Key pair. Parameters customer_access_key_id (required): Customer Secret Key credentials. customer_secret_key (required): Customer Secret Key credentials. bucket (required): The name of the bucket that will receive the order output. region (required): The region where the bucket lives in Oracle. namespace (required): Object Storage namespace name. path_prefix (optional): An optional string that will be prepended to the files delivered to the bucket. A slash ( / ) character is treated as a \"folder\". A slash will be added to the end of the path_prefix if not already provided. Example Request { \"name\": \"oracle_delivery_order\", \"products\": [ { \"item_ids\": [ \"20151119_025740_0c74\", \"20151119_025740_0c74\" ], \"item_type\":\"PSScene\", \"product_bundle\":\"analytic_udm2\" } ], \"delivery\": { \"oracle_cloud_storage\": { \"bucket\": \"foo-bucket\", \"namespace\": \"ORACLE_NAMESPACE\", \"region\": \"us-sanjose-1\", \"customer_access_key_id\": \"YOUR_ACCESS_ID\", \"customer_secret_key\": \"YOUR_SECRET_KEY\", \"path_prefix\": \"folder1/prefix/\" } } } Zipping results With the zip delivery option, you can receive the output of your order as a \"per order\" or \"per bundle\" zip archive. Parameters archive_type (optional): Only zip format is supported. archive_filename (optional): The name of the archive file you will receive. You can use template variables {{name}} and {{order_id}} and in the string, which vary based on whether the order is per-bundle or per-order (i.e. single_archive ) and are described in more detail below. single_archive (optional): When true , this option will archive all bundles together in a single file. Per-Bundle Zipping For per-bundle zipping (i.e. when single_archive is null or false ), the archive filename variable {{name}} will return { item_type item_id product_bundle } and {{order_id}} will return the order_id . Example Request { \"name\": \"per-bundle-zipped-order\", \"products\": [ { \"item_ids\": [ \"20151119_025740_0c74\", \"20151119_025741_0c74\" ], \"item_type\":\"PSScene\", \"product_bundle\":\"analytic_udm2\" } ], \"delivery\": { \"archive_type\": \"zip\", \"archive_filename\": \"{{name}}_{{order_id}}.zip\" } } Output files ( order_id = 68b2e5c0-aaf0-49cb-b5a8-13a96083dd41 ): 68b2e5c0-aaf0-49cb-b5a8-13a96083dd41/PSScene_20151119_025741_0c74_analytic_68b2e5c0-aaf0-49cb-b5a8-13a96083dd41.zip 68b2e5c0-aaf0-49cb-b5a8-13a96083dd41/PSScene_20151119_025740_0c74_analytic_68b2e5c0-aaf0-49cb-b5a8-13a96083dd41.zip 68b2e5c0-aaf0-49cb-b5a8-13a96083dd41/manifest.json Whole-Order Zipping For per-order zipping (i.e. when single_archive is true ), the archive filename variable {{name}} will list the order name and {{order_id}} will list the order_id . Example Request { \"name\": \"per-order-zipped-order\", \"products\": [ { \"item_ids\": [ \"20151119_025740_0c74\", \"20151119_025741_0c74\" ], \"item_type\":\"PSScene\", \"product_bundle\":\"analytic_udm2\" } ], \"delivery\":{ \"archive_type\": \"zip\", \"single_archive\": true, \"archive_filename\": \"{{name}}_{{order_id}}.zip\" } } Output files ( order_id = 1b36c36c-8965-4e6f-9eef-ee9694f3d69c ): 1b36c36c-8965-4e6f-9eef-ee9694f3d69c/per-order-zipped-order_1b36c36c-8965-4e6f-9eef-ee9694f3d69c.zip 1b36c36c-8965-4e6f-9eef-ee9694f3d69c/manifest.json","tags":"orders","url":"https://developers.planet.com/apis/orders/delivery/","loc":"https://developers.planet.com/apis/orders/delivery/"},{"title":"Notifications","text":"While you can poll the Orders API for an order periodically to determine its state and whether it is ready for download, the Orders API also supports email and webhook notification options, making it easier for you to follow order progress. Email Notifications To enable email notifications for an order, you can specify \"email\": true as a notification option in your order request. By default, this value will be set to false . When enabled, an email will be delivered to the email address of the user who created the order when the order reaches a success , partial , or failed state. Example Request POST https://api.planet.com/compute/ops/orders/v2 { \"name\":\"simple order\", \"source_type\": \"scenes\", \"products\":[ { \"item_ids\":[ \"20220304_093300_37_2430\", \"20220304_093257_90_2430\", \"20220304_103324_1105\", \"20220304_103325_1105\" ], \"item_type\":\"PSScene\", \"product_bundle\":\"analytic_udm2\" } ], \"notifications\":{ \"email\": true } } Webhook Notifications To enable webhook notifications for an order, you can specify webhook URL for notification when your order is ready. If a cloud storage delivery option is not specified in the order, the webhook will contain the URLs to the downloadable files. By default, the provided webhook will be called for each delivered item. You can request a single webhook call per order by including the \"per_order\": true parameter. Example Request POST https://api.planet.com/compute/ops/orders/v2 { \"name\":\"simple order\", \"source_type\": \"scenes\", \"products\":[ { \"item_ids\":[ \"20220304_093300_37_2430\", \"20220304_093257_90_2430\", \"20220304_103324_1105\", \"20220304_103325_1105\" ], \"item_type\":\"PSScene\", \"product_bundle\":\"analytic_udm2\" } ], \"notifications\":{ \"webhook\":{ \"per_order\": true, \"url\":\"{URL}\" } } } Example Webhook Body { \"_links\": { \"_self\": \"https://api.planet.com/compute/ops/orders/v2/02fb0492-006f-44ad-8370-7b59a935f076\" }, \"created_on\": \"2022-11-16T03:46:59.559Z\", \"error_hints\": [], \"id\": \"02fb0492-006f-44ad-8370-7b59a935f076\", \"last_message\": \"Preparing order\", \"last_modified\": \"2022-11-16T03:46:59.559Z\", \"name\": \"simple order\", \"notifications\": { \"webhook\": { \"per_order\": true, \"url\": \"<REDACTED>\" } }, \"products\": [ { \"item_ids\": [ \"20220304_093300_37_2430\", \"20220304_093257_90_2430\", \"20220304_103324_1105\", \"20220304_103325_1105\" ], \"item_type\": \"PSScene\", \"product_bundle\": \"analytic_udm2\" } ], \"source_type\": \"scenes\", \"state\": \"queued\" }","tags":"orders","url":"https://developers.planet.com/apis/orders/notifications/","loc":"https://developers.planet.com/apis/orders/notifications/"},{"title":"Orders Overview","text":"The Planet Orders API enables ordering, customization, and delivery of imagery and Basemaps. While Data and Basemap APIs are useful for discovering imagery, Orders is the core API for ordering scenes and Basemaps in bulk, customizing with a suite of raster tools, and delivering as downloadable items for working in a local environment or to the cloud as optimized GeoTIFFs. Scenes Basemaps Activate, customize, and deliver bulk PlanetScope, SkySat, and archival imagery such as Rapid Eye, Sentinel 2, and LandSat Order Global Basemaps for mapping and visualizations or Select Basemaps for your area of interest Tools Delivery Generate Planet-hosted raster operations to prepare data for your area of study Download imagery and Basemaps or deliver to the cloud Notifications States Set email and webhook notifications to follow order progress Get explanations of the different order states Learning Resources For information on working with Planet APIs, see Getting Started with Planet APIs . Find a collection of guides and tutorials on Planet School . Also checkout Planet notebooks on GitHub, such as the Python tutorial: Tools and Toolchains .","tags":"orders","url":"https://developers.planet.com/apis/orders/","loc":"https://developers.planet.com/apis/orders/"},{"title":"Ordering Scenes","text":"Basic Ordering A scene is a single logical observation captured by a satellite. A scenes order in the Orders API includes a source type, a set of item ids, an item type, and a product bundle–a predefined set of imagery and metadata assets. source_type : is the product you are choosing to order. The choices are scenes or basemap . All orders, except for basemaps , are scenes source types. item_ids : represent the catalog items of the scenes you wish to download. You can find the item_ids of the items you wish to download by creating a search in the Data API or Planet Explorer. Note: item_ids ending in the following characters are items from test satellites and may not have the full range of associated assets: (0f02, 0f06, 0f4c, 1055). item_type : represents the sensors and processing characteristics of a catalog item. Example item types include PSScene and SkySatCollect . You can read more about item types on our Imagery Reference page . product_bundles : are scenes-specific concept which group sets of asset_types together for more streamlined ordering. A valid product bundle for a set of items depends on their item type. An item is only delivered for an order if all assets in its specified product bundle are available. You can read more about scene assets on our Imagery Reference page and more about product bundles on our Product Bundle Reference page . Example Request POST https://api.planet.com/compute/ops/orders/v2 { \"name\":\"simple order\", \"source_type\": \"scenes\", \"products\":[ { \"item_ids\":[ \"20220304_093300_37_2430\", \"20220304_093257_90_2430\", \"20220304_103324_1105\", \"20220304_103325_1105\" ], \"item_type\":\"PSScene\", \"product_bundle\":\"analytic_udm2\" } ] } Example Response { \"_links\": { \"_self\": \"https://api.planet.com/compute/ops/orders/v2/98d124c3-0857-49f5-aa1b-2250c6f907ed\" }, \"created_on\": \"2022-11-16T02:54:43.824Z\", \"error_hints\": [], \"id\": \"98d124c3-0857-49f5-aa1b-2250c6f907ed\", \"last_message\": \"Preparing order\", \"last_modified\": \"2022-11-16T02:54:43.824Z\", \"name\": \"simple order\", \"products\": [ { \"item_ids\": [ \"20220304_093300_37_2430\", \"20220304_093257_90_2430\", \"20220304_103324_1105\", \"20220304_103325_1105\" ], \"item_type\": \"PSScene\", \"product_bundle\": \"analytic_udm2\" } ], \"source_type\": \"scenes\", \"state\": \"queued\" } Order Type and Fallback Bundles The Orders API supports two order types: full and partial . full Order Type By default, if unspecified, all orders have an order_type of full . A full order type will fail an order if any single bundle fails to deliver, or if complete product bundles (with all required asset_types ) are not available for all items included in the order. This is not uncommon for analytic_sr bundles, due to the publishing delay for analytic_sr assets, as well as for *_udm2 bundles, due to intermittent availability of udm2 assets before July 2018. To avoid this issue (especially for analytic_sr product bundles), we recommend using the AssetFilter search feature in the Data API to ensure that all items supplied to the Orders API have all the required assets in the specified product bundle. A full order type will also fail if: The requester lacks permissions to access any of the required asset_types in the product_bundle The requester lacks permissions to access any of the order's specified item_types The requester lacks permissions to access any of the specified item_ids due to geometry or time of interest policy restrictions partial Order Type A partial order type will deliver product bundles for all items included in the order which have all the complete product bundles (all required asset_types ). In the analytic_udm2 product bundle example provided above, a partial order would deliver all the items in the order which have all analytic_udm2 assets, and omit delivery of items which are missing any of the required assets. A partial order type will also omit delivery of items which the requester lacks permissions to access and provide error hints for items which failed to deliver, as long as at least one item bundle is deliverable. An important note here is that the Orders API will always deliver all or none of the assets in the product bundle for an item. It will never deliver partial product bundles – only partial orders , with complete product bundles for the items which were delivered. Example Request POST https://api.planet.com/compute/ops/orders/v2 { \"name\": \"partial simple order\", \"source_type\": \"scenes\", \"order_type\": \"partial\", \"products\":[ { \"item_ids\":[ \"20220304_093300_37_2430\", \"20220304_093257_90_2430\", \"20220304_103324_1105\", \"20220304_103325_1105\" ], \"item_type\": \"PSScene\", \"product_bundle\": \"analytic_udm2\" } ] } Fallback Bundles A \"fallback\" bundle is a product bundle that the Orders API will deliver if the first choice product bundle fails for any reason (asset availability, permissions, etc.). As an example, a fallback bundle could be used to deliver an analytic_udm2 bundle for an item, if all the assets in the analytic_8b_udm2 bundle are not available. To specify a fallback bundle simply add the alternate bundle(s) to the product_bundle field separated by commas. Example Request POST https://api.planet.com/compute/ops/orders/v2 { \"name\":\"fallback order\", \"source_type\": \"scenes\", \"products\":[ { \"item_ids\":[ \"20220304_093300_37_2430\", \"20220304_093257_90_2430\", \"20220304_103324_1105\", \"20220304_103325_1105\" ], \"item_type\":\"PSScene\", \"product_bundle\":\"analytic_8b_udm2,analytic_udm2\" } ] } Ordering Multiple Item Types To order items of multiple item_types , you can add another products set within the array of the products block. Note Different item types (such as PlanetScope or SkySat) can be included in the same order. Item types can be ordered as long as there is a plan that enables access to all of those item types. Example Request POST https://api.planet.com/compute/ops/orders/v2 { \"name\":\"multiple_item_type_order\", \"source_type\": \"scenes\", \"products\":[ { \"item_ids\":[ \"20220306_094818_22_2276\",\"20220306_094815_93_2276\" ], \"item_type\":\"PSScene\", \"product_bundle\":\"analytic_udm2\" }, { \"item_ids\": [ \"20171226_222055_6021709_RapidEye-3\" ], \"item_type\": \"REOrthoTile\", \"product_bundle\": \"analytic\" } ] } Please submit a request with any questions about your quota or Admin Subscriptions. Get an Order You can get the status and results of your order, with the following request: GET https://api.planet.com/compute/ops/orders/v2/{order_id} The response schema will include the original order request and timestamp, order state, error hints, last message, last update timestamp, and an array of results. error_hints : lists human readable details which may provide insights to why an order failed. These descriptions may change; do not build on these values. last_message : lists human readable details on sub-state processing. These descriptions may change; do not build on these values. last_modified : lists a timestamp on the order's last sub-state processing step. Modification sequencing may change; do not build on these values. results : lists the outputs of the order; results may look different depending raster and zip tools applied delivery : \"success\" or \"failed\" name : file path of the output; see our Delivery page for more details on delivery layouts expires_at : timestamp after which the order's download URL must be refreshed for a successful download. To refresh a download link send another GET Order request. location : a link to download the output if a cloud delivery is not used Example Request GET https://api.planet.com/compute/ops/orders/v2/d4c52078-0935-4255-aafd-c889726b5a9c Example Response { \"_links\": { \"_self\": \"https://api.planet.com/compute/ops/orders/v2/d4c52078-0935-4255-aafd-c889726b5a9c\", \"results\": [ { \"delivery\": \"success\", \"expires_at\": \"2022-11-17T03:27:11.487Z\", \"location\": \"[DOWNLOAD_URL]\", \"name\": \"d4c52078-0935-4255-aafd-c889726b5a9c/PSScene/20220304_103325_1105_3B_udm2.tif\" }, { \"delivery\": \"success\", \"expires_at\": \"2022-11-17T03:27:11.496Z\", \"location\": \"[DOWNLOAD_URL]\", \"name\": \"d4c52078-0935-4255-aafd-c889726b5a9c/PSScene/20220304_103325_1105_metadata.json\" }, { \"delivery\": \"success\", \"expires_at\": \"2022-11-17T03:27:11.499Z\", \"location\": \"[DOWNLOAD_URL]\", \"name\": \"d4c52078-0935-4255-aafd-c889726b5a9c/PSScene/20220304_093257_90_2430_3B_udm2.tif\" }, { \"delivery\": \"success\", \"expires_at\": \"2022-11-17T03:27:11.508Z\", \"location\": \"[DOWNLOAD_URL]\", \"name\": \"d4c52078-0935-4255-aafd-c889726b5a9c/PSScene/20220304_093257_90_2430_metadata.json\" }, . . . { \"delivery\": \"success\", \"expires_at\": \"2022-11-17T03:27:11.507Z\", \"location\": \"[DOWNLOAD_URL]\", \"name\": \"d4c52078-0935-4255-aafd-c889726b5a9c/manifest.json\" } ] }, \"created_on\": \"2022-11-16T03:19:45.458Z\", \"error_hints\": [], \"id\": \"d4c52078-0935-4255-aafd-c889726b5a9c\", \"last_message\": \"Manifest delivery completed\", \"last_modified\": \"2022-11-16T03:21:57.218Z\", \"name\": \"fallback order\", \"order_type\": \"partial\", \"products\": [ { \"item_ids\": [ \"20220304_093300_37_2430\", \"20220304_093257_90_2430\" ], \"item_type\": \"PSScene\", \"product_bundle\": \"analytic_8b_udm2\" }, { \"item_ids\": [ \"20220304_103324_1105\", \"20220304_103325_1105\" ], \"item_type\": \"PSScene\", \"product_bundle\": \"analytic_udm2\" } ], \"source_type\": \"scenes\", \"state\": \"success\" } Download an Order You can download the output of an order simply by following the location URL in the order's results. Example Request GET https://api.planet.com/compute/ops/download/?token=... List Orders You can get a list of all orders created within the last three months with the following request: GET https://api.planet.com/compute/ops/orders/v2/ Query Parameters The List Orders endpoint supports filtering on state with the following query parameters appended to the request: ?state=<queued|running|success|partial|failed|cancelled> Orders created more than three months ago will not be available through the Orders API. You can submit a request for inquiries about orders placed more than three months ago. Example Request GET https://api.planet.com/compute/ops/orders/v2/?state=queued Example Response The List Orders response will return a paged list of all your queued orders placed in the last three months with an order schema that is consistent with the Get Order response. Cancel an Order Orders may be cancelled while they are in a queued state. After an order moves into a running state, it may no longer be cancelled. You can cancel a single order with the following request: PUT https://api.planet.com/compute/ops/orders/v2/{order_id} Example Request * PUT https://api.planet.com/compute/ops/orders/v2/adfaaa2b-947b-4ca8-9faf-44340db6dcfa Bulk Cancel Orders The Orders API supports two bulk order cancel methods: Bulk cancel all queued orders Bulk cancel a specified list of order_ids Bulk Cancel queued Orders You can cancel all of your \"queued\" orders by POST-ing an empty JSON object ({}) to https://api.planet.com/compute/ops/bulk/orders/v2/cancel Example Request * POST https://api.planet.com/compute/ops/bulk/orders/v2/cancel {} Example Response * The response will include a count of orders which were successfully concelled, or which failed to cancel. { \"result\": { \"failed\": { \"count\": 0, \"failures\": [] }, \"succeeded\": { \"count\": 6 } } } Note Because of the asynchronous nature of the Planet's ordering system, some of the orders in a \"queued\" state at the time of the request may transition to a \"running\" state as we service the request and may no longer be cancellable. As such, we cannot guarantee that all 100% of orders \"queued\" at the time of the request will be successfully cancelled. Bulk Cancel Specified Orders You can cancel a set of orders orders by POST-ing an array of order_ids to https://api.planet.com/compute/ops/bulk/orders/v2/cancel Example Request POST https://api.planet.com/compute/ops/bulk/orders/v2/cancel { \"order_ids\": [ \"6031093e-90b7-4a94-9eb6-f3e5ca976a78\", \"dd2e95fa-a4bb-447f-93a1-44fe0ba80d3d\", \"04cf3dff-1774-4b2b-888d-a090de15023e\", \"08989bf2-8d9c-44d7-8b7d-f23d89ae2be9\", \"afe85e41-170f-40eb-8c98-c511e0814604\", \"34de3a40-ae7a-4904-abea-3aaf64f79e99\" ] } Example Response { \"result\": { \"failed\": { \"count\": 2, \"failures\": [ { \"message\": \"Order not in a cancellable state\", \"order_id\": \"afe85e41-170f-40eb-8c98-c511e0814604\" }, { \"message\": \"Order not in a cancellable state\", \"order_id\": \"34de3a40-ae7a-4904-abea-3aaf64f79e99\" } ] }, \"succeeded\": { \"count\": 4 } } } In the response above, two of the six orders failed to successfully cancel. Aggregate Orders Stats You can view the status of your organization's running and queued orders with the following request: GET https://api.planet.com/compute/ops/stats/orders/v2 The response schema will include counts of orders in running and queued states for the requester and the requester's organization to give context on queue depth and throughput. Example Request GET https://api.planet.com/compute/ops/stats/orders/v2 Example Response { \"organization\": { \"queued_orders\": 5, \"running_orders\": 352 }, \"user\": { \"queued_orders\": 0, \"running_orders\": 1 } }","tags":"orders","url":"https://developers.planet.com/apis/orders/scenes/","loc":"https://developers.planet.com/apis/orders/scenes/"},{"title":"Order States","text":"Order States Order state represents the state of the order in its lifecycle. Queued The order is accepted and in the queue to run. Orders start in a \"queued\" state before they move to a \"running\" state. Within an organization, orders in the \"queued\" state are moved into \"running\" in round-robin order by API key, across all of the organization's active orders. This ensures no single organizational user can impact order delivery times for other users in their organization. Each organization can keep up to 10,000 orders total in the queue. The time an order stays in \"running\" depends on: The size of the order (assets per order). While orders with more assets take longer to run, the Orders API is designed to service a bulk ordering use case. As such, orders with more assets have a shorter per-asset running time. Wherever possible, Planet recommends ordering fewer orders with more assets per order, to keep per-item running times low. The raster processing tools included in the order. Read more about tools in the Tools & Toolchains page . Some asset types coincide with longer running times. For example, scenes orders item_types that may take longer running times include REOrthoTile and SkySatCollect. Success The order is complete and was successful. All requested data were delivered. Partial The order is complete and was partially successful. This state is valid for order_type partial orders. Generally, orders with a state of partial indicate that some requested items were not delivered because assets were not available, the requester lacked permission to download those assets, or for an indeterminant reason. Failed The order failed. Orders may fail due to permission issues, lack of availability of certain asset types (especially if the order_type is full ), or other validation issues or internal errors. Any available details on order failure are supplied in the error_hints field. Cancelled The order was cancelled and will not be completed.","tags":"orders","url":"https://developers.planet.com/apis/orders/states/","loc":"https://developers.planet.com/apis/orders/states/"},{"title":"Orders API Tools","text":"The Orders API exposes a suite of raster customization tools. You can preprocess data at Planet before downloading it or delivering it to a cloud data source. Tools have their own settings and may work on scenes and Basemaps differently depending on the nature of those files. You can request an individual tool or use a chain of tools in the same call. When chaining tools, the sequence matters. After reviewing Using tools and the Creating toolchains sections, use this reference for all available tools. Using tools Creating toolchains Add a tools block to your JSON orders packet and review the results Understand the precedence of tools in a chain and the expected behavior Scenes tools Basemap tools Band Math Clip Composite Coregister File Harmonization Reproject Tile TOAR Band Math Clip Merge Reproject Using tools In this example, we show how to use the Clip tool. Clip basically crops the imagery to the provided boundary. The API payload can be read as: Activate 20170614_113217_3163208_RapidEye-5 analytic bundle and then clip the imagery to the specified AOI, and return download URL for the result. { \"name\": \"just clip\", \"source_type\": \"scenes\", \"source_type\": \"scenes\", \"products\": [ { \"item_ids\": [ \"20170614_113217_3163208_RapidEye-5\" ], \"item_type\": \"REOrthoTile\", \"product_bundle\": \"analytic\" } ], \"tools\": [ { \"clip\": { \"aoi\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ -163.828125, -44.59046718130883 ], [ 181.7578125, -44.59046718130883 ], [ 181.7578125, 78.42019327591201 ], [ -163.828125, 78.42019327591201 ], [ -163.828125, -44.59046718130883 ] ] ] } } } ] } Creating toolchains To derive insights or perform any meaningful analysis, it is likely that you may need multiple tools to process the data. You can push Planet data through an individual tool or several tools chained together to achieve the results you need. Planet processes tool requests synchronously in an order that has been validated against prior methodology. Given the changing output of each tool, certain processes necessarily go before others. When using multiple tools in an order, the sequence of tools processed is as follows: Scenes tools Basemap tools harmonize toar clip reproject bandmath tile composite coregister fileformat merge clip reproject bandmath Even if the array you provide does not follow the sequence above, the tools are executed in the sequence above. In this example, the REOrthoTile analytic product is manipulated by three tools in series: TOAR --> Reproject --> Tile . TOAR, Reproject, and Tile { \"name\": \"toar and reproject\", \"source_type\": \"scenes\", \"source_type\": \"scenes\", \"products\": [ { \"item_ids\": [ \"20170614_113217_3163208_RapidEye-5\" ], \"item_type\": \"REOrthoTile\", \"product_bundle\": \"analytic\" } ], \"tools\": [ { \"toar\": { \"scale_factor\": 10000 } }, { \"reproject\": { \"projection\": \"WGS84\", \"kernel\": \"cubic\" } }, { \"tile\": { \"tile_size\": 1232, \"origin_x\": -180, \"origin_y\": -90, \"pixel_size\": 0.000027056277056, \"name_template\": \"C1232_30_30_{tilex:04d}_{tiley:04d}\" } } ] } Tools Reference Band math The bandmath tool allows you to apply band math expressions to the bands of your input files to produce derived outputs and indices for analysis. Popular indices include NDVI ( Normalized Difference Vegetation Index ), EVI (Enhanced Vegetation Index), and NDWI (Normalized Difference Water Index). The bands of the input file are referenced as b1, b2, b3, etc., where b1 equals \"band 1\". For each band expression, the bandmath tool supports normal arithmetic operations and simple math operators offered in the Python numpy package . (For a list of supported mathematical functions, see Bandmath supported numpy math routines .) Product inputs The source_type for this tool is scenes . The bandmath tool supports PlanetScope, SkySat, and RapidEye bundles except for those with non-orthorectified images (designated as basic_* bundles). Parameters The parameters of the bandmath tool define how each output band in the derivative product should be produced, referencing the product inputs' original bands. Band math expressions may not reference neighboring pixels, as non-local operations are not supported. The tool can calculate up to 15 bands for an item. Input band parameters may not be skipped. For example, if the b4 parameter is provided, then b1 , b2 , and b3 parameters are also required. b1 (string): An expression defining how output band 1 should be computed. (required) b2 (string): An expression defining how output band 2 should be computed. (optional) ... b15 (string): An expression defining how output band 15 should be computed. (optional) pixel_type (string): A value indicating what the output pixel type should be. By default this value will be \"Auto\", the same as the input file. \"8U\" (8bit unsigned), \"16U\" (16bit unsigned), \"16S\" (16bit signed), and \"32R\" (32bit floating point) may also be used depending on the type of equation or index being calculated. (optional) Example request { \"name\": \"ndvi_bandmath_example\", \"source_type\": \"scenes\", \"products\": [ { \"item_ids\": [ \"20220124_062250_31_220b\" ], \"item_type\": \"PSScene\", \"product_bundle\": \"analytic_udm2\" } ], \"tools\": [ { \"bandmath\": { \"b1\": \"b1\", \"b2\": \"b2\", \"b3\": \"b3\", \"b4\": \"arctan(b1)\", \"b5\": \"(b4-b3)/(b4+b3)\", \"pixel_type\": \"32R\" } } ] } The output of this tool is a bundle that includes all four bands of the original file, a fourth band that is the ar tangent of the original first band, and a fifth band with NDVI values. Tool outputs One bandmath imagery output file is produced for each product bundle, with output bands derived from the band math expressions. nodata pixels are processed with the band math equation. These files have \"_bandmath\" appended to their file names. The tool passes through UDM, RPC, and XML files, and does not update values in these files. Clip The clip tool allows you to clip a scene or a Basemap to a specified area of interest (polygon or multipolygon) to limit your storage costs. clip may also be used as a billing management tool, depending on the Raster Tools Plan you've purchased. For Basemaps, use this operation only with orders that use a geometry in the product block. When you order a Basemap using an Area of Interest, whole quads are returned. This tool clips those quads to your Area of Interest and operates on that geometry specified in your product block. For example: \"tools\": [{\"clip\": {}}] This code does not work for Basemap orders placed using quad IDs. Product inputs The source_type for this tool is either scenes or basemaps . The clip tool supports all item types and all bundle types except for those with non-orthorectified images ( basic_* bundles). Parameters For Basemaps, there are no parameters for this operation, as the geometry in the product block is used as the area of interest. For scenes, there is one parameter: aoi (dict): GeoJSON polygon or multipolygon defining the clip area, with up to 500 vertices. The minimum geographic area of any polygon or internal ring is one square meter. The clip tool requires an AOI when used with scenes orders but doesn't take an AOI when used for basemaps orders. Example request { \"name\": \"clip_example\", \"source_type\": \"scenes\", \"products\": [ { \"item_ids\": [ \"20201129_150531_19_1065\" ], \"item_type\": \"PSScene\", \"product_bundle\": \"analytic_sr_udm2\" } ], \"tools\": [ { \"clip\": { \"aoi\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ -71.42186164855957, 41.830816472727356 ], [ -71.41611099243164, 41.812267143599804 ], [ -71.39302253723143, 41.821862295060974 ], [ -71.39920234680176, 41.83363038420449 ], [ -71.42186164855957, 41.830816472727356 ] ] ] } } } ] } AOI geometry limits on clipping scenes While clipping an AOI with GeoJSON, users should be aware of multipolygon limitation for successful order creation. The python-geojson and python-shapely validation process involved in passing an AOI to the clip tool, as well as Orders v2 limitations, may flag validation errors that result in your order being rejected. The following geometries are invalid and will result in unsuccessful orders: GeoJSON Polygons with holes first will be rejected. GeoJSON Polygons with multiple exterior rings will be rejected. GeoJSON MultiPolygons with overlapping/intersecting Polygons will be rejected. The GeoJSON spec technically allows this, but is generally invalid geometry in many programs (PostGIS, Shapely, QGIS to name a few). GeoJSON containing more than 500 vertices will be rejected. Clipping outside of the contract AOI may result in a rejected order. Tool outputs For scenes, one clipped imagery output file is produced for each product bundle. nodata pixels will be preserved. UDM files will also be clipped, and XML file attributes \"filename\", \"numRows\", \"numColumns\" and \"footprint\" are updated based on the clip results. The clipped file outputs have \"_clip\" appended to their file names. If the clip AoI is so large that full scenes or quads may be delivered without any clipping, those files do not have \"_clip\" appended to their file name. Info There may sometimes be discrepancies between an asset's footprint and the area of its usable pixels. When clipping, this can result in a clipped AoI that does not intersect with any usable pixels of an image. In this circumstance, no imagery file is delivered but auxiliary assets are delivered. Composite The composite tool allows you to composite a set of images into a single output. Product inputs The source_type for this tool is scenes . The composite tool supports all item types except for SkySatCollect and all bundle types except for those with non-orthorectified images ( basic_* bundles). All product inputs must share the same item type and product bundle. All product inputs must be in the same coordinate system (i.e. epsg_code) and have the same band configuration and pixel type. While product inputs do not need to have the same resolution, the output of the composite tool has the same resolution as the first product file. The composite tool applies images to the composite \"in order\" with the later images applied over the earlier images. The ordering of the products influences the output where the last item included in the array is applied last on top. Output GeoTIFFs created by the composite tool have a maximum area. The limit depends on the item type of the input scenes due to differences in resolution. High resolution ( SkySatScene ) : Limit of 375 sqkm per composite Medium resolution ( PSScene , REOrthoTile , Sentinel2L1C ) : Limit of 9,000 sqkm per composite Low resolution ( Landsat8L1G ) : Limit of 1,200,000 sqkm per composite Parameters group_by (enum) (optional): Defines how items are grouped to create one or more composites. Currently, the tool supports two group_by values: \"order\" : All input items in the order will be used to create a single output composite geotiff. This is the default behavior if no group_by parameter is provided. \"strip_id\" : Input items will be grouped by their strip_id . If there are items from multiple strips then there will be multiple output composite geotiffs. Example request - composite by order { \"name\": \"composite by order example\", \"products\": [ { \"item_ids\": [ \"20200710_172116_0e19\", \"20200710_172117_0e19\" ], \"item_type\": \"PSScene\", \"product_bundle\": \"analytic_udm2\" } ], \"tools\": [ { \"composite\": { } } ] } Example request - composite by strip_id The payload below contains 5 items from two unique strips so the order will contain two output composite files. { \"name\": \"composite by strip_id example\", \"products\": [ { \"item_ids\": [ \"20220808_181151_70_2426\", \"20220808_181149_44_2426\", \"20220808_181147_18_2426\", \"20220808_175911_89_249d\", \"20220808_175909_61_249d\" ], \"item_type\": \"PSScene\", \"product_bundle\": \"visual\" } ], \"tools\": [ { \"composite\": { \"group_by\": \"strip_id\" } } ] } Tool outputs One or more imagery composites are delivered for a set of product bundles. Corresponding UDMs will also be composited. These files will have _composite appended to their file names. If grouping by order, output composite files will use the format composite.tif . If grouping by strip_id , output composite files will use the format <date>_strip_<strip_id>_composite.tif . In addition, a metadata file is delivered that includes cloud statistics of the composite raster (for example, cloud_cover) and an updated geometry to reflect the extent of the composite raster.. The metadata file name of the composite by area is: composite_metadata.json The metadata file name of the composite by strip is: <date>_strip_<stripid>_composite_metadata.json where <date> is the date of the strip and <stripid> is the strip id of the scenes in the composite. The tool passes through rpc and xml files. Coregister The coregister tool, allows you to coregister a set of target items to a single anchor item within your order, making it easier to perform time series analysis of deep temporal imagery stacks. The coregistration tool ensures that images in a specified time series are spatially aligned, so that any feature in one image overlaps as precisely as possible with its position in any other image in the series. This tool is designed to support coregistration of small areas of interest – contained within a single scene – and works best with high geographic overlap between scenes in the times series. Product inputs The source_type for this tool is scenes . The coregister tool supports all item types except for REScene and all bundle types except for basic_* and *_nitf bundles. It is not compatible with the composite tool. Parameters anchor_item (string) (required): The item_id of the item to which all other items should be coregistered. Currently, only one item_id may be supplied, and it must be included as one of the products in the order. Items in the order must geographically overlap with the anchor item to be successfully coregistered. Example request { \"name\": \"coreg_example\", \"source_type\": \"scenes\", \"products\": [ { \"item_ids\": [ \"20200720_194019_0f4c\", \"20200714_165944_0f4e\", \"20200630_164149_0e3a\" ], \"item_type\": \"PSScene\", \"product_bundle\": \"analytic_udm2\" } ], \"tools\": [ { \"coregister\": { \"anchor_item\": \"20200630_164149_0e3a\" } } ] } Tool outputs One imagery output file is produced for each bundle. The anchor imagery file and corresponding udm will have \"_anchor\" appended to their file names. Imagery files and their corresponding udms which are successfully coregistered, or already spatially aligned with the anchor item (i.e. did not need to be coregistered) will have \"_coreg\" appended to their file names. The tool delivers an additional coregistration quality json file for each item in the order (except for the anchor item), which includes details on each output item's transformation. Rpc and xml files will be passed through. Item coregistration quality JSON file parameters The item coregistration quality json sidecar file includes the following information on coregistration transformations: projection_epsg_before : Lists the original projection of the item. projection_epsg_after : Lists the projection of the item after transformation. If it was transformed to the anchor item's reprojection, it will be updated. If the item was not reprojected, this field will be empty. pixel_shift : Describes the coregistration transformation in pixels. matching_score_before : A derived metric which describes image alignment before coregistration. The matching score looks at a combination of Normalized Root Mean Square Error and Structural Similarity Index. A matching score goes from 0 to 1. A score above 0.8 indicates that the item already has very good alignment and is already correlated. These files will be marked with the \"_coreg\" suffix and will be passed through (or reprojected to the anchor item projection and delivered). If the score is below 0.8, the tool will attempt to coregister the item. Note that a score of 0.8 does not necessarily indicate poor alignment. matching_score_after : A derived metric which describes image alignment after coregistration. If it was not coregistered because it was already correlated or it failed to successfully coregister, this field will be empty. matching_score_improvement : The difference in image alignment after coregistration. Items which fail to coregister, or which result in a matching score improvement of less than 0.001 after the coregistration transformation will not be transformed. Instead, those will be delivered without any coregistration (or reprojection) transformation and \"_coreg\" will not be appended to their file names. Output example – successful coregistration { \"projection_epsg_after\":\"\", \"matching_score_after\":0.533, \"pixel_shift\":[ -1.2461, 0.909 ], \"coreg_method\":\"imreg_dft\", \"coreg_method_version\":\"imreg_dft-2.0.0\", \"target_item\":\"20200531_133140_0f21_3B_Analytic.tif\", \"output_item\":[ \"coregistration_example/20200531_133140_0f21_3B_Analytic_coreg.tif\", \"coregistration_example/20200531_133140_0f21_3B_Analytic_DN_coreg_udm.tif\" ], \"matching_score_improvement\":0.005, \"anchor_item\": \"20200526_182301_0f4c_3B_Analytic.tif\", \"matching_score_before\":0.528, \"projection_epsg_before\":\"32618\", \"details\": {} } Output example – coregistration failure { \"projection_epsg_after\":\"\", \"matching_score_after\":\"\", \"pixel_shift\":\"\", \"coreg_method\":\"imreg_dft\", \"coreg_method_version\":\"imreg_dft-2.0.0\", \"target_item\":\"20200720_194019_0f4c_3B_AnalyticMS.tif\", \"output_item\":\"coregistration_example/20200720_194019_0f4c_3B_AnalyticMS.tif\", \"matching_score_improvement\":\"\", \"anchor_item\":\"20200630_164149_0e3a_3B_AnalyticMS.tif\", \"matching_score_before\":\"\", \"projection_epsg_before\":\"\", \"details\":{ \"reason\":\"Coregistration not improved\", \"message\":\"Calculated improvement for Target 20200720_194019_0f4c_3B_AnalyticMS.tif against reference 20200630_164149_0e3a_3B_AnalyticMS.tif is too low. Matching alignment score difference before and after warping is 0.000138218077682 and below minimum of 0.001\" } } Output example – coregistration skipped; item already correlated { \"projection_epsg_after\":null, \"matching_score_after\":\"\", \"pixel_shift\":\"\", \"coreg_method\":\"imreg_dft\", \"coreg_method_version\":\"imreg_dft-2.0.0\", \"target_item\":\"20200714_165944_0f4e_3B_AnalyticMS.tif\", \"output_item\":[ \"coregistration_example/20200714_165944_0f4e_3B_AnalyticMS_DN_coreg_udm.tif\", \"coregistration_example/20200714_165944_0f4e_3B_AnalyticMS_coreg.tif\" ], \"matching_score_improvement\":\"\", \"anchor_item\":\"20200630_164149_0e3a_3B_AnalyticMS.tif\", \"matching_score_before\":0.852, \"projection_epsg_before\":\"32614\", \"details\":{ \"reason\":\"Images already correlated\", \"message\":\"Image 20200714_165944_0f4e_3B_AnalyticMS.tif and reference [u'20200630_164149_0e3a_3B_AnalyticMS.tif'] are highly corelated already. MatchingScore: 0.851835213831 (MAX: 0.8)\" } } Because the matching_score_before for 20200714_165944_0f4e_3B_AnalyticMS.tif is greater than 0.8, the item is passed thorugh. File Format The file_format tool allows you to convert imagery to Cloud Optimized GeoTIFF (ideal for light-weight, web-based workflows) or NITF 2.1 formats. Product inputs The source_type for this tool is scenes . The file_format tool supports all item types and all bundle types except for those with NITF images (designated as *_nitf bundles). When used with SkySatCollect item types, no more than 100 items should be ordered. Parameters format (enum): The format of the tool output. Currently, the tool supports two formats: \"COG\" : This option produces a tiled Cloud Optimized GeoTIFF, with LZW compression and powers of two overviews. You can find more information on Cloud Optimized GeoTIFFs here . \"PL_NITF\" : This option converts the output to the National Imagery Transmission Format 2.1 specification. You can find more information the NITF 2.1 specification here . The NITF format only supports WGS84 geographic and UTM projections. A Reproject tool may be used to change projections prior to File Format. Example request { \"name\": \"file_format_example\", \"source_type\": \"scenes\", \"products\": [ { \"item_ids\": [ \"20200710_172116_0e19\" ], \"item_type\": \"PSScene\", \"product_bundle\": \"analytic_udm2\" } ], \"tools\": [ { \"file_format\": { \"format\": \"COG\" } } ] } Tool outputs One formatted imagery output file is produced for each product bundle. These files will have \"_file_format\" appended to their file names. The tool passes through udms, rpcs, and xml files. Harmonization The harmonize tool allows you to radiometrically harmonize imagery captured by one satellite instrument type to imagery captured by another. Parameters target_sensor (string) : A value indicating to what sensor the input product bundles should be calibrated. Each sensor value transforms items captured by a defined set of instrument IDs. Items which have not been captured by that defined set of instrument IDs are unaffected by (passed through) the harmonization operation. Target Sensor Options Sentinel-2 PSScene surface reflectance bundles from PlanetScope instrument types ( PS2.SD and PSB.SD ) can be harmonized to Sentinel-2. With the Sentinel-2 target sensor, the tool harmonizes PSScene surface reflectance bundle types ( analytic_8b_sr_udm2 , analytic_sr_udm2 ) to Sentinel-2 bands (blue, green, red, and narrow near-infrared (NIR)). Note: analytic bundles are not supported. Read more about the harmonization to Sentinel-2 in Scene Level Normalization and Harmonization of Planet Dove Imagery . Tool outputs One imagery output file with harmonized band values is delivered for each product bundle. The transformation of each item depends on the instrument used to capture that item and its relationship to the target sensor. Files which have been transformed have \"_harmonize\" appended to their file names. The Harmonization tool passes through UDM, RPC, and XML files, and does not update values in these files. Merge The Basemap merge tool combines all quads that fall within the geometry you specify into a composite image. One raster GeoTIFF is returned instead of the individual quads. Any assets, such as UDM, are also merged. The output files have _merge appended to the file names. The merge tool requires a geometry and does not work for orders by list of quad_ids . Product inputs The source_type for this tool is basemaps. Parameters There are no parameters for this operation. Example request { \"name\": \"basemap order with geometry\", \"source_type\": \"basemaps\", \"products\": [ { \"mosaic_name\": \"global_monthly_2022_01_mosaic\", \"geometry\":{ \"type\": \"Polygon\", \"coordinates\":[ [ [4.607406, 52.353994], [4.680005, 52.353994], [4.680005, 52.395523], [4.607406, 52.395523], [4.607406, 52.353994] ] ] } } ], \"tools\": [ {\"merge\": {}} ] } Tool outputs One raster GeoTIFF is returned instead of the individual quads. Any assets, such as UDM, are also merged. The output files have \"_merge\" appended to their file names. The merged output must be less than 425 megapixels (approximately equal to the area of 25 quads with pixel dimensions 4096x4096 pixels). If the requested merge exceeds 425 megapixels, the create order request returns an error_hint containing the estimated pixel size of the attempted order. Reproject The reproject tool allows you to reproject and resample scenes and Basemaps to a new projected coordinate system and resolution. Product inputs The reproject tool supports all Basemaps, and all scene item types and bundle types except for those with non-orthorectified images ( basic_* bundles). For scenes, the item type REScene is also disallowed. Parameters projection (string) : A coordinate system in the form EPSG:n (for example, EPSG:4326 for WGS84, EPSG:32611 for UTM 11 North (WGS84), or EPSG:3857 for Web Mercator). Well known text CRS values are also supported (for example, WGS84). resolution (float) : The pixel width and height in the output file. If not provided, the default is the resolution of the input item. This value is in meters unless the coordinate system is geographic (such as EPSG:4326), in which case, it is pixel size in decimal degrees. kernel (string) : The resampling kernel used. If not provided, the default is \"near\". UDM files always use \"near\". This parameter also supports \"bilinear\", \"cubic\", \"cubicspline\", \"lanczos\", \"average\", \"mode\", \"min\", \"max\", \"med\", \"q1\", and \"q3\" (see the gdalwarp \"resampling_method\" docs for details). Example request { \"name\": \"reproject_example\", \"source_type\": \"scenes\", \"products\": [ { \"item_ids\": [ \"20200710_172116_0e19\" ], \"item_type\": \"PSScene\", \"product_bundle\": \"analytic_udm2\" } ], \"tools\": [ { \"reproject\": { \"projection\": \"EPSG:4326\", \"kernel\": \"cubic\" } } ] } Tool outputs One imagery output file reprojected to the target configuration is produced for each product bundle. UDM files are also reprojected to the target configuration. These file outputs have \"_reproject\" appended to their file names. The tool passes through XML files. Tile The tile tool allows you to split an item or multi-item composite into a regular set of tiles based on a specified tiling system. The tiling system is a mapping from the projected coordinate system coordinates to tiles referenced by an x and y integer offset from the origin (see {tilex} and {tiley} in the \"name_template\"). If your workflow is unconcerned with the tiling coordinate system and simply needs imagery broken into regular chunks, set \"tile_size\" to indicate tile size in pixels and accept the default for all other tile parameters. If you want to control the alignment of the tile grid, you can set the origin_x and origin_y values. These two parameters default to zero. When the defaults are used, the lower left of tile 0, 0 is at the origin of the projected coordinate system. The {tilex} and {tiley} values increase in the same direction as the x and y axes in the projected coordinate system (typically x increases going eastward and y increases going northward). Given that, you can calculate the left edge of a tile in projected coordinates with this formula: origin_x + tilex * tile_size * pixel_size And the bottom edge of the tile in projected coordinates can be calculated with this: origin_y + tiley * tile_size * pixel_size Product inputs The source_type for this tool is scenes . The tile tool supports all item types and all bundle types except for those with non-orthorectified images ( basic_* bundles) and NITF images ( *_nitf bundles). Parameters origin_x (float): Tiling system x origin in projected coordinates (default is zero) origin_y (float): Tiling system y origin in projected coordinates (default is zero) pixel_size (float): Tiling system pixel size in projected coordinates (defaults to pixel_size of input raster). tile_size (integer): Height and width of output tiles in pixels and lines (always square) (required) name_template (string): A naming template for creating output tile filenames. The default is \"{tilex}_{tiley}.tif\" resulting in filenames like 128_200.tif. The {tilex} and {tiley} parameters can be of the form {tilex:06d} to produce a fixed width field with leading zeros. conformal_x_scaling (boolean): If the coordinate system is conformal (such as WGS84) it may be desirable to scale output tiles in the X direction in order to minimize the distortion of shape as the poles are approached. Enabling this will reduce in the width of tiles being less than tile_size as one gets further away from the equator. Example request { \"name\": \"web_mercator_zoom_15_tile_example\", \"source_type\": \"scenes\", \"products\": [ { \"item_ids\": [ \"20200710_172116_0e19\" ], \"item_type\": \"PSScene\", \"product_bundle\": \"analytic_udm2\" } ], \"tools\": [ { \"tile\": { \"origin_x\": -20037508.340, \"origin_y\": -20037508.340, \"pixel_size\": 3, \"tile_size\": 256, \"name_template\": \"{tilex:07d}_{tiley:07d}.tif\" } } ] } The output will produce Web Mercator tiles at Zoom Level 15. Tool outputs A set of tiled output files are produced for each bundle (or a composite, if paired with composite). Udm files are also tiled. The tiled files will have a file name defined by the \"name_template\" tool parameter below. The tool passes through xml files. Top of Atmosphere Reflectance The Top of Atmosphere Reflectance (TOAR) tool converts Analytic assets from top of atmosphere (TOA) radiance to a TOA scaled reflectance. The Orders API TOAR tool is only applicable to Analytic assets, which represent TOA radiance. The tool converts the pixel values to a scaled reflectance, accounting for varying solar irradiance based on the distance to the sun and geometry of incoming solar radiation. The resulting product is a top of atmosphere reflectance value, no atmospheric correction is applied. Product inputs The source_type for this tool is scenes . The toar tool supports the analytic bundle type for all item types. Parameters scale_factor (integer): Scale factor applied to convert 0.0 to 1.0 reflectance floating point values to a value that fits in 16bit integer pixels. The Default is 10000. Values over 65535 could result in high reflectances not fitting in 16bit integers. { \"name\": \"toar_example\", \"source_type\": \"scenes\", \"products\": [ { \"item_ids\": [ \"20200710_172116_0e19\" ], \"item_type\": \"PSScene\", \"product_bundle\": \"analytic_udm2\" } ], \"tools\": [ { \"toar\": { \"scale_factor\": 10000 } } ] } Tool outputs One 16bit imagery output file, holding scaled reflectance values, will be produced for each product bundle. These files will have \"_toar\" appended to their file names. The tool passes through udms, rpcs, and xml files.","tags":"orders","url":"https://developers.planet.com/apis/orders/tools/","loc":"https://developers.planet.com/apis/orders/tools/"},{"title":"Tasking Order creation, editing and deletion","text":"The Planet Tasking API is a REST based API, which can be integrated into any service regardless of the language used. Below are some examples of how to integrate the most commonly used aspects of the Tasking API Orders creation, editing and cancellation methods. Tasking Order creation The creation of an order via the Tasking API is done by sending a POST request to the Tasking API tasking/v2/orders endpoint. The creation of Tasking Order can be as simple as the following request example: curl --request POST --url 'https://api.planet.com/tasking/v2/orders/' \\ --header 'accept: application/json' \\ --header 'authorization: api-key <YOUR_API_KEY>' \\ --header 'content-type: application/json' \\ --data '{ 'name': 'Order 01', 'geometry': { 'type': 'Point', 'coordinates': [ 149.44135, 28.49240 ] } } Defining the minimum and maximum Satellite elevation angles It is possible, as part of the Tasking Order creation request, to define the desired range of angles relative to the target that the satellite should attempt to take an image. These values are sat_elevation_angle_min and sat_elevation_angle_max , and whilst both have a theoretical range from 0° to 90° it is likely that these values will be defined in your contract as having a range between 60° and 90° inclusive. These angles are relative to the target, so 90° is directly above the target, and it should be noted that the more restrictive the range between the min and max values the more likely it is that you Tasking Order will not succeed. Selecting the PL-Number and Product If the PL-Number and Product are not defined in the order POST request, then the Tasking API service will select the default values that are defined for the given api-key. In the majority of cases this will be sufficient and thus the PL-Number and Product do not need to be defined. If a different PL-Number and/or product are to be chosen, then these can simply be defined as part of the order payload: { \"name\": \"Order 01\", \"geometry\": { \"type'\": \"Point\", \"coordinates\": [ 149.44135, 28.49240 ] }, \"pl_number\": \"PL-YourPlNumber\", \"product\": \"one_time_tasking\" } The response will contain the UUID that has been generated to identify the newly created Tasking Order, as well as any geometry created and other values related to the Tasking Order: { \"id\": \"9d79b9ba-efa3-4e6d-bc08-407b545875a1\", \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ 149.415829, 28.469843 ], [ 149.466885, 28.469843 ], [ 149.466896, 28.514958 ], [ 149.415818, 28.514958 ], [ 149.415829, 28.469843 ] ] ] }, \"original_geometry\": { \"type\": \"Point\", \"coordinates\": [ 149.441357, 28.492403 ] }, \"order_type\": \"IMAGE\", \"sat_elevation_angle_min\": 60.0, \"sat_elevation_angle_max\": 90.0, \"start_time\": \"2020-03-23T12:26:35.820963Z\", \"end_time\": \"2020-04-22T12:26:35.820963Z\", \"n_stereo_pov\": null, \"is_cancellable\": false, \"cancellable_until\": \"2021-08-05T10:18:00.000000Z\", \"requested_sqkm\": 25.0, \"created_time\": \"2020-03-23T12:26:36.137220Z\", \"updated_time\": \"2020-03-23T12:26:36.137259Z\", \"name\": \"test_order_426\", \"created_by\": \"a.user@a.fake.email.address.com\", \"status\": \"RECEIVED\", \"fulfilled_sqkm\": 0.0, \"capture_status_published_count\": 0, \"capture_assessment_success_count\": 0, \"capture_assessment_invalid_count\": 0, \"scheduling_type\": \"FLEXIBLE\", \"rrule\": null, \"exclusivity_days\": 0, \"next_planned_acquisition_time\": null, \"last_acquired_time\": null, \"imaging_window\": null } Strip vs Point The previous example showed how to create a Point Tasking Order, which takes the provided geo-coordinates and generates a 5x5 km square around that point, giving an overall area of 25 km 2 . If you have two points geographically close to each other that need to be imaged, or require a longer (but not wider) area to be imaged, then defining a Strip Tasking Order would be more suitable. The difference is simple in that instead of providing a GEoJSON Point in the Tasking Order payload, instead a LineString is provided. For example: curl --request POST --url 'https://api.planet.com/tasking/v2/orders/' \\ --header 'accept: application/json' \\ --header 'authorization: api-key <YOUR_API_KEY>' \\ --header 'content-type: application/json' \\ --data '{ 'name': 'Order 01', 'geometry': { 'type': 'LineString', 'coordinates': [ [ 10.92041015625, 48.91527985344383 ], [ 10.78857421875, 49.0738659012854 ] ] } } Strip Tasking Orders have a fixed width of 5 km and a minimum length of 6 km and a maximum length of 100 km. Retrieving, filtering and paginating your Tasking Orders Once you have created your Tasking Order, you can check up on it and any other Tasking Orders you may have created by performing a GET request on the same /orders endpoint that you used to create your Tasking Orders: curl --request GET \\ --url https://api.planet.com/tasking/v2/orders/ \\ --header 'Authorization: api-key <YOUR_API_KEY>' \\ --header 'Content-Type: application/json' If you want to retrieve a specific Tasking Order, you would simply append the ID of the Tasking Order to the URL, e.g. /orders/some_UUID_number In the event that you have multiple Tasking Orders, the /orders endpoint provides filtering and pagination to help manage the response payload. Through filtering you can ensure that only those Tasking Orders that you want to see are returned. Tasking Orders can be filtered by created, start and end times, name and many other values (for a full list of available parameters see: https://developers.planet.com/docs/tasking/reference/#operation/v2_orders_list) Below is an example of request all Tasking Orders that have a name containing a given string and that were created after a particular date. Note that the created date must be a correctly formatted date/time value of the type \"YYYY-mm-ddThh:mm:ssZ\" and that all time are in UTC: curl --request GET \\ --url 'https://api.planet.com/tasking/v2/orders/?name__icontains=test&created_time__gt=2021-01-01T23:59:59Z' \\ --header 'Authorization: api-key <YOU_API_KEY>' \\ --header 'Content-Type: application/json' The parameters limit and offset are used to define the boundaries of the response pagination. limit defines how many results are returns per page and offset determines the starting index of the response. Taking this into account, the following request would return 30 results per page, starting with the 10th possible result: curl --request GET \\ --url 'https://api.planet.com/tasking/v2/orders/?limit=30&offset=10' \\ --header 'Authorization: api-key <YOU_API_KEY>' \\ --header 'Content-Type: application/json' The response payload will then include the key next and previous with the corresponding values containing URLs that will point to the next and previous page of results. The format of these URLs is the same as the original request in the above example. Tasking Order Editing The ability to edit an existing Tasking Order depends upon what needs to be changed as well as the current status of the Tasking Order in the system. The following table shows what can be edited and in what state. Tasking Orders in the following states FULFILLED , CANCELLED , REJECTED and EXPIRED cannot be edited : FIELD PENDING IN_PROGRESS start_time yes no end_time yes yes Rather than a POST request, an edit requires a PUT request to be made. The following command would edit the name and start time of a an existing Tasking Order. The UUID that identifies the order is including as part of the URL: curl --request PUT --url 'https://api.planet.com/tasking/v2/orders/<ORDER_ID_GOES_HERE>' \\ --header 'accept: application/json' \\ --header 'authorization: api-key <YOUR_API_KEY>' \\ --header 'content-type: application/json' \\ --data '{ 'start_time': '2020-04-23T12:26:35Z' } With a response that shows the updated fields plus the other fields that can be edited: { \"start_time\": \"2020-05-23T12:26:35.000000Z\", \"end_time\": \"2020-06-23T12:26:35.000000Z\" } Tasking Order Deletion Tasking Order deletion follows similar rules to editing. Tasking Orders can be deleted or cancelled only when the Tasking Order is in one of the following states: PENDING , IN_PROGRESS and RECEIVED . A Tasking Order deletion is acheived by creating a DELETE request to the tasking/v2/orders endpoint with the ID of the Tasking Order that is to be deleted: curl --request DELETE --url 'https://api.planet.com/tasking/v2/orders/<ORDER_ID_GOES_HERE>' \\ --header 'accept: application/json' \\ --header 'authorization: api-key <YOUR_API_KEY>' \\ --header 'content-type: application/json' Note the lack of a body in the request. A successful request receives a HTTP 204 response","tags":"tasking","url":"https://developers.planet.com/docs/tasking/examples/orders","loc":"https://developers.planet.com/docs/tasking/examples/orders"},{"title":"Analytics Overview","text":"Planet Analytics leverages computer vision to transform our imagery into Analytic Feeds that detect and classify objects, identify geographic features, and understand change over time across the globe. This user guide is intended to help users access the Analytic Feeds and leverage them to build applications and solutions. Our Analytic Feed Viewer, located here , is a great example of what can be built on top of our Analytics API. For more details about our Analytic Feed Viewer, please visit our developer center here . Authentication The Analytics API uses Basic HTTP Authentication and requires that you have a Planet API key. Currently, anyone can sign up for a free account on our website . Once you're signed up, you can find your API key in your account settings . Authenticate by setting username to your API key. Authentication Via Basic HTTP using Python: import requests # install requests module to make request PL_API_KEY = '12345' # set your Planet API key as a string BASE_URL = \"https://api.planet.com/analytics/\" BASIC_AUTH = (PL_API_KEY, '') # construct tuple to access API via Basic Auth feed_list_url = f'{BASE_URL}feeds?limit=1' resp = requests.get(feed_list_url, auth=BASIC_AUTH) if resp.status_code == 200: print('Yay, you can access the Analytics API') else: print('Something is wrong:', resp.content) # test your credentials and access to Analytics API Authentication Via cURL: curl --header \"Authorization: api-key ${PL_API_KEY}\" https://api.planet.com/analytics/ Analytics API The Analytics API is a RESTful API interface to provide programmatic access to Planet Analytic Feeds. It enables search and retrieval of analytic results within the user's subscription. Find details about the supported resources and operations in the API reference documentation . Analytic Feeds An Analytic Feed represents the blueprint for what model and what processing needs to take place to create analytics output derived from Planet imagery. Each feed essentially represents an analytic capability that has been uniquely configured to optimize performance and quality, and each feed has unique types of outputs. For example, a Monthly Road Detection Feed represents roads detected on monthly Planet Basemaps, and outputs raster \"segmentation mask\" data. Many different types of Feeds are currently available through the Planet Analytics API, and we plan on releasing new feeds in the future. Subscriptions Users have subscriptions to feeds in a specific Area of Interest (AOI) and Time Interval of Interest (TOI). For example, a subscription could be Road Detection over 12 months in San Francisco, California. Users can get a list of their subscriptions from the Analytics API. Results When new imagery is published in a user's subscription, Planet's computer vision models process the imagery and its output is added to a collection of results associated with the subscription. For example, if a user has a subscription for the Vessel Detection Feed, newly published daily imagery within that subscription AOI will be processed and new vessel detections will be added to the subscription results. Feature Collections results are ordered by creation date, with most recent collections listed first. Each result contains reference links to the source imagery that was used to derive the result. This should enable you to download or reference the imagery as you deem appropriate. Note: for Analytic Feeds that surface change over time, multiple source imagery references will be made. This is to enable users to be able to quickly find a \"before\" and \"after\" view. Vector Results For vector-based results, geojson outputs are stored in Web Feature Service collections. These detections will be served as vector features. Each feature in the feature collection from the API will reference an individual instance of a detection (e.g. a vessel) or change detection (e.g, building construction). Raster Results GeoTIFF outputs containing raster results will be served as links within a feature collection. Each feature in the feature collection from the Analytics API references a mosaic quad with links to the source (input imagery for the analytic operation) and target (results of the analytic operation (ie, roads or building pixels). Available Feeds, imagery and Output Formats Feed Source Imagery Result Format Building Detection Mosaic Raster Road Detection Mosaic Raster Vessel Detection Scene Vector Plane Detection Scene Vector Building Change Detection Multiple Mosaics Vector Road Change Detection Multiple Mosaics Vector Web Map Tile Service By leveraging Planet's Webmap Tile Service (WMTS), you can stream source imagery and derived raster output into ArcGIS, QGIS or any other GIS you wish to use. Enter the URL shown below into your GIS to surface a list of raster items you have access to. https://api.planet.com/basemaps/v1/mosaics/wmts?api_key={api-key} This will produce a list of the mosaic imagery you have access to - this includes both satellite imagery and derivative raster output (e.g. road detections). Our naming convention for derivative raster output is \"SIF- -yyyy-mm-dd\". You'll most likely see several that look like the following: Item Title Description Global Monthly 2020 01 Mosaic This represents Planet's global visual mosaic product for January 2020 sif-b442c53b-fc72-4bee-bab4-0b7aa318ccd9-2020-01-01 This represents the derivative raster output for a given Feed. This one is for the Feed ID \"b442c53b-fc72-4bee-bab4-0b7aa318ccd9\" which is a monthly building detection feed. Bringing these layers into your tool of choice will enable you to compare them against each other as well as other public or private datasets you leverage. Learn more about how to leverage Planet's WMTS in the tile service reference documentation . OGC Features API Planet's Analytics API adheres to the Open Geospatial Consortium's (OGC) Features API specification which means you can stream in vector detections into your GIS platform of choice through a Web Feature Service (WFS) integration. Just make sure you select the OGC Features as the version of WFS. Enter the URL shown below to surface a list of Analytics Results you have access to. https://api.planet.com/analytics/ Learn More When you're ready to dive deeper into using Planet's Analytics API, you'll find a collection of guides and tutorials on Planet School . You may be interested in this Python tutorial: Converting Building Footprints to Vector Layers along with this collection of quickstart guides to working with Analytics API .","tags":"analytics","url":"https://developers.planet.com/docs/analytics/","loc":"https://developers.planet.com/docs/analytics/"},{"title":"Basemaps Overview","text":"Planet offers a range of Basemap products, each suited for different applications and use cases. The Global Basemap is best suited for mapping and visual simulation use cases. It is automatically generated annually, covers the entire globe in RGB bands, and has a visual color curve applied. Authentication The Basemaps API uses Basic HTTP Authentication and requires that you have a Planet API key. Currently, anyone can sign up for a free account on our website . Once you're signed up, you can find your API key in your account settings . Authenticate by setting username to your API key or by providing a valid api_key as a query parameter to all tile requests. Authentication via Basic HTTP with Python import os # import os module to access enviornmental modules import requests from requests.auth import HTTPBasicAuth # import helper functions to make Basic request to Planet API PLANET_API_KEY = os.getenv('PL_API_KEY') # Setup the API Key from the `PL_API_KEY` environment variable BASE_URL = 'https://api.planet.com/basemaps/v1/mosaics' if PLANET_API_KEY is None: PLANET_API_KEY = '12345' #pass in your API key auth = HTTPBasicAuth(PLANET_API_KEY, '') # HTTPBasicAuth() wants a username & password; you can pass an empty string for the password res = requests.get(url=BASE_URL, auth=auth) print(res.status_code) # make a request to the Basemaps API and test the response Authentication via cURL curl --header \"Authorization: api-key {your api key}\" https://api.planet.com/basemaps/v1/mosaics Passing API Key via URL Parameter https://api.planet.com/basemaps/v1/mosaics?api_key={your api key} Basemaps API Planet Basemap imagery is distributed as a grid of GeoTIFF files, which are called \"basemap quads\" or simply \"quads.\" Using the Basemaps API you can download a full mosaic or just one or more selected quads.","tags":"basemaps","url":"https://developers.planet.com/docs/basemaps/","loc":"https://developers.planet.com/docs/basemaps/"},{"title":"Overview","text":"Basemaps Viewer is an online tool used to view and download basemaps. Planet's Basemaps are composed of Planet's best daily images to provide a cloud-free comparison over time. Features Overview Find Your Basemap : See the basemaps available to you for your area of interest. Compare Basemaps : Compare two basemaps side by side to identify change. Inspect Contributing Scenes : Identify which scenes contributed to the basemap quad for more granular inspection. Download Basemap Quads : Download basemap quads to use in other tools.","tags":"apps-basemapsviewer","url":"https://developers.planet.com/docs/apps/basemapsviewer/","loc":"https://developers.planet.com/docs/apps/basemapsviewer/"},{"title":"Overview","text":"The Analytic Feeds Viewer is a web application that displays detections from Planet Analytic Feeds and the source imagery. It is designed to help users identify desired objects and features and demonstrate how Planet's machine learning models perform in certain regions. The Viewer is built entirely on Planet's public APIs, including our Analytics API and tile services. You can find our Analytic Feeds Viewer at https://www.planet.com/feeds . This user guide provides an overview of the functionality of the Viewer and assumes a general understanding of Planet Analytic Feeds. For more information on Analytic Feeds, please refer to https://developers.planet.com/docs/analytics . KEY FEATURES The following are key features of the Analytic Feeds Viewer. For more detail on our Analytic Feeds, please refer to https://developers.planet.com/docs/analytics/ . Raster Geotiffs Certain Analytic Feeds, like Buildings, have outputs formatted as raster GeoTIFF outputs. The Viewer displays these detections over their source imagery, either Planet Basemaps or Planet imagery. Vector Bounding Boxes Certain Analytic Feeds, like Vessels, have outputs formatted as vector bounding boxes. The Viewer displays these detections and their source imagery, either Planet Basemaps or Planet imagery. Redo Search Option When zoomed into a particular area within a subscription, the option to redo the search for detections within the viewable window will pop up. Transparency Slider Use the transparency slider to compare raster GeoTIFF outputs to the underlying source imagery and easily see what features resulted in detections. Confidence Score Filtering Each detection contains a confidence score representing how likely it is that the detection is a true positive detection. Use the confidence score filtering feature to show bounding box detections with higher confidence and remove false positives with lower confidence scores. Toggle For Scenes Without Detections There may be times when a PlanetScope or SkySat scene has zero detections that day. By default, the Viewer does not display these scenes. However you can use the toggle feature to display images with zero detections. XYZ Tile Services The Viewer surfaces the XYZ tile API URL so you can stream raster GeoTIFF outputs in your GIS platform of choice. Heatmap Visualization The Viewer includes an option to view detections as a heatmap to help point you to where you need to focus first. Toggle to See all Detects All detections within the filtered time period can be shown at once by selecting the Show All Detects option. Choose Your Own Color Palette The heatmap visualization can be altered to reflect different color ramps. Compare Imagery Over Time View how your area has changed over time and let Planet's detections guide you to where the most change has taken place Review and Export Cycle through detections to quickly remove false positives and export a clean dataset for further analysis.","tags":"apps-feedviewer","url":"https://developers.planet.com/docs/apps/feedviewer/","loc":"https://developers.planet.com/docs/apps/feedviewer/"},{"title":"GEE Delivery Integration Overview","text":"The Planet Google Earth Engine (GEE) Delivery Integration is a supported delivery destination from the Planet Orders API cloud-storage destinations . The integration simplifies the GEE delivery experience by creating a direct connection from the Planet API to GEE. Note : To use the integration, your organization must have download quota. To set up a download quota, Contact Sales . The Planet GEE Delivery Integration is not subject to a Service-Level Agreement (SLA). Setting Up Planet GEE Delivery Integration The The GEE Setup Guide provides details on how to connect the Planet API to a GEE account. Placing an Order The Order & Delivery documentation guides you through creating an order, and viewing a response. The documentation details which Planet items and which API operations are supported by the Planet Google Earth Engine (GEE) Delivery Integration. Getting Started in GEE Using Planet in GEE documentation provides helpful code-snippets for working with Planet data in the GEE Code Editor. Accessing NICFI Basemaps in GEE Planet maintains a special integration in GEE for the NICFI Basemaps. To access, please consult our NICFI Basemaps in GEE . Citing Planet Data From a concept in our garage, to operating the largest fleet of Earth-imaging satellites, many people have invested time and energy in developing and enabling access to Planet's unique data feed. Please cite Planet when using our imagery and tools. To cite Planet data in publications, include the following copyright notice: \"Image © 20xx Planet Labs PBC\" (where xx denotes the year of the content used) Learn More The Planet One Minute to Integrations videos demonstrate short workflows in GEE.","tags":"integrations-gee","url":"https://developers.planet.com/docs/integrations/gee/overview","loc":"https://developers.planet.com/docs/integrations/gee/overview"},{"title":"Overview","text":"Planet QGIS Plugin The Planet QGIS Plugin provides access to Planet's satellite imagery directly from QGIS. To order Planet imagery for use in QGIS, specify the area of interest (AOI) and the filters in your search. Also, you can discover and stream Planet Basemaps, and send tasking coordinates to Planet's Tasking Dashboard for high-resolution, on-demand imagery captures. Download the QGIS Plugin at Download the Planet QGIS Plugin . The Integrations Changelog provides the most current information on new releases, features, and functionality. Using the Planet QGIS Plugin Once the Planet QGIS Plugin is installed, a Planet Imagery ribbon is added to the QGIS interface. The following tools enable you to interact with the Planet Platform: Image Search - Search the Planet Imagery catalog to find and to order imagery when and where it is needed. Planet Basemaps - Search for Planet Basemaps to stream for visualization or download for analysis workflows. Planet Inspector - Inspect the source images and their metadata for Basemaps that you have added to your maps. Planet Tasking - Specify coordinates for high-resolution tasking to send to Planet's Tasking Dashboard. Order Status - View the status of your orders and add them to your maps. System Requirements QGIS version 3.10 and later Python 3.6+ A Planet account (don't have an account? Please contact us )","tags":"integrations-qgis","url":"https://developers.planet.com/docs/integrations/qgis/","loc":"https://developers.planet.com/docs/integrations/qgis/"},{"title":"Overview","text":"Planet Add-in for ArcGIS Pro The Planet Add-in for ArcGIS Pro provides access to Planet's satellite imagery directly from ArcGIS Pro. To order Planet imagery for use in ArcGIS Pro, specify the area of interest (AOI) and the filters in your search. Also, you can discover and stream Planet Basemaps and send tasking coordinates to Planet's Tasking Dashboard for high-resolution, on-demand imagery captures. Getting started: Get the Planet Add-in at Download Planet Add-in for ArcGIS Pro . Follow the instructions in the Getting Started Guide. The Integrations Changelog provides the most current information on new releases, features and functionality. Using the Planet Add-in for ArcGIS Pro Once the Planet Add-in is installed, a Planet Imagery ribbon is added to all ArcGIS Pro projects. The following tools enable you to interact with the Planet Platform: Image Search - Search the Planet Imagery catalog to find and order imagery when and where it is needed. Planet Basemaps - Search for Planet Basemaps to stream for visualization or download for analysis workflows. Planet Inspector - Inspect the source images and their metadata for Basemaps that you have added to your maps. Planet Tasking - Specify coordinates for high-resolution tasking to send to Planet's Tasking Dashboard. Order Status - View the status of your orders and add them to your maps. System Requirements ArcGIS Pro 3.0+ for version 3.x of the add-in ArcGIS Pro 2.4.3 - 2.9 for version 2.x of the add-in Python 3.6+ A Planet account (don't have an account? Please contact us ) NOTE on ArcGIS Pro version compatibility If you use a 2.x version of ArcGIS Pro, you must use version 2.2.1 of the Planet Add-in for ArcGIS Pro. This is our last version of the add-in that supports ArcGIS Pro 2.x versions and there will be no future updates, patches, or fixes for ArcGIS Pro version 2.x. Update to ArcGIS Pro 3.x for access to the most current Planet Add-in.","tags":"integrations-arcgis","url":"https://developers.planet.com/docs/integrations/arcgis/","loc":"https://developers.planet.com/docs/integrations/arcgis/"},{"title":"Reports Overview","text":"The Reports API allows Organization Administrators to download usage reports systematically for internal processing and analysis. Reports downloaded from the API are the exact same reports available from the user interface accessible from your Account at www.planet.com/account . Usage Reports Overview Planet's usage system generates reports every day; each report covers the activity for the previous 24 hours. Each day at GMT 23:59:59 Planet's system starts generating the daily report. When reports are completed for all customers they are made accessible via both your Account and the Reports API at the same time. Reports are generated according to the assigned quota style. Each PlanetScope plan has an assigned quota style: Starter, Preferred, Premium, or Area Under Management. Please note: no quota style selection is required in the API. If you have questions please reach out to your Customer Success Manager or support@planet.com . PlanetScope usage reports have two different formats: Standard usage reports sum all of the usage charged to the plan by date, item (for example: PSScene, SkySatCollect), and by user (who downloaded the image). Detailed usage reports list out every image and all metadata (e.g. xml files) downloaded. Key Feature: List Usage Reports The Reports API allows customers and partners to systematically list all of the reports that are available for each plan. Planetscope reports are available in Usage Report and Detailed Usage report versions. Usage reports are produced for each day covering 00:00:00 to 23:59:59 GMT. Key Feature: Download Usage Reports The Reports API also allows customers and partners to download the selected usage reports for a plan. You must be an Organization Administrator to list and download usage reports for a plan. Key Feature: Download Usage Reports for Sub-Orgs The Reports API allows administrators to download usage reports for their organizations. You can select between a detailed report or a summary. The API returns a link for downloading the usage report for the time (within the last 90 days) you've specified.","tags":"reports","url":"https://developers.planet.com/docs/reports/","loc":"https://developers.planet.com/docs/reports/"},{"title":"Subscriptions Overview","text":"The Subscriptions API is Planet's next-gen data delivery API. With a single API call, the Subscriptions API \"order a search\" capability allows you to subscribe to continuous cloud delivery of imagery and metadata collections, which meet your item filter criteria. To create a subscription, you can specify imagery filter criteria, raster processing tools, and a cloud delivery location. The API will then automatically process and deliver all items which meet your subscription criteria, as soon as they are published to the catalog. The Subscriptions API is Planet's recommended data delivery API for customers in need of daily imagery over stable areas of interest. Subscriptions Schema A subscription request has four main blocks. source : Describes the data products and criteria used to define what the subscription delivers. Currently, the catalog source type is supported. It takes item_types , asset_types , geometry , start_time , and a filter , and closely mirrors a Data API /quick-search request . tools : Describes raster tools which may be applied to a subscription. delivery : Describes the Google Cloud Storage, Amazon S3, and Microsoft Azure cloud delivery options for the items returned by the subscription. notifications : Describes the notifications which can be delivered for a subscription. More details on source , tools , delivery , and notifications block parameters are available in the left-hand navigation pages, or jump straight to Create Subscription Example Request , below. Subscription Status Status Descriptions preparing : The subscription was successfully submitted and is being set up. pending : The subscription's source start time ( start_time value) has not yet passed. Delivery has not yet started. running : The subscription's source start time has passed and it is actively monitoring new catalog publish events and/or processing results. Delivery may be in progress. completed : The subscription's source end time ( end_time value) has passed and all items are delivered. Delivery has stopped. suspended : The subscription has a policy or quota conflict. Delivery has stopped. cancelled : The subscription was cancelled by a user. Delivery has stopped. failed : There was an issue with the subscription. Forwardfill and Backfill Subscriptions The Subscriptions API supports delivery of both archive imagery and future imagery collections. Forwardfill subscriptions are subscriptions with an end time in the future. Backfill subscriptions are subscriptions with a start and end time in the past. Subscriptions may have either a backfill or forwardfill portion, or both. For example, a subscription's start time may be 3 years in the past to gather baseline data and then end at a time in the future. Create a Subscription A basic subscription must include a name , catalog source block (with item_types , asset_types , geometry , start_time , end_time ), and a delivery block with a specified cloud storage location. Subscriptions also support select tools . A subscription request will be rejected if the geometry specified in the geometry attribute and clip tool exceeds 500 vertices. A subscription will process and deliver items as soon as all item filter criteria are met and all requested asset types have been published and are available for delivery. Monitoring across seasons The Subscriptions API can support seasonal monitoring by delivering archive imagery and future collections for specific months over the duration of a subscription. To create a subscription that delivers imagery within specific time periods during a time of interest, utilize the rrule attribute that leverages iCalendar recurrence rules . This can be used to create subscriptions that deliver items for recurring periods within the total coverage time. More details can be found in the Source RRule section . Example Request This example creates a subscription that will deliver imagery between March 2021 and October 2023. POST https://api.planet.com/subscriptions/v1/ { \"name\": \"Example Subscription\", \"source\": { \"type\": \"catalog\", \"parameters\": { \"geometry\": { \"coordinates\": [[[139.5648193359375,35.42374884923695], [140.1031494140625,35.42374884923695], [140.1031494140625,35.77102915686019], [139.5648193359375,35.77102915686019], [139.5648193359375,35.42374884923695]]], \"type\": \"Polygon\" }, \"start_time\": \"2021-03-01T00:00:00Z\", \"end_time\": \"2023-11-01T00:00:00Z\", \"item_types\": [\"PSScene\"], \"asset_types\": [\"ortho_analytic_4b\"] } }, \"delivery\": { ... } } Info The requested image is not clipped to the specified geometry unless the clip tool is applied. For more information, see our Tools Documentation page. Edit a Subscription You can edit a subscription by submitting a full subscription request to the following endpoint: PUT https://api.planet.com/subscriptions/v1/<subscription_id> When a subscription is in pending state, it may be edited in full. After the subscription transitions to running , the following source block edits will be disallowed: Changes to item_types Changes to start_time values All other source filter criteria may be edited, as long as subscription does not surpass the limit on expected items delivered daily. Importantly, the edit will only apply to future item publications and deliveries. No items will be redelivered. If you need to reorder archive items based on an updated filter or tool specifications, you can search for and order archive items with the Data API and Orders API . Backfill subscriptions cannot be edited. Cancel a Subscription You can cancel subscription, with the following request: POST https://api.planet.com/subscriptions/v1/<subscription_id>/cancel After a subscription is cancelled, no additional items will be delivered (except for any items in processing or delivery). A cancelled subscription cannot be transitioned to running state. cancelled subscriptions will continue to be returned in the GET subscriptions response. Get Subscriptions You can get a list of your subscriptions, with the following request: GET https://api.planet.com/subscriptions/v1 The response will include a list of your subscriptions (including cancelled subscriptions). Each listed subscription will include the original subscription request, subscription status , created timestamp, and updated timestamp. You can filter subscriptions by status with the status query parameter. As an example, this API call would return all subscriptions in running or completed states: GET https://api.planet.com/subscriptions/v1?status=running&status=completed You can get details on a specific subscription with the following request: GET https://api.planet.com/subscriptions/v1/<subscription_id> If you are an organization administrator, you can get details for all subscriptions in an organization by including the user_id=all query parameter (Note: the api_key must be of a requestor that is an org admin): GET https://api.planet.com/subscriptions/v1?user_id=all or GET https://api.planet.com/subscriptions/v1/<subscription_id>?user_id=all Get Subscriptions Results A result for the catalog source type subscription represents an attempt to process and deliver an item that matches your subscription criteria. You can get a paginated list of your subscription's results, with the following request: GET https://api.planet.com/subscriptions/v1/<subscription_id>/results The response will include a paginated list of all of the subscription's results which were created within the last 30 days. Results more than 30 days old will not be returned. The response schema will include: id : The unique id of the subscription result. status : The status of delivery of the result's item. Result status can take one of the following values: created : The result has been created in our system. For catalog source type subscriptions, this means an item has been published which matches your subscription. queued : The result is in queue for processing. processing : The result is in processing. success : The result is completed and the outputs have been delivered. failed : The result is completed; the outputs failed to be delivered. properties : item_id : The item_id of the result. item_types : The item_type of the result. created : The time the result was generated. For a catalog source type subscription, this will be the time that the subscription acknowledges the newly published item. updated : The time that the result was last updated. completed : The time the result reached an end status of success or failed . errors : Information on result failure, including a reason and array of details . output : The directories of the final output files. You can filter subscriptions results by status (i.e. ?status=processing ) and by created , updated , or completed timestamps, using STAC API timestamp and interval conventions : A datetime: \"2020-09-01T00:00:00Z\" A closed interval: \"2020-09-01T00:00:00Z/2020-09-30T23:59:59Z\" Open intervals: \"2020-09-01T00:00:00Z/..\" or \"../2020-09-01T00:00:00Z\" As an organization administrator, you also have the ability to get subscription results for any subscription created in your organization by including the user_id=all query parameter. As an example, this API call would return all of a subscription's success results completed before September 30, 2020 (and created within the last 30 days). GET https://api.planet.com/subscriptions/v1/b9ec5d6b-8753-440a-852c-528188f914d0/results?status=success&completed=../2020-09-30T00:00:00Z Example Response { \"name\": \"Example Subscription\", \"source\": { \"type\": \"catalog\", \"parameters\": { \"asset_types\": [ \"ortho_analytic_4b\" ], \"end_time\": \"2025-11-01T00:00:00Z\", \"geometry\": { \"coordinates\": [ [ [ 139.5648193359375, 35.42374884923695 ], [ 140.1031494140625, 35.42374884923695 ], [ 140.1031494140625, 35.77102915686019 ], [ 139.5648193359375, 35.77102915686019 ], [ 139.5648193359375, 35.42374884923695 ] ] ], \"type\": \"Polygon\" }, \"item_types\": [ \"PSScene\" ], \"start_time\": \"2022-01-01T00:00:00Z\" } }, \"delivery\": { \"type\": \"google_cloud_storage\", \"parameters\": { \"bucket\": \"[your-GCP-bucket-name]\", \"credentials\": \"[base64-encoded-credentials-for-service-agent…]\" } }, \"created\": \"2022-11-21T21:46:18.392063Z\", \"_links\": { \"_self\": \"https://api.planet.com/subscriptions/v1/1ac43ca5-2ac5-48b0-a4b2-f72032cc3f03\" }, \"status\": \"preparing\", \"id\": \"1ac43ca5-2ac5-48b0-a4b2-f72032cc3f03\", \"updated\": \"2022-11-21T21:46:18.392063Z\" } Subscriptions API Limits Note These limits are validated when a subscription is created. If an organization exceeds its limits, all existing active subscriptions (i.e.: end_time has not passed) continue to deliver imagery and are not suspended or cancelled. Only new subscriptions cannot be created. Additionally, if an organization has insufficient quota, new subscriptions cannot be created, however, active systems are not be suspended or cancelled. An \"active\" subscription is one where the end_time has not passed. Subscriptions API use is limited to a maximum count of active subscriptions and a maximum total count of expected items delivered daily across all forwardfill portions of a subscriptions. Backfill portions of subscriptions are limited to 5 years of archive delivery from the defined start_time . This means that if a subscription has a start_time of December 1, 2015, a valid end_time would be December 1, 2020. If more than 5 years of archive imagery is required, we recommend creating additional subscriptions to deliver that imagery. Max Forwardfill Subscriptions : Maximum number of active subscriptions. A new subscription may not be created if an organization has already maxed out its number of active subscriptions. Total Expected Forwardfill Items Delivered Daily : Total number of expected items matched and delivered daily across all forwardfill subscriptions. A new forwardfill subscription cannot be created if its expected number of items delivered daily puts the organization over its total cap. To estimate the expected number of items a forwardfill subscription will deliver daily, the Subscriptions API uses Data API's Search Stats endpoint and averages daily items matched over the last seven days. These numbers are totaled across all forwardfill subscriptions. Note: Validation on \"expected items delivered daily\" is done upfront, at subscription creation. The Subscriptions API does not artificially limit item delivery if a subscription happens to match more items than expected on a given day. By default, customers are subject to the following limits: Max Forwardfill Subscriptions: 1,000 Total Expected Forwardfill Items Delivered Daily: 1,000 Please reach out to your Account Manager, or submit a request , if you need these limits to be increased. Rate Limiting To improve the experience for all of our users, Planet uses rate limiting to prevent overloading the system. If handled correctly, rate limiting errors can be a normal and useful part of working with the API. When a rate limit has been exceeded, the Planet API responds with an HTTP 429 response code. When this occurs, we recommend implementing retry with an exponential backoff . An exponential backoff means that you wait for exponentially longer intervals between each retry of a single failing request. The following rate limits are currently in place: Subscription Creation - 5 requests per second, per API key. Subscription Cancelation - 5 requests per second, per API key. Get Subscription - 5 requests per second, per API key. Get Subscription Results - 5 requests per second, per API key.","tags":"subscriptions","url":"https://developers.planet.com/docs/subscriptions/","loc":"https://developers.planet.com/docs/subscriptions/"},{"title":"Tasking Dashboard Overview","text":"The Tasking Dashboard is a graphical user interface that streamlines order submission and management. The Tasking Dashboard also provides the ability to preview the image captures taken for orders. NOTE The Tasking Dashboard is optimized for Desktop browsers only, currently only Chrome and Firefox. Order Entry By inputting various parameters in the Order creation windows, you can create any of the following order types: Point Line Area In the Tasking Dashboard > Create an Order > Other Requirements , the Order Type selections are: Single image, available for Point, Line and Area orders Stereo, available for Point and Line orders Tri-stereo, available for Point and Line orders NOTE During order entry, you can start over with an area of interest (AOI) by using the Trash icon at the top of the toolbar. The geometry will be removed so you can create a new AOI. Estimated Quota The functionality of quota calculations is improved. As you enter a tasking order, a quota preview displays the estimated quota in sqkm directly in the Tasking Dashboard Order Summary. Quota estimates are dynamically updated as you input and adjust requirements. Point Order Sorry, your browser doesn't support embedded videos. Point orders capture a specific point and a 2 km radius circle is automatically added to your coordinates representing the guaranteed collection area. Line Order Sorry, your browser doesn't support embedded videos. Line orders capture a rectangular area and a 5 km wide strip that is a maximum of 100 km long. Area Order Sorry, your browser doesn't support embedded videos. Area orders capture any form of an area. If the area is too large to be captured all at once, the area is tessellated into smaller strips. NOTE Area orders less than 25 sqkm are charged for a default minimum of 25 sqkm if fulfilled. Flexible Order A flexible order purchases SkySat capacity at various areas of interest (AOI). There are no guarantees on the delivery timeframe. The duration is measured from the start date to the end date of the time of interest (TOI). The order must be at least 14 calendar days and must be placed at least 24 hours before the TOI start date. To create a Flexible order, at least 24 hours before the TOI start date: Select Flexible Tasking as the product name. Set the end date to a date at least 14 days in the future from the start date. Set the following values (required): Geometry type AOI Order type (image or stereo) Off-nadir angle A maximum 30º Off-Nadir Angle (ONA) applies to all orders. This enables Planet to maximize fulfillment and deliver as many high quality captures as possible. To change the duration of the flexible order, change the values of the date-time calendar on flexible orders by hovering over the date and selecting the checkmark. NOTE The start date can only be changed if the order is pending. The end date can only be changed if the order state is pending or in progress. You can also change the date in the order detail view when you select it from the orders list: Hover over the date-time field and select the pencil icon. Change the date-time. Confirm by selecting the checkmark icon. Historical Cloud Coverage Flexible orders introduce the seven-day historical average of cloud coverage. This additional adjustment can increase transparency and improve order delivery. You can filter the data for one month, three months, six months, or one year. NOTE Not all time periods are available. Hover over a bar in the Cloud Coverage chart to view the seven-day average value. The lowest value represents the lowest seven-day average historical cloud cover in the order AOI. Assured Tasking Orders Assured Tasking orders are assured to occur at a specific time and date for a satellite while it is scheduled to be over the specified geo-coordinate. If the timeslot is within 6 hours, the order is set to Express and costs 1.5 times more than a normal Assured order. Select Assured Tasking from the Product name field. Select an imaging window for the Assured order. In the Order Summary , Assured tasking is listed under Scheduling type . Stereo Order Stereo orders take two or three captures of the same point in one order. Monitoring Order Monitoring orders capture the same point over a series of time. Available options are days, weeks and months for configuring the temporal resolution. You can also generate an additional occurrence between now and when the order is scheduled to start. Off-nadir Angles A maximum 30º off-nadir Angle (ONA) applies to all orders by default. This enables Planet to maximize fulfillment and deliver as many high quality captures as possible. Off-nadir angle warnings indicate values that are difficult to schedule or can result in image capture failures. Order Progress View the order status in the All Orders table view or the map view. Order Progress – table view Order Progress – map view In the map view, orders are clustered together initially, until you \"zoom in\" and the clusters disperse into the individual order geometries. Clicking on an individual order opens the order flyout in the right panel with more detailed information. Switch between the table view and the map view by using the control at the top right of the window. Filter by the current map view or by a manually-drawn geometry. Manually draw a geometry by opening the Draw polygon filter dialog and selecting the top control in the bottom right corner of the map. After using Select viewport or drawing a polygon in the map, click ADD AS FILTER to apply the filter. The same filter is applied to the table view. To remove the geographic filter, use the Delete option from the dialog or click X on the Geometry filter option. Order View In the table view, customers can drill deeper into their individual orders to review the configuration and status for each order. The order detail view can be expanded to display captures made for each of the orders. Each capture page also provides a link to the image in Planet Explorer to download the imagery assets. For point orders, a 25 sqkm box is drawn around the area of interest. Duplicating / Cloning an Order You can use completed orders as blueprints for new orders, eliminating the need to re-input requirements and AOIs. All fields, with the exception of the TOI are copied to the order entry form. Sorry, your browser doesn't support embedded videos. Email notifications The EMAIL PREFERENCES settings is available from the Settings menu. EMAIL PREFERENCES settings determine the details for email notifications that you receive for tasking order events in Order History . Order History The History tab lists all of the events that occurred with an order. The events include order creation, order edits and order fulfillment for the timeline. Captures Table The Captures table provides a complete overview of all image captures taken for an order. If you click on a row in the captures table, the capture modal displays. You can page through all of the image captures. Deeplink You can open the order creation window directly with the following url: https://www.planet.com/tasking/orders/new You can prepopulate order fields in the order creation form by providing additional query parameters after the order entry url. For example: https://www.planet.com/tasking/orders/new/?name=order-name&geometry=POINT(13.2275 52.5897) To access Deeplink, be sure to always start from the order entry route /orders/new and then append the query parameters. https://www.planet.com/tasking/orders/new/?name=TestOrder&plNumber=PL-Example&product=One Time Tasking&geometry=POINT(13.2275 52.5897) Supported parameters Use the following parameters in the Deeplink URL. NOTE All fields are optional. However, product specific fields require a valid plNumber. Fields without dependencies. Field Value name Maximum 80 characters geometry Geometry in WKT format plNumber Valid plNumber Fields that depend on a plNumber Field Value product Product name which belongs to given plNumber startTime Date in YYYYMMDD or YYYY-MM-DD format i.e., 2020-06-30 endTime Date in YYYYMMDD or YYYY-MM-DD format and must be later than startTime orderType Specific order type that is allowed for chosen product nStereoPov Number of stereo collects for orderType STEREO only satElevationAngleMax Satellite elevation angle max value satElevationAngleMin Satellite elevation angle min value For example: https://www.planet.com/tasking/orders/new/?name=SFO order&plNumber=PL-Impact&product=One Time Tasking&orderType=IMAGE&geometry=POINT(-122.38627 37.616862) Example with all supported parameters: https://www.planet.com/tasking/orders/new/?name=mock_order&plNumber=PL-TEST&product=Basemap&orderType=IMAGE&geometry=POINT (-98.934519 19.724712&satElevationAngleMax=90&satElevationAngleMin=60","tags":"apps-taskingdashboard","url":"https://developers.planet.com/docs/apps/taskingdashboard/","loc":"https://developers.planet.com/docs/apps/taskingdashboard/"},{"title":"Viewing a Flood Event with the Planet Explorer ArcGIS Pro Add-In","text":"Time to complete: this tutorial is expected to take anywhere from 30 minutes to 2 hours depending on your ArcGIS Pro and satellite imagery familiarity. IT'S INSTALL TIME First things first, you will need to purchase a Planet subscription here or sign up for Planet's Developer Program . If going with the latter option, there will be a link in the Planet Explorer ArcGIS Pro Add-In that you are about to install. The Planet Explorer ArcGIS Pro Add-In can be installed, but not used, until you log in. Second, if you don't already have ArcGIS Pro you will need to purchase, install, and log in to it. If ArcGIS Pro is open, it is best to close it before installing the Add-In. You can download the Add-In here. Once downloaded, double-click the Add-In file to validate it and install it. Click Install Add-In . Now open ArcGIS Pro and verify that the Add-In was installed correctly by clicking on the Project tab from a new open project, then clicking Add-In Manager from the list at left. If the Add-In is installed it will be listed in the My Add-Ins section. Click the back arrow to go back to the new project. Notice that a new ribbon is added and accessed by clicking on the Planet Imagery tab. On the ribbon, click Planet Login to fill in the credentials you obtained earlier when you purchased a Planet subscription. This dialog also has a Contact us link to sign up for Planet's Developer Program . Click log in once you have filled in your credentials. Note that login credentials must be re-entered with each new ArcGIS Pro session. The Planet ribbon (i.e., the new set of buttons now available near the top of the ArcGIS Pro window) is now active. The Basemaps drop down menu contains several mosaics to browse. Click on one and notice how it is now placed in the left-hand Contents pane under the heading Planet Basemaps , where you can turn it on and off or remove it. Use the Load More button to load more mosaics into the drop-down. Some of the mosaics have partial coverage, some have snow. They are interesting to take a look through. Remove the mosaic(s) once you are finished browsing them to keep the project clean by right-clicking on the Planet Basemaps heading and choosing Remove . IT'S CRAZY QUICK TIME Sometimes people want to jump right in. If that sounds like you, use this section as your 30-second quick-start and then proceed to the tutorial. Otherwise, skip to the tutorial. Zoom to an interesting location Click Planet Imagery > Search for Planet Imagery Draw a rectangle around your area of interest and click Search in the Search For Planet Imagery panel Browse the results and click Order IT'S TUTORIAL TIME Flooding occurred along the Missisquoi River, Vermont in early November 2019. Let's take a look at what happened there by exploring a location that was affected: Richford, Vermont. We'll see what satellite imagery is available before and during the flood, which took place on and around November 1, 2019. We've extracted the village point for Richford from OpenStreetMap and put it in a feature service , located in this directory. Download that file and its other components (i.e., also download the .cpg, .dbf, .prj, .qpj, .shx files) then drag and drop the file with the .shp extension onto the ArcGIS Pro Contents pane. Make sure it is at the top of the Drawing Order and use Alt + layer-click several times or use the mouse wheel to zoom all the way to the point. It is helpful to have the default ArcGIS Pro basemap on to locate the general town boundaries. Click Search for Planet Imagery in the Planet Imagery ribbon. A toolbar pops up on the bottom of the map view. Using the tool that is already selected, the Line tool, click on the map view to form a square around this location. At the last point of the square, right-click and choose Finish . This indicates the search area, also called Area of Interest (AOI), that will be used for your imagery searches. Your AOI will not exactly match those in the tutorial. Did you make a mistake and want to try again? Just start a new AOI. When it is completed, the old one will be discarded. But for this tutorial an approximation is okay. Notice that a new pane, and pane tab, at the left-hand side of the ArcGIS Pro window will appear that is titled Search For Planet Imagery . If you need to return to the Contents pane at any time, click the tab labeled Contents at the bottom-left of the ArcGIS Pro window or go to View > Contents in the ribbon. Next, because we want imagery from a specific time period, use the Date Acquired input boxes in the Search For Planet Imagery pane to provide two dates: 10/23/2019 and 11/03/2019. These are found in the Search section of the pane. Click the Source tab and ensure that just 4 Band PlanetScope imagery is selected. Click Search . A few PlanetScope 4-band Scenes now appear under the Search button. Unfold these using the down-arrows and browse the images in the map view by clicking them on and off here. The small preview next to each scene will indicate the general amount of cloud cover in the scene. While your list of available scenes may look different depending on the size of the rectangle you drew, in our case some of the scenes in our list look cloudy. Click the Cloud Cover tab, then move the upper slider down to 30%, then press Search . Unfold these results and notice that fewer images are available now that we've constrained the cloud cover parameters. The Nov 02, 2019 image shows some of the flooding that occurred during this \"Halloween\" storm. It will be perfect for our analysis. The other images aren't good enough for the analysis. To gain an understanding of the typical amount of water here during a non-storm-event, it will be okay to extend the date search to 10/21/2019 for the earlier date and to keep 11/03/2019 for the later date. Make that change in the Date Acquired tab and click Search again. Browsing through the new Oct 21, 2019 images, notice that the image with the suffix \"_0f32\" will be perfect for the pre-flood part of the analysis. It's now time to place an order to get the imagery since previously we were just looking at previews. The two scenes that we want to order are the Nov 02, 2019 scene with the \"_100a\" suffix and the Oct 21, 2019 scene with the \"_0f32\" suffix. Make sure these are clicked on and then click the Order button. The Order Window pops up. Unfold the 4-band PlanetScope Scene listing at the top, choose Analytic Surface Reflectance with UDM2 in the drop-down, and click the Select All box next to it to select both images that we had selected in the main Search For Planet Imagery pane. In the Order Name: box type in a name for the order and then click Place Order . A results bar appears at the bottom of the Order Window . Click the Orders tab in the main Search For Planet Imagery pane. This is where the order will appear once it is ready. Click the Refresh button to check if it is. The Status for your order will show \"running\" while it is processing and \"success\" when it is finished processing and ready to download. Once it is finished, scroll the bar to the right if needed and click the Download link. You are prompted for a download location. Click OK once you select a location for the scenes. A notification lets you know when the download is complete. Using Windows Explorer, navigate to the location where you downloaded the files and click through the various folders until you see the two .tif files we need (they will be in separate folders but it is good to verify they are both there, while leaving them in their original folders): 20191021_134736_0f32_3B_AnalyticMS_SR.tif 20191102_152019_100a_3B_AnalyticMS_SR.tif Add them to ArcGIS Pro by dragging and dropping the tif files--you know which one you need by looking at the Size in Windows Explorer, the largest ones in each folder are the correct ones--onto the ArcGIS Pro Contents pane. Click the Planet Daily Imagery box off or remove it to keep the ArcGIS Pro project clean. Notice that the first one in the above screenshot is the November 2 dated scene, which is apparent from the beginning of the file name, and the second is the October 21 dated scene. These files each have 4 bands despite the fact that ArcGIS Pro has displayed only three of them automatically. You can verify that each pixel contains four values, one for each band, by looking at the symbology for one of the scenes. Do this by right-clicking a scene in the Contents pane, choosing Symbology and clicking the drop-down next to Red in the Symbology pane that appears at the right-hand side of the ArcGIS Pro window. There will be 4 bands to choose from in this drop-down. Leave it as is, however. We want to depict the extent of change in water between the two scenes using a Normalized Difference Water Index (NDWI), which is calculated with Band 2 (corresponding to green) and Band 4 (corresponding to the near-infrared). The formula for NWDI is: NDWI = (Green - near infrared) / (Green + near infrared) In terms of the PlanetScope 4-band imagery, this formula can be expressed as: NDWI = (Band 2 - Band 4) / (Band 2 + Band 4) (There are two methods of calculating NDWI, in this tutorial we are using the Green and NIR band method rather than the near infrared and short-wave infrared method.) We want to calculate the NDWI for each of our two images. ArcGIS Pro has several pre-configured indices computations listed in the Imagery ribbon under Indices . However, our NDWI index will need to be computed via the raster calculator. Please note that this tool is only available with either the Spatial Analyst license or the Image Analyst license. Before we use the raster calculator, we first need to extract the bands from the images. To do this, open Raster Functions in the Imagery pane. In the raster Functions pane, go to Data Management > Extract Bands . Use the drop-down to choose the Oct 21 tif file. Make sure the drop-down under Band says \"2\", and type \"2\" in the Combination text box (i.e., delete the other numbers in that box). Leave everything else the same and press Create new layer . Re-name this layer by clicking on its name in the layer list, which is the list of datasets in the Contents pane, and typing, \"Oct 21 Band 2\". Repeat this process for the same Oct 21 tif file except this time for band number 4, renaming it to \"Oct 21 Band 4\". Repeat the process again two more times for the Nov 02 tif file, first for band number 2 and then again for band number 4. The Contents pane should now look like this: At this point we should also clip the bands to the area of interest. With the Nov 02 Band 4 layer active and selected (this means you need to actually click on the name of the layer so that it is highlighted) in the Contents pane, click Clip . A new layer appears in the Contents pane that is clipped to the map view's extent named \"Clip_Nov 02 Band4.\" Do this for all 4 band layers so that the Contents pane now looks like this: Now we're ready for the NDWI calculation. Click Tools in the Analysis ribbon to open the Geoprocessing pane on the right-hand side of the ArcGIS Pro window. Type raster calculator in the Find Tools box and select it in the list that appears. Note that it will appear in the list twice if you have both the Image Analyst license and the Spatial Analyst license. Either one is fine.) Expand the raster calculator panel so you can see your work better. All the rasters in the map will be displayed in the Rasters section. Using the NDWI formula, double-click the appropriate bands and fill in the appropriate math symbols for the October 21 scene until you have an expression that looks like what we show below. Note that we've named the result \"Oct21NDWI.\" Remember you can double click the raster layers in the Rasters list to populate the expression input box: Click Run in the lower right-hand corner of the Geoprocessing panel. The computed layer will appear in the Contents pane. Do the same thing for the Nov 02 computation. The results will look something like what we show below, though your raster min and max values will vary depending on your exact area of interest. To better visualize the results, we'll reclassify the data using a \"Con\" expression in the Raster calculator . Go back to the Raster Calculator in the Geoprocessing tab as before and type the following expression to create a new output raster that assigns a 1 pixel value to all pixels between two values in the result data and a 0 to all other values. Note the use of our output result name in the expression. Make sure whatever you named your output result is put into the calculation if you've named yours differently. Name this output raster \"Oct21NDWI_reclassified\". Con(( \"Oct21NDWI\">-0.35) & (\"Oct21NDWI\"<-0.2),1,0) In the Symbology tab for this new layer, choose Unique Values , change the 0 value color to No Color and the 1 value color to a blue hue as shown: Do the same thing for the Nov02NDWI layer using the following expression: Con(( \"Nov02NDWI\">-0.26) & (\"Nov02NDWI\"<-0.1),1,0) Now we can see the difference between the pre-storm event and the storm event: Please note: A land-water threshold was manually applied to classify the images into two classes, land and water. These were -0.35 and -0.2 for the October 21 results and -0.26 and -0.1 for the November 02 results. These suitable land-water thresholds for each index were determined through trial and error and comparison to reference maps generated using visual interpretation. For visual interpretation of water bodies, the near-infrared (NIR) band is usually preferred, because NIR is strongly absorbed by water and is strongly reflected by the terrestrial vegetation and dry soil - source .","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/viewing-a-flood-event-with-the-planet-explorer-arcgis-pro-add-in/","loc":"https://developers.planet.com/docs/planetschool/viewing-a-flood-event-with-the-planet-explorer-arcgis-pro-add-in/"},{"title":"Viewing a Flood Event with the Planet Explorer QGIS Plugin","text":"Time to complete: this tutorial is expected to take anywhere from 30 minutes to 2 hours depending on your QGIS and satellite imagery familiarity. IT'S INSTALL TIME First things first, you will need to purchase a Planet subscription here or sign up for Planet's Developer Program . The Planet QGIS Plugin can be installed, but not used, until you log in with your Planet account. Additionally, some functionality such as imagery download may be limited with a Developer Program account. Second, if you don't already have QGIS, download and install it by going to Download QGIS . Most likely you will want to use the QGIS Standalone Installer rather than the OSGeo4W Network Installer . Planet's QGIS plugin is designed to work on QGIS versions 3.6+. Remember that you can have concurrent QGIS installs of different versions on the same machine, so if you haven't upgraded in a while, it would be best to get the latest version, without fear of ruining older projects or needing to uninstall older versions. Once installed, start up QGIS Desktop (you can choose the with GRASS version or the one without). In the QGIS menu bar, select the Plugins drop-down, then select All if it isn't already selected, and type \"Planet Explorer\" in the Search… box. Select it in the list and press Install Plugin . A new button is added to the toolbar. Your QGIS may look different than the one below depending on the version and which panels and toolbars are open but the general process should be the same. Note: if an Enter Credentials window pops up, put in your Planet login password twice and press OK . Press the Planet Explorer button that now appears in the QGIS Toolbar section. Note that your button may appear in a different place depending on your past toolbar configurations. Once you press the button the Planet Explorer Panel will appear, located on the right-hand side of the QGIS window. Note that if you already had one or more panels open on the right-hand side of your QGIS window from previous QGIS sessions, the Planet Explorer Panel will appear at the lower-right, underneath them. Use the Email address and Password input boxes to input your credentials if you already have them. If you do not have them and would like to sign up for Planet's Developer Program , use the Sign up! link, sign up, and then return here and input your credentials. Once authenticated, the Planet Explorer Panel will look like this: If you ever close the Planet Explorer Panel and want to get back to it, simply click on View in the menu bar, then Panels , and then check the box next to Planet Explorer . IT'S CRAZY QUICK TIME Sometimes people want to jump right in. If that sounds like you, use this section as your 30-second quick-start and then proceed to the tutorial. Otherwise, skip to the tutorial. Add a dataset to QGIS Click Extent > Current visible extent in the Planet Explorer Panel Click Search Under Date acquired , check one of the checkboxes. Next to it, press the sunburst Settings button and choose Add preview layer to map . IT'S TUTORIAL TIME Flooding occurred along the Missisquoi River, Vermont in early November 2019. Let's take a look at what happened there by exploring a location that was affected: Richford, Vermont. We'll see what satellite imagery is available before and during the flood, which took place on and around November 1, 2019. We've extracted some village points in Northern Vermont from OpenStreetMap and prepared them in a geojson file called village-points.geojson , located in this directory. Download that file and drag and drop it onto the QGIS Layers Panel . Use the Draw > Rectangle button in the Planet Explorer Panel to draw a rough rectangle around the point representing Richford, which is the northernmost point in this dataset. To do this, make sure to keep the mouse button pressed while clicking and dragging the rectangle onto the QGIS map window. Note: we used the QuickMapServices plugin for QGIS to add a basemap to the project. This is optional. The map automatically zooms to this location and places a blue dashed line around it. This indicates the search area, also called Area of Interest (AOI). Next, because we want imagery from a specific time period, use the Date range (UTC) input boxes to provide two dates: 2019/10/23 and 2019/11/03. These are found in the Filters section of the panel. You may have to scroll the Filters section down to see the Date range (UTC) input section, depending on how much screen space is available for you. Then click Search . A few PlanetScope 4-band Scenes appear under the Date acquired section. Hover over those scene listings and notice that blue lines appear on the map. These show you where, exactly, the satellite captured imagery on that date. Depending on the initial size of your search rectangle, you may want to zoom out a bit in order to see the entirety of the PlanetScope imagery footprints. The image thumbnail next to each scene will also give you a sense of the general amount of cloud cover in the scene. While your list of available scenes may look different depending on the size of the rectangle you drew, in our case the first and third scenes in our list look cloudy. To see the two less cloudy images in the big map view, click the blue sunburst settings button to the right of each of them, and click Add preview layer to map . Please look closely at the following screenshot so that you can try and add the same two scenes to your map, since your list may differ from ours. Specifically, we are adding the Nov 02, 2019 and Oct 24, 2019 scenes. Notice that the QGIS Layers Panel now lists those two scenes as image previews. You can turn them on and off in the Layers Panel and pan and zoom the map to examine them. Zoom the map into the town of Richford with the Nov 02, 2019 Image preview clicked on but the Oct 24, 2019 Image preview clicked off. You can see some of the flooding during this \"Halloween\" storm in the map now: That Nov 02, 2019 image is fairly clear. However, if you click on the Oct 24 image you may notice that it looks too cloudy. Since this Oct 24 scene was going to be our before image, it is probably okay to expand our date search to a slightly earlier time frame to see if we can get a better before image. Change the first date in the Filters section to 2019/10/20 and press Search again. A new tab appears in the results area with the new search results. Add the Oct 21, 2019 scene as a preview to the map, just as we did with the other two images. This one is mostly cloud-free and will work as our before image. Close the first results tab so that just the one results tab is open: It's now time to place an order to get the imagery since we were just looking at previews up until now. Ordering an image will make it available for download, where we can run more advanced analysis on the GeoTIFF. Expand the November 2 scene listing to see that there are actually three images that we could order. Click the checkbox next to the image with the \"100a\" suffix. Expand the October 21 scene listing as well and expand the image listing with the \"0f32\" suffix. Click the checkbox next to the listing 20191021_134736_0f32 . Now click the Order button to open the order dialog. Add a name for the order and check Clip items to AOI to clip them automatically to our location. Click Place Order . Notice that the bottom of the dialog now shows an order request. Click the link provided to open your Orders monitor dialog . This will show the status of your previous orders as well as this new order. You can always get to the Orders monitor dialog again if you close it, via the User Menu button at the lower-right corner of the Planet Explorer panel shown here: Once the order status is complete the download button will be activated when you press Refresh . You will also be notified by email that the order is ready and you can download it directly from the provided email link if you prefer. If the preview scenes from earlier in our explorations are still in your QGIS project, remove them by right-clicking on them and choosing Remove . This will keep the project easier to work with. Download the zip file in the Orders monitor , unzip it, and add the scenes to QGIS by dragging and dropping the two <.tif> files with the largest sizes to the QGIS Layers Panel . Note, after unzipping the download, the data will be in a sub-folder called files. These files are called: 20191021_134736_0f32_3B_AnalyticMS_clip.tif 20191102_152019_100a_3B_AnalyticMS_clip.tif Notice that the first one is the October 21 dated scene, which is apparent from the beginning of the file name, and the second is the November 2 dated scene. Each of these files has 4 bands. You can see that each pixel contains four values by using the Identify Features button to view some of these values. PlanetScope bands are ordered: blue, green, red, NIR. Remember that for the Identify Features tool to work you must have one of the layers selected in the Layers panel (or you can right-click on the map and choose the layer you are identifying). We want to depict the extent of change in water between the two scenes using a Normalized Difference Water Index (NDWI), which is calculated with Band 2 (corresponding to green) and Band 4 (corresponding to the near-infrared). The formula for NWDI is: NDWI = (Green - near infrared) / (Green + near infrared) In terms of the PlanetScope 4-band imagery, this formula can be expressed as: NDWI = (Band 2 - Band 4) / (Band 2 + Band 4) (There are two methods of calculating NDWI, in this tutorial we are using the Green and NIR band method rather than the near infrared and short-wave infrared method.) We want to calculate the NDWI for each of our two images. In QGIS, Click Raster in the menu bar and choose Raster Calculator... All the raster bands will be displayed in the Raster Bands section. Using the formula, double-click the appropriate bands and fill in the appropriate math symbols for the October 21 scene until you have an expression that looks like this. Remember you can double click the raster bands in the Raster Bands list to populate the Raster Calculator Expression input box: But don't press OK yet! Here's the tricky part: these PlanetScope scene values are radiance values and we need what's referred to as reflectance values. To do this, we have to multiply our data by a certain coefficient that we'll find in the metadata that came with the datasets we downloaded. Go back to the metadata xml file that came with the October 21 dataset and open it in a text editor (on Windows you would right-click and choose Open with > Notepad ) and scroll to the bottom of the file. This is where the coefficients for the scene will be listed. Here is a screenshot of how this looks along with the appropriate coefficients to use. Notice the coefficients we want are listed in the band number 2 and band number 4 sections, respectively. The two coefficients for this image are: Band 2: 0.0000438963652969 Band 4: 0.0000747815337148 Applying these multipliers to the bands in the calculation we will have the following expression, which is formatted so you can simply copy/paste if you'd like. (Note that in some cases a copy/paste will cause the Rster calculator to appear strangely formatted but rest assured that the paste did work and the calculation will also still work.) Essentially, you will be replacing the calculation that you placed in the calulator earlier with this one, since it has the coefficients we need. ( ( \"20191021_134736_0f32_3B_AnalyticMS_clip@2\" * 0.0000438963652969 ) ( \"20191021_134736_0f32_3B_AnalyticMS_clip@4\" * 0.0000747815337148 ) ) / ( ( \"20191021_134736_0f32_3B_AnalyticMS_clip@2\" * 0.0000438963652969 ) + ( \"20191021_134736_0f32_3B_AnalyticMS_clip@4\" * 0.0000747815337148 ) ) Be sure to provide a name for the output in the Output layer input box at the upper-right of the Raster Calculator dialog. A suggestion is to make sure the name has the date of this scene in it. Then click OK . It will do this math on every pixel in the image. Do this entire process for the November 2 scene, remembering to get the coefficients from its metadata file, as they will be different. When finished it will look something like this, remembering that your result numbers will be slightly different because your AOI will be slightly different. McFeeters (1996) reports that the NDWI results in negative or zero pixel values when they represent soil and vegetation but that the results will have positive values when they represent water. In our case, on visual inspection, the data may seem to lend itself to a slightly lower threshold of perhaps -0.1 and higher. To comport with the existing literature and to proceed with the least error of commission, we will still use zero as our lower threshold even though some water may not be captured. So we are interested in visualizing just the values in both result layers that are greater than zero. Open the Layer Styling Panel if it is not already open using the View drop-down in QGIS's menu bar, and then Panels > Layer Styling . For both layers, follow the same procedure. In the Layer Styling Panel change the first drop-down to one of the layers that was just calculated (this will probably already be the case), then change the second drop-down to Singleband pseudocolor . Change the Min input box to 0. The Color ramp should be set to Blues if it isn't already. The project should look something like this: Double-click the color rectangle next to the \"0\" value in the Layer Styling Panel , change the Opacity input box to 0% and press OK . This makes all the zero values transparent. Take a look at the result on top of the corresponding scene layer. This seems to give us an adequate and conservative approximation of water volume for this scene for our demonstration purposes. Do the same to the other layer. Now we have measurable depictions of the change in water from before a storm event to after a storm event. Citation: S. K. McFEETERS (1996) The use of the Normalized Difference Water Index (NDWI) in the delineation of open water features, International Journal of Remote Sensing, 17:7, 1425-1432, DOI: 10.1080/01431169608948714 Please note, in many cases flood events correspond with high cloud events. Therefore, it may not be possible to perform this same type of analysis on every flood event. Additionally, this analysis is not ground-truthed and no estimate of error was attempted. This tutorial is for demonstration purposes only and fitness for use of this calculation must be made before applying to real-world scenarios.","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/viewing-a-flood-event-with-the-planet-explorer-qgis-plugin/","loc":"https://developers.planet.com/docs/planetschool/viewing-a-flood-event-with-the-planet-explorer-qgis-plugin/"},{"title":"Visualize Planet Analytics insights for Port Activity monitoring using QGIS","text":"Time to complete: this tutorial is expected to take anywhere from 30 minutes to 2 hours depending on your QGIS and satellite imagery familiarity. In this tutorial, you will learn how to explore Planet Analytic Ship Detection Feeds , visualize Collections over your AOI and derive insights from them using QGIS. Make sure to review our public Analytic Jupyter Notebooks for more knowledge on retrieving Collections from different Feeds . What will you need? We will be using Python 3+ to download Collections using the Analytics API with a Jupyter Notebook . Therefore, make sure the requests and notebook packages are installed. We will use QGIS v3.10, which is the most stable and recommended version at time of creation of the tutorial. And for plotting, we will be using Plotly , which extends QGIS native plotting features. The plugin can easily be found and installed from the QGIS plugin manager. You will also need to make sure you have a Subscription to Planet Analytic Vessel Detection Feeds, although a subscription for Airplane detection should work too. If you don't have one, you can contact our Sales team to request trial access. But, what are Analytic Feeds? Planet Analytics leverages machine learning and computer vision techniques to extract critical objects and features from Planet imagery, providing customers with deeper insights at a higher frequency than ever before. Currently, insights are delivered in the shape of raster layers for Buildings and Roads detection Feeds while Ships and Airplanes detections are packaged as GeoJSON FeatureCollection objects. A final note before we start: You have probably noticed that the words Feeds , Subscriptions and Collections on this tutorial have been consistently emphasized . That is because they are important concepts that we need to know to understand how Planet Analytics work. Let's define them: Feeds : an analytic derived from Planet imagery. Subscription : the access you will have to a Feed in terms of an Area of Interest (AOI) and Time Interval of Interest (TOI). Collections : Analytic outputs from Planet's computer vision models. Learn more about Planet Analytics here . Let's Download the data Tip: The code found in the following section is extracted from a this Jupyter Notebook ; view that Notebook for additional details. To create a new Jupyter notebook and run the following code blocks in iPython cells, simply run the following command from a terminal: jupyter notebook Retrieving subscriptions Using your Planet API key, make a call to the Analytics API to GET all of your subscriptions. import os import requests # Build URL for the Subscriptions endpoint BASE_URL = \"https://api.planet.com/analytics/\" subscriptions_list_url = BASE_URL + \"subscriptions\" # construct auth tuple for use in the requests library BASIC_AUTH = (\"PASTE YOUR API KEY HERE\", \"\") # Make GET call response = requests.get(subscriptions_list_url, auth=BASIC_AUTH) # Parse JSON response into a variable subscriptions = response.json()[\"data\"] # List all subscriptions by name and ID for s in subscriptions: print(\"Subscription name: {}, ID: {}\".format(s[\"title\"], s[\"id\"])) Now, let's pick a Subscription to pull results for and use it for our example. Copy the chosen Subscription ID and paste it inline on the code below. import json subscription_ID = \"PASTE YOUR SUBSCRIPTION ID HERE\" # Construct the url for the subscription's results collection subscription_results_url = BASE_URL + 'collections/' + subscription_ID + '/items' # Get subscription results collection resp = requests.get(subscription_results_url, auth=BASIC_AUTH) if resp.status_code == 200: subscription_results = resp.json() else: print('Something is wrong:', resp.content) Setting Collections Time of Interest (TOI) Let's define a time window to look for Collections . In the code below, we will use a 60 days window, but you can edit that parameter to include Collections on less or more days. from dateutil.parser import parse from datetime import timedelta, datetime # Let's first grab the latest published features results = sorted(subscription_results['features'],key=lambda r: r[\"properties\"][\"observed\"], reverse=True) latest_feature = results[0] # And set the END_DATE of our timeframe to that latest date (We need to use Date objects here) end_date = parse(latest_feature['created']).date() print('Latest feature observed date: {}'.format(end_date.strftime(\"%Y-%m-%d\"))) # Set our date filter to START N days prior to the latest observed date. Change *days=N* to your desired number of days start_date = latest_date - timedelta(days=60) print('Aggregate all detections from after this date: {}'.format(start_date.strftime(\"%Y-%m-%d\"))) Get Collections Now, let's apply the time window filter above and iterate through all the pages of our Subscription results. # Helper function for paginating API response def get_next_link(results_json): for link in results_json['links']: if link['rel'] == 'next': return link['href'] return None # GeoJSON object to populate with detections feature_collection = {'type': 'FeatureCollection', 'features': []} next_link = subscription_results_url # Iterate through all pages of subscription results while next_link: results = requests.get(next_link, auth=BASIC_AUTH).json() # Sort features by observed date, descending next_features = sorted(results['features'],key=lambda r: r[\"properties\"][\"observed\"], reverse=True) if next_features: # Add only the features 1 day before end date. for f in next_features: if (parse(f['properties']['observed']).date() >= start_date and parse(f['properties']['observed']).date() < end_date): feature_collection['features'].extend([f]) # Check if there are more features within the requested time period on the next pages latest_feature_creation = parse(next_features[0]['properties']['observed']).date() earliest_feature_creation = parse(next_features[-1]['properties']['observed']).date() if earliest_feature_creation >= min_date: print('Fetched {} features fetched ({}, {})'.format( len(next_features), earliest_feature_creation, latest_feature_creation)) next_link = get_next_link(results) else: next_link = False else: next_link = None print('Total features: {}'.format(len(feature_collection['features']))) # Create downloading directory if not os.path.exists(\"data\"): os.mkdir(\"data\") # Save features as GeoJSON file filename = 'data/collection_{}_{}.geojson'.format(subscription_ID, start_date.strftime(\"%Y%m%d\")) with open(filename, 'w') as file: json.dump(feature_collection, file) print(\"File saved at {}\".format(filename)) Let's visualize the data in QGIS Go over to your QGIS Desktop, load your preferred Basemap layer, such as OSM standard, and add the recently downloaded GeoJSON with our set of Collections . Data preparation As you can see, this dataset contains all of the Ship detections observed through out the last 10 days on our Area of Interest (AOI). Although already helpful, the dataset is not filtered nor categorized, so understading insights such as daily activity on the port might be not straightforward. In order to create better visualizations from this data and make that understanding more direct, we'll need to do some data shaping. For instance, since we want to plot detections per day, it would look nicer if our timestamps contained only date information. We can get that information simply by parsing the dates from the existing observed field. In QGIS, open the Collections attribute table and make the layer editable (1). Then go ahead and open the Field Calculator tool (2). Let's use add the conversion function to_date() to convert the datetime objects stored in the field Observed into date -type objects saved on a new field called date . After we saved the changes to the layer, we need to group all the detections daily using the field we just added. To do that, we will make use of Virtual Layers . Go over to Layer > Create Layer > New Virtual Layer . On the new window, give your Virtual Layer a name. On the Embedded layers section, click on import to load our Collections layer (1) . On the Query section, copy the following SQL statement using the name of your Collections layer (2) . Click on Add to add layer to our Map extent. select \"date\", count(*) as nr_of_ships from \"YOUR_COLLECTIONS_LAYER\" group by \"date\"; Planet's model performance for Vessel dections is around 70% in precision, recall and F1. Hence, we recommend the product to be used for applications in conjunction with other data sources. To make our visualisation more insightful, we can also create a virtual layer to show only those detections where we are mostly sure the objects detected are ships, i.e., those where the confidence score is more than 90%. Repeat the previous step, go to Layer > Create Layer > New Virtual Layer and use the following SQL query: select \"date\", count(*) as nr_of_ships from \"YOUR_COLLECTIONS_LAYER\" where score >= 0.9 group by \"date\"; Data visualization Now that we have the data in the shape we want it, let's use Plotly to create subplots for both our virtual datasets. Once installed, a Plotly button will appear on the top right side in your panels. Click on it to start plotting. First, let's visualise all of the detections using a bar plot, so make sure that option is selected as Plot Type . On the Plot Parameters section, select the All_vessels virtual layer we just created. We want to plot the number of ships detected (Y-axis) on a daily basis (X-axis) for our complete TOI. Hit Create Plot to get our first graph. Now, let's add the graph for all the high confidence detections. On Plotly, repeat the steps above but this time selecting our Filtered vessels layer. Choose a different color for the new bar graph for contrast. Hit Create Plot to add the second plot to our main graph. You can always modify your plot Settings within Plotly. For instance, for the plot above, we decided to overlay our bars instead of stacking or grouping them. And that's it! Now, you can easily visualize daily activity over your port of interest by leveraging Planet's high frequency imagery, high performance machine learning models and open source QGIS tools. You can export these plots also as more interactive ´.html´ files that can be pasted within reports, in web applications or slides decks to share.","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/visualize-planet-analytics-insights-for-port-activity-monitoring-using-qgis/","loc":"https://developers.planet.com/docs/planetschool/visualize-planet-analytics-insights-for-port-activity-monitoring-using-qgis/"},{"title":"Building a Simple Web Map with Planet APIs","text":"Introduction This tutorial will cover how to build a basic web mapping application that utilizes Planet's APIs. The first few sections cover basic Web Development principles, Planet APIs, and Mapping Libraries. If you are familiar with these topics and just want to start with code, jump to the Writing the App section . If you would rather view this content video form, you can watch the session \"Build Web Applications with Planet data and APIs\" from Planet Explore 2020 . You can download the sample code for that session here . Before you start You will find tutorial this useful if you want to do any of the following: Develop a web application that uses Planet's APIs Use Planet data with a web mapping library, such as OpenLayers or Leaflet This is an intermediate tutorial. While it will cover the basics of web mapping, you should already be familiar with the following concepts: Web Application Development — JavaScript, CSS, and HTML Command Line Interface (CLI) Basic spatial concepts REST APIs Web (\"slippy\") maps For coverage of some of these topics, review the Planet 101 section of the Planet School . Why Make a Web Application? Web Maps provide many benifits when compared to traditional Desktop GIS, but have their own set of drawbacks. Consequently, it is useful to review both the benefits and limitiations of web app development in general, and web mapping in particular. The most common benefit web apps provide is accessibility. Most modern data and service providers expose Application Programing Interfaces (or APIs) for accessing more complex capabilites, often exposed through the web. While useful and versatile, these APIs aren't epecially user-friendly, particularly if you only need one specific capability. You can often make a Web App that takes advantage of a specific feature of an APIs and provides a much nicer user experience relatively easily. Additionally, since web apps are served over the web, they are both multiplatform and easy to distribute (as opposed to desktop apps, which often require custom installers and other special considerations for each platform you want to support). These days, web development is a very broad field, which means there many different libraries and frameworks available to handle any number of things you might want to do, making web dev fairly approachable to new developers. There are some use cases you should avoid when considering whether to make a web app. The major one is heavy data processing - JavaScript keeps getting more efficient (and browsers more powerful), but its still a fairly slow programming language, and many users have limited hardware. Instead, you should leave the heavy lifting to desktop applications or dedicated servers. You can still expose any results of such processing through a web app using your own APIs. The GIS sphere has a particularly large number of processiong-intensive use cases - a couple specific things to avoid are: Raster transformations (including reprojection, and band math) Bulk data operations (anything touching more than around 100 MB data or 10,000+ features) Common use cases that are a good fit for web apps include: Rendering web tiles Overlaying vector data raster basemaps Searching, filtering, and browsing spatial data Planet Data in Web Maps Planet provides both data and APIs that you can make use of in your web maps. We also host several web applications that expose this data, which may be an easier alternative to making your own web app. Planet Explorer is our flagship web application. Its core function is to search and view Planet data, and to order that data for local (or cloud) delivery. If you are thinking of making a web app for some purpose, its a good idea to see if Explorer already does the thing you need. If it doesn't, Explorer still provides an example of a large web application that utilizes Planet APIs and may help inform how you want to structure your own app. For more information on Planet Explorer, refer to the Planet Apps page When making a web map that uses Planet data, you'll want to make sure you are familiar with Planet's APIs For detailed information about these APIs, refer to the Planet APIs page . The following sections will provide a brief summary of each within the context of web mapping. Tiles API The Tiles API serves tiles of Planet imagery. These tiles can then be used by a mapping library to display a map in a web-friendly manner. All the images you see in Planet Explorer are served via the tiles API. If you're making a web app, you will most likely be using this API. If you are new to web mapping, you may be wondering what exactly is a tile? If so, review XYZ Tiles and \"Slippy Maps\" , as it provides a good overview of this topic. A mapping library will keep track of what tiles correspond to your current zoom level and viewport, and request only those tiles for display. The Tiles API provides both XYZ and WMTS endpoints, and exposes tiles for basemaps and items (although items are only available as XYZ). In general, these endpoints are structured as follows: Basemap XYZ: https://tiles.planet.com/basemaps/v1/planet-tiles/BASEMAP_NAME/gmap/{z}/{x}/{y}.png WMTS: https://api.planet.com/basemaps/v1/mosaics/wmts (Individual tile URLs are the same as XYZ, above) Item XYZ: https://tiles.planet.com/data/v1/ITEM_TYPE/ITEM_ID/{z}/{x}/{y}.png Basemaps API The Basemaps API provides utilities for searching available Planet basemaps by TOI, AOI, or other metadata. In this context, \"basemaps\" are harmonized imagery covering a large area (as opposed to scenes, described later). You will still need to use the Tiles API to display these basemaps, but this API can let you find basemaps that match certain critera, and provide the tile URLs you'll use to display them. If your app uses a fixed tileset, you might only use this API manually while developing the app, to find the tileset you'll use Alternatively, if you want to support a dynamic set of basemaps, you can integrate this API into your app. For example, if you want to include a time slider to change the displayed map based on the corresponding time, you can use this API to search for basemaps within a given TOI, and new times will automatically show up in the app as soon as they are available from the Planet Platform. Data API The Data API provides utilities for searching Planet scenes and items (raw imagery captured by a sattelite) This is normally the first API you'd encounter when using Planet imagery, but it is a little less useful in web mapping context, as basemaps are more visually coherent within a web map. Additionally, nearly all the capabilities of the Data API are already available through Planet Explorer, so if you want a UI on top of the Data API Explorer already fills that need. However, if you have a use case that requires viewing individual items you can use the Data API to find those items. You will still need to use the Tiles API to actually display the items. The vector geometry and bounds of the item are provided by the Data API, and can be used directly. If you do use the Data API in your web app, the @planet/client JavaScript library serves as an easy-to-use wrapper for most of its capabilities. I reccomend using it either if you have multiple users with their own API key (I'll go into more details on such use cases later), or want to use the basic capabilities of the Data API in your app. Analytics API The Analytics API allows you to search for Planet Analytic Feeds and view feed metadata Planet provides two types of Analytic Feeds: Classification feeds. These feeds are served as basemaps, so while you can discover them using the Analytics API, you must use the Tiles API to display them. Object detection feeds. The geometry of these feeds can be retrieved directly from the Analytics API, and then displayed using a mapping library. This API is best used in conjunction with basemaps to highlight some feature or class. Orders API The Orders API allows you to order items for local or cloud delivery. Much like the Data API, the Orders API is less useful for web apps, both because it is more applicable to desktop applications, and because Planet Explorer already exposes much of its functionality. Tasking API The Tasking API allows you to task specific locations for high-resolution imaging. This API was released relatively recently compared to the others, so it hasn't seen much use yet in web mapping contexts, but Planet does provide a Tasking Dashboard to expose this capability as a web app. Web Mapping Libraries In order to actually visualize the tiles and other data obtained from Planet's APIs, you'll need a web mapping library. There are a number of different mapping libraries available. As such, it is generrally a good idea to pick the one that best fits your use-case. However, all of them can do basic web mapping, so if there is one you are already familiar with and you have a simple use case, you can just use the one you already understand. The two most popular general-purpose libraries are OpenLayers and Leaflet , both of which are free and open-source. Additionally, most commercial GIS providers distribute their own mapping library for integrating with their systems. These include (but are not limited to) ESRI ArcGIS, Google Maps, Microsoft Bing Maps, and MapBox GL JS. If you are already using one of these platforms, then you'll most likely want to use the matching library. Leaflet Leaflet is a lightweight mapping library that is good for simple applications. It is small, fast and efficient. Leaflet supports all basic mapping tasks, but lacks more advanced capabilities. I recommend using it if you want to get a simple web map working quickly. Sample code for creating a Leaflet web map: const map = L.map('map').setView([37.783, -122.395], 12); L.tileLayer( 'https://tiles.planet.com/basemaps/v1/planet-tiles/global_monthly_2020_01_mosaic/gmap/{z}/{x}/{y}.png?api_key=' + getPlanetApiKey(), { id: 'global_monthly', maxzoom: 22 }).addTo(map); OpenLayers OpenLayers is a comprehensive mapping library that has been under continuos development since 2006. It has a large feature set, and is readily extensible, so you can use it to do just about anything. However, this does come at a cost - the distributable is more than 10 times the size of Leaflet, and the library itself can be complicated to use. I would recommend using OpenLayers if you want to do something more complicated, or need to build a customizable web map integration. Sample code for creating an OpenLayers web map: const map = new Map({ target: 'map', layers: [ new TileLayer({ source: new XYZ({ url: 'https://tiles{0-3}.planet.com/basemaps/v1/planet-tiles/global_monthly_2020_01_mosaic/gmap/{z}/{x}/{y}.png?api_key=' + getPlanetApiKey() }) }) ], view: new View({center: fromLonLat([-122.395, 37.783]), zoom: 12}) }); Other Tools In addition to web mapping libraries, you'll also need a few core JS tools to manage basic functions. If you are already familiar with web development, you can skip this section. Node.js and npm Node.js is a local JS runtime, used to run JS on desktop systems when developing an app. npm is the node package manager, used for downloading libraries and managing your own application, and is bundled with Node.js. While you can technically do web dev without these, you should use them, they'll make development a lot easier. Code Editor To actually write your app, you'll need a code editor. This can be a dedicated JavaScript development environment like VSCode, or a plain text editor such as Notepad++, Sublime Text, or emacs. Web Frameworks Web Frameworks provide a variety of tooling for app development and composition, and should generally be used for any nontrivial app. Some of the most popular are React, Vue, and Angular. If your organization favors a particular one, use that, as it makes it easy to trade elements between individual applications. Most mapping libraries either integrate naturally with these frameworks or have additional integration libraries. Writing the App Now that I've gone over everything needed to make a web map, I'll walk through creating a simple web map. Prerequisites Node.js A Planet Account, with streaming access to basemaps or other imagery Initialization The first thing to do before writing any code is to setup the app. If you don't already have have Node.js installed, do that first . Then, create a new empty directory for your app code to live in. If you are using a web framework, this is where you would initialize a blank project in that framework. Since this sample app is a trivial example, we'll just use npm init to create an empty Node app: npm init Now, install any dependencies - here we are using OpenLayers and the Planet JS client : npm install --save ol @planet/client The --save argument tells npm to save these as dependencies in the package.json file that describes our app (which was created by npm init ) Note: While this example uses OpenLayers, you can change it to use another mapping library by replacing the contents of index.js with the approapriate code snippet from the Web Mapping Libraries section , above. You'll also need to install the alternate mapping library - e.g. use npm install --save leaflet to install Leaflet . Content We can now start adding content to the app. All web apps are made of 3 main types of files: Layout (HTML) Style (CSS) Script (JS) I'll start by creating an index.js file in the src subfolder, with corresponding index.html and index.css files in the dist subfolder. The index.html file describes the structure of the app. Most of the actual functionality will be handled by the .js file, so this is pretty basic - it includes a page title, some metadata, a header, and a spot for the map, as well as imports for the css and js files. dist/index.html : <html> <head> <meta charset=utf-8 /> <title>Planet Webmap App</title> <link rel=\"icon\" href=\"favicon.ico\" /> <meta name='viewport' content='initial-scale=1,maximum-scale=1,user-scalable=no' /> <link href=\"index.css\" rel=\"stylesheet\" > </head> <body> <noscript> You need to enable JavaScript to run this app. </noscript> <div> <header class=\"pl-header mdl-layout__header\"> <img src=\"planet_white.png\" class=\"pl-logo\" alt=\"logo\" /> <span class=\"flex-space\"></span> <button id=\"logout\" onclick=\"logout()\">Sign Out</button> </header> <div id='map'></div> </div> <script src=\"./index.js\"></script> <script src=\"./login.js\"></script> </body> </html> The index.js file describes the functionality of the app, which is to display a map. This example will use openlayers; if you want to see how to do the same thing in leaflet refer back to the Leaflet slide. For this map, we use the Planet global monthly mosaic for January 2020, with initial zoom level and viewport centered on downtown San Francisco. To find other basemaps you have access to and can add to your web map, you can use the Basemaps API - the following API request will list the 50 most recent basemaps available to you: https://api.planet.com/basemaps/v1/mosaics?api_key={your api key} src/index.js : import Map from 'ol/Map'; import View from 'ol/View'; import TileLayer from 'ol/layer/Tile'; import XYZ from 'ol/source/XYZ'; import { fromLonLat } from 'ol/proj'; import 'ol/ol.css'; import {getPlanetApiKey} from './login.js' const map = new Map({ target: 'map', layers: [ new TileLayer({ source: new XYZ({ url: 'https://tiles{0-3}.planet.com/basemaps/v1/planet-tiles/global_monthly_2020_01_mosaic/gmap/{z}/{x}/{y}.png?api_key=' + getPlanetApiKey() }) }) ], view: new View({ center: fromLonLat([-122.395, 37.783]), zoom: 12 }) }); Last but not least, the .css file describes the styling of the app, or how everything looks. Since the mapping library we are using includes its own styling for the map components, we just need to style the header, and reserve a space for the map. dist/index.css : body { margin: 0px; } #map { position: absolute; top: 70; bottom: 0; left: 0; right: 0; width:100%; } .pl-logo { height: 50px; margin: 10px; } .flex-space { flex-grow: 1; } .pl-header { background-color: #282c34; align-items: flex-start; color: white; display: flex; align-items: center; } Authentication Before continuing with the example, I'd like to go into a brief aside about authentication. Planet APIs use an API key for authentication. This is a secret sequence of characters used to provide access to our APIs to a single user (be that a person or an organization). You should not expose your API key publicly, which in most cases means it should not be included in source of a web app. However, you still need to use the API key to access the imagery being displayed. The method for accomplishing both these requirements will differ depending upon your use case: If all users of your app have their own Planet Account (and corresponding API key), you can use the auth capabilities included in the @planet/client library and allow each user to log in to planet. While this still results in including an API key in requests from the app, you are sending the API key of the user using the app, so the only api key visible is their own. This is the approach Planet Explorer takes, and is what we will be using in this example. If instead you want a public app where unauthenticated users can view map tiles, you should set up a proxy server that intercepts valid, authorized requests from your app and appends a service-level API key. This does raise other secrity concerns (such as random users consuming all your tile quota.). Implementation of this is out-of-scope for this presentation. If you have an internal-only or single-user app, it is reasonable to use a fixed API key, but this is still not reccomended. If you must use this approach, you should at least use an environment variable or secret store to make it easy to change and avoid leaking it through a file share or version control system. Adding a Login Page Note: If you do not have a Planet Account, skip this section, and modify the app to use a basemap that doesn't require authentication: Edit src/index.js and replace the line url: 'https://tiles{0-3}.planet.com/basemaps/v1/planet-tiles/global_monthly_2020_01_mosaic/gmap/{z}/{x}/{y}.png?api_key=' + getPlanetApiKey() with a freely available basemap, such as OpenStreetMap: url: 'https://{a-c}.tile.openstreetmap.org/{z}/{x}/{y}.png' Edit src/index.js and remove the line import {getPlanetApiKey} from './login.js' Edit dist/index.html and remove the line <script src=\"./login.js\"></script> To implement these authentication recommendations, we're going to add a new page that presents a login dialog and saves the API key to local storage Create login.html , to define a dialog with username and password fields and login.js for the login functionality: dist/login.html <html> <head> <meta charset=utf-8 /> <title>Planet Webmap Login</title> <link rel=\"icon\" href=\"favicon.ico\" /> <meta name='viewport' content='initial-scale=1,maximum-scale=1,user-scalable=no' /> <link href=\"index.css\" rel=\"stylesheet\" > </head> <body> <noscript> You need to enable JavaScript to run this app. </noscript> <div id=\"login-container\"> <div class=\"login-modal\"> <div class=\"login-dialog\"> <div class=\"pl-header\"><img src=\"planet_white.png\" class=\"pl-logo\" alt=\"logo\" /></div> <div class=\"login-body\"> <div><input id=\"email\" type=\"text\" placeholder=\"Email address\" name=\"email\" required></div> <div><input id=\"password\" type=\"password\" placeholder=\"Password\" name=\"password\" required></div> <div><button id=\"login\" onclick=\"login()\">Sign In</button></div> <div id=\"error\">Error: Invalid email or password</div> </div> </div> </div> </div> <script src=\"./login.js\"></script> </body> </html> src/login.js : import '@planet/css/lib/main.css' import auth from '@planet/client/api/auth'; const STORAGE_KEY = 'planet-token-4ux3ak8eqtypr4dh'; const sessionStorage = window.sessionStorage; function login() { const email = document.getElementById('email') const password = document.getElementById('password') const response = auth.login(email.value, password.value).then(() => { if (auth.getToken()) { sessionStorage.setItem(STORAGE_KEY, auth.getToken()); email.value = ''; password.value = ''; window.location.href = '/'; } }).catch(error => { password.value = ''; document.getElementById('error').style.visibility = 'visible'; }) } function logout() { auth.logout() sessionStorage.removeItem(STORAGE_KEY); window.location.href = '/login.html'; } export function getPlanetApiKey() { return auth.getKey(); } window.auth = auth; window.login = login; window.logout = logout; const storedToken = sessionStorage.getItem(STORAGE_KEY); if (storedToken) { auth.setToken(storedToken) } else if (window.location.pathname != '/login.html') { window.location.href = '/login.html'; } Additinally, add styling rules to the existing index.css file for the new dialog and the logout button in the header of the index page: dist/index.css : button { border-radius: 5px; border-width: 1px; padding: 5px 10px; } .pl-header > button { color: white; background-color: transparent; border-width: 2px; margin: 10px; } #login-container { position: absolute; top: 0; bottom: 0; left: 0; right: 0; width: 100%; height: 100%; } #error { visibility: hidden; color: red; } .login-modal { background-color: rgba(0, 0, 0, 1); width: 100%; height: 100%; display: flex; align-items: center; justify-content: center; } .login-body { margin: 10px } .login-body > * { margin: 5px; } .login-dialog { display: inline-block; background-color: white; border-radius: 5px; overflow: hidden; text-align: center; } .login-body > div > input { width: 100% } .login-body > div > button { border-color: black; color: white; } .login-body > div > button { color:black; border-color: black; background-color: white; } I'm not going to go into too much detail about how this all works, since the focus here is on the map portion. You can download all the example app files here if you run into any problems getting these changes to work. Packaging The last step before the app is ready to run is to handle packaging Because we rely on third-party libraries for the mapping and authentication functionality, we must include them in our app somehow. You could just link them from index.html, but this gets difficult to maintain with lots of dependencies, so instead we'll add a build step to package.json that does this for us. We'll also add some devDependencies that will be used to actually do the packaging. These dependencies are only used to assist app development, and are not included in the app itself. Modify package.json to have the following content: package.json : \"name\": \"planet-webmap\", \"version\": \"1.0.0\", \"private\": true, \"scripts\": { \"build\": \"webpack\", \"clean\": \"rm -rf dist/*.js\", \"serve\": \"webpack-dev-server\" }, \"dependencies\": { \"@planet/client\": \"&#94;3.0.0\", \"ol\": \"&#94;6.3.1\" }, \"devDependencies\": { \"css-loader\": \"&#94;3.5.3\", \"file-loader\": \"&#94;6.0.0\", \"style-loader\": \"&#94;1.2.1\", \"webpack\": \"&#94;4.43.0\", \"webpack-cli\": \"&#94;3.3.11\", \"webpack-dev-server\": \"&#94;3.11.0\" }, \"browserify-css\": { \"autoInject\": true, \"minify\": true, \"rootDir\": \".\" } } In addition to the new content in package.json , we also need a configuration file for the packaging. This defines the input and output files, as well as loaders for handling certain file types, like css (since we are importing css files from the mapping library). Create a new file named webpack.config.js : webpack.config.js : const path = require('path'); module.exports = { mode: 'development', entry: { index: './src/index.js', login: './src/login.js', }, module: { rules: [ { test: /\\.css$/, use: [\"style-loader\",\"css-loader\"] }, { test: /\\.(png|jpe?g|gif)$/, use: [ 'file-loader' ] }, ], }, output: { filename: '[name].js', path: path.resolve(__dirname, 'dist'), }, devServer: { contentBase: path.join(__dirname, 'dist'), compress: true, port: 9000 } }; Testing and Deploying Finally, we are ready to build and run the app: npm run build runs the build script to package the depdencies with your app, outputting the result to the dist folder. npm run serve runs a local web server hosting this content on localhost:9000 . When first navigating to the app, you will be presented with a login dialog: After entering your Planet credentials and clicking Sign In , the app should look something like this: When deploying the app to a real webserver, you just need to run the build and then copy the contents of the dist folder to your server. If you run into any problems building and running the app, you can download the full example app here . Next Steps This basic example web map is broadly applicable to most use cases, but to actually make it useful, you'll probably want to add more functionality. Depending upon what you need, the steps to do so may vary. Here are some resources to get you started: Custom Controls Custom controls can let you extend the capabilities of your web map beyond what is possible with the default functions provided by your mapping library. For example, you could add a time slider that incorporates the Basemaps API to swap between monthly basemaps, or a search box that uses the Data API to jump between different scenes. The methods for writing custom controls differs between the different mapping libraries, but here's some useful resources to get you started: Openlayers provides an example of a Custom Control. For your first attempt at custom OpenLayers controls, I'd reccomend copying that example and gradually modifying it to get something like what you want. The Leaflet Tutorials page includes a 3-part tutorial on Extending Leaflet; the third part covers custom controls. Vector Data While this example only covered map tiles, you can also display vector data (e.g. scene footprints from the Data API or Object Detections from the Analytics API). Openlayers provides examples of loading a GeoJSON object as well as a GeoJSON file . You can also apply custom styles to your vector layers. To add Vector data in leaflet, you can use the Polygon object . If you have GeoJSON data, you can just pass the coordinates of the GeoJSON geometry to the Polygon (Or PolyLine or CircleMarker , for line or point geometries, respectively). Resources Planet Resources Example Web Map code Developer Resource Center Planet Explorer Planet API Docs @planet/client on npm Other Resources Node.js OpenLayers Leaflet","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/building-a-simple-web-map-with-planet-apis/","loc":"https://developers.planet.com/docs/planetschool/building-a-simple-web-map-with-planet-apis/"},{"title":"Planet School","text":"Not sure where to begin with geospatial data? Need a hand getting started with web resources like Planet's API? Planet School is here to help. Planet School is aimed at data scientists, software engineers, imagery analysts, and more: anyone who is engaged in working with Earth Observation imagery and interested in learning more about basic EO and geospatial concepts. Below you'll find a collection of self-guided tutorials with the information you need to get up to speed on tools and technology that will let you get the most out of Planet's data.","tags":"pages","url":"https://developers.planet.com/docs/pages/planet-school/","loc":"https://developers.planet.com/docs/pages/planet-school/"},{"title":"PlanetScope","text":"PlanetScope, operated by Planet, is a constellation of approximately 130 satellites, able to image the entire land surface of the Earth every day (a daily collection capacity of 200 million km²/day). PlanetScope images are approximately 3 meters per pixel resolution. Constellation and sensor overview The PlanetScope satellite constellation consists of multiple launches (\"flocks\") of Dove satellites. On-orbit capacity is constantly improving in capability and quantity, with technology improvements deployed at a rapid pace. Each satellite is a CubeSat 3U form factor (10 cm by 10 cm by 30 cm). Since our first launch in 2014, we have released three PlanetScope instrument types: Instrument Name Instrument Id Description Dove Classic PS2 Built with a telescope we call \"PS2\", this instrument captures red, green, blue, and near infrared channels. It produces Scene products which are approximately 25.0 x 11.5 sq km. Earliest imagery available on July, 2014 to April 29, 2022. Dove-R PS2.SD Built with the same \"PS2\" telescope, but with updated Bayer pattern and pass-band filters, this instrument captures red, green, blue, and near infrared channels. It produces Scene products which are approximately 25.0 x 23.0 sq km. Earliest imagery available is on March, 2019 to April 22, 2022. SuperDove PSB.SD Built with a telescope we call \"PSB\" and the same filter response as PS2.SD instrument, this instrument captures red, green, blue, near infrared, as well as a new red edge, green I, coastal blue, and yellow channel. It produces Scene products which are approximately 32.5 x 19.6 sq km. Earliest imagery available is mid-March, 2020 to current monitoring. You can read a more detailed overview of our PlanetScope Constellation and Sensors here . For detailed technical information on PlanetScope images refer to PlanetScope Product Specification . Imagery products Item types PlanetScope Products are available for search and download via Planet's APIs, User Interfaces, and Integrations, in the form of Basic Scene and Ortho scene products, which are available through our platform as a set of Item Types and Asset Types. A PlanetScope Scene Product is an individual framed scene within a strip, captured by the satellite in its continuous line-scan of the Earth. Scenes within a strip are overlapping and not organized to any particular tiling grid system. PlanetScope Scene products range from approximately 280 to 630 square kilometers in size, depending on which instrument type captured them. They are represented in the Planet Platform as PSScene item types. PSScene supports access to 8-Band imagery (RGB, NIR, Red Edge, Yellow, Green I, and Coastal Blue). Asset types PlanetScope Scene imagery products are available for download in the form of imagery assets. Multiple asset types are made available for Scene products, each with differences in radiometric processing and/or rectification. See PSScene Supported Assets for asset type availability. Basic Analytic ( basic_analytic ) assets are non-orthorectified, calibrated, multispectral imagery products that have been corrected for sensor artifacts and transformed to Top of Atmosphere (at-sensor) radiance. These products are designed for data science and analytic applications, and for users who wish to geometrically correct the data themselves with the associated rational polynomial coefficients (RPCs) asset type. Analytic ( analytic ) assets are orthorectified, calibrated, multispectral imagery products that have been corrected for sensor artifacts and terrain distortions, and transformed to Top of Atmosphere (at-sensor) radiance. These products are designed for data science and analytic applications which require imagery with accurate geolocation and cartographic projection. Visual ( visual ) assets are orthorectified, color-corrected, RGB imagery products that are optimized for the human eye, providing images as they would look if viewed from the perspective of the satellite. These products are designed for simple and direct visual inspection, and can be used and ingested directly into a Geographic Information System or application. Surface Reflectance ( analytic_sr ) assets are orthorectified and radiometrically corrected to ensure consistency across localized atmospheric conditions, and to minimize uncertainty in spectral response across time and location. These multispectral imagery products are designed for temporal analysis and monitoring applications, especially in agriculture and forestry sectors. Note Surface Reflectance asset types take longer to generate than our other PlanetScope products. They are typically available 8-12 hours after an item is published to our catalog. You can find our complete Imagery Product Specification here . Product naming The name of each acquired PlanetScope image is designed to be unique and allow for easier recognition and sorting of the imagery. It includes the date and time of capture, as well as the ID of the satellite that captured it. The name of each downloaded image product is composed of the following elements: PlanetScope Scene <acquisition date>_<acquisition time>_<acquisition time seconds hundredths>_<satellite_id>_<productLevel>_<bandProduct>.<extension> Example: 20200922_183720_11_106a_3B_AnalyticMS.tif Processing Several processing steps are applied to PlanetScope imagery to produce the set of data products available for download. Click for full-size image Sensor and radiometric calibration Darkfield/Offset Correction : Corrects for sensor bias and dark noise. Master offset tables are created by averaging on-orbit darkfield collects across 5-10 degree temperature bins and applied to scenes during processing based on the CCD temperature at acquisition time. Flat Field Correction : Flat fields are collected for each optical instrument prior to launch. These fields are used to correct image lighting and CCD element effects to match the optimal response area of the sensor. Flat fields are routinely updated on-orbit during the satellite lifetime. Camera Acquisition Parameter Correction : Determines a common radiometric response for each image (regardless of exposure time, number of TDI stages, gain, camera temperature and other camera parameters). Absolute Calibration : As a last step, the spatially and temporally adjusted datasets are transformed from digital number values into physical based radiance values (scaled to W/(m² str μm)*100). For additional technical detail, refer to On-Orbit Radiometric Calibration of the Planet Satellite Fleet . Orthorectification Removes terrain distortions. This process consists of two steps: The rectification tiedown process wherein tie points are identified across the source images and a collection of reference images (ALOS, NAIP, Landsat) and RPCs are generated. The actual orthorectification of the scenes using the RPCs, to remove terrain distortions. The terrain model used for the orthorectification process is derived from multiple sources (Intermap, NED, SRTM and other local elevation datasets) which are periodically updated. Snapshots of the elevation datasets used are archived (helps in identifying the DEM that was used for any given scene at any given point). Visual product processing Presents the imagery as natural color, optimized as seen by the human eye. This process consists of three steps: Nominalization - Sun angle correction, to account for differences in latitude and time of acquisition. This makes the imagery appear to look like it was acquired at the same sun angle by converting the exposure time to the nominal time (noon). Unsharp mask (sharpening filter) applied before the warp process. Custom color curve applied post warping. Surface reflectance product processing Removes atmospheric effects. This process consists of three steps: Top of Atmosphere (TOA) reflectance calculation using coefficients supplied with the at-sensor radiance product. Lookup table (LUT) generation using the 6SV2.1 radiative transfer code and MODIS near-real-time data inputs. Conversion of TOA reflectance to surface reflectance for all combinations of selected ranges of physical conditions and for each satellite sensor type using its individual spectral response as well as estimates of the state of the atmosphere. You can find a detailed white paper on our Surface Reflectance Products here . A note regarding imagery collection vs publication While the PlanetScope constellation collects imagery of nearly all the landmass on Earth at a daily cadence, imagery must pass all quality thresholds for publication in our catalog. There are a few common reasons for non-publication of imagery or for the publication of test quality imagery in lieu of standard imagery. Non-publication due to weather Unpublished imagery is almost always due to weather events. Heavy cloud cover prevents our pipelines from rectifying imagery correctly and achieving ground lock. Unrectified imagery is only published in special circumstances. If you notice gaps in image publication in your area, it's very likely due to clouds, as weather conditions vary tremendously region to region. To get a sense of how many days to expect imagery to be published in a given season and region, you can look up average cloud cover on sites like weatherspark.com. Non-publication due to lack of ground lock We choose not to publish images that don't have groundlock. About 95% of the time lack of groundlock is due to clouds (see above). However other conditions, such as extreme latitudes, topography and open water can also impact our ability to reference images to the ground. Non-groundlocked imagery only has approximate geo-location. We recommend only using imagery that has achieved groundlock to prevent user dis-orientation or analysis errors. Very occasionally a test quality image without groundlock will achieve groundlock and be re-categorized after 24-72 hours. However, it is more common that ground control points get refined post-publication. Normally this happens within the first 24 hours an image appears in our catalog. Non-publication due to image quality A small percentage of images collected cannot be fully processed due to anomalies in image capture, atmospheric conditions, or other factors. To maintain quality standards we do not publish anything that cannot be processed to a final composited image. Image quality: standard vs test imagery Planet's data API provides metadata in regards to image quality. This falls into two categories: standard and test. The vast majority of published imagery falls into the \"standard\" category, meaning that it's passed all Planet's image quality metrics in the processing pipeline. The remaining published imagery falls into the \"test\" category. The majority test of quality images are categorized this way due to lack of ground lock (see above). For most use cases we recommend using standard quality imagery. You can find whether an image is standard or test quality within the scene metadata in Explorer. Access scene meta data via the info icon View scene meta data in the table on the left, look for \"Quality category\"","tags":"data","url":"https://developers.planet.com/docs/data/planetscope","loc":"https://developers.planet.com/docs/data/planetscope"},{"title":"Item Previews","text":"Thumbnails The Data API provides previews of Planet imagery data as thumbnails. A thumbnail is a down-sampled PNG version of an item's visual asset that can be used as a preview of the image without needing to download a full GeoTIFF. The thumbnail URL is advertised by the key thumbnail in the _links dictionary of an item's metadata. To see an example, inspect the response of https://api.planet.com/data/v1/item-types/PSScene/items/20160223_174714_0c72 . \"_links\": { \"_self\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20160223_174714_0c72\", \"assets\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20160223_174714_0c72/assets/\" \"thumbnail\": \"https://tiles.planet.com/data/v1/item-types/PSScene/items/20160223_174714_0c72/thumb\" } Size The thumbnail by default is 256×256 pixels, and can be scaled up to 512×512 by passing in the width parameter and setting it to values up to 512 . If you have download access to the visual asset, you can scale the thumbnail higher by setting the width parameter to a maximum of 2048 . Authentication Authentication for thumbnails can be done with basic HTTP or by providing an api_key parameter to the URL.","tags":"data-api","url":"https://developers.planet.com/docs/apis/data/item-previews/","loc":"https://developers.planet.com/docs/apis/data/item-previews/"},{"title":"Scenes Product Bundles Reference","text":"Product bundles comprise of a group of assets for an item . In the Planet API, an item is an entry in our catalog, and generally represents a single logical observation (or scene) captured by a satellite. Each item is defined by an item_type , which represents the class of spacecraft and/or processing level of the item. Assets (or products, such as visual or analytic) can be derived from the item's source data. In addition, Product Bundles will also include a GeoJSON metadata file describing the spatial location and geographic features of an item. With the Orders API, you have to specify the product bundles in your request. You can request fallback bundles , which allow Orders to pick an alternate bundle if your first choice can't be found. For more information on items and assets, please visit our Data API docs . Select a product bundle type from the list below to learn more about the items & assets in each bundle. Download the complete product bundle specification (JSON format). analytic Analytic Radiance (TOAR) Calibrated to top of atmosphere radiance Item Type Available assets Landsat8L1G analytic_b1 analytic_b2 analytic_b3 analytic_b4 analytic_b5 analytic_b6 analytic_b7 analytic_b8 analytic_b9 analytic_b10 analytic_b11 analytic_bqa metadata_txt PSOrthoTile analytic udm analytic_xml REOrthoTile analytic analytic_xml udm Sentinel1 ortho_analytic_vv ortho_analytic_vh Sentinel2L1C analytic_b1 analytic_b2 analytic_b3 analytic_b4 analytic_b5 analytic_b6 analytic_b7 analytic_b8 analytic_b8a analytic_b9 analytic_b10 analytic_b11 analytic_b12 metadata_aux SkySatScene ortho_analytic ortho_analytic_udm SkySatCollect ortho_analytic ortho_analytic_udm analytic_udm2 Analytic Radiance (TOAR) Calibrated to top of atmosphere radiance Item Type Available assets PSOrthoTile analytic udm udm2 analytic_xml PSScene ortho_analytic_4b ortho_analytic_4b_xml ortho_udm2 SkySatScene ortho_analytic ortho_analytic_udm ortho_analytic_udm2 SkySatCollect ortho_analytic ortho_analytic_udm ortho_analytic_udm2 analytic_3b_udm2 Analytic Radiance (TOAR) 3b Calibrated to top of atmosphere radiance, 3 band Item Type Available assets PSScene ortho_analytic_3b ortho_analytic_3b_xml ortho_udm2 analytic_5b Analytic Radiance (TOAR) 5b Calibrated to top of atmosphere radiance, 5 band Item Type Available assets PSOrthoTile analytic_5b analytic_5b_xml udm analytic_5b_udm2 Analytic Radiance (TOAR) 5b Calibrated to top of atmosphere radiance, 5 band Item Type Available assets PSOrthoTile analytic_5b analytic_5b_xml udm udm2 analytic_8b_udm2 Analytic Radiance (TOAR) 8b Calibrated to top of atmosphere radiance, 8 band Item Type Available assets PSScene ortho_analytic_8b ortho_analytic_8b_xml ortho_udm2 visual Visual RGB only -- color corrected and optimized for visual analysis Item Type Available assets Landsat8L1G visual PSOrthoTile visual visual_xml PSScene ortho_visual REOrthoTile visual visual_xml Sentinel2L1C visual SkySatCollect ortho_visual SkySatScene ortho_visual uncalibrated_dn Uncalibrated DN Uncalibrated digital numbers, suitable for custom radiometric processing Item Type Available assets PSOrthoTile analytic_dn udm analytic_dn_xml SkySatCollect ortho_analytic_dn ortho_analytic_udm SkySatScene ortho_analytic_dn ortho_analytic_udm uncalibrated_dn_udm2 Uncalibrated DN Uncalibrated digital numbers, suitable for custom radiometric processing Item Type Available assets PSOrthoTile analytic_dn analytic_dn_xml udm udm2 SkySatCollect ortho_analytic_dn ortho_analytic_udm ortho_analytic_udm2 SkySatScene ortho_analytic_dn ortho_analytic_udm ortho_analytic_udm2 basic_analytic Basic Analytic Radiance (TOAR) Calibrated to top of atmosphere radiance - includes RPC text file for georeferencing Item Type Available assets REScene basic_analytic_b1 basic_analytic_b2 basic_analytic_b3 basic_analytic_b4 basic_analytic_b5 basic_analytic_xml basic_analytic_rpc basic_udm basic_analytic_sci browse SkySatScene basic_analytic basic_analytic_rpc basic_analytic_udm basic_analytic_udm2 Basic Analytic Radiance (TOAR) Calibrated to top of atmosphere radiance - includes RPC text file for georeferencing Item Type Available assets PSScene basic_analytic_4b basic_udm2 basic_analytic_4b_rpc basic_analytic_4b_xml SkySatScene basic_analytic basic_analytic_rpc basic_analytic_udm basic_analytic_udm2 basic_analytic_8b_udm2 Basic Analytic Radiance (TOAR) 8b Calibrated to top of atmosphere radiance - includes RPC text file for georeferencing Item Type Available assets PSScene basic_analytic_8b basic_udm2 basic_analytic_4b_rpc basic_analytic_8b_xml basic_uncalibrated_dn Basic Uncalibrated DN Uncalibrated digital numbers - includes RPC text file for georeferencing Item Type Available assets SkySatScene basic_analytic_dn basic_analytic_dn_rpc basic_analytic_udm basic_uncalibrated_dn_udm2 Basic Uncalibrated DN Uncalibrated digital numbers - includes RPC text file for georeferencing Item Type Available assets SkySatScene basic_analytic_dn basic_analytic_dn_rpc basic_analytic_udm basic_analytic_udm2 analytic_sr Surface Reflectance Corrected for surface reflectance – recommended for most analytic applications Item Type Available assets PSOrthoTile analytic_sr udm analytic_xml REOrthoTile analytic_sr udm analytic_xml MOD09GQ analytic_num_observations analytic_orbit_pnt analytic_granule_pnt analytic_sur_refl_b01 analytic_sur_refl_b02 analytic_qc_250m analytic_obscov analytic_iobs_res MYD09GQ analytic_num_observations analytic_orbit_pnt analytic_granule_pnt analytic_sur_refl_b01 analytic_sur_refl_b02 analytic_qc_250m analytic_obscov analytic_iobs_res MOD09GA analytic_num_observations_500m analytic_num_observations_1km analytic_state_1km analytic_sensor_zenith analytic_sensor_azimuth analytic_range analytic_solar_zenith analytic_solar_azimuth analytic_gflags analytic_orbit_pnt analytic_granule_pnt analytic_sur_refl_b01 analytic_sur_refl_b02 analytic_sur_refl_b03 analytic_sur_refl_b04 analytic_sur_refl_b05 analytic_sur_refl_b06 analytic_sur_refl_b07 analytic_qc_500m analytic_obscov_500m analytic_iobs_res analytic_q_scan MYD09GA analytic_num_observations_500m analytic_num_observations_1km analytic_state_1km analytic_sensor_zenith analytic_sensor_azimuth analytic_range analytic_solar_zenith analytic_solar_azimuth analytic_gflags analytic_orbit_pnt analytic_granule_pnt analytic_sur_refl_b01 analytic_sur_refl_b02 analytic_sur_refl_b03 analytic_sur_refl_b04 analytic_sur_refl_b05 analytic_sur_refl_b06 analytic_sur_refl_b07 analytic_qc_500m analytic_obscov_500m analytic_iobs_res analytic_q_scan SkySatCollect ortho_analytic_sr ortho_analytic_udm SkySatScene ortho_analytic_sr ortho_analytic_udm analytic_sr_udm2 Surface Reflectance 4b Corrected for surface reflectance – recommended for most analytic applications, 4 band Item Type Available assets PSScene ortho_analytic_4b_sr ortho_analytic_4b_xml ortho_udm2 PSOrthoTile analytic_sr udm udm2 analytic_xml SkySatCollect ortho_analytic_sr ortho_analytic_udm ortho_analytic_udm2 SkySatScene ortho_analytic_sr ortho_analytic_udm ortho_analytic_udm2 analytic_8b_sr_udm2 Surface Reflectance 8b Corrected for surface reflectance – recommended for most analytic applications, 8 band Item Type Available assets PSScene ortho_analytic_8b_sr ortho_analytic_8b_xml ortho_udm2 basic_analytic_nitf Basic Analytic Radiance (TOAR) – NITF Calibrated to top of atmosphere radiance - includes RPC text file for georeferencing Item Type Available assets REScene basic_analytic_b1_nitf basic_analytic_b2_nitf basic_analytic_b3_nitf basic_analytic_b4_nitf basic_analytic_b5_nitf basic_analytic_xml_nitf basic_analytic_rpc basic_udm basic_analytic_sci browse basic_panchromatic Basic Panchromatic Unrectified panchromatic band - includes RPC text file for georeferencing Item Type Available assets SkySatScene basic_panchromatic basic_panchromatic_rpc basic_panchromatic_udm2 basic_panchromatic_dn Basic Panchromatic DN Unrectified, panchromatic band, uncalibrated digital numbers - includes RPC text file for georeferencing Item Type Available assets SkySatScene basic_panchromatic_dn basic_panchromatic_dn_rpc basic_panchromatic_udm2 panchromatic Panchromatic Panchromatic band, calibrated to top of atmosphere radiance Item Type Available assets SkySatCollect ortho_panchromatic ortho_panchromatic_udm SkySatScene ortho_panchromatic ortho_panchromatic_udm panchromatic_dn Panchromatic DN Uncalibrated panchromatic band - suitable for custom radiometric processing Item Type Available assets SkySatCollect ortho_panchromatic_dn ortho_panchromatic_udm SkySatScene ortho_panchromatic_dn ortho_panchromatic_udm panchromatic_dn_udm2 Panchromatic DN Uncalibrated panchromatic band - suitable for custom radiometric processing Item Type Available assets SkySatCollect ortho_panchromatic_dn ortho_panchromatic_udm ortho_panchromatic_udm2 SkySatScene ortho_panchromatic_dn ortho_panchromatic_udm ortho_panchromatic_udm2 pansharpened Ortho-pansharpened Pansharpened, color corrected, 4-band multispectral data Item Type Available assets SkySatCollect ortho_pansharpened ortho_pansharpened_udm SkySatScene ortho_pansharpened ortho_pansharpened_udm pansharpened_udm2 Ortho-pansharpened Pansharpened, color corrected, 4-band multispectral data Item Type Available assets SkySatCollect ortho_pansharpened ortho_pansharpened_udm ortho_pansharpened_udm2 SkySatScene ortho_pansharpened ortho_pansharpened_udm ortho_pansharpened_udm2 basic_l1a_dn Basic L1A Unrectified, uncalibrated panchromatic band only, no super resolution applied - includes RPC text file for georeferencing Item Type Available assets SkySatScene basic_l1a_panchromatic_dn basic_l1a_panchromatic_dn_rpc SkySatCollect basic_l1a_all_frames","tags":"orders","url":"https://developers.planet.com/apis/orders/product-bundles-reference/","loc":"https://developers.planet.com/apis/orders/product-bundles-reference/"},{"title":"PSOrthoTile Deprecation and Migration Plan","text":"Deprecation Announced : March 22, 2023 Scheduled End-of-Life : June 20, 2023 This article describes the deprecation of the PSOrthoTile item type. What's changing? Planet is deprecating the PSOrthoTile item type on Wednesday, March 22, 2023 with plans to formally end-of-life the item types on Tuesday, June 20, 2023. We recommend all customers begin to migrate to the PSScene item type as soon as possible. The PSScene item type provides the same spectral bands and pixel values as PSOrthoTiles. Planet will continue to publish imagery to the PSOrthoTile item types until June 20, 2023 . After June 20, 2023, Planet will no longer publish images to the PSOrthoTile item type while the customers will still have access to the older archive for proceeding months while we update our Data API, Orders API, Subscriptions API, SDK/CLI, and Planet Jupyter Notebooks . We highly recommend that PSOrthoTile users plan their transition to using PSScene as soon as possible to ensure there is minimal disruption to workflows. Why is Planet removing PSOrthoTiles? We are deprecating the PSOrthoTile to improve the way customers access our PlanetScope imagery. We recommend customers to take advantage of PSScene, our new PlanetScope item type that unifies 3-Band, 4-Band, and 8-Band assets. Am I affected? This deprecation announcement affects all users accessing PlanetScope imagery from the PSOrthoTile item type through Planet Data API, Orders API, Subscriptions API, SDK/CLI, and Planet Jupyter Notebooks . What happens after June 20, 2023? Planet will stop publishing new PlanetScope images to the PSOrthoTile item-type after June 20, 2023. Customers will still have access to the older archive for proceeding months while we update our Data API, Orders API, Subscriptions API, SDK/CLI, and Planet Jupyter Notebooks . Who should I contact if I have questions or concerns about PSScene migration? Please reach out to your Customer Success Manager or contact us at Planet Support for assistance. What do I need to do? Review the following top-level table, then step through the Migration Path, below. API What Action Customers Need to Take All Review the mapping between PSOrthoTile asset types to understand the corresponding PSScene asset types. Data API Update new quick and saved searches to use the PSScene item type. If applicable, adjust AssetFilter to use PSScene Asset Types . Orders API Identify the appropriate PSScene bundle , and update order requests to use the PSScene item_type and bundle. Subscriptions API Identify the appropriate PSScene Asset Types . Create new subscriptions with the PSScene item_type and asset_types, and cancel existing subscriptions for the same AOI. (You cannot edit an item_type of an existing subscription.) Migration Path If you would like to use or maintain any requests or code that uses PlanetScope imagery, your migration path is as follows: Review your saved searches and subscriptions for asset types that do not map directly to PSScene assets. Update Order API requests to use PSScene bundle types. Unsupported asset types in PSScene The following assets are unavailable with PSScene: PSOrthoTile : analytic_5b, analytic_5b_xml, analytic_dn, anallytic_dn_xml, visual_xml, udm2, and udm Create new saved searches and subscriptions Before June 20, 2023, create new saved searches and subscriptions using the PSScene item type The following table assists in reviewing the new asset types in PSScene. The first column lists the legacy PSOrthoTile asset and the middle column lists the comparable PSScene asset. PSOrthoTile Asset PSScene Asset analytic -> ortho_analytic_4b analytic_5b -> ortho_analytic_8b analytic_5b_xml -> ortho_analytic_8b analytic_sr -> ortho_analytic_4b_sr analytic_xml -> ortho_analytic_4b_xml visual -> ortho_visual udm2 -> ortho_udm2 Review your saved searches Get your saved searches, either by selecting your saved searches in the Explorer or through the API . Cancel any saved searches you no longer need. Review remaining saved searches for unsupported asset types . For each saved search that contains an unsupported asset type, create a new saved search using the PSScene item type and comparable asset type by choosing to: Create a new saved search in the Explorer Create a new saved search through the API Delete the saved search that contained the unsupported asset type. Review your subscriptions Get your subscriptions by listing all active subscriptions through the API . Cancel any subscriptions you no longer need. Review remaining subscriptions for unsupported asset types . For each subscription that contains an unsupported asset type, create a new subscription using the PSScene item type and comparable asset type in the Subscription API . Cancel the subscription that contained the unsupported asset type through the Subscriptions API . Before June 20, 2023, update Orders API to use the PSScene item type. Update Order API requests to use PSScene bundle types Change all references from PSOrthoTile item types to PSScene in the Order API request. For any PSOrthoTile item types, search for the appropriate PSScene bundle type and replace it with the new bundle. Finally, review all code repositories where you may be making calls using the deprecated item and asset types. The following table assists in reviewing the new asset types for the updated bundles. The first column lists the legacy bundle types, PSOrthoTile, the middle column lists the comparable PSScene bundle type, and the last column lists the new asset types for PSScene. PSOrthoTile Bundle PSScene Bundle PSScene Assets in Bundle analytic -> analytic_udm2 ortho_analytic_4b ortho_analytic_4b_xml ortho_udm2 analytic_5b -> analytic_8b_udm2 ortho_analytic_8b ortho_analytic_8b_xml ortho_udm2 analytic_5b_udm2 -> analytic_8b_udm2 ortho_analytic_8b ortho_analytic_8b_xml ortho_udm2 visual -> visual ortho_visual analytic_sr -> analytic_sr_udm2 ortho_analytic_4b_sr ortho_analytic_4b_xml ortho_udm2 analytic_sr_udm2 -> analytic_sr_udm2 ortho_analytic_4b_sr ortho_analytic_4b_xml ortho_udm2","tags":"data-api","url":"https://developers.planet.com/docs/apis/data/psorthotile-deprecation/","loc":"https://developers.planet.com/docs/apis/data/psorthotile-deprecation/"},{"title":"Setting up a Python development environment","text":"Development Environment Setup The Basics The following tools are regularly used in Planet School's guides: Python 3x (Note: Python 2.7 is in legacy support) cURL requests geojsonio-cli jq If you choose to follow along with code here, you may find it useful to install these libraries in your development environment: $ pip install requests $ pip install retrying $ pip install jq # Requires Node.js $ npm install -g geojsonio-cli For convenience, some examples here may pipe JSON API output to jq and filter for a specific field. You may prefer to remove the jq filter in order to familiarize yourself with the complete API objects. Working with Planet Data When working with datasets like Planet's satellite imagery, here are a few useful Python libraries to know: Rasterio Fiona NumPy MatPlotLib Rasterio is a free and open source library for working with geospatial raster imagery. Rasterio is used extensively in the Python code that you'll find through Planet School, as well as in most Jupyter Notebooks in Planet's open source Notebook collection. Fiona is a sibling library to Rasterio used when working with geospatial vector data. While less frequently used in Planet's developer resources, Fiona can still come in handy when, for example, creating or manipulating an AOI (Area of Interest) vector dataset. NumPy and MatPlotLib can be used to manipulate, plot, and display raster data that has been loaded via Rasterio. Installing Planet's Python client library and CLI Most Python-savvy users find Planet's Python client ( import planet ) a convenient way to incorporate Planet API into new and existing Python workflows. Additionally, the Planet CLI (command-line interface) is used widely, and you'll find it referenced frequently in Planet School and throughout our Notebook collection. To install both the Python client library and CLI in your development environment: $ pip install planet Note: if you want to use the Planet CLI outside of your development environment, you may instead prefer to do: $pip install --user planet For complete documentation as well as usage examples, see the docs here .","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/setting-up-a-python-development-environment/","loc":"https://developers.planet.com/docs/planetschool/setting-up-a-python-development-environment/"},{"title":"QGIS One Minute to Integrations","text":"Get started with common tasks using Planet GIS integrations with the following series of videos. To learn more about Planet ArcGIS Pro, QGIS, and Google Earth Engine integrations, visit this page . QGIS QGIS: Search & Preview Planet Imagery QGIS: Stream & Download Planet Basemaps (NICFI) QGIS: Identify Source Scene in Planet Basemap QGIS: Define AOI for High-Res Tasking","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/qgis-one-minute-to-integrations/","loc":"https://developers.planet.com/docs/planetschool/qgis-one-minute-to-integrations/"},{"title":"Analyzing a Flood Event in QGIS","text":"To follow along with this guide, check out the complete tutorial here .","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/analyzing-a-flood-event-in-qgis/","loc":"https://developers.planet.com/docs/planetschool/analyzing-a-flood-event-in-qgis/"},{"title":"Beginners QGIS Workflow","text":"Beginners QGIS Workflow with NICFI data Introduction This tutorial will cover basic raster operations in QGIS. You will first mosaic two basemap quads and then clip the mosaic to an area of interest. After clip, you are going to use Raster Calcualtor to perform NIDVI. The steps in this workflow are Mosaic basemap quads Clip to an AOI Create NDVI Raster You can choose to follow all three of the steps, or only follow one step. The workflow is meant for beginners starting to work with NICFI data. Before you start You will need QGIS installed on your machine to perform the raster operations in this tutorial. This tutorial is using QGIS version 3.12 but the raster operations should be available in all QGIS versions. You will need to download at least two basemap quads from Planet. You will need an area of interest that you want to clip the mosaic. Area of interest can be in GeoJSON or shapefile, and should work with all QGIS supported vector formats. While this is a simple tutorial, it is recommended that you have basic familiarity with GIS concepts. You can find more on working with raster data in QGIS here . 1. Mosaic Basemap Quads To start, open a QGIS project and add your GeoTiff basemap quads (It is assumed that you have the two basemap quads stored locally in your machine). Loading Raster Data: Layer > Add Layer > Add Raster Layer On the pop up window, under source, click the \" ... \" and choose your GeoTiff quads. More than one layer can be loaded at the same time by holding down the Ctrl and Shift key and clicking on multiple items. Click Add to add the quads to your project. 1.1 Merge two quads together: Click on Raster Hover over Miscellaneous Click on Merge On the Merge dialogue In the Input Layers click on ... In the Output data type choose Int16 Click Run Good Job! You have merged multpile quads together! 1.2 Save the Merge output: Right click on the Merge output Export Click Save As Navigate to where you want to save your Merged GeoTiff and provide name Choose CRS (Planet mosaic quads are ESPG:3857 - WGS 84 / Pseudo) Click OK 2. Clip to an AOI In this step, you are are going to clip the merged GeoTIFF to a area of interst (e.g. shapefile or GeoJSON). Loading Shapefile Data: Layer > Add Layer > Add Vector Layer On the pop up window, under source, click the \" ... \" and choose your clip file. As with the GeoTIFFs, more than one vector layer can be loaded at the same time by holding down the Ctrl and Shift key and clicking on multiple items. Click Add to add the quads to your project. Example of merged quads before clip. 2.1 Clip the merged raster to features Right click on Raster Hover over Extraction Click on Clip Raster by Mask Layer On the Clip Raster By Extent dialogue Select Input Layer (merged_quads.tif) Selet Mask Layer (clip_features.shp) Click Run 2.2 Save the Merge output: Right click on the Clipped (mask) output Export Click Save As Navigate to where you want to save your Merged GeoTiff and provide name Choose CRS (Planet mosaic quads are ESPG:3857 - WGS 84 / Pseudo) Click OK Example of merged quads after clip. 3. Create NDVI Raster Finally, you will calculate NDVI (Normalized Difference Vegetation Index) and create a new raster with these values. 3.1 NDVI Overview NDVI, developed by a NASA scientist named Compton Tucker in 1977, is commonly used to assess whether an area contains live green vegetation or not. It can show the difference between water and plants, bare soil and grass, whether plants are under stress, and what lifecycle stage a crop is in. It compares how much more near-infrared light is reflected by chlorophyll vs visible red light and is given as the following equation: 3.2 Calculating NDVI in QGIS Click on Raster Choose Raster Calculator In the Raster Calculator Expression Type ( \"clipped_quads@4\" - \"clipped_quads@3\" ) / ( \"clipped_quads@4\" + \"clipped_quads@3\" ) where clipped_quads is the raster image you want to perfrom NDVI. Save your NDVI by choosing the path in Output layer Nice work! The final step is to make the color ramp vegetation friendly. 3.3 Edit Color Ramp Right click on the NDVI layer Choose Properties On the left side click Symbology In the Render Type choose singleband pseudocolor For mode pick equal interval Click Apply and then OK Good work! You have finished the whole workflow!","tags":"nicfi","url":"https://developers.planet.com/docs/nicfi/beginners-qgis-workflow/","loc":"https://developers.planet.com/docs/nicfi/beginners-qgis-workflow/"},{"title":"Querying Results","text":"The following queries indicate means to query the results with specific filters. REGION-BASED FILTERING A user can filter the collection of results by bounding box regions using the bounding box filter. This filters the items in a specific collection of results by those that are detected within a specified bounding box {min Longitude , min Latitude , max Longitude , max Latitude} Example: curl --header \"Authorization: api-key ${PL_API_KEY}\" https://api.planet.com/analytics/collections/886b4dbb-b878-4f6b-b000-0d96cbf71d4d/items\\?bbbox\\=121.771088,31.209278,121.907043,31.309062 TIME-BASED FILTERING A user can filter the collections of results by bounded time windows or unbounded time windows. Here are a few examples: Example: curl --header \"Authorization: api-key ${PL_API_KEY}\" https://api.planet.com/analytics/collections/886b4dbb-b878-4f6b-b000-0d96cbf71d4d/items\\?datetime\\=2019-01-18T02:08:40.761735Z LIST RESULTS A user can paginate through results for a subscription. Results are returned in descending creation order. Result IDs act as cursors when paginating backwards or forwards. To get older pages of results, use the before query parameter with the id of the oldest (last) result in a page of results. When returning to the API to query for newly created results, use the ‘after' query parameter with the id of the newest (first) result in a page. Results have a created field that can be stored and used later for sorting to determine the oldest or newest result from a previous query.","tags":"analytics","url":"https://developers.planet.com/docs/analytics/querying_results/","loc":"https://developers.planet.com/docs/analytics/querying_results/"},{"title":"Quick & Saved Search","text":"The Data API supports two main types of search: Quick Search and Saved Search Quick Search is recommended for one-off, ad-hoc searches of the Planet catalog. Saved Search is recommended for searches you use frequently. Saved searches are persisted for the duration of your access period and can be easily retrieved and executed for repeat use. You can also enable Saved Search email notifications to receive daily updates with newly published imagery which meets your search criteria. Quick Search Quick search is the easiest way to search the Planet catalog for ad-hoc, everyday use. Quick searches will remain available via the API for repeat use for 30 days. Query Parameters Quick search supports several query parameters to format your results. _page_size : limits the number of results to returned per page. It may only be used at the start of pagination. _sort : allows you to sort search results by ascending or descending acquired time or published time. Supported values are acquired asc , acquired desc , published asc , and published desc . When unspecified, published desc is the default value. Example Query Parameters https://api.planet.com/data/v1/quick-search?_sort=acquired asc&_page_size=50 Request Body The body of a quick-search must include item type(s) and a filter. item_types : is a list of item types filtered by your search. You can read more on available item types here . filter : is your structured search criteria. You can read more on supported search filters here . asset_types : is an optional search parameter filterered by available asset types here . Example Request Body POST https://api.planet.com/data/v1/quick-search { \"item_types\":[ \"PSScene\" ], \"filter\":{ \"type\":\"AndFilter\", \"config\":[ { \"type\":\"GeometryFilter\", \"field_name\":\"geometry\", \"config\":{ \"type\":\"Polygon\", \"coordinates\":[ [ [ 6.067543029785156, 45.859890320433756 ], [ 6.1969757080078125, 45.859890320433756 ], [ 6.1969757080078125, 45.95831029909359 ], [ 6.067543029785156, 45.95831029909359 ], [ 6.067543029785156, 45.859890320433756 ] ] ] } }, { \"type\":\"DateRangeFilter\", \"field_name\":\"acquired\", \"config\":{ \"gte\":\"2022-04-14T00:00:00Z\", \"lte\":\"2022-04-15T00:00:00Z\" } }, { \"type\":\"StringInFilter\", \"field_name\":\"quality_category\", \"config\":[ \"standard\" ] }, { \"type\":\"AssetFilter\", \"config\":[ \"ortho_analytic_8b\" ] }, { \"type\":\"RangeFilter\", \"config\":{ \"gte\":0, \"lte\":0.6 }, \"field_name\":\"cloud_cover\" }, { \"type\":\"PermissionFilter\", \"config\":[ \"assets:download\" ] } ] } } Response Schema A Quick Search response includes metadata and links for items matching your search criteria. The number of results included is based on the page size and additional links are provided to enable pagination. Page links reference different pages of the returned search results. _self : references the current page of search results _first : references the first page of the search results _next : references the next page of the search results Features include additional detail on each item returned in the search results. _links : _self : is an endpoint for this specific item result assets : references a set of asset activation links for each published asset of the item thumbnail : is a Tile Service API endpoint, which hosts a thumbnail of the item _permissions : lists all of your asset download permissions which apply to this particular item assets : lists all the assets that have been published for this particular item geometry : is the footprint geometry for this particular item id : is the item id for this particular item properties : lists all metadata fields and values for a particular item; properties may vary by item type Example Response { \"_links\": { \"_first\": \"https://api.planet.com/data/v1/searches/5ff575bd0a8c4b3aa108c6bfaa529587/results?_page=eyJwYWdlX3NpemUiOiAyNTAsICJzb3J0X2J5IjogInB1Ymxpc2hlZCIsICJzb3J0X2Rlc2MiOiB0cnVlLCAic29ydF9zdGFydCI6IG51bGwsICJzb3J0X2xhc3RfaWQiOiBudWxsLCAic29ydF9wcmV2IjogZmFsc2UsICJxdWVyeV9wYXJhbXMiOiB7fX0%3D\", \"_next\": \"https://api.planet.com/data/v1/searches/5ff575bd0a8c4b3aa108c6bfaa529587/results?_page=eyJwYWdlX3NpemUiOiAyNTAsICJzb3J0X2J5IjogInB1Ymxpc2hlZCIsICJzb3J0X2Rlc2MiOiB0cnVlLCAic29ydF9zdGFydCI6ICIyMDIyLTA0LTE1VDE3OjA0OjM4LjAwMDAwMFoiLCAic29ydF9sYXN0X2lkIjogIjIwMjIwNDE0XzEwMTkxNl83OV8yNDBhIiwgInNvcnRfcHJldiI6IGZhbHNlLCAicXVlcnlfcGFyYW1zIjoge319\", \"_self\": \"https://api.planet.com/data/v1/searches/5ff575bd0a8c4b3aa108c6bfaa529587/results?_page=eyJwYWdlX3NpemUiOiAyNTAsICJzb3J0X2J5IjogInB1Ymxpc2hlZCIsICJzb3J0X2Rlc2MiOiB0cnVlLCAic29ydF9zdGFydCI6IG51bGwsICJzb3J0X2xhc3RfaWQiOiBudWxsLCAic29ydF9wcmV2IjogZmFsc2UsICJxdWVyeV9wYXJhbXMiOiB7fX0%3D\" }, \"features\": [ { \"_links\": { \"_self\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20220414_101919_00_240a\", \"assets\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20220414_101919_00_240a/assets/\", \"thumbnail\": \"https://tiles.planet.com/data/v1/item-types/PSScene/items/20220414_101919_00_240a/thumb\" }, \"_permissions\": [ \"assets.basic_analytic_4b:download\", \"assets.basic_analytic_4b_rpc:download\", \"assets.basic_analytic_4b_xml:download\", \"assets.basic_analytic_8b:download\", \"assets.basic_analytic_8b_xml:download\", \"assets.basic_udm2:download\", \"assets.ortho_analytic_4b:download\", \"assets.ortho_analytic_4b_sr:download\", \"assets.ortho_analytic_4b_xml:download\", \"assets.ortho_analytic_8b:download\", \"assets.ortho_analytic_8b_sr:download\", \"assets.ortho_analytic_8b_xml:download\", \"assets.ortho_udm2:download\", \"assets.ortho_visual:download\" ], \"assets\": [ \"basic_analytic_4b\", \"basic_analytic_4b_rpc\", \"basic_analytic_4b_xml\", \"basic_analytic_8b\", \"basic_analytic_8b_xml\", \"basic_udm2\", \"ortho_analytic_4b\", \"ortho_analytic_4b_sr\", \"ortho_analytic_4b_xml\", \"ortho_analytic_8b\", \"ortho_analytic_8b_sr\", \"ortho_analytic_8b_xml\", \"ortho_udm2\", \"ortho_visual\" ], \"geometry\": { \"coordinates\": [ [ [ 5.95456036106261, 45.903977558439216 ], [ 5.894418694239513, 45.71873410766648 ], [ 6.336370462891481, 45.64820921278849 ], [ 6.397913442243694, 45.83198472407456 ], [ 5.95456036106261, 45.903977558439216 ] ] ], \"type\": \"Polygon\" }, \"id\": \"20220414_101919_00_240a\", \"properties\": { \"acquired\": \"2022-04-14T10:19:19.007955Z\", \"anomalous_pixels\": 0, \"clear_confidence_percent\": 98, \"clear_percent\": 97, \"cloud_cover\": 0, \"cloud_percent\": 0, \"ground_control\": true, \"gsd\": 4, \"heavy_haze_percent\": 0, \"instrument\": \"PSB.SD\", \"item_type\": \"PSScene\", \"light_haze_percent\": 0, \"pixel_resolution\": 3, \"provider\": \"planetscope\", \"published\": \"2022-04-15T17:04:44Z\", \"publishing_stage\": \"finalized\", \"quality_category\": \"standard\", \"satellite_azimuth\": 103.3, \"satellite_id\": \"240a\", \"shadow_percent\": 0, \"snow_ice_percent\": 3, \"strip_id\": \"5570053\", \"sun_azimuth\": 150.2, \"sun_elevation\": 50.3, \"updated\": \"2022-04-15T20:53:48Z\", \"view_angle\": 3.1, \"visible_confidence_percent\": 74, \"visible_percent\": 100 }, \"type\": \"Feature\" }, { \"_links\": { \"_self\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20220414_101916_79_240a\", \"assets\": \"https://api.planet.com/data/v1/item-types/PSScene/items/20220414_101916_79_240a/assets/\", \"thumbnail\": \"https://tiles.planet.com/data/v1/item-types/PSScene/items/20220414_101916_79_240a/thumb\" }, \"_permissions\": [ \"assets.basic_analytic_4b:download\", \"assets.basic_analytic_4b_rpc:download\", \"assets.basic_analytic_4b_xml:download\", \"assets.basic_analytic_8b:download\", \"assets.basic_analytic_8b_xml:download\", \"assets.basic_udm2:download\", \"assets.ortho_analytic_4b:download\", \"assets.ortho_analytic_4b_sr:download\", \"assets.ortho_analytic_4b_xml:download\", \"assets.ortho_analytic_8b:download\", \"assets.ortho_analytic_8b_sr:download\", \"assets.ortho_analytic_8b_xml:download\", \"assets.ortho_udm2:download\", \"assets.ortho_visual:download\" ], \"assets\": [ \"basic_analytic_4b\", \"basic_analytic_4b_rpc\", \"basic_analytic_4b_xml\", \"basic_analytic_8b\", \"basic_analytic_8b_xml\", \"basic_udm2\", \"ortho_analytic_4b\", \"ortho_analytic_4b_sr\", \"ortho_analytic_4b_xml\", \"ortho_analytic_8b\", \"ortho_analytic_8b_sr\", \"ortho_analytic_8b_xml\", \"ortho_udm2\", \"ortho_visual\" ], \"geometry\": { \"coordinates\": [ [ [ 5.999163695183379, 46.04148258266974 ], [ 5.938510217497761, 45.85631756620983 ], [ 6.381913829835591, 45.78592106408607 ], [ 6.443192005557489, 45.969523303104324 ], [ 5.999163695183379, 46.04148258266974 ] ] ], \"type\": \"Polygon\" }, \"id\": \"20220414_101916_79_240a\", \"properties\": { \"acquired\": \"2022-04-14T10:19:16.797043Z\", \"anomalous_pixels\": 0, \"clear_confidence_percent\": 98, \"clear_percent\": 96, \"cloud_cover\": 0, \"cloud_percent\": 0, \"ground_control\": true, \"gsd\": 4, \"heavy_haze_percent\": 0, \"instrument\": \"PSB.SD\", \"item_type\": \"PSScene\", \"light_haze_percent\": 0, \"pixel_resolution\": 3, \"provider\": \"planetscope\", \"published\": \"2022-04-15T17:04:38Z\", \"publishing_stage\": \"finalized\", \"quality_category\": \"standard\", \"satellite_azimuth\": 103.4, \"satellite_id\": \"240a\", \"shadow_percent\": 0, \"snow_ice_percent\": 4, \"strip_id\": \"5570053\", \"sun_azimuth\": 150.4, \"sun_elevation\": 50.2, \"updated\": \"2022-04-15T20:53:42Z\", \"view_angle\": 3.1, \"visible_confidence_percent\": 73, \"visible_percent\": 100 }, \"type\": \"Feature\" } ], \"type\": \"FeatureCollection\" } Saved Search Saved Search is a helpful option for managing searches that you use frequently. Saved Searches can be easily retrieved and executed for repeated use and optionally support daily email notifications for newly published imagery which meets your search criteria. Request Body In addition to item types and filters required in a quick-search, the body of a saved search requires a name. There is also an option to enable daily email notifications for new imagery updates. name : name of the Saved Search __daily_email_enabled : if set to true , an email will be delivered daily between 00:00:00 and 00:02:00 UTC with an Explorer link to all imagery that meets your search criteria published within the last 24 hours. By default, this value will be set to false . Example Request Body { \"name\": \"Saved Search Example\", \"__daily_email_enabled\": true, \"item_types\": [ \"PSScene\" ], \"filter\": { \"type\":\"AndFilter\", \"config\":[ { \"type\":\"DateRangeFilter\", \"field_name\":\"acquired\", \"config\":{ \"gte\":\"2020-01-01T00:00:00Z\", \"lte\":\"2020-01-31T00:00:00Z\" } }, { \"type\": \"AssetFilter\", \"config\": [ \"analytic_sr\" ] } ] } } Response Schema The Saved Search response includes all details of the saved search: __daily_email_enabled : true if emails are enabled, and false if not enabled _self : is an endpoint for the specific search _results : is an endpoint to execute the saved search and see results created : is the timestamp when the saved search was created filter : lists the structured search criteria id : is the saved search identifier last_executed : is the timestamp when the saved search was last executed name : is the name of the saved search updated : is the timestamp when the saved search was last updated Example Response { \"__daily_email_enabled\": true, \"_links\": { \"_self\": \"https://api.planet.com/data/v1/searches/3b5cc5df661b4ff89ca70dfdeede238f\", \"results\": \"https://api.planet.com/data/v1/searches/3b5cc5df661b4ff89ca70dfdeede238f/results\" }, \"created\": \"2020-03-03T20:40:36.825325Z\", \"filter\": { \"config\": [ { \"config\": { \"gte\": \"2020-01-01T00:00:00Z\", \"lte\": \"2020-01-31T00:00:00Z\" }, \"field_name\": \"acquired\", \"type\": \"DateRangeFilter\" }, { \"config\": [ \"analytic_sr\" ], \"type\": \"AssetFilter\" } ], \"type\": \"AndFilter\" }, \"id\": \"3b5cc5df661b4ff89ca70dfdeede238f\", \"item_types\": [ \"PSScene\" ], \"last_executed\": null, \"name\": \"Saved Search Example\", \"search_type\": \"saved\", \"updated\": \"2020-03-03T20:40:36.825325Z\" } Run a Saved Search To get the results of a saved search, you can call the endpoint below, with the saved search id: https://api.planet.com/data/v1/searches/{search_id}/results This endpoint accepts the same query parameters ( _page_size , sort ) and returns the same response schema as the quick-search endpoint. List Searches To get a list of historical searches, you can call the endpoint below: https://api.planet.com/data/v1/searches This endpoint supports the _page and _page_size query parameters, in addition to: _sort : allows you to sort searches by ascending or descending created time. Supported values are created asc and created desc . When unspecified, created desc is the default value. This parameter may not be used with the _page parameter. search_type : allows you to filter searches by search type. Supported values are any , quick , and saved . When unspecified, any is the default value, returning all searches. Example Query Parameters https://api.planet.com/data/v1/searches?_page_size=50&_sort=created asc&search_type=saved Other Supported Search Operations See our API Reference documentation for more detail and examples of other operations you can run for Saved Searches. Get Saved Search Delete Saved Search Update Saved Search","tags":"data-api","url":"https://developers.planet.com/docs/apis/data/quick-saved-search/","loc":"https://developers.planet.com/docs/apis/data/quick-saved-search/"},{"title":"GEE Setup Guide","text":"Connect to Google Earth Engine To enable Planet imagery delivery: To use the Planet GEE Delivery Integration, integrate your GEE account with Google Cloud Platform (GCP) projects. GCP-integrated GEE accounts are under development by Google, sign up for an upgrade account by using the EE Account Upgrade Form . Note : To upgrade your account, you must already have an existing Earth Engine account. Sign up for a GEE license, at the EE signup page . An email is sent to your inbox. Create a GCP project that is configured with the EE API. The first time you return to the EE code editor , there is a pop-up dialog with setup instructions. Completing the setup automatically enables the EE API in the GCP project. You can also create a cloud project and enable the EE API directly in Google Cloud Platform: Complete the instructions for setting up a free GCP project as described in Set up your Earth Engine enabled Cloud Project . Complete the instructions for enabling the GCP project as described in Enable the Earth Engine API . The EE API enabled account appears similar to the following image. However, in the top-right of the Earth Engine Code Editor , there is an option to Choose a Cloud Project . There is also a new Cloud Assets section in the Assets tab. When the Earth Engine IAM privileges are granted to the GCP project, grant the Planet service account write permission to the GCP Project. Imprortant : When creating an order, you must input your credentials for successful delivery of Planet data to cloud storage. This introduces a potential security risk. For secure delivery to cloud storage, limit access to the required delivery path without read/write access for any other storage locations or cloud services. Navigate to the Google Cloud Platform Console On the navigation-menu, select IAM and Admin . On the IAM page, click Add to add a new member. Paste in the Planet Google Service account, and grant the Earth Engine Resource Writer role: planet-gee-uploader@planet-earthengine-staging.iam.gserviceaccount.com The Earth Engine account is now able to accept Planet imagery through the Planet Orders API. How to Video","tags":"integrations-gee","url":"https://developers.planet.com/docs/integrations/gee/quickstart/","loc":"https://developers.planet.com/docs/integrations/gee/quickstart/"},{"title":"Getting Started","text":"Installation & Configuration Make sure QGIS is downloaded and installed. ( Need help? Check out our guide to installing QGIS ) Launch QGIS and from the dropdown menus along the top, choose Plugins --> Manage and Install Plugins . Search for the plugin planet_explorer , click Install Using the Plugin After installation is complete, make sure the Planet QGIS Plugin is activated in the Manage and Install Plugins interface (Plugins --> Manage and Install Plugins...) Then from the QGIS menu bar, select Web --> Planet Explorer --> Planet Explorer : Once activated, the Planet toolbar will be added to your QGIS project. Log in to your Planet account The login interface lets you to log in with the email and password associated with your Planet account. Selecting the option to Save Credentials will cache your login within QGIS's authentication system to save time when working in the same project. Once the plugin is open, you'll see this login interface. Enter your Planet account information, or click the Contact Us! link to be in touch with our team. Once logged in, the imagery & Basemaps available to your account will be accessible.","tags":"integrations-qgis","url":"https://developers.planet.com/docs/integrations/qgis/quickstart/","loc":"https://developers.planet.com/docs/integrations/qgis/quickstart/"},{"title":"Getting Started","text":"Installation & Configuration Make sure ESRI ArcGIS Pro is downloaded and installed Download the Planet ArcGIS Add-In Once downloaded, double-click the .esriAddinX file to open the Add-In file and install. When you open ArcGIS Pro, you should now see a Planet Imagery tab available in the toolbar ribbon You can learn more about managing and installing Add-Ins in ArcGIS Pro here Planet Login Select the Account icon from the Planet Imagery ribbon to log in, then authenticate using your Planet username and password. Once logged in, the imagery & Basemaps available to your account will be accessible through Add-In's tools.","tags":"integrations-arcgis","url":"https://developers.planet.com/docs/integrations/arcgis/quickstart/","loc":"https://developers.planet.com/docs/integrations/arcgis/quickstart/"},{"title":"Getting Started with Planet","text":"Prerequisites To use any part of Planet's platform or any of Planet's applications, you'll need a Planet account. If you don't already have one, you can sign up for trial access. If you are a developer interested in developing with Planet's APIs, you can apply to our Developer Program - be sure to include details on your development needs or usecase(s) in your application. Choose your own Adventure Want to see Planet Imagery in your browser? Get started with Planet Explorer Prefer to use QGIS or ArcGIS? Check out Planet's Integrations for your GIS software of choice Ready to dive into Planet's collection of APIs? The APIs quickstart guide is for you","tags":"quickstart","url":"https://developers.planet.com/quickstart/","loc":"https://developers.planet.com/quickstart/"},{"title":"RapidEye","text":"RapidEye, formerly operated by Planet, is a retired constellation of five satellites, in operation from 2009 to 2020. RapidEye images are approximately 5 meters per pixel resolution. Constellation and Sensor Overview The RapidEye satellite constellation consisted of a single launch of five RapidEye satellites. Imagery Products Item Types RapidEye Products are available for search and download via Planet's APIs, User Interfaces, and Integrations, in the form of Scene and OrthoTile products, which are encoded in our platform as a set of Item Types and Asset Types. A RapidEye Scene Product is an individual framed scene, captured by the satellite in its line-scan of the Earth. Scenes within a strip are overlapping, and not organized to any particular tiling grid system. RapidEye Scene products range from 75 x 50 square kilometers to 75 x 300 square kilometers. They are represented in the Planet Platform as the REScene item type. A RapidEye OrthoTile Product is a 25 x 25 square kilometers orthorectified and tiled product generated from a set of consecutive scenes within a strip (usually 1 or 2), based on a worldwide, fixed UTM grid system. They are represented in the Planet Platform as the REOrthoTile item type. Asset Types RapidEye Scene and OrthoTile imagery products are available for download in the form of imagery assets. Multiple asset types are made available for Scene and OrthoTile products, each with differences in radiometric processing, and/or rectification. Asset Type availability varies by Item Type. You can find an overview of supported assets by item type here: REScene Supported Assets REOrthoTile Supported Assets Basic Analytic ( basic_analytic ) assets are non-orthorectified, calibrated, multispectral imagery products that have been corrected for sensor artifacts and transformed to Top of Atmosphere (at-sensor) radiance. These products are designed for data science and analytic applications, and for users who wish to geometrically correct the data themselves (leveraging the associated rational polynomial coefficient asset type). Analytic ( analytic ) assets are orthorectified, calibrated, multispectral imagery products that have been corrected for sensor artifacts and terrain distortions, and transformed to Top of Atmosphere (at-sensor) radiance. These products are designed for data science and analytic applications which require imagery with accurate geolocation and cartographic projection. Visual ( visual ) assets are orthorectified and color-corrected to optimize colors seen by the human eye, providing images as they would look if viewed from the perspective of the satellite. These products are designed for simple and direct visual inspection, and can be used and ingested directly into a Geographic Information System or application. Surface Reflectance ( analytic_sr ) assets are orthorectified and radiometrically corrected to ensure consistency across localized atmospheric conditions, and to minimize uncertainty in spectral response across time and location. These products are designed for temporal analysis and monitoring applications, especially in agriculture and forestry sectors. You can find our complete Imagery Product Specification here . Product Naming The name of each acquired RapidEye image is designed to be unique and allow for easier recognition and sorting of the imagery. It includes the date and time of capture, as well as the id of the satellite that captured it, product level, and product type. The name of each downloaded image product is composed of the following elements: RapidEye Scene <acquisition_date>T<acquisition_time>_<satellite_id>_<productLevel>_<bandProduct>.<extension> Example: 2018-09-29T163919_RE1_1B_band1.tif RapidEye OrthoTile <tileid>_<acquisition_date>_<satellite_id>_<productLevel>_<bandProduct>.<extension> Example: 1657017_2018-09-29_RE1_3A_Analytic.tif Processing Several processing steps are applied to RapidEye imagery to produce the set of data products available for download. Click for full-size image Sensor & Radiometric Calibration Flat Field Correction : Flat fields were collected for each optical instrument prior to launch. These fields were used to correct image lighting and CCD element effects to match the optimal response area of the sensor. Temporal Calibration : To achieve cross calibration, corrections were applied such that all RapidEye cameras read the same DN (digital number) regardless of when the image has been taken in the mission lifetime. Absolute Calibration : As a last step, the spatially and temporally adjusted datasets were transformed from digital number values into physical based radiance values (scaled to W/(m² str μm)*100). Orthorectification Removes terrain distortions. This process consists of two steps: The rectification tiedown process wherein tie points are identified across the source images and a collection of reference images (ALOS, NAIP, Landsat) and RPCs are generated. The actual orthorectification of the scenes using the RPCs, to remove terrain distortions. The terrain model used for the orthorectification process is derived from multiple sources (Intermap, NED, SRTM and other local elevation datasets) which are periodically updated. Snapshots of the elevation datasets used are archived (helps in identifying the DEM that was used for any given scene at any given point). Visual Product Processing Presents the imagery as natural color, optimized as seen by the human eye. This process consists of three steps: Nominalization - Sun angle correction, to account for differences in latitude and time of acquisition. This makes the imagery appear to look like it was acquired at the same sun angle by converting the exposure time to the nominal time (noon). Unsharp mask (sharpening filter) applied before the warp process. Custom color curve applied post warping. Surface Reflectance Product Processing Removes atmospheric effects. This process consists of three steps: Top of Atmosphere (TOA) reflectance calculation using coefficients supplied with the at-sensor radiance product. Lookup table (LUT) generation using the 6SV2.1 radiative transfer code and MODIS near-real-time data inputs. Conversion of TOA reflectance to surface reflectance for all combinations of selected ranges of physical conditions and for each satellite sensor type using its individual spectral response as well as estimates of the state of the atmosphere. You can find a detailed white paper on our Surface Reflectance Products here .","tags":"data","url":"https://developers.planet.com/docs/data/rapideye","loc":"https://developers.planet.com/docs/data/rapideye"},{"title":"Release notes","text":"24 October 2019 This is a major release with a few important changes. The order states QUEUED and PROCESSING have been moved to the capture level, which now includes the following states: QUEUED (new) PROCESSING PUBLISHED FAILED To show more visibility into granular capture states at the order level, the following two fields were introduced to the orders response: capture_status_queued_count lists the number of captures in QUEUED state capture_status_processing_count lists the number of captures in PROCESSING state Together the following calls can be used to identify corders which were previously considered QUEUED or PROCESSING : GET /tasking/v2/orders/?capture_status_queued_count__gt=0 GET /tasking/v2/orders/?capture_status_processing_count__gt=0 The order state FINALIZING was introduced. This state represents an order with an end time that has expired, but still has one or more captures in QUEUED or PROCESSING states. This state will ensure an order isn't marked as EXPIRED when a SUCCESS capture is about to be PUBLISHED . New endpoint /tasking/v2/orders/aggregates/status/ was introduced to give you a roll-up of all your organization's orders by status. The endpoint /tasking/v1/orders/<order_id>/captures is now deprecated.","tags":"tasking","url":"https://developers.planet.com/docs/tasking/release-notes/","loc":"https://developers.planet.com/docs/tasking/release-notes/"},{"title":"Getting Started with REST APIs","text":"To follow along with this guide, check out the complete tutorial here .","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/getting-started-with-rest-apis/","loc":"https://developers.planet.com/docs/planetschool/getting-started-with-rest-apis/"},{"title":"\"Satellites & Sensors\"","text":"[block:callout] { \"type\": \"danger\", \"title\": \"TODO - Need to discuss what should be in this section.\" } [/block] Planet operates the PlanetScope (PS) and RapidEye (RE) Earth-imaging constellations. Imagery is collected and processed in a variety of formats to serve different use cases, be it mapping, deep learning, disaster response, precision agriculture, or simple temporal image analytics to create rich information products. PlanetScope satellite imagery is captured as a continuous strip of single frame images known as \"scenes.\" Scenes may be acquired as a single RGB (red, green, blue) frame or a split-frame with a RGB half and a NIR (near-infrared) half depending on the capability of the satellite. Planet offers three product lines for PlanetScope imagery: a Basic Scene product, an Ortho Scene product, and an Ortho Tile product. The Basic Scene product is a scaled Top of Atmosphere Radiance (at sensor) and sensor-corrected product. The Basic Scene product is designed for users with advanced image processing and geometric correction capabilities. The product is not orthorectified or corrected for terrain distortions. Ortho Scenes represent the single-frame image captures as acquired by a PlanetScope satellite with additional post processing applied. Ortho Tiles are multiple orthorectified scenes in a single strip that have been merged and then divided according to a defined grid. [block:image] { \"images\": [ { \"image\": [ \"https://files.readme.io/a2700c1-Figure_A-Planet-Imagery-Product-Offerings.jpg\", \"Figure_A-Planet-Imagery-Product-Offerings.jpg\", 5965, 3385, \"#dae5e5\" ], \"caption\": \"Planet Imagery Product Offerings\", \"sizing\": \"full\" } ] } [/block]","tags":"data","url":"https://developers.planet.com/docs/data/satellites-sensors/","loc":"https://developers.planet.com/docs/data/satellites-sensors/"},{"title":"How to Save Your Work","text":"Create a Saved Search Start by searching for your imagery by creating an area of interest (AOI), either by drawing an AOI or by typing in a location in the Search panel. To find the Search panel, which can be found in the upper left hand corner, indicated by the magnifying glass icon. Once the panel is open, you can select your cadence (i.e. daily, weekly, monthly, quarterly), choose filters and date ranges. When you are happy with your selections, you will find a Save Search button above the search results. When you click Save Search you will see a window appear where you can make some additional selections. You will name your search, and then make selections under Search Options and Search Parameters . The name of your Saved Search will default to the text you typed into the Search bar initially. On the left hand side under Search Options , you have the option to enable or disable email notifications and also organize your search into a Folder. When selecting email notifications, email notifications are enabled when the toggle is teal. When the toggle is grey, the email notifications are disabled. * Note: these notifications are not affected by the Date Range Filter you specified - it applies to all new imagery within your AOI boundary. You can create a new Folder to organize your searches by clicking typing in a name and clicking Add . Your search will be added to the Folder that is highlighted in teal. Under Search Parameters you can verify your selected date range or omit an end date for your saved search. If you click No End Date you will always see the most recent imagery in your saved search. You can also verify the other parameters of your saved search. If any of these parameters are incorrect to you, click the x in the upper right hand corner and adjust in the Search panel. To access Searches that you have Saved, click the icon just below the Search icon in the left-hand toolbar, called Saved Search . Update Saved Search If you have already Saved your Search, and wish to update it with new filter parameters, you can choose Update Search at the top (where Save Search text was initially). Download area of interest as GEOJSON You can download the GEOJSON file of the area of interest (AOI) you drew in Explorer by clicking this icon on the map. The icon only appears once you have drawn an AOI. Name your file and click Download . Share your session with a link When you select the link icon, you will see a short URL to copy. Anyone with this link can view your entire session: your area of interest, your search filters, and your current selections.","tags":"apps-explorer","url":"https://developers.planet.com/docs/apps/explorer/how-to-save-work/","loc":"https://developers.planet.com/docs/apps/explorer/how-to-save-work/"},{"title":"Searching for Imagery with Data API","text":"Overview This API Quickstart guide will walk you through how to search for imagery using the Planet Data API. This guide is all about image metadata. When you're done, see Step 2: Downloading imagery to learn how to start downloading the image files. If you haven't already, see the \"Getting Started\" guide for info on how to acquire an API key and setup your development environment. ItemTypes The Planet API brings together different classes of imagery, some classes represent different satellites, some represent different formats, sometimes it's both. Each class of imagery is identified by its \"ItemType\". Examples of ItemTypes are \"REOrthoTile\" - Images taken by RapidEye satellites in the OrthoTile format. We can see what ItemTypes are avaliable to our API key with our first API query: ➜ curl -L -H \"Authorization: api-key $PL_API_KEY\" \\ 'https://api.planet.com/data/v1/item-types' | jq '.item_types[].id' \"REOrthoTile\" Select an Area of Interest (AOI) You can use geojson.io to get geometry coordinates for an area that interests you, start small : ) Here's an AOI around a Reservoir near Redding California: The highlighted JSON is a GeoJSON geometry object that we can use as a filter in the Planet API. Search Filters Several Planet API endpoints operate on filters, which can be used to narrow down imagery by a variety of attributes like location, cloud coverage %, acquisition date etc. At this point, it will be easier if we start using Python to interact with the API. The runnable source file for all code snippets will be linked above each snippet. Let's define some filters: examples/demo_filters.py # the geo json geometry object we got from geojson.io geo_json_geometry = { \"type\": \"Polygon\", \"coordinates\": [ [ [ -122.52227783203125, 40.660847697284815 ], [ -122.52227783203125, 40.987154933797335 ], [ -122.01690673828124, 40.987154933797335 ], [ -122.01690673828124, 40.660847697284815 ], [ -122.52227783203125, 40.660847697284815 ] ] ] } # filter for items the overlap with our chosen geometry geometry_filter = { \"type\": \"GeometryFilter\", \"field_name\": \"geometry\", \"config\": geo_json_geometry } # filter images acquired in a certain date range date_range_filter = { \"type\": \"DateRangeFilter\", \"field_name\": \"acquired\", \"config\": { \"gte\": \"2016-07-01T00:00:00.000Z\", \"lte\": \"2016-08-01T00:00:00.000Z\" } } # filter any images which are more than 50% clouds cloud_cover_filter = { \"type\": \"RangeFilter\", \"field_name\": \"cloud_cover\", \"config\": { \"lte\": 0.5 } } # create a filter that combines our geo and date filters # could also use an \"OrFilter\" redding_reservoir = { \"type\": \"AndFilter\", \"config\": [geometry_filter, date_range_filter, cloud_cover_filter] } Stats Endpoint A good first step would be to use our filter to query the stats endpoint, this will give us a date bucketed histogram to show us how many items match our filter: examples/stats_endpoint.py import os import requests from requests.auth import HTTPBasicAuth # our demo filter that filters by geometry, date and cloud cover from demo_filters import redding_reservoir # Stats API request object stats_endpoint_request = { \"interval\": \"day\", \"item_types\": [\"REOrthoTile\"], \"filter\": redding_reservoir } # fire off the POST request result = \\ requests.post( 'https://api.planet.com/data/v1/stats', auth=HTTPBasicAuth(os.environ['PL_API_KEY'], ''), json=stats_endpoint_request) print result.text Run the script: ➜ python examples/stats_endpoint.py | jq { \"utc_offset\": \"+0h\", \"interval\": \"day\", \"buckets\": [ { \"count\": 6, \"start_time\": \"2016-07-07T00:00:00.000000Z\" }, { \"count\": 9, \"start_time\": \"2016-07-13T00:00:00.000000Z\" }, { \"count\": 3, \"start_time\": \"2016-07-17T00:00:00.000000Z\" }, { \"count\": 6, \"start_time\": \"2016-07-19T00:00:00.000000Z\" }, { \"count\": 6, \"start_time\": \"2016-07-22T00:00:00.000000Z\" } ] } Nice! We can see that in July 2016, RapidEye satellites imaged the area on 5 different days. Search Endpoint Now let's do a search, this takes the same filter object as the stats endpoint but returns complete metadata objects about the matching items. examples/search_endpoint.py import os import requests from requests.auth import HTTPBasicAuth # our demo filter that filters by geometry, date and cloud cover from demo_filters import redding_reservoir # Search API request object search_endpoint_request = { \"item_types\": [\"REOrthoTile\"], \"filter\": redding_reservoir } result = \\ requests.post( 'https://api.planet.com/data/v1/quick-search', auth=HTTPBasicAuth(os.environ['PL_API_KEY'], ''), json=search_endpoint_request) print result.text You can use jq to filter the search response down to only item ids: ➜ python examples/search_endpoint.py | jq '.features[].id' \"20160707_195147_1057916_RapidEye-1\" \"20160707_195146_1057917_RapidEye-1\" \"20160707_195150_1057817_RapidEye-1\" \"20160707_195143_1058017_RapidEye-1\" \"20160707_195143_1058016_RapidEye-1\" \"20160707_195150_1057816_RapidEye-1\" \"20160722_194931_1057916_RapidEye-2\" \"20160722_194930_1057917_RapidEye-2\" \"20160722_194928_1058016_RapidEye-2\" \"20160722_194927_1058017_RapidEye-2\" ... With some more jq magic, we can grab the 3rd item from our search and display its properties. All of these values can be used in a search filter. ➜ python examples/search_endpoint.py | jq '.features[3].properties' { \"acquired\": \"2016-07-07T19:51:47Z\", \"anomalous_pixels\": 0.05, \"black_fill\": 0, \"cloud_cover\": 0.05, \"columns\": 5000, \"epsg_code\": 32610, \"grid_cell\": \"1057916\", \"gsd\": 6.5, \"item_type\": \"REOrthoTile\", \"origin_x\": 523500, \"origin_y\": 4536500, \"pixel_resolution\": 5, \"provider\": \"rapideye\", \"published\": \"2016-08-18T21:26:07Z\", \"rows\": 5000, \"satellite_id\": \"RapidEye-1\", \"sun_azimuth\": 162.95195, \"sun_elevation\": 71.12186, \"updated\": \"2016-08-29T04:50:33Z\", \"usable_data\": 0.95, \"view_angle\": -13.04192 } One Weird Trick: jq and geojson.io A cli exists to easily send GeoJson geometries to geojson.io. You can use jq to extract the geometry coordinates of a specific item from the search results and pipe it into the geojsonio tool: python examples/search_endpoint.py | jq '.features[3].geometry' | geojsonio This visualizes the footprint of the 3rd item in the search: Next Guide: Downloading imagery","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/searching-for-imagery-with-data-api/","loc":"https://developers.planet.com/docs/planetschool/searching-for-imagery-with-data-api/"},{"title":"Search Filters","text":"Search supports four main filter types: Field Filters allow you to search items by item metadata. There are six field filter types, each supporting different data types and configurations. Asset Filters allow you to search items by published asset types. Permission Filters allow you to search items based on your download permissions. Logical Filters allow you to combine multiple filters using logical operators to further expand or restrict your search. Field Filters Field filters support search by item metadata and require a mandatory field_name to indicate the relevant property targeted by the filter. Field filters are supported for all item metadata. For more detail on available item metadata, read more on item types and item properties in the Items & Assets tab. A full list of field filter types are described below. Filter Description Supported Configs DateRangeFilter Matches items with a specified timestamp property which falls within a specified range. gte , gt , lt or lte GeometryFilter Matches items with a footprint that intersects with a specified GeoJSON geometry. GeoJSON object NumberInFilter Matches items with a specified numerical property that matches a specified array of numbers. array of numbers RangeFilter Matches items with a specified numerical property that falls within a specified range. gte , gt , lt or lte StringInFilter Matches items with a specified string property that fully matches a specified array of strings. Boolean properties are also supported with this filter type. array of strings UpdateFilter Matches items by changes to a specified property made on after a specified date, due to a republishing event. gt or gte DateRangeFilter The DateRangeFilter can be used to search on any property with a timestamp such as acquired or published . The filter's configuration is a nested structure with optional keys: gte , gt , lt or lte . Each corresponding value is an RFC 3339 date. Example DateRangeFilter { \"type\":\"DateRangeFilter\", \"field_name\":\"acquired\", \"config\":{ \"gt\":\"2019-12-31T00:00:00Z\", \"lte\":\"2020-01-31T00:00:00Z\" } } Returns all items acquired after midnight on Dec 31, 2019 and on or before January 31, 2020. GeometryFilter The GeometryFilter can be used to search for items with a footprint geometry which intersects with the specified geometry . The filter's configuration supports Point, MultiPoint, LineString, MultiLineString, Polygon, and MultiPolygon GeoJSON object. For best results, the geometry should meet OpenGIS Simple Features Interface Specification requirements. If an invalid GeoJSON object is supplied, the API will automatically attempt to correct the geometry and return matching search results. Pro Tip Check out the Planet School tutorial GeoJSON and Areas of Interest (AOIs) for more on defining an area of interest. Example GeometryFilter { \"type\":\"GeometryFilter\", \"field_name\":\"geometry\", \"config\":{ \"type\":\"Polygon\", \"coordinates\":[ [ [ -120.27282714843749, 38.348118547988065 ], [ -120.27282714843749, 38.74337300148126 ], [ -119.761962890625, 38.74337300148126 ], [ -119.761962890625, 38.348118547988065 ], [ -120.27282714843749, 38.348118547988065 ] ] ] } } Returns all items which intersect with the specified geometry . NumberInFilter The NumberInFilter can be used to search for items with numerical properties. It is useful for matching fields such as gsd . The filter's configuration is an array of numbers. Example NumberInFilter { \"type\":\"NumberInFilter\", \"field_name\":\"gsd\", \"config\":[ 3 ] } Returns all items with a gsd value of 3. RangeFilter The RangeFilter can be used to search for items with numerical properties. It is useful for matching fields that have a continuous range of values such as cloud_cover or view_angle . The filter's configuration is a nested structure with optional keys: gte , gt , lt or lte . Example RangeFilter { \"type\":\"RangeFilter\", \"field_name\":\"cloud_cover\", \"config\":{ \"lte\":0.1 } } Returns all items with cloud_cover less than or equal to 10%. StringInFilter The StringInFilter can be used to search for items with string properties such as instrument or quality_category . Boolean properties such as ground_control are also supported with the StringInFilter . The filter's configuration is an array of strings. When multiple values are specified, an implicit \"or\" logic is applied, returning items with the given field matching any of the values. Example StringInFilter { \"type\":\"StringInFilter\", \"field_name\":\"quality_category\", \"config\":[ \"standard\", \"test\" ] } Returns all items with a quality category of standard or test . UpdateFilter The UpdateFilter can be used to filter items by changes to a specified metadata field value made after a specified date, due to a republishing event. This feature allows you identify items which may have been republished with improvements or fixes, enabling you to keep your internal catalogs up-to-date and make more informed redownload decisions. The filter works for all items published on or after April 10, 2020. The filter accepts a field name and a gt or gte timestamp. While any field name may be specified, the primary fields which may be impacted by quality, usability, or rectification improvements are geometry , quality_category , ground_control , and udm or udm2 fields (including visible_percent , clear_percent , cloud_percent , heavy_haze_percent , light_haze_percent , snow_ice_percent , shadow_percent , cloud_cover , black_fill , usable_data , and anomalous_pixels ). Example UpdateFilter { \"type\":\"UpdateFilter\", \"field_name\": \"ground_control\", \"config\":{ \"gt\": \"2020-04-15T00:00:00Z\" } } Returns all items with a ground_control value which has changed on or after April 15, 2020. To filter items by field value changes to multiple fields (i.e. changes to ground_control or quality_category ), multiple UpdateFilters can be used within a logical AndFilter or OrFilter . Asset Filters The AssetFilter can be used to search for items which have published a specified asset_type . This filter is commonly used to filter items by published asset types which: May be published at delay after an item's first publish. analytic_sr , for instance, may be published up to 12 hours after an item first becomes available. May not be available for the full catalog. udm2 , for instance, is only available globally through July 2018. The filter's configuration is a list of asset types. When multiple values are specified, an implicit \"or\" logic is applied, returning all items which include any of the listed asset types. An AndFilter can be used to filter items by multiple asset types. { \"type\": \"AndFilter\", \"config\": [ { \"type\": \"AssetFilter\", \"config\": [ \"analytic_sr\" ] }, { \"type\": \"AssetFilter\", \"config\": [ \"udm2\" ] } ] } Returns all items with published analytic_sr and udm2 assets. Permission Filters The PermissionFilter can be used to limit results to items that a user has permission to download, taking into consideration area of interest, time of interest, item type, and asset type download permissions. Its recommended configuration is an array which includes the assets:download permission. Example PermissionFilter { \"type\":\"PermissionFilter\", \"config\":[ \"assets:download\" ] } Returns all items within the requester's area and time of interest which have published assets the requester has permission to download. Tips for Using the PermissionFilter with Logical Filters: OrFilter : We do not recommend nesting the assets:download PermissionFilter in an OrFilter . In this context, it will continue to filter all results by AOI, TOI, item type, and asset type permissions. NotFilter : We do not recommend not nesting the assets:download PermissionFilter in a NotFilter . This search will return no results. Caution We are deprecating support for asset type permission filters (i.e. assets.<asset_type>:download ). To filter items by published assets, use the AssetFilter . To limit those results by items with assets you have permission to download, combine the AssetFilter with the assets:download PermissionFilter using an AndFilter . Logical Filters Logical filters allow you to search on complex criteria, expressed across multiple fields, with a variety of conditions. In most cases, you'll want to start your search with a single logical filter. The most common use of logical filters is to have a top-level AndFilter to ensure criteria across all field and permission filters are met. Filter Description AndFilter Matches items with properties or permissions which match all the nested filters. OrFilter Matches items with properties or permissions which match at least one of the nested filters. NotFilter Matches items with properties or permissions which do not match the nested filter. This filter type supports a single nested filter. AndFilter The AndFilter can be used to limit results to items with properties or permissions which match all nested filters. It is most commonly used as a top-level filter to ensure criteria across all field and permission filters are met. Example AndFilter { \"type\":\"AndFilter\", \"config\":[ { \"type\":\"DateRangeFilter\", \"field_name\":\"acquired\", \"config\":{ \"gte\":\"2020-01-01T00:00:00Z\", \"lte\":\"2020-01-31T00:00:00Z\" } }, { \"type\":\"StringInFilter\", \"field_name\":\"ground_control\", \"config\":[ \"true\" ] }, { \"type\": \"AssetFilter\", \"config\": [ \"analytic_sr\" ] }, { \"type\":\"PermissionFilter\", \"config\":[ \"assets:download\" ] } ] } Returns all orthorectified items that were acquired from January 1st, 2020 through January 31st, 2020, have a published analytic_sr asset, and meet the requester's AOI, TOI, and item type/asset type download permissions. OrFilter The OrFilter can be used to match items with properties or permissions which match at least one of the nested filters. Example OrFilter { \"type\":\"OrFilter\", \"config\":[ { \"type\":\"RangeFilter\", \"field_name\":\"visible_percent\", \"config\":{ \"gte\":90 } }, { \"type\":\"RangeFilter\", \"field_name\":\"usable_data\", \"config\":{ \"gte\":0.90 } } ] } Returns all items that for which visible_percent is greater or equal to 90, or usable_data is greater or equal to 0.90. This example could be useful for a query of older items which may or may not have a udm2 metadata available. NotFilter The NotFilter can be used to match items with properties or permissions which do not match the nested filters. This filter only supports a single nested filter. Multiple NotFilter s can be nested within an AndFilter to filter across multiple fields or permission values. Example NotFilter { \"type\":\"NotFilter\", \"config\":{ \"type\":\"StringInFilter\", \"field_name\":\"quality_category\", \"config\":[ \"test\" ] } } Filters out test items to return all items which have a quality_category of standard or test .","tags":"data-api","url":"https://developers.planet.com/docs/apis/data/searches-filtering/","loc":"https://developers.planet.com/docs/apis/data/searches-filtering/"},{"title":"Search Stats","text":"Search Stats gives you a quick way to determine the number of items which meets your search specifications. This endpoint allows you to specify a time interval and search filter and returns a histogram of item counts, grouped by interval, which match your filter criteria. This endpoint can be used to answer questions such as: How does availability of imagery with less than 10 percent cloud cover change seasonally in Jakarta? How deep is Planet's 2019 SkySat archive over Shanghai? How many items which meet my search criteria are published each hour? Request Body The body of a stats request must include a search filter and time interval. filter (required): is your structure search criteria; you can read more on supported filters on our Search Filters page interval (required): specifies the time interval of the returned histogram buckets; \"hour\" , \"day\" , \"week\" , \"month\" , or \"year\" item_types (required): limits results by item type(s) utc_offset (optional): offsets the start time of your histogram buckets to match your desired timezone (ISO 8601 UTC offset, ex. +1h or -8h) Example Request POST https://api.planet.com/data/v1/stats { \"item_types\": [ \"PSScene\" ], \"interval\": \"day\", \"filter\": { \"type\":\"AndFilter\", \"config\":[ { \"type\":\"DateRangeFilter\", \"field_name\":\"acquired\", \"config\":{ \"gte\":\"2022-03-01T00:00:00Z\", \"lte\":\"2022-03-07T00:00:00Z\" } }, { \"type\": \"AssetFilter\", \"config\": [ \"ortho_analytic_8b\" ] } ] }, \"utc_offset\": \"-8h\" } Request for counts of all PlanetScope 4-band items with analytic_sr assets acquired between February 1, 2020 and February 7, 2020, grouped by day in Pacific Standard Time. Response Schema The stats response returns an array of stats bucket results, each of which include a bucket start time and count of items which meet the request's filter criteria. Example response { \"buckets\": [ { \"count\": 178479, \"start_time\": \"2022-02-28T16:00:00.000000Z\" }, { \"count\": 226455, \"start_time\": \"2022-03-01T16:00:00.000000Z\" }, { \"count\": 242567, \"start_time\": \"2022-03-02T16:00:00.000000Z\" }, { \"count\": 243330, \"start_time\": \"2022-03-03T16:00:00.000000Z\" }, { \"count\": 230189, \"start_time\": \"2022-03-04T16:00:00.000000Z\" }, { \"count\": 219070, \"start_time\": \"2022-03-05T16:00:00.000000Z\" }, { \"count\": 38622, \"start_time\": \"2022-03-06T16:00:00.000000Z\" } ], \"interval\": \"day\", \"utc_offset\": \"-8h\" } Response includes daily histogram buckets and counts of items which meet the request's filter criteria. The time zone of each bucket has been adjusted to Pacific Standard Time (with a UTC offset of -8h).","tags":"data-api","url":"https://developers.planet.com/docs/apis/data/search-stats/","loc":"https://developers.planet.com/docs/apis/data/search-stats/"},{"title":"Segmentation on Imagery","text":"Number Description 1 Title of the Subscription. Generated manually by the Planet Account Manager. 2 Subscription Description. This is the title of the analytic subscription you're reviewing 3 Timeframe for Planet Basemap. These dates represent the time period from which imagery is used to generate a Planet Basemap. 4 More Information. Click to bring up details on the source and target layers, described in more detail below. 5 Transparency Slider. Darken or dim the output using the transparency slider. Number Description 1 Target Mosaic Information . The \"Target Mosaic\" is the derived raster GeoTIFF showcasing where Planet was able to detect features. 2 XYZ Tile URL for Target Mosaic . Use this URL within QGIS, ArcGIS, or your GIS tool of choice to stream in the derived raster layer. 3 Source Mosaic Information . The \"Source Mosaic\" is the basemap that is processed by Planet's machine learning models to derive the analytic output. 4 XYZ Tile URL for Source Mosaic. Use this URL within QGIS, ArcGIS, or your GIS tool of choice to stream in tiles of the source Planet Basemap 5 Link to Planet Basemap Viewer for the Target Mosaic . Leverage Planet Basemap Viewer to download source mosaic GeoTIFFs. 6 Instructions for Planet's XYZ Tile Service . This links to Planet Developer Center for details on how to best use our XYZ tile service. 7 Link to Planet Basemap Viewer for Source Mosaic . Leverage Planet Basemap Viewer if you wish to download source mosaic GeoTIFFs. 8 Instructions for using Planet's XYZ Tile Service . This links to Planet Developer Center for details on how to best use our XYZ tile service.","tags":"apps-feedviewer","url":"https://developers.planet.com/docs/apps/feedviewer/segmentation/","loc":"https://developers.planet.com/docs/apps/feedviewer/segmentation/"},{"title":"Simplifying Geometries","text":"Simplifying geometries When possible, reducing the complexity of a geometry makes geospatial computation more efficient. Some applications cannot handle geometries of complex shapes or with hundreds of vertices. For example, the Planet Platform (our applications and APIs) requires geometries to be less than 500 vertices. When using the Planet Platform, you are comparing your geometry with the catalog to find items within your area of interest. So you can ensure coverage with a reduced number of vertices to make any operation run more smoothly. Common geometry simplification routines You can view common simplification routines online at sites such as Mapshaper . There you can upload a file, select \"Simplify,\" choose from common algorithms, and use a percentage slider to decrease the number of lines. Mapshaper also has a command-line tool . You can also find simplification routines in your geospatial software. For example, QGIS has a rendering routine that simplifies geometries on-the-fly , as well as a way to simplify existing geometries in their Processing Toolbox (Vector geometries > Simplify). These sorts of geospatial applications also have programming interfaces, for example, the Google Earth Engine simplify API . And common geospatial libraries also have simplification routines. (See GeoPandas and Shapely simplify API.) Buffer when needed Most simplification algorithms, when reducing curves or number of lines, have a tendency to reduce area in convex cases and increase it in concave cases (for example, inner bends or elbows). Polygon lines eventually need to close up and tend to have more convex bends than concave bends, which lose area during simplification. The greater percentage of simplification, the more area lost. Convex line before simplification Convex line after simplification If you are interested in minimizing the loss during simplification, you can buffer slightly before simplification. For example, you could add a small buffer, then simplify by half of that buffer distance to remove extra points. Sometimes creating a buffer, itself, is enough to reduce the complexity of the geometry. Many geospatial applications, API, and libraries have a buffer routine (see for example, the Google Earth Engine buffer API or QGIS buffers ). Your mileage may vary with simplified buffers and good results require care and experience. It's actually not difficult to increase the complexity of shapes by buffering. Convex hulls are more \"foolproof\" than simplified buffers. They always preserve area (they have extra, of course) and don't require tuning (there are no knobs to tune). Concave hull operations will be available soon and these will be qualitatively better than convex hulls and easier to use than simplified buffers. Learning Resources For information on simplifying your geometries see Simplifying Your Complex Area of Interest: a Planet Developers Deep Dive .","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/simplifying-geometries/","loc":"https://developers.planet.com/docs/planetschool/simplifying-geometries/"},{"title":"SkySat","text":"SkySat, operated by Planet, is a high resolution constellation of 21 satellites, able to image revisit any location on Earth up to 10x daily (a daily collection capacity of 400 thousand km²/day). SkySat images are approximately 50 centimeters per pixel resolution. Constellation & Sensor Overview The SkySat satellite constellation consists of multiple launches of our SkySat-C generation satellites, first launched in 2016. Each satellite is 3-axis stabilized and agile enough to slew between different targets of interest. Each satellite has four thrusters for orbital control, along with four reaction wheels and three magnetic torquers for attitude control. All SkySats contain Cassegrain telescopes with a focal length of 3.6m, with three 5.5 megapixel CMOS imaging detectors making up the focal plane. SkySat Imagery Products Item Types SkySat Products are available for search and download via Planet's APIs, User Interfaces, and Integrations, in the form of Scene, Collect, and Video products, which are encoded in our platform as a set of Item Types and Asset Types. A SkySat Scene Product is an individual framed scene within a strip, captured by the satellite in its line-scan of the Earth. SkySat Satellites have three cameras per satellite, which capture three overlapping strips. Each of these strips contain overlapping scenes, not organized to any particular tiling grid system. SkySat Scene products are approximately 1 x 2.5 square kilometers in size. They are represented in the Planet Platform as the SkySatScene item type. A SkySat Collect Product is created by composing roughly 60 SkySat Scenes along an imaging strip into an orthorectified segment, approximately 20 x 5.9 square kilometers in size. They are represented in the Planet Platform as the SkySatCollect item type. This product may be easier to handle, if you're looking at larger areas of interest with SkySat imagery. Due to the image rectification process involved in creating this product, Collect is generally recommended over the Scene product when the AOI spans multiple scenes, particularly if a mosaic or composite image of the individual scenes is required. Collect performs necessary rectification steps automatically. This is especially useful for users who don't feel comfortable doing orthorectification manually. A SkySat Video Product is a full motion video are collected between 30 and 120 seconds by a single camera from any of the SkySats. Its size is comparable to a SkySat Scene, about 1 x 2.5 square kilometers. They are represented in the Planet Platform as the SkySatVideo item type. Imagery Asset Types SkySat Scene and Collect products are available for download in the form of imagery assets. Multiple asset types are made available for Scene and Collect products, each with differences in radiometric processing and/or rectification. Asset Type availability varies by Item Type. You can find an overview of supported assets by item type here: SkySatScene Supported Assets SkySatCollect Supported Assets Basic Analytic ( basic_analytic ) assets are non-orthorectified, calibrated, multispectral imagery products with native sensor resolution (0.72-0.81m), that have been transformed to Top of Atmosphere (at-sensor) radiance. These products are designed for data science and analytic applications, and for users who wish to geometrically correct the data themselves with associated rational polynomial coefficients (RPCs) assets (ground control applied). Basic L1A Panchromatic ( basic_l1a_panchromatic_dn ) assets are non-orthorectified, uncalibrated, panchromatic-only imagery products with native sensor resolution (0.72-0.81m), that have been made available roughly two hours before all other SkySat asset types are available in the catalog. These products are designed for time-sensitive, low-latency monitoring applications, and can be geometrically corrected with associated rational polynomial coefficients (RPCs) assets (derived from satellite telemetry). Basic Panchromatic ( basic_panchromatic ) assets are non-orthorectified, calibrated, super-resolved (0.65m), panchromatic-only imagery products that have been transformed to Top of Atmosphere (at-sensor) radiance. These products are designed for data science and analytic applications which depend on a wider spectral range (Pan: 450 - 900 nm), and for users who wish to geometrically correct the data themselves with associated rational polynomial coefficients (RPCs) assets (ground control applied). Ortho Analytic ( ortho_analytic ) assets are orthorectified, calibrated, multispectral imagery products with native sensor resolution (0.72-0.81m), that have been transformed to Top of Atmosphere (at-sensor) radiance. These products are designed for data science and analytic applications which require imagery with accurate geolocation and cartographic projection. Ortho Analytic Surface Reflectance ( ortho_analytic_sr ) assets are corrected for the effects of the Earth's atmosphere, accounting for the molecular composition and variation with altitude along with aerosol content. Combining the use of standard atmospheric models with the use of MODIS water vapor, ozone and aerosol data, this provides reliable and consistent surface reflectance scenes over Planet's varied constellation of satellites as part of our normal, on-demand data pipeline. Ortho Panchromatic ( ortho_panchromatic ) assets are orthorectified, calibrated, super-resolved (0.50m), panchromatic-only imagery products that have been transformed to Top of Atmosphere (at-sensor) radiance. These products are designed for data science and analytic applications which require a wider spectral range (Pan: 450 - 900 nm), highest available resolution, and accurate geolocation and cartographic projection. Ortho Visual ( ortho_visual ) assets are orthorectified, color-corrected, super-resolved (0.50m), RGB imagery products that are optimized for the human eye, providing images as they would look if viewed from the perspective of the satellite. Lower resolution multispectral bands are sharpened by the super-resolved panchromatic band. These products are designed for simple and direct visual inspection, and can be used and ingested directly into a Geographic Information System or application. Ortho Pansharpened ( ortho_pansharpened ) assets are orthorectified, uncalibrated, super-resolved (0.50m) multispectral imagery products. Lower resolution multispectral bands are sharpened to match the resolution of the super-resolved panchromatic band. These products are designed for multispectral applications which require highest available resolution and accurate geolocation and cartographic projection. You can find our complete Imagery Product Specification here . Video Asset Types SkySat Video products are available for download in the form of video assets. You can find an overview of supported assets by SkySatVideo item type here . Video File ( video_file ) assets are video mp4 files, produced with Basic L1a Panchromatic scene assets captured as part of the full-motion video. Video Frames ( video_frames ) assets are compressed folders which include all of the frames used to create the Video File, packaged as Basic L1a Panchromatic scene assets with accompanying rational polynomial coefficients (RPCs). These products are designed primarily for customers interested in using video frames for 3D reconstruction. Product Naming The name of each acquired SkySat image is designed to be unique and allow for easier recognition and sorting of the imagery. It includes the date and time of capture, as well as the satellite id that captured it. The name of each downloaded image product is composed of the following elements: SkySatScene <acquisition date>_<acquisition time>_<satellite_id><camera_id>_<frame_id>_<bandProduct>.<extension> Example: 20200814_162132_ssc4d3_0021_analytic.tif SkySat Collect <acquisition date>_<acquisition time>_<satellite_id>_<frame_id>_<bandProduct>.<extension> Example: 20200815_091045_ssc6_u0002_visual.tif SkySat Video <acquisition date>_<acquisition time>_<satellite_id><camera_id>_video.mp4 Example: 20200808_133717_ssc3d1_video.mp4 Processing Several processing steps are applied to SkySat imagery to produce the set of data products available for download. Click for full-size image Sensor & Radiometric Calibration Darkfield/Offset Correction : Corrects for sensor bias and dark noise. Master offset tables are created by averaging on-orbit darkfield collects across 5-10 degree temperature bins and applied to scenes during processing based on the CCD temperature at acquisition time. Flat Field Correction : Flat fields are collected for each optical instrument prior to launch. These fields are used to correct image lighting and CCD element effects to match the optimal response area of the sensor. Flat fields are routinely updated on-orbit during the satellite lifetime. Camera Acquisition Parameter Correction : Determines a common radiometric response for each image (regardless of exposure time, number of TDI stages, gain, camera temperature and other camera parameters). Inter-Sensor Radiometric Response (Intra-Camera) : Cross calibrates the 3 sensors in each camera to a common relative radiometric response. The offsets between each sensor is derived using on-orbit cloud flats and the overlap regions between sensors on SkySat spacecraft. Super Resolution (Level 1B Processing) : Super resolution is the process of creating an improved resolution image by fusing information from low resolution images, with the created higher resolution image being a better description of the scene. Orthorectification Removes terrain distortions. This process consists of two steps: The rectification tiedown process wherein tie points are identified across the source images and a collection of reference images (ALOS, NAIP, Landsat) and RPCs are generated. The actual orthorectification of the scenes using the RPCs, to remove terrain distortions. The terrain model used for the orthorectification process is derived from multiple sources (Intermap, NED, SRTM and other local elevation datasets) which are periodically updated. Snapshots of the elevation datasets used are archived (helps in identifying the DEM that was used for any given scene at any given point). Visual Product Processing Presents the imagery as natural color, optimized as seen by the human eye. This process consists of three steps: Nominalization - Sun angle correction, to account for differences in latitude and time of acquisition. This makes the imagery appear to look like it was acquired at the same sun angle by converting the exposure time to the nominal time (noon). Unsharp mask (sharpening filter) applied before the warp process. Custom color curve applied post warping.","tags":"data","url":"https://developers.planet.com/docs/data/skysat/","loc":"https://developers.planet.com/docs/data/skysat/"},{"title":"XYZ Tiles and \"Slippy Maps\"","text":"A Slippy Map is an architecture for building mapping applications on the web. It was popularized the Open Street Map (OSM). http://wiki.openstreetmap.org/wiki/Slippy_Map A core component of Slippy Maps is that the images should be served as tiles on a grid. Tiling images is an efficient way to browse large amounts of raster and vector map data that would be much too large to render as a single map image. Tiles can be loaded on the fly as a user browses around a map to give the impression of a large seemless image. Slippy Maps define a loose standard for how tiles should be requested based on 2 concepts: Zoom Levels and Tile Coordinates. Once you understand Slippy Maps you can use Planet's tiling service to embed Planet imagery into your own applications. Zoom Levels Zoom Levels define the scale of the map. At zoom level 0, an entire mercator projection of the earth is contained in one 256px by 256px tile: At each further zoom level the number of tiles increases by a factor of four and the spatial resolution (ground meters per pixel) of each tile roughly doubles. The highest zoom level depends on the application, at zoom level 15 there are over a billion tiles each with a spatial resolution of 4.77 meters per pixel. Here's an example of a Z15 tile from Open Street Map. X Y coordinates At any given zoom level, a specific tile can be identified by cartesian coordinates with 0,0 starting in the top left of the map. Request Format The structure of a typical Slippy Map tile request looks like this: url/zoom-level/x-coordinate/y-coordinate.png Putting it all together an Open Street Map tile request would look like this:","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/xyz-tiles-and-slippy-maps/","loc":"https://developers.planet.com/docs/planetschool/xyz-tiles-and-slippy-maps/"},{"title":"Source","text":"The Subscription API's source block describes the items you want, in the formats you want, and filtered to your specifications. The subscription pulls this source data from Planet's imagery catalog. Deprecated Please note that the source schema has been updated in October 2021. The Subscriptions API has transitioned the area of interest geometry from the GeometryFilter to the geometry top-level attribute, and subscription start and end time from the DateRangeFilter to the start_time and end_time top-level attributes. Catalog Source Type The catalog source block references Planet's core imagery catalog of scenes. These Planet data products are automatically published in our catalog and immediately searchable via Planet's Data API. Parameters The parameters of the catalog source block require item_types , asset_types , and a filter , much like the Data API's /quick-search endpoint. item_types : represent the class of spacecraft and processing level of the subscription's matching items. PSScene is an example of an item type. You can read more on item types here . asset_types : represent the data products which will be delivered for all subscription matching items. An item will only match and deliver if all specified asset types are published for that item. analytic_sr is an example of an asset type available for a PSScene item. You can view an overview of available asset types here . geometry : represents the GeoJSON geometry of the subscription's area of interest, which is used to determine matches. Only Polygon & MultiPolygon geometry types are supported. start_time : represents the start time of the subscription. This time can be in the past or future. end_time (optional): represents the end time of the subscription. This time can be in the past or future, and must be after the start_time . rrule (optional): represents the recurrence rule. Only monthly recurrences are supported at this time. More details can be found in the Source RRule section . filter (optional): describes item filter criteria based on item-level metadata. Available filter types are described in more detail in the next section. RRules (Recurrence Rules) Recurrence rules can be used to create subscriptions that deliver during recurring periods within the total coverage time. Our implementation leverages the iCalendar Recurrence Rules specification. At this time, a subscription supports only monthly recurrences (i.e. recurrences defined using the BYMONTH property along with FREQ=YEARLY or recurrences defined using FREQ=MONTHLY ). If an rrule is included in a subscription creation request, an end_time must be included that is within 5 years of the subscription's creation time. Start and end times should not be provided in the RRule: the subscription will always respect the timestamps included in the start_time and end_time parameters. Example A subscription where only imagery between March and October is delivered for images published between March 1, 2020 and November 1, 2022: { \"start_time\": \"2020-03-01T00:00:00Z\", \"end_time\": \"2022-11-01T00:00:00Z\", \"rrule\": \"FREQ=MONTHLY;BYMONTH=3,4,5,6,7,8,9,10\" } Filter Details The filter object is designed to leverage search filters in the Data API . The filter can support a top level AndFilter , OrFilter , NotFilter , and one level of filters nested under it, or one top level filter of another type. A subscription can leverage all filter types (with the exception of DateRangeFilter and GeometryFilter ). Deprecated We have deprecated DateRangeFilter and GeometryFilter types in order to support features that provide more control over a subscription such as RRules that enable customers to tailor when imagery is delivered. The Subscriptions API implicitly includes the PermissionFilter when delivering results based on the requester's permissions to download. Validation The Subscriptions catalog source block has a handful of validation exceptions to take note of. item_types Validation: a subscription can only be successfully created if one item type is specified. asset_types Validation: a subscription can only be successfully created if all asset_types specified are supported for the item type specified. end_time Validation: A subscription must end after the start_time timestamp. A subscription must have an end time less than or equal to 5 years from the start_time if an rrule is included. rrule Validation: A subscription can only support monthly recurrences. BYWEEKNO , BYMONTHDAY , BYYEARDAY , BYDAY , BYHOUR , BYMINUTE , BYSECOND , BYEASTER are not supported. Start and end times provided using DTSTART and/or UNTIL are not supported and will produce an error. filter Validation: If a geometry attribute is included in the source block, a GeometryFilter cannot be used. If a start_time and/or end_time attribute is included in the source block, a DateRangeFilter cannot be used. We have deprecated the option to use DateRangeFilter , and encourage users to leverage start_time , end_time , and rrule to manage times of interest. DateRangeFilter acquired and updated values are not currently supported.","tags":"subscriptions","url":"https://developers.planet.com/docs/subscriptions/source/","loc":"https://developers.planet.com/docs/subscriptions/source/"},{"title":"Surface Reflectance Basemaps","text":"Planet's Surface Reflectance Basemaps are 16-bit, time series mosaic products which are optimized for radiometric consistency and minimize the effects of clouds, haze, atmospheric effects, and other image variability. They are ideal for use in forestry, vegetation, and land cover mapping use cases to enable an understanding of change over time. PlanetScope Surface Reflectance Basemaps (Zoom Level 15 - 4.77 meter, and Zoom Level 16 - 2.38 meter cell size at the equator) are generated with a proprietary algorithm which harmonizes the source imagery to Landsat and uses cloud masking to mosaic only the best underlying pixels. Surface Reflectance Basemaps can be purchased over custom areas of interest at a quarterly, monthly, biweekly, or weekly cadence. We do not currently offer Surface Reflectance Basemaps for our SkySat product line. Surface Reflectance Basemaps are available for download via the Basemaps API and Basemaps Viewer , and can be streamed via Planet Web Tile Services . You can read a detailed overview of our Basemap Product Specification here . Imagery Products Overview Below is a high level overview of our PlanetScope Surface Reflectance Basemap product. Source Imagery Download (GeoTIFF) Bands Streaming (WMTS) Bands Monitoring Frequency Zoom Level Normalization PlanetScope analytic_sr assets BGRN RBG, NRG Quarterly, monthly, biweekly, weekly 15, 16 Landsat, Sentinel-2, none (non-normalized) Publication Planet aims to publish all standard select basemaps 7 days after the end of the acquisition period. However, there may be instances where publishing may take longer. Publishing times for custom basemaps are determined on a case-by-case basis. Cadence Basemaps are generated at a specified cadence based on the \"first_acquired\" and \"last_acquired\" UTC timestamps for underlying source imagery. Cadence first_acquired last_acquired Quarterly January 1st, April 1st, July 1st, and October 1st at 00:00:00 UTC March 31st, June 30th, September 30th, and December 31st at 23:59:59 UTC Monthly The first day of each month at 00:00:00 UTC The last day of each month at 23:59:59 UTC Biweekly Every other Monday (starting at 1/1/2018 00:00:00 UTC) 14 days after Biweekly first_acquired date Weekly Mondays at 00:00:00 UTC Sundays at 23:59:59 UTC Scene Provenance During the Basemap generation process, a record of each individual PlanetScope or SkySat image used is retained. All source scenes are traceable through Planet's Basemaps API and Basemaps Viewer . Basemap Quads Basemaps can be downloaded as a set of \"basemap quads\", or simply \"quads.\" Quads are a distributed grid of GeoTIFF files which compose the basemap. Basemap with quad boundaries An individual Surface Reflectance Basemap quad has the following standard specifications: Attribute Description Imagery PlanetScope Pixel size (resolution) 4.77 meter (Zoom Level 15) and 2.39 meter (Zoom Level 15) at the equator Image bit depth 16 bits per pixel Bands Blue, Green, Red, NIR, Alpha Projection WGS84 Web Mercator (EPSG:3857) Size 4096 x 4096 pixels The projection used in Planet Basemaps has been selected to match what standard web mapping applications (Web Mercator Projection). The last band in the GeoTIFF of every mosaic quad includes an Alpha Mask which indicates areas of the quad where there is no imagery data available. Single quad within a basemap Product Naming The name of each PlanetScope Surface Reflectance Basemap is custom and will be made available to you following the purchase of your basemap product. The name of each basemap quad within the Basemaps API is designed to represent the x and y position of the quad within the two dimensional grid which makes up the basemap. It is generally {X}-{Y}, where X and Y are the x and y position of the quad in the grid. Example: 439-1220 Upon download, the name of the downloaded quad is designed to represent the zoom level and the mosaic's tiling scheme. Example: L15-0439E-1220N.tif Processing Normalization Following scene selection, Surface Reflectance Basemap source scenes are normalized to a quarterly Landsat reference dataset to minimize variability between scenes and improve spatial and radiometric consistency. Each scene is fitted with a linear model based on co-located, non-cloudy Planetscope and Landsat reference pixels to transform the input reflectance coefficients to approximately match the Landsat reference values for each band. After adjacent scenes have been combined into a mosaic tile, a seamline-reduction algorithm is applied to minimize any remaining local differences between scenes. This algorithm is optimized for landmass coverage, and may exhibit inconsistencies in visual quality over open water. While Planet cannot guarantee that a basemap will not contain visible scene lines or artifacts resulting from the mosaicing process, these approaches generally make the imagery appear more consistent and seamless. Packaging Basemaps are converted into a Web Mercator projection and resampled to a default pixel size of 4.77 meters. The resulting quads are then indexed within the Planet platform so that they may be downloaded for offline use via the Mosaics API. Lower zoom level overviews are created to populate the full stack of web tiles. These feed into Planet's Web Tile Services, which are easily integrated in other applications, serving up only the part of the basemap a user needs. Quality In addition to basemap production techniques described above to ensure quality output, basemap quality and coverage are also functions of source imagery input constraints based on the specified time of interest and cadence of delivery. For a smaller time of interest and shorter cadence periods, basemap quality and coverage are more likely to be impacted.","tags":"data","url":"https://developers.planet.com/docs/data/sr-basemaps","loc":"https://developers.planet.com/docs/data/sr-basemaps"},{"title":"STAC Resource Center","text":"","tags":"pages","url":"https://developers.planet.com/docs/pages/stac-resource-center/","loc":"https://developers.planet.com/docs/pages/stac-resource-center/"},{"title":"Remote-Friendly States","text":"*Planeteers may also currently work in all Canadian provinces but Quebec. Arizona California Colorado Connecticut Delaware Florida Georgia Hawaii Iowa Idaho Illinois Indiana Kentucky Louisiana Maryland Michigan Minnesota Missouri Montana North Carolina New Jersey New York Oregon Pennsylvania Texas Utah Virginia Washington Washington, D.C. Wisconsin","tags":"pages","url":"https://developers.planet.com/docs/pages/remote-friendly-states/","loc":"https://developers.planet.com/docs/pages/remote-friendly-states/"},{"title":"Stereo order creation","text":"The Planet Tasking API is a REST based API, which can be integrated into any service, regardless of the language used. Below are some examples of how to integrate the most commonly used aspects of the Tasking API Stereo orders creation, editing and cancellation. The creation, editing and deletion of Stereo orders follows the same rules as normal orders with one extra field required during creation. Stereo create The creation of a STEREO order is done via a POST request to the Tasking API /orders endpoint. The creation of a stereo order can be a simple as the following request example: curl --request POST --url 'https://api.planet.com/tasking/v2/orders/' \\ --header 'accept: application/json' \\ --header 'authorization: api-key <YOUR_API_KEY>' \\ --header 'content-type: application/json' \\ --data '{ 'name': 'Stereo Order 01', 'geometry': { 'type': 'Point', 'coordinates': [ -110.974052, 39.634139 ] }, 'order_type': 'STEREO', 'n_stereo_pov': '2' } Two field to take note of with a stereo order are the order_type field, which is defined and set to STEREO as well as the n_stereo_pov parameter. n_stereo_pov defines how many shots are taken for the stereo image can be either 2 or 3 . Any other value will result in an error.","tags":"tasking","url":"https://developers.planet.com/docs/tasking/examples/stereo","loc":"https://developers.planet.com/docs/tasking/examples/stereo"},{"title":"Creating a Subscription","text":"Overview Planet's Subscriptions API is its latest data delivery API. A user can create subscriptions to continuous cloud delivery of curated imagery and metadata with a single API call. No longer will users have to worry about delivery options, selecting the correct product bundle, or extracting item id's. This API Quickstart Guide will walk you through a subscription from creation to cloud delivery. Before getting started with the Subscriptions API see The Getting Started Guide for API key access and more information on searching Planet data. Also, read the docs for a more detailed guide to the mechanics of the Subscriptions API. Creating a Subscription To create a Subscription you must define an AOI and create a POST request to https://api.planet.com/subscriptions/v1/. The request body can include name, source, tools, and delivery blocks. Name, source and delivery are required. Name is easy. Source describes the data from which the subscription is derived. Simply put, the source catalog allows access to all of Planet's imagery archives, which take parameters of item_types, asset_types, and filters. It operates with the same search and filter capabilities of the Data API. Search filters are a powerful tool allowing a user to narrow down their search programmatically by boolean argument, metadata, location, and many more.Tool is optional and limited to clip at the moment with more raster toolkit functionality to come in the future. Delivery specifies your cloud delivery provider. Currently, cloud delivery is the only delivery option for Subscriptions. It supports GCP, AWS, and Azure cloud storage buckets. Now let's take a look at some examples. subscription_schema = { name: \"string\", source: { type: \"catalog\", parameters: { filter: {}, item_types: [\"string\"], asset_types: [\"string\"], }, }, *tools: [ { type: \"clip\" parameters: { aoi: {}, }, }, ], delivery: { type: \"cloud_storage_provider\", parameters: { \"parameter1-name\": \"p1-value\", \"parameter2-name\": \"p2-value\" }, }, } Defining AOI's with GeoJSON Before making a request to Subscriptions. We must first define an area of interest (AOI). AOI is how we define a selected geographic area of data. Planet`s APIs accept AOI's in GeoJSON format. Users can clip an area by geometry utilizing Planet Explorer, and the geojson will be generated for the user. An alternative is using geojson.io. For this example, I used Planet Explorer to define the AOI of a vineyard in California. Below is the GeoJSON output from Planet Explorer. { \"type\": \"FeatureCollection\", \"features\": [ { \"type\": \"Feature\", \"properties\": {}, \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ -121.096221, 36.183758 ], [ -121.086524, 36.183758 ], [ -121.086524, 36.187311 ], [ -121.096221, 36.187311 ], [ -121.096221, 36.183758 ] ] ] } } ] } Sending a Request Now create a simple request to send to the Subscriptions API! request = { # Name Block \"name\": \"basic_subscription\", # Source Block \"source\": { \"type\": \"catalog\", \"parameters\": { \"item_types\": [ \"PSScene\" ], \"asset_types\": [ \"analytic\" ], #There's no limit to the types of searches you can create with the filter functionality. \"filter\": { \"type\": \"AndFilter\", \"config\": [ { \"type\": \"DateRangeFilter\", \"field_name\": \"published\", \"config\": { \"gt\":\"2021-06-01T00:00:00Z\", \"lte\":\"2021-09-01T00:00:00Z\" } }, { # Here we pass in our geoJSON from Explorer. The geometry filter accepts any valid GeoJSON object. # It was cleaned up to make our request more pretty. \"type\": \"GeometryFilter\", \"field_name\": \"geometry\", \"config\": { \"type\": \"Polygon\", \"coordinates\": [ [ [-121.096221,36.183758], [-121.086524,36.183758], [-121.086524,36.187311], [-121.096221,36.187311], [-121.096221,36.183758] ] ] } }, { \"type\": \"RangeFilter\", \"field_name\": \"visible_percent\", \"config\": { \"gte\": 50 } } ] } } }, #Delivery \"delivery\": { \"type\": \"google_cloud_storage\", \"parameters\": { \"bucket\": \"subscriptions-practice\", \"credentials\": \"nunya\" } } } More on Delivery Let's use a GCP storage bucket and walk through the steps to delivery of our vineyard data. GCP Buckets For GCP delivery you will need a GCS account and project with write and delete permissions. You then need to create a bucket. We named our bucket subscriptions-practice in this example. You could additionaly add folders to your bucket and add the path prefix parameter for delivery to that path. Creating and Accessing Credentials To create credentials in GCP. You will need to create a service account for your desired project and create keys for it. For more detailed instructions click me . This will allow you to download a JSON file with your credentials. You will only be allowed to download it once, so do not lose it. You must now encode your credentials as a base64 string. Use the following command: cat creds.json | base64 | tr -d '\\n' Paste the encoded json as a string for the credentials parameter into the example request. Now we can send our subscription! The Response The POST request should yield a 200 response, which means success! You have created and delivered a subscription. The returned response body is included below. An order id, status, and endpoint for the subscription is created among other details. You can modify your subscription with the id. { \"_links\": { \"_self\": \"https://api.planet.com/subscriptions/v1/4ca9dccc-4204-49ae-9b29-cb900862acc1\" }, \"id\": \"4ca9dccc-4204-49ae-9b29-cb900862acc1\", \"status\": \"preparing\", \"name\": \"basic_subscription\", \"source\": { \"type\": \"catalog\", \"parameters\": { \"asset_types\": [\"analytic\"], \"filter\": { \"config\": [ { \"config\": { \"gt\": \"2021-06-01T00:00:00Z\", \"lte\": \"2021-09-01T00:00:00Z\", }, \"field_name\": \"published\", \"type\": \"DateRangeFilter\", }, { \"config\": { \"coordinates\": [ [ [-121.096221, 36.183758], [-121.086524, 36.183758], [-121.086524, 36.187311], [-121.096221, 36.187311], [-121.096221, 36.183758], ] ], \"type\": \"Polygon\", }, \"field_name\": \"geometry\", \"type\": \"GeometryFilter\", }, { \"config\": {\"gte\": 50}, \"field_name\": \"visible_percent\", \"type\": \"RangeFilter\", }, ], \"type\": \"AndFilter\", }, \"item_types\": [\"PSScene\"], }, }, \"delivery\": { \"type\": \"google_cloud_storage\", \"parameters\": {\"bucket\": \"subscriptions-practice\", \"credentials\": \"<REDACTED>\"}, }, \"created\": \"2021-08-20T15:36:14.53073Z\", \"updated\": \"2021-08-20T15:36:14.53073Z\", } Accessing and Modifying Subscriptions # Create a Subscription POST https://api.planet.com/subscriptions/v1/ # Edit a Subscription PUT https://api.planet.com/subscriptions/v1/<subscription_id> # Cancel a Subscription POST https://api.planet.com/subscriptions/v1/<subscription_id>/cancel # Filter Subscriptions by Status GET https://api.planet.com/subscriptions/v1?status=running&status=completed # Return Subscription Results GET https://api.planet.com/subscriptions/v1/<subscription_id>/results Questions or comments about this guide? Join the conversation at Planet Community or contact developers@planet.com.","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/creating-a-subscription/","loc":"https://developers.planet.com/docs/planetschool/creating-a-subscription/"},{"title":"Planet Summer Camp","text":"","tags":"pages","url":"https://developers.planet.com/docs/pages/planet-summer-camp/","loc":"https://developers.planet.com/docs/pages/planet-summer-camp/"},{"title":"Support","text":"If you have an issues with the Tasking API, please let us know. We'd love to hear your feedback! If you have questions, comments, or feature requests, please submit a request , or reach out to your Account Manager.","tags":"tasking","url":"https://developers.planet.com/docs/tasking/support/","loc":"https://developers.planet.com/docs/tasking/support/"},{"title":"How to Task High-Res Imagery","text":"High-Res images are taken upon request and require a paid plan. You can go directly from Explorer to the Tasking Dashboard to place an order for SkySat imagery for the same area of interest you were looking at. SkySat imagery ranges from 50 cm resolution to 80 cm resolution, depending on orthorectification and altitude. Search for your Area of Interest in Explorer You can search for your area of interest by typing in a location, uploading a geo file, or drawing an area of interest on the map. Click Task button in Explorer In the left hand toolbar, click on the fifth icon from the top. The tooltip message will read Task a high resolution image. By clicking this button, you will be taken to the Tasking Dashboard. The center-point of your screen in Explorer will be transferred to the Tasking Dashboard and you can submit your request to task a SkySat satellite. Log in to the Tasking Dashboard You will need to log in to the Tasking Dashboard with your Planet Account credentials to continue. If you or your organization have not yet purchased a tasking plan, you will not be able to log in. If your organization has purchased a tasking plan, but your account does not have access, you will not be able to log in. If you have trouble logging in, click Get Help right under the Login button. You will see two options, depending on your scenario. If you have not purchased a tasking plan, contact sales. If you have, email us to request access. Submit details in the Tasking Dashboard Once you log in to the Tasking Dashboard, you will be able to submit a point order for your area of interest. Your area of interest will be displayed as a pin on the map on the left handside and as latitude and longitude coordinates. You may adjust your area of interest by moving the pin on the map.","tags":"apps-explorer","url":"https://developers.planet.com/docs/apps/explorer/how-to-task-highres/","loc":"https://developers.planet.com/docs/apps/explorer/how-to-task-highres/"},{"title":"How To Task a High-Res Image","text":"SkySat","tags":"apps-explorer","url":"https://developers.planet.com/docs/apps-explorer/explorer/","loc":"https://developers.planet.com/docs/apps-explorer/explorer/"},{"title":"Set AOI for High Res Tasking in QGIS","text":"In the Planet QGIS Plugin V2+ users can create a task for high-res imagery from Planet's SkySat constellation by selecting a location directly in QGIS. To create a task, select the Tasking Panel from the Planet QGIS Plugin panel. In the Panel click on \"Selection\" and then click on the location you'd like to acquire high-res imagery for in your QGIS map. This will create a centroid point and a 5x5 sqkm box around the location- highlighting the area likely to be captured by SkySat. Once your location is set, select \"Create Task\" from the Tasking Panel. This will open a pop-out window in QGIS that will let you know that you're being taken to Planet's Tasking Dashboard to complete the order. Click \"Take me to the Tasking Dashboard\" once you've read through the text. The Planet QGIS Plugin will automatically send and fill the coordinates you selected to the Tasking Dashboard where you can complete the rest of your order. To learn more about how to use Planet's Tasking Dashboard, take a look at our Tasking Dashboard Documentation . Note that in order to create a high-res tasking order your account must have a SkySat tasking Plan.","tags":"integrations-qgis","url":"https://developers.planet.com/docs/integrations/qgis/task-imagery/","loc":"https://developers.planet.com/docs/integrations/qgis/task-imagery/"},{"title":"Set Area for High Res Tasking in ArcGIS","text":"In the Planet ArcGIS Add-In V2+ users can create a task for high-res imagery from Planet's SkySat constellation by selecting a location directly in ArcGIS Pro. To create a task, select the Tasking Panel from the Planet Imagery ribbon. In the panel click on \"Selection\" and then click on the location you'd like to acquire high-res imagery for in your Pro map. This will create a centroid point and a 5x5 sqkm box around the location- highlighting the area likely to be captured by SkySat. Once your location is set, select \"Create Task\" from the Tasking Panel. This will open a pop-out window in Pro that will let you know that you're being taken to Planet's Tasking Dashboard to complete the order. Click \"Take me to the Tasking Dashboard\" once you've read through the text. The Planet ArcGIS Add-In will automatically send and fill the coordinates you selected to the Tasking Dashboard where you can complete the rest of your order. To learn more about how to use Planet's Tasking Dashboard, take a look at our Tasking Dashboard Documentation . Note that in order to create a high-res tasking order your account must have a SkySat tasking Plan.","tags":"integrations-arcgis","url":"https://developers.planet.com/docs/integrations/arcgis/task-imagery/","loc":"https://developers.planet.com/docs/integrations/arcgis/task-imagery/"},{"title":"Tasking Basics","text":"Tasking orders follow a defined process from order creation to order fulfillment to imagery delivery. This section describes the steps and the language used to describe the process and timing of imagery collection and delivery. Planet operates in Universal Time Coordinated (UTC). Order Time : This is when a customer submits an order for imagery. Scheduled Time : The time at which the order is accepted and slotted into a satellite's schedule for collection. Collection Time : This is the time at which the image is captured. Responsiveness : The end to end time from order entry to delivery. Reaction Time : the time between a customer entering a tasking order and collection time. Latency Time : The time between collection time and delivery (standard or fast track) Standard Delivery : The standard latency for imagery delivery to customers that place order; deliver according to SLA not as soon as data is ready. Fast Track Delivery : Expedited delivery, less Latency Time, for imagery delivery as soon as data is ready. Archive Time : The amount of time between when an image is delivered to a customer and publication to the archive. Archive Publication : Point in time that an image is published to the archive and available to anyone with access to the SkySat archive. The Archive Publication feature is available to all SkySat archive customers. Customers can choose to set the duration of their Archive Time from 0 to 30 days. Archive time is measured from the date/time of image capture to Archive Publication.","tags":"tasking","url":"https://developers.planet.com/docs/tasking/basics/","loc":"https://developers.planet.com/docs/tasking/basics/"},{"title":"Tasking Overview","text":"Planet's Tasking API is a programmatic interface that enables customers to manage and request imagery collection in an efficient and automated way. With the Tasking API, customers can: Create, edit, and cancel SkySat Tasking Orders Get the status of their order and check the collection progress View the metadata on the images tasked in attempting to fulfill their order Automated Tasking currently supports Point, Strip, Stereo and Area Tasking Orders. As we continue to improve our capabilities, we plan to support additional order types (e.g. Video). Key Concepts Order : A request to obtain imagery of an area of interest. Order Status : A representation of where an order is at in its lifecycle – from creation and collection to order fulfillment. Capture : An image which was tasked in an attempt to fulfill an order. There is currently a one-to-many relationship between orders and captures, as an order may need to be tasked multiple times in order to meet cloud cover specifications or other fulfillment criteria. A given capture may or may not fulfill any order. Capture Status : A representation of where a capture is at in its lifecycle – from uplink to satellite to publication to the ordering customer and the SkySat Archive. Capture Assessment : A representation of whether a capture meets the order's specifications, thereby fulfilling an order. Archive Publication Time Period : the time between when a capture is published to the customer who ordered the imagery and the published to the SkySat archive. Tasking Order Status After a Tasking Order has been entered, you may check the Tasking API for the status of that Tasking Order. The diagram below outlines how Tasking Orders flow through the system. NOTE These Tasking Order states are not applicable to Assured Tasking Orders. For information on how Assured Tasking Order states differ, refer to Assured Tasking Order creation . Received : The Tasking Order has been entered into the system. Rejected : The Tasking Order could not be accepted due to it not passed feasibility checks, for example, tessellation if it is an area order Pending : The Tasking Order has been accepted but has not yet reached its start time IN_PROGRESS : The Tasking Order's start time has passed, and it is ready to be scheduled. Time in this state will depend on local cloud cover and collection capacity. Tasking Orders that have taken captures which did not meet specifications will stay in IN_PROGRESS while they are re-tasked. Fulfilled : The Tasking Order has a capture which meets fulfillment specifications. Cancelled : The Tasking Order was cancelled. Orders may be cancelled if they are Pending or IN_PROGRESS , however captures already Queued , Processing or Published at the time of cancellation, may still be subject to charge (see Capture Status for details). Expired : The order's end time has passed, all of its captures have been Published , and none meet specifications. The order will no longer be scheduled for imaging. Tasking Order Status Example To see the status of your order, you can make GET request for your order id. You can also filter orders by additional order metadata. See our API reference for more information. Endpoint https://api.planet.com/tasking/v2/orders/?status=FULFILLED Response example { \"id\": \"bfc45520-8a72-4d23-bfd1-7b22f23ed133\", \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ -77.306467, 45.435827 ], [ -77.229787, 45.435827 ], [ -77.22975, 45.489812 ], [ -77.306504, 45.489812 ], [ -77.306467, 45.435827 ] ] ] }, \"capture_status_published_count\": 0, \"capture_assessment_success_count\": 0, \"capture_assessment_invalid_count\": 0, \"start_time\": \"2019-09-30T20:30:50.836516Z\", \"end_time\": \"2020-09-27T23:59:59.999000Z\", \"created_time\": \"2019-09-30T20:30:51.807703Z\", \"name\": \"cairo_egypt\", \"status\": \"FULFILLED\" } Capture Status As described under Key Concepts, an order may have multiple captures, as multiple collections may be required to acquire an image which meets your specifications (cloud cover, etc.). Each capture of an order has a status, so that you may follow along with where that capture is at in its lifecycle to inform expectations on acquisition or when an image might be published. The diagram below outlines how captures flow through the system. Queued : The capture has been created and sent to a satellite. It will be imminently acquired and downlinked. Processing : The capture has been downlinked and is in our processing pipeline. Published : Captures are published first to the customer who ordered the image. Only other users in this user's organization may see this collect during this archive time period. After the Archive Time period has elapsed the imagery is published to all customers who have purchased the SkySat archive. Failed : The capture has failed to be captured or failed in processing. Capture Status Example To see the status of your order's captures, you can make a GET request for captures, filtering by order id(s). You can also filter by additional capture metadata. See our API reference for more information. Endpoint https://api.planet.com/tasking/v2/captures/?order_id=<order-id> Response example { \"count\": 1, \"next\": null, \"previous\": null, \"results\": [ { \"id\": \"1e0268d2-8c96-49ed-b809-eceafa563950\", \"assessment\": \"SUCCESS\", \"updated_time\": \"2019-09-21T23:57:43.783444Z\", \"acquired_time\": \"2019-09-21T08:51:31.094000Z\", \"published_time\": \"2019-09-21T23:57:43.783444Z\", \"status\": \"PUBLISHED\", \"status_description\": null, \"strip_id\": \"s104_20190921T085131Z\", \"cloud_cover\": 0.16, \"item_types\": [ \"SkySatScene\", \"SkySatCollect\" ] } ] } Retasking & Assessment If an order's capture does not meet specifications, it will be retasked until its end time expires. Multiple captures may be collected for an order to satisfy its cloud cover and collection requirements. As captures are collected they are algorithmically assessed for cloud cover and may also be subject to another round of human-in-the-loop review. A capture will be assessed as SUCCESS if cloud cover is less than or equal to your contractual cloud cover specifications. If a capture meets specifications, its order's state will change from IN_PROGRESS to FULFILLED . A capture will be assessed as INVALID if cloud cover exceeds contractual specifications. If a capture is invalid, its order's state will stay in IN_PROGRESS and be retasked if its end time has not passed, or transition to EXPIRED if its end time has passed. Note that as part of our human-in-the-loop review, a capture evaluated by the system may be manually reassessed, which may cause its order's state to change. For example, a capture the system marked as SUCCESS may be manually reviewed as INVALID changing its order's state from FULFILLED to IN_PROGRESS (or EXPIRED ). Similar order state changes would be expected for a capture marked INVALID which was manually reviewed as a SUCCESS . Typically any manual review happens within 24 hours of capture publish and changes to an order's state due to manual assessment after this time are unlikely. Standard delivery and archive As part of Planet's mission to make hi-res data more accessible and actionable, Tasking orders, by default, are automatically published to the SkySat Archive. However, if you have the \"30-day SkySat Archive withhold\" product, you can withhold orders from the SkySat Archive for up to 30 days. If you have the \"30-day SkySat Archive withhold\" offering, you can request that your CSM set a number of days—up to 30—to withhold the data from the SkySat Archive. In the Order details view, you can see the number of days you've requested in the \"Exclusivity days\" field. To derive the SkySat Archive publication date, add the number of exclusivity days to date of acquisition. If you want to calculate this from the API, take the following steps: Retrieve the order via the v2/orders/{order_id} endpoint. The response includes a field called exclusivity_days , which indicates the exclusivity period for captures attributed to that tasking order. Then make a second call to v2/captures/?order_id={order_id}&status=PUBLISHED , which returns all captures for the given tasking order that have been published. For each returned capture, take the date stored in the acquired_time field and add the number of exclusivity_days to it to find the date when that capture's exclusivity period ends. For example, if the acquired_time is 2020-10-10T12:00:00 and the exclusivity_days value is 30, then the exclusivity period for that capture will end on 2020-11-09T12:00:00. Note that acquired_time is always UTC. Limits In order to safely scale use of the Tasking API, each organization using the Tasking API will have configurable system limits. Please check in with your Account Manager to confirm what your organization's limits are. Maximum active orders refer to the number of orders you may have in PENDING or IN_PROGRESS states. Maximum order duration may not exceed your contract duration or 1 year (whichever ends earlier). Orders that are submitted which hit the maximum active order limit or exceed maximum order duration will return a 400 Bad Request response. API Access To determine whether you qualify for early access, please reach out to your Account Manager. The Tasking API uses Basic HTTP Authentication and requires that you have a Planet API key. To read more about how to authenticate with the Tasking API, visit the Tasking Examples page for this and examples on how to create orders and much more.","tags":"tasking","url":"https://developers.planet.com/docs/tasking/","loc":"https://developers.planet.com/docs/tasking/"},{"title":"Tile Services Overview","text":"The API Tile Service and Basemap Tile Service make it easy to visualize Planet imagery in desktop or web mapping applications that support either the XYZ or the WMTS protocol. Planet tile services provide a way for web developers and GIS analysts to interact with, and derive value from Planet imagery without additional image processing. Authentication A valid Planet account is required to access either of the tile services (XYZ or WMTS). Authenticate by providing a valid api_key as a query parameter to all tile requests. Note : For all Planet tile services, you must be authenticated for the specific requested resource. If you do not have the correct permissions, the tile request results in a 404 error. To be properly authenticated, provide a valid api_key as a query parameter in all tile requests. API Key Security Risk There is a potential security risk with the Planet API tile service. If you are using your own API key to access tiles or Basemaps there is no security risk . However, if you are accessing tiles in an application where others can view the request, then the API key is potentially exposed. An example of this is available by viewing the Network tab of Developer Tools in your browser while logged in to your Planet Explorer account. Although the API key is secure in this example, it illustrates that the API key is exposed. To avoid the API key security risk, create a reverse proxy or store your API key as an environment variable. Create a Reverse Proxy (Recommended) A reverse proxy: Is the most secure method for safely storing Planet API key credentials Stores secure credentials that make requests for the application and passes request responses to the application Stores and encrypts API keys in one location Stores API keys with HTTPS over a Transport Layer Security (TLS) channel. Provides greater web acceleration (faster requests and responses between the server and the client browser) Provides load balancing configuration Eliminates the risk of: Exposing credentials to malicious clients Updating API keys in the wrong location You can create a reverse proxy from most cloud providers, including NGINX and Google Cloud Platform (GCP). Creating a secret with Secret Manager provides complete details on creating and accessing the secret key from the GCP Secret Manager. Store the API Key as an Environment Variable Store the API key as an environment variable, and use the git ignore command when pushing to the repository. This is not the recommended method and if your credentials are not encrypted, the risk of API key exposure remains. Do not use the API key environment variable with public applications. To obtain a new API key, contact Planet Support if your API key is shared or exposed. Tile Service URLs The Planet tile services provide tiles by using the following domains: https://tiles0.planet.com https://tiles1.planet.com https://tiles2.planet.com https://tiles3.planet.com Load more tiles concurrently in web browsers by using multiple subdomains. Libraries such as OpenLayers and Leaflet provide the ability to access all subdomains by using the proper string patterns. API Tile Service The API Tile Service acts as an extension to the Planet API by visually listing the Planet assets that are available in the item archive as tiles. The imagery returned by the tile service is a compressed version of the high-quality visual asset, making it easy to incorporate into any supporting client. Currently, only clients using the XYZ tile protocol are supported. API Tile Service Request Structure https://tiles{0-3}.planet.com/data/v1/{item_type}/{item_id}/{z}/{x}/{y}.png?api_key={api-key} API Tile Service Request in Python with Basic HTTP Authentication import os # import os module to access environmental modules import requests from requests.auth import HTTPBasicAuth # import helper functions to make Basic request to Planet API PLANET_API_KEY = os.getenv('PL_API_KEY') # Setup the API Key from the `PL_API_KEY` environment variable BASE_URL = 'https://tiles{0-3}.planet.com/data/v1/{item_type}/{item_id}/{z}/{x}/{y}.png' if PLANET_API_KEY is None: PLANET_API_KEY = '12345' # pass in your API key auth = HTTPBasicAuth(PLANET_API_KEY, '') # HTTPBasicAuth() wants a username & password; you can pass an empty string for the password res = requests.get(url=BASE_URL, auth=auth) print(res.status_code) # make a request to Tile Services API and test the response Parameter Value item_type Item type of the item to view. item_id Item id of the item to view. z Tile zoom level. x Tile row in the grid. y Tile column in the grid. The following example is a complete URL for a tile request for the PSScene item with an id of 20161221_024131_0e19 : API Tile Service Example https://tiles1.planet.com/data/v1/PSScene/20161221_024131_0e19/14/12915/8124.png?api_key={api-key} Basemap Tile Service The Planet Basemap tile service provides access to tiles for weekly or monthly, color corrected global mosaics. The Basemap tile service works with any client that supports the XYZ or the WMTS protocol. Details on Planet specifications are available in Planet Basemaps Product Specifications . Learning Resources Dive deeper into Planet tile services with guides and tutorials available at Planet School . Explore Using Planet Tile Services in ArcGIS Online for more detailed information on Planet tile services. Complete the Python Tutorial for Visualizing Imagery Over Time .","tags":"basemaps","url":"https://developers.planet.com/docs/basemaps/tile-services/","loc":"https://developers.planet.com/docs/basemaps/tile-services/"},{"title":"Tips & Tricks: Planet ArcGIS Add-In","text":"Add Download Folders to the ArcGIS Pro Catalog After downloading an order, you can quickly add the download folder as a folder connection in the Catalog. Select the Re-Download drop-down menu and select Add to project catalog . Adding Imagery to Maps with True Color Band Order After downloading an order, you can add imagery directly to your maps from the Planet Order Status pane. Select the Add to map option and the imagery will be added to your active map with the red, green, and blue bands assigned to the correct color channels. The imagery will also be added with a Percent Clip stretch. You can also add downloaded imagery to your map through the catalog pane or File Explorer. By default, ArcGIS Pro will assign bands 1, 2, and 3 to the red, green, and blue channels, respectively. With PlanetScope 8-band imagery, this won't result in a true color visualization because Planet's bands are ordered ascending by wavelength. The default bands that are selected for visualization can be changed in the Raster and Imagery appearance settings. You can access these settings from Project tab > Options > Raster and Imagery . In the Set default RGB composition > Multispectral data section, assign bands 6, 4, and 2 to red, green, and blue, respectively. These are the RGB band indices for PlanetScope 8-band data. When you add 8-band PlanetScope rasters from the catalog or File Explorer to your map, they will now be added with the correct band order for true color visualization. For more information, see Raster and imagery default options . Creating a False Color Composite To create a False Color Composite, select your Planet imagery and open the symbology pane. Assign the bands to the color channels in this order: near-infrared to red, red to green, and green to blue. See table below for corresponding band names and index for 4 and 8 band imagery products. Color Channel Assigned Band 4-band Band Index 8-band Band Index Red Near Infrared 4 8 Green Red 3 6 Blue Green 2 4 Mosaicing Multiple Raster Products If your order contains multiple scenes, or if you are visualizing data from multiple orders, you may notice color differences where two nearby scenes meet. This is because each raster in a map is individually stretched based on the statistical distribution of pixel values across the dataset. This difference is only visual and will not impact analysis, such as comparing pixel values over time in the same location. For a more seamless visualization, you may want to create a mosaic dataset to manage your imagery. You can find documentation for creating mosaic datasets and adding imagery to mosaics datasets here: ArcGIS Pro - Create a mosaic dataset . Note: After adding imagery to a mosaic dataset, bands are renamed to band_index# . You can find spectral band names and orders for Planet imagery in the Planet Imagery Product Specifications . When using the Add Rasters To Mosaic Dataset tool, you can quickly add all rasters from one or many orders at the same time. Choose the folder which has your downloaded Planet imagery as the Input Data . You can use the Input Data Filter parameter to exclude unwanted products, such as Usable Data Masks (UDM). For example, to filter for only Surface Reflectance assets, use the filter ‘*SR*'. Toggle on Include Sub Folders to make sure you capture the entire folder structure from an order download. For more information, see Using mosaic datasets to manage imagery . Copying Snippets for Working with Planet API's After executing a search for imagery, Planet's ArcGIS Add-in allows you to copy the search request as a cURL or Python 3 code snippet. Select the Actions drop-down list from the bottom of the Planet Image Search pane and click Copy Request . You can also copy your API key and selected image IDs.","tags":"integrations-arcgis","url":"https://developers.planet.com/docs/integrations/arcgis/tips-and-tricks/","loc":"https://developers.planet.com/docs/integrations/arcgis/tips-and-tricks/"},{"title":"Tips & Tricks: Planet QGIS Plugin","text":"Copy Python or cURL request After executing a search for imagery, Planet's QGIS Plugin allows you to copy the search request as a cURL or Python3 code snippet. Select the \"Actions\" drop down list from the bottom of the Search panel and click \"view cURL request.\" You can also copy selected image ids or your API key. Easily find your Download Order location Forgot where you downloaded your Planet data? Open the Order Status Panel from the QGIS Plugin Toolbar. Any download you've previously made has a Re-Download button instead of a Download button. Under each Re-Download button is an Open order folder hyperlink text that opens the folder you placed your download into. Customize your plugin default settings You can customize default settings for your imagery download location, and whether to apply download operations by default, such as clip and harmonize. To adjust your settings go to Web -> Planet Explorer -> Settings .","tags":"integrations-qgis","url":"https://developers.planet.com/docs/integrations/qgis/tips-and-tricks/","loc":"https://developers.planet.com/docs/integrations/qgis/tips-and-tricks/"},{"title":"Tools","text":"The Subscriptions API supports select raster processing tools which can be applied to imagery before delivery to reduce time spent in data post-processing. Tools schema The schema for Subscriptions API tools is below. Note that this schema varies slightly different from the tools schema of the Orders API. \"tools\": [ { \"type\": \"tool-name\", \"parameters\": { \"parameter-1-name\": \"p1-value\", \"parameter-2-name\": \"p2-value\" } } ] Creating toolchains To derive insights or perform any meaningful analysis, it is highly likely that multiple tools will be required to process the data. You can push Planet data through individual or several of these tools chained together to achieve the results you need. Planet processes tool requests synchronously in an order that has been validated against prior methodology. Given the changing output of each tool, certain processes necessarily go before others. Other tool chains are arbitrarily chosen based on the inputs or the effects on the output. For example, although not required, it's recommended to run the clip tool before reproject and bandmath in order to reduce processing time. But, depending on the clip geometry, clipping before reprojecting may produce undesirable edge effects. In that case, you would clip before reproject. When using multiple tools in a subscription, you must request tools in a specific order in the request body in order to ensure each tool succeeds. The required order of tools is as follows: harmonize toar clip , reproject , bandmath (can go in any order) file_format If the array you provide does not follow the sequence above, a 400 error is returned clarifying which tool must be declared before another. Toolchain example In this example, the ortho-analytic product is manipulated by three tools in the series: TOAR --> Reproject --> File format . TOAR, reproject, and file format \"tools\": [ { \"type\": \"toar\", \"parameters\": { \"scale_factor\": 10000 } }, { \"type\": \"reproject\", \"parameters\": { \"projection\": \"EPSG:3857\", \"kernel\": \"near\" } }, { \"type\": \"file_format\", \"parameters\": { \"format\": \"COG\" } } ] Supported tools Band Math The bandmath tool allows you to apply band math expressions to the bands of your input files to produce derived outputs and indices for analysis. Popular indices include NDVI ( Normalized Difference Vegetation Index ), EVI (Enhanced Vegetation Index), and NDWI (Normalized Difference Water Index). The bands of the input file are referenced as b1, b2, b3, etc., where b1 equals \"band 1\". For each band expression, the bandmath tool supports normal arithmetic operations and simple math operators offered in the Python numpy package . (For a list of supported mathematical functions, see Bandmath supported numpy math routines .) Product inputs The bandmath tool supports PlanetScope, SkySat, and RapidEye except for those with non-orthorectified images (designated as basic_* assets). Parameters The parameters of the bandmath tool define how each output band in the derivative product should be produced, referencing the product inputs' original bands. Band math expressions may not reference neighboring pixels, as non-local operations are not supported. The tool can calculate up to 15 bands for an item. Input band parameters may not be skipped. For example, if the b4 parameter is provided, then b1 , b2 , and b3 parameters are also required. b1 (string): An expression defining how output band 1 should be computed. (required) b2 (string): An expression defining how output band 2 should be computed. (optional) ... b15 (string): An expression defining how output band 15 should be computed. (optional) pixel_type (string): A value indicating what the output pixel type should be. By default this value will be \"Auto\", the same as the input file. \"8U\" (8bit unsigned), \"16U\" (16bit unsigned), \"16S\" (16bit signed), and \"32R\" (32bit floating point) may also be used depending on the type of equation or index being calculated. (optional) Example request \"tools\": [ { \"type\": \"bandmath\", \"parameters\": { \"b1\": \"b1\", \"b2\": \"b2\", \"b3\": \"b3\", \"b4\": \"arctan(b1)\", \"b5\": \"(b4-b3)/(b4+b3)\", \"pixel_type\": \"32R\" } } ] The output of this tool is an asset that includes all four bands of the original file, a fourth band that is the arc tangent of the the original first band, and a fifth band with NDVI values. Tool outputs One bandmath imagery output file is produced for each product asset, with output bands derived from the band math expressions. nodata pixels are processed with the band math equation. These files have \"_bandmath\" appended to their file names. The tool passes through UDM, RPC, and XML files, and does not update values in these files. Clip The clip tool allows you to clip a scene to a specified area of interest (polygon or multipolygon) to limit your storage costs. clip may also be used as a billing management tool, depending on the Raster Tools Plan you've purchased. Product inputs The clip tool supports all item types except SkySatVideo and all asset types except for non-orthorectified, basic_* asset types. Tool outputs Imagery and udm files will be clipped to your area of interest. nodata pixels will be preserved. Xml file attributes \"filename\", \"numRows\", \"numColumns\" and \"footprint\" will be updated based on the clip results. The clipped output files will have \"_clip\" appended to their file names. If the clip aoi is so large that full scenes may be delivered without any clipping, those files will not have \"_clip\" appended to their file name. Note: There may sometimes be discrepancies between an item's footprint and the area of its usable pixels. When clipping, this can result in a clipped aoi which does not intersect with any usable pixels of an image. In this circumstance, no imagery file will be delivered while auxiliary assets will continue to be delivered. Parameters aoi (dict): GeoJSON polygon or multipolygon defining the clip area, with up to 500 vertices. The minimum geographic area of any polygon or internal ring is one square meter. Example request \"tools\": [ { \"type\": \"clip\", \"parameters\": { \"aoi\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ -163.828125, -44.59046718130883 ], [ 181.7578125, -44.59046718130883 ], [ 181.7578125, 78.42019327591201 ], [ -163.828125, 78.42019327591201 ], [ -163.828125, -44.59046718130883 ] ] ] } } } ] AOI geometry limits While clipping an AOI with GeoJson, users should be aware of multipolygon limitations for successful subscription creation. Notable validation changes are due to the python-geojson + python-shapely validation process and may result in your subscription being rejected. The following geometries are invalid and will result in the failure of a subscription request: GeoJSON Polygons with holes first will be rejected. GeoJSON Polygons with multiple exterior rings will be rejected. GeoJSON MultiPolygons with overlapping/intersecting Polygons will be rejected. The GeoJSON spec technically allows this, but is generally invalid geometry in many programs (PostGIS, Shapely, QGIS to name a few). GeoJSON containing more than 500 vertices will be rejected. Clipping outside contract AOI may result in a rejected order. File Format The file_format tool allows you to convert imagery to Cloud Optimized GeoTIFF (ideal for light-weight, web-based workflows) or NITF 2.1 formats. Product inputs The file_format tool supports all item types and all asset types except for those with NITF images (designated as *_nitf assets). Parameters format (enum): The format of the tool output. Currently, the tool supports two formats: \"COG\" : This option produces a tiled Cloud Optimized GeoTIFF, with LZW compression and powers of two overviews. You can find more information at Cloud Optimized GeoTIFF . \"PL_NITF\" : This option converts the output to the National Imagery Transmission Format 2.1 specification. Find out more about the NITF 2.1 Interface Standard . The NITF format only supports WGS84 geographic and UTM projections. If your imagery is in a different projection, use the Reproject tool first. Example \"tools\": [ { \"type\": \"file_format\", \"parameters\": { \"format\": \"COG\" } } ] Tool outputs One formatted imagery output file is produced for each asset. These files have \"_file_format\" appended to their file names. The tool passes through UDM and XML files, and does not update values in these files. Harmonization The harmonize tool allows you to radiometrically harmonize imagery captured by one satellite instrument type to imagery captured by another. Parameters target_sensor (string) : A value indicating to what sensor the input asset types should be calibrated. Each sensor value transforms items captured by a defined set of instrument IDs. Items which have not been captured by that defined set of instrument IDs are unaffected by (passed through) the harmonization operation. Target sensor options Sentinel-2 PSScene surface reflectance assets from PlanetScope instrument types ( PS2.SD and PSB.SD ) can be harmonized to Sentinel-2. With the Sentinel-2 target sensor, the tool harmonizes PSScene surface reflectance asset types ( ortho_analytic_8b_sr , ortho_analytic_4b_sr ) to Sentinel-2 bands (blue, green, red, and narrow near-infrared (NIR)). This sensor type requires that the surface reflectance asset and the supplemental Ortho UDM2 and XML (i.e., ortho_analytic_4b_xml , ortho_analytic_8b_xml ) assets are included when creating a subscription. Read more about the harmonization to Sentinel-2 in Scene Level Normalization and Harmonization of Planet Dove Imagery . Example request \"tools\": [ { \"type\": \"harmonize\", \"parameters\": { \"target_sensor\": \"Sentinel-2\" } } ] Tool outputs One imagery output file with harmonized band values is delivered for each asset type. The transformation of each item depends on the instrument used to capture that item and its relationship to the target sensor. Files which have been transformed have \"_harmonize\" appended to their file names. The Harmonization tool passes through UDM, RPC, and XML files, and does not update values in these files. Reproject The reproject tool allows you to reproject and resample imagery products to a new projected coordinate system and resolution. Product inputs The reproject tool supports all item types and all asset types except for those with non-orthorectified images (basic_* assets). Tool outputs One imagery output file reprojected to the target configuration is produced for each product asset. Udm files are also reprojected to the target configuration. These file outputs will have \"_reproject\" appended to their file names. Parameters projection (string) : A coordinate system in the form EPSG:n (for example, EPSG:4326 for WGS84, EPSG:32611 for UTM 11 North (WGS84), or EPSG:3857 for Web Mercator). Well known text CRS values are also supported (for example, WGS84). resolution (float) : The pixel width and height in the output file. If not provided, the default is the resolution of the input item. This value is in meters unless the coordinate system is geographic (such as EPSG:4326), in which case, it is pixel size in decimal degrees. kernel (string) : The resampling kernel used. If not provided, the default is \"near\". UDM files always use \"near\". This parameter also supports \"bilinear\", \"cubic\", \"cubicspline\", \"lanczos\", \"average\", \"mode\", \"min\", \"max\", \"med\", \"q1\", and \"q3\" (see the gdalwarp \"resampling_method\" docs for details). Example \"tools\": [ { \"type\": \"reproject\", \"parameters\": { \"projection\": \"EPSG:4326\", \"kernel\": \"near\" } } ] Top of Atmosphere Reflectance (TOAR) The Top of Atmosphere Reflectance (TOAR) tool converts Analytic assets from top of atmosphere (TOA) radiance to a TOA scaled reflectance. The Subscriptions API TOAR tool is only applicable to Analytic assets, which represent TOA radiance. The tool converts the pixel values to a scaled reflectance, accounting for varying solar irradiance based on the distance to the sun and geometry of incoming solar radiation. The resulting product is a top of atmosphere reflectance value, no atmospheric correction is applied. Product inputs The toar tool supports the analytic asset type for PSScene and REOrthoTile item types. In addition to the asset type, the corresponding XML metadata asset type is required. Pairs of analytic and XML asset types are listed below: ortho_analytic_4b, ortho_analytic_4b_xml ortho_analytic_8b, ortho_analytic_8b_xml analytic, analytic_xml Parameters scale_factor (integer): Scale factor applied to convert 0.0 to 1.0 reflectance floating point values to a value that fits in 16bit integer pixels. The default is 10000. Values over 65535 could result in high reflectances not fitting in 16bit integers. Example \"tools\": [ { \"type\": \"toar\", \"parameters\": { \"scale_factor\": 10000 } } ] Tool outputs One 16bit imagery output file, holding scaled reflectance values, produced for each analytic asset. These files have \"_toar\" appended to their file names. The tool also passes through the corresponding XML assets.","tags":"subscriptions","url":"https://developers.planet.com/docs/subscriptions/tools/","loc":"https://developers.planet.com/docs/subscriptions/tools/"},{"title":"Usable Data in Planet imagery","text":"In this guide, you'll learn about Planet's automatic detection of pixels which are cloudy or otherwise obscured, so that you can make more intelligent choices about whether the data meets your needs. In 2018, Planet undertook a project to improve cloud detection, and this guide will focus on the improved metadata that can be used for filtering and the new udm2 asset that provides access to detail classification of every pixel. Planet is not currently planning on removing old cloud cover metadata or the old udm asset. Full specification The full specification for the udm2 asset and the related metadata fields can be found in the UDM 2 section of the API documentation. Finding clear imagery One of the benefits of accurate and automated cloud detection is that it allows users to filter out images that don't meet a certain quality threshold. Planet's Data API allows users to search based on the value of the imagery metadata. For example, if you are using the Planet command-line tool, you can search for all four-band PlanetScope scenes that have less than 10% cloud cover in them with the following: planet data search --item-type PSScene --range cloud_percent lt 10 Planet's cloud detection algorithm classifies every pixel into one of six different categories, each of which has a corresponding metadata field that reflects the percentage of data that falls into the category. Class Metadata field clear clear_percent snow snow_ice_percent shadow shadow_percent light haze light_haze_percent heavy haze heavy_haze_percent cloud cloud_percent These can be combined to refine search results even further. An example of searching for imagery that has less than 10% clouds and less than 10% heavy haze: planet data search --item-type PSScene --range cloud_percent lt 10 --range heavy_haze_percent lt 10 Every pixel will be classified into only one of the categories above; a pixel may be snowy or obscured by a shadow but it can not be both at the same time! The following example will show how to do a search for imagery that is at least 90% clear using Planet's Python client. In [1]: from planet import api client = api . ClientV1 () In [10]: # build a filter for the AOI filter = api . filters . range_filter ( \"clear_percent\" , gte = 90 ) # show the structure of the filter print ( filter ) {'config': {'gte': 90}, 'field_name': 'clear_percent', 'type': 'RangeFilter'} In [8]: # we are requesting PlanetScope 4 Band imagery item_types = [ 'PSScene' ] request = api . filters . build_search_request ( filter , item_types ) # this will cause an exception if there are any API related errors results = client . quick_search ( request ) In [9]: # print out the ID of the most recent 10 images that matched for item in results . items_iter ( 10 ): print ( ' %s ' % item [ 'id' ]) 20190316_174936_101e 20190316_193503_101e 20190209_074408_0f4c 20190209_154011_1_0f2b 20190209_154000_0f2b 20190209_101802_100e 20190209_101801_100e 20190209_101800_100e 20190209_043131_0f2a 20190209_044523_1053 The udm2 asset In addition to metadata for filtering, the udm2 asset provides a pixel-by-pixel map that identifies the classification of each pixel. In the example below, cloudy pixels are highlighted in yellow, shadows in red and light haze in blue. Original image udm2 overlay 20190228_172942_0f1a_3B_Visual.tif 20190228_172942_0f1a_udm2.tif The udm2 structure is to use a separate band for each classification type. Band 2, for example, indicates that a pixel is snowy when its value is 1, band 3 indicates shadow and so on. The following Python will download the data above and then display pixels that fall into a certain classifications. In [12]: item_type = \"PSScene\" item_id = \"20190228_172942_0f1a\" In [15]: import time # activate assets assets = client . get_assets_by_id ( \"PSScene\" , item_id ) . get () client . activate ( assets [ \"analytic\" ]) client . activate ( assets [ \"udm2\" ]) # wait until activation completes while True : assets = client . get_assets_by_id ( \"PSScene\" , item_id ) . get () if assets [ \"analytic\" ] . has_key ( \"location\" ) and assets [ \"udm2\" ] . has_key ( \"location\" ): break time . sleep ( 10 ) In [16]: # start downloads r1 = client . download ( assets [ \"analytic\" ], callback = api . write_to_file ()) r2 = client . download ( assets [ \"udm2\" ], callback = api . write_to_file ()) In [17]: # wait until downloads complete r1 . wait () r2 . wait () img_file = r1 . get_body () . name udm_file = r2 . get_body () . name print ( \"image: {} \" . format ( img_file )) print ( \"udm2: {} \" . format ( udm_file )) image: 20190228_172942_0f1a_3B_AnalyticMS.tif udm2: 20190228_172942_0f1a_udm2.tif In [18]: import rasterio from rasterio.plot import show In [22]: with rasterio . open ( udm_file ) as src : shadow_mask = src . read ( 3 ) . astype ( bool ) cloud_mask = src . read ( 6 ) . astype ( bool ) In [23]: show ( shadow_mask , title = \"shadow\" , cmap = \"binary\" ) show ( cloud_mask , title = \"cloud\" , cmap = \"binary\" ) Out[23]: <matplotlib.axes._subplots.AxesSubplot at 0x7fb449b1fd50> In [24]: mask = shadow_mask + cloud_mask show ( mask , title = \"mask\" , cmap = \"binary\" ) Out[24]: <matplotlib.axes._subplots.AxesSubplot at 0x7fb449a93790> In [25]: with rasterio . open ( img_file ) as src : profile = src . profile img_data = src . read ([ 3 , 2 , 1 ], masked = True ) / 10000.0 # apply RGB ordering and scale down In [26]: show ( img_data , title = item_id ) Out[26]: <matplotlib.axes._subplots.AxesSubplot at 0x7fb449a23e10> In [27]: img_data . mask = mask img_data = img_data . filled ( fill_value = 0 ) In [28]: show ( img_data , title = \"masked image\" ) Out[28]: <matplotlib.axes._subplots.AxesSubplot at 0x7fb4499a2890> The image stored in img_data now has cloudy pixels masked out and can be saved or used for analysis.","tags":"planetschool","url":"https://developers.planet.com/docs/planetschool/usable-data-in-planet-imagery/","loc":"https://developers.planet.com/docs/planetschool/usable-data-in-planet-imagery/"},{"title":"UDM 2","text":"About UDM2 Availability - Date Ranges Usable Data Masks are available for 4-band Planetscope imagery back to August 2018 globally, and specific agricultural regions back to January 2018. A small percentage of PlanetScope 4-band imagery after August 2018 do not have the UDM2 asset. This is because of rectification or image processing failures. Usable Data Masks are also available for the SkySat archive dating back to 2017. In very rare instances, a UDM2 asset may not be available for specific SkySat items. New metadata fields The addition of the UDM2 asset also introduced a number of new metadata fields for PSScene4Band datasets. Like existing fields, these new metadata fields may be used to construct filters for searching Planet imagery: learn more about searches and filtering here . UDM2-related metadata fields Field Type Value Range Description clear_percent int [0-100] Percent of clear values in dataset. Clear values represents scene content areas (non-blackfilled*) that are deemed to be not impacted by cloud, haze, shadow and/or snow. clear_confidence_percent int [0-100] percentage value: per-pixel algorithmic confidence in 'clear' classification cloud_percent int [0-100] Percent of cloud values in dataset. Cloud values represent scene content areas (non-blackfilled) that contain opaque clouds which prevent reliable interpretation of the land cover content. heavy_haze_percent int [0-100] Percent of heavy haze values in dataset. Heavy haze values represent scene content areas (non-blackfilled) that contain thin low altitude clouds, higher altitude cirrus clouds, soot and dust which allow fair recognition of land cover features, but not having reliable interpretation of the radiometry or surface reflectance. light_haze_percent int [0-100] Percent of light haze values in dataset. Light haze values represent scene content areas (non-blackfilled) that contain thin low altitude clouds, higher altitude cirrus clouds, soot and dust which allow reliable recognition of land cover features, and have up to +/-10% uncertainty on commonly used indices (EVI and NDWI). shadow_percent int [0-100] Percent of shadow values in dataset. Shadow values represent scene content areas (non-blackfilled) that are not fully exposed to the solar illumination as a result of atmospheric transmission losses due to cloud, haze, soot and dust, and therefore do not allow for reliable interpretation of the radiometry or surface reflectance. snow_ice_percent int [0-100] Percent of snow and ice values in dataset. Snow_ice values represent scene content areas (non-blackfilled) that are hidden below snow and/or ice. visible_percent int [0-100] Visible values represent the fraction of the scene content (excluding the portion of the image which contains blackfill) which is comprised of clear, light haze, shadow, snow/ice categories, and is given as a percentage ranging from zero to one hundred. visible_confidence_percent int [0-100] Average of confidence percent for clear_percent, light_haze_percent, shadow_percent and snow_ice_percent * Blackfilled content refers to empty regions of a scene file that have no value UDM2 Map Deliverable The new UDM2 asset is delivered as a multi-band GeoTIFF file, with the following bands and values: UDM2 Bands Band Description Pixel Value Range Interpretation Band 1 Clear map [0, 1] 0: not clear, 1: clear Band 2 Snow map [0, 1] 0: no snow or ice, 1: snow or ice Band 3 Shadow map [0, 1] 0: no shadow, 1: shadow Band 4 Light haze map [0, 1] 0: no light haze, 1: light haze Band 5 Heavy haze map [0, 1] 0: no heavy haze, 1: heavy haze Band 6 Cloud map [0, 1] 0: no cloud, 1: cloud Band 7 Confidence map [0-100] percentage value: per-pixel algorithmic confidence in classification Band 8 Unusable pixels -- Equivalent to the UDM asset. For the PlanetScope 8th Band, the bits are as follows. Bit 0: Black fill, Bit 1: Likely cloud, Bit 2: Blue (Band 2) is anomalous, Bit 3: Green (Band 4) is anomalous, Bit 4: Red (Band 6) is anomalous, Bit 5: Red Edge (Band 7) is anomalous, Bit 6: NIR (Band 8) is anomalous, Bit 7: Coastal Aerosol (Band 1) and/or Green-I (Band 3) and/or Yellow (Band 5) is anomalous. See Planet's Imagery Specification for complete details. UDM2 Classification Methodology Planet's UDM2 classification approach is based on supervised machine learning techniques that use observation data from Planet-sensors to train a classification model. Planet collects a set of truth scenes that are used to train the model. The truth scenes consist of 4-band top-of-atmosphere-radiance (TOAR) images and their corresponding cloud masks (usable data masks). Each usable data mask is created by manually labeling the TOAR images to assign a UDM2 value to each pixel in the image. To ensure that the truth scenes dataset are representative of the global catalog of Planet images, Planet draws from a diversity of satellites, scene content, seasonality, geography and cloud types to contribute to the truth scene curation and classification process. The labeled cloud mask dataset is then used to train a machine learning model, which is based on convolutional neural networks. The model can then be applied to generate a usable data mask for any new input image. A portion of the labeled cloud mask dataset is not used for training and instead is passed into the completed model for validation. If particular areas perform poorly (e.g., light haze accuracy over urban scenes), additional scenes are added to the truth set to improve the classification accuracy. Planet's engineering team regularly reviews cloud masks and identifies new scenes to add to the truth scene training set. Additionally, customer reports of poorly performing scenes or regions are part of the feedback process to improve the truth training set.","tags":"data-api","url":"https://developers.planet.com/docs/data/udm-2","loc":"https://developers.planet.com/docs/data/udm-2"},{"title":"Planet Explorer Overview","text":"Planet Explorer is an online tool used to search and analyze geospatial imagery, allowing you to see change across the planet over time. You can use Planet Explorer to search through an imagery catalog and either download full-resolution data or analyze hosted data in the browser. Planet Explorer includes imagery from Planet's catalog (PlanetScope, SkySat and RapidEye) as well as public imagery from Sentinel-2 and Landsat 8. Planet's imagery is available at multiple cadences (ranging from daily scenes to weekly, monthly and quarterly basemaps), as well as at various resolutions (for example, SkySat is high-resolution and PlanetScope is medium-resolution). Features Overview Search for Imagery : You can search for daily scenes and basemaps by typing in a location, uploading a geo file, drawing an area of interest on the map, or clicking on the timeline. View Catalog : You can view and filter on daily scenes in the catalog and also view basemaps. Analyze Data : You can analyze data by taking measurements on the map, comparing images side by side, enhancing pixels, or applying spectral visualizations. Order Hosted Data : You can order daily scenes for analysis in the browser (i.e. enhance pixels, spectral visualizations). Download Daily Scenes : You can download daily scenes by ordering directly from the app or by sourcing cURL requests for specific scene IDs if you prefer the API. You must purchase a plan to do so. Task a High-Res Image : You can task a High-Res image in the Tasking Dashboard, linked from Explorer. High-Res images are taken upon request and require a paid plan. Save your work : You can come back to your work and pick up where you left off. Manage Settings : You can manage preferences for coordinate systems or check on usage. Manage Account : You can manage your usage and organizations in your Account Page. Get Help : You can read about new features, take a tour, access the Help Center and the user guide at any time. Try Beta Features : You can try new, experimental features before they are officially released. FAQs : Frequently Asked Questions and their answers.","tags":"apps-explorer","url":"https://developers.planet.com/docs/apps/explorer/","loc":"https://developers.planet.com/docs/apps/explorer/"},{"title":"User Interface","text":"Number Description 1 Title of the Subscription. Generated manually by the Planet Account Manager. 2 Description of the Subscription. Each Subscription generates a description that is designed to give additional information about what the Subscription is for. 3 Search. Use this bar to search through Subscriptions to find the one you want to inspect 4 Start Date of the Subscription. Imagery captured after this date (but before the end date) is processed by the Analytic Feed. 5 End Date of the Subscription. Imagery captured before this date (but after the start date) is processed by the Analytic Feed. 6 Creation Date of the Subscription. The date that the subscription was created.","tags":"apps-feedviewer","url":"https://developers.planet.com/docs/apps/feedviewer/userinterface","loc":"https://developers.planet.com/docs/apps/feedviewer/userinterface"},{"title":"Area of Interest","text":"Defining your Area of Interest (AOI) The plugin interface has many different options for definining and customizing the AOI that you would like to use to search for imagery. Once one of the tools has been used to auto-generate the Active Coordinates, you have options to zoom to, copy or change the active coordinates to whichever AOI fits your use case the best. Once you have drawn, chosen an extent, or otherwise defined an AOI, the Active Coordinates (GeoJSON) field will automatically populate with the vertices of the AOI (in GeoJSON format): Using layer or view extent Setting an Extent - three options are available to you for setting the extent of the search area. These options allow you to define an AOI from the current map view extent, the extent of an active layer withint the map view, or the extent of all layers within the map view. Drawing an AOI Choosing a Draw tool - three options for shapes to draw in order to create a custom extent to use as the search area are available. You can draw a rectangle, polygon or circle to establish an AOI. Selecting polygon(s) from your map workspace The Selection menu allows you to select a single polygon or multiple polygons from an active vector layer in the map to create the extent for the search option. Using GeoJSON coordinates Once one of the three tools mentioned above is used to create, load or select an AOI, the information about that (or those) polygons is automatically generated in the GeoJSON Active Coordinates text box. Alternatively, you may also paste a GeoJSON-formatted polygon type string directly into this box to create your AOI. If you do so, the pasted text must meet the following requirements: * in GeoJSON format * Is a polygon type * in WGS 84 projection (latitude/longitude) * 500 vertices or less You can also directly load an AOI from a GeoJSON file that you have locally saved, without copying and pasting the file's contents into the Active Coordinates text box: Viewing your AOI After you've defined your AOI using one or more of the methods above, the Active Coordinates text box will display the GeoJSON coordinates for your AOI. From here you have the option to zoom to your AOI, copy the coordinates or load a new AOI from a JSON file instead. Zoom to AOI This will zoom the map view to the extent of the AOI that is chosen: Copy AOI Coordinates You can also copy to your clipboard the coordinates of the AOI that you chose:","tags":"integrations-qgis-v1","url":"https://developers.planet.com/docs/integrations/qgis/v1/aoi/","loc":"https://developers.planet.com/docs/integrations/qgis/v1/aoi/"},{"title":"Viewing and Downloading Basemaps","text":"Stream and Download Planet Basemaps Tools In this section of the ribbon, there is a Basemaps dropdown and Filter text box. The dropdown menu will list any Planet basemaps that your Planet account has access to. Users can narrow the search results using the Filter text box, and can paginate more results using the Load More arrow. Next to the Basemaps Dropdown menu is the Download Basemaps tool. This tool allows users to draw an AOI and download the corresponding basemap quads that intersect the AOI. Basemaps Dropdown The Basemaps dropdown lists the basemaps your account has access to. When you click on a basemap listed in the dropdown interface, that basemap layer is automatically added to your map view as a Web Map Tile Service ( WMTS ) and is available to toggle on/off in the ArcGIS Pro Contents tab under the layer title: Planet Basemaps. Once added to the Map View, the basemaps layer can be treated like any other WMTS layer (i.e. Properties, Zoom to layer, etc). Filter Textbox The basemaps dropdown can be filtered using the Filter box. For example, if you want imagery only from 2018, type \"2018\". The Filter box is text only and queries text in a basemap's title. Load More Button The Load More option below the Filter text box allows you to load 10 more basemaps each time you click it. This button will respect the Filter options set above. However, if there are no more basemaps that satisfy the Filter criteria, no more will appear in the dropdown. Download Basemaps Button The Download Basemaps button allows users to download a basemap's source quads as TIF files. In order to download, a user must have sufficient download quota through their Planet subscription. You can check your download permissions here . To download basemap quads, first the Planet Basemap layer must be selected in the Contents tab of the Map Viewer. Then use the Download Basemaps button to draw an AOI using the draw tools that appear at the bottom of your map-view. Once you complete the AOI, a search results panel will appear with a list of corresponding basemaps quads. The panel will also give a size estimate of the quads in Square Kilometers. Choose a location on your machine to download the source quads to. Note: If you have another layer selected, you will recieve an error stating \"The selected layer is not a Planet Image layer\". Area of Interest (AOI) Toolbar By default, the Line draw option is selected in the AOI toolbar. Other options for drawing an AOI are available in the AOI toolbar. The default option is the Line. Next to the Line icon is the Right Angle Line button (default). You can choose either to create a right angle, or by clicking the small down arrow next to it, you can toggle to the Midpoint Line option (top icon below). Streaming (F8): Turn on stream mode editing so vertices are placed at an interval as you move around the map. Click the map to stop streaming temporarily, then click again to start creating vertices. At the far right of the AOI Toolbar, there are two buttons: Finish (F2) and Cancel (Ctrl + Del) . Finish applies the changes you made and completes the operation. Cancel deletes the changes you made and cancels the operation. Once you have finalized the area of interest, you can either cancel or finish the Downloading Basemaps operation. When you click Finish , a popup window appears where you can choose the directory to save the downloaded basemap TIF files. Once fully downloaded, the mosaic basemap imagery will be automatically added to your ArcGIS Pro project. Geoprocessing tasks will be done to synchronize the mosaic datasets, and a success window will popup at the end of the geoprocessing tasks. You should have your mosaic layers available in the map view and in the Contents tab.","tags":"integrations-arcgis-v1","url":"https://developers.planet.com/docs/integrations/arcgis/v1/basemaps/","loc":"https://developers.planet.com/docs/integrations/arcgis/v1/basemaps/"},{"title":"Using Filters","text":"The filters pane allows you to filter the results of your search based on multiple criteria - if you're familiar with Planet Explorer , you've most likely used these filters before. Otherwise, check out the video below to see the filters you can use to narrow down an imagery search using this plugin: These Search Filters allow you to specify the data source, a Time of Interest (TOI), and act on imagery metadata. You can learn more about metadata fields and imagery type in our documentation here . Once all filters are set, and the AOI is loaded in the Active Coordinates (GeoJSON) field, click the Search button at the top right of the plugin pane to execute the search: When the search is complete, you will see a set of image results in the lower pane of the plugin window: Note: it's possible that a search returns no results, depending on the search filters you use. If you get an empty list of results, try adjusting your filters to allow more imagery into the results.","tags":"integrations-qgis-v1","url":"https://developers.planet.com/docs/integrations/qgis/v1/filters/","loc":"https://developers.planet.com/docs/integrations/qgis/v1/filters/"},{"title":"Overview","text":"Planet Add-In User Guide for ArcGIS Pro The Planet Add-In for ArcGIS is a tool for discovering, streaming and downloading Planet imagery and basemaps using your Planet account from within ArcGIS Pro. The Add-In allows users to combine the power of Planet's high-cadence and high-resolution imagery with the geo-analysis capabilities of the ArcGIS Platform. System Requirements ESRI ArcGIS Pro 2.3.0 or greater Python 3.6 or greater Planet subscription or trial for accessing and downloading Planet data Learn more at Planet School Looking for more? Check out this hands-on tutorial that uses Planet's Add-In for Arc Pro to visualize a flood event . Don't have time for a walk though? Planet School's one-minute-to-integrations videos quickly demonstrate the capabilities of Planet's integrations suite.","tags":"integrations-arcgis-v1","url":"https://developers.planet.com/docs/integrations/arcgis/v1/","loc":"https://developers.planet.com/docs/integrations/arcgis/v1/"},{"title":"Overview","text":"Discover, Stream, and Download Planet Imagery in QGIS Planet QGIS Plugin v2 Released These docs are for the deprecated v1 plugin. For the latest plugin documentation, see here The Planet QGIS Plugin enables QGIS users to quickly discover, stream, and download Planet imagery and basemaps. The plugin provides an imagery discovery interface that allows users to search for, stream and download Planet imagery within QGIS. QGIS is a free and open-source GIS desktop application, which anyone can download from the QGIS website . Requirements QGIS version 3.6 or greater Python 3.6 or greater The user will need to have a Planet subscription or trial for accessing and downloading Planet imagery. Don't have a subscription? Contact our team to learn more. Learn more at Planet School Looking for more? Check out this hands-on tutorial that uses the Planet QGIS Plugin to visualize a flood event . Open Source The Planet QGIS Plugin is open source and welcomes contributions: https://github.com/planetlabs/qgis-planet-plugin . If you'd like to see a feature, but aren't sure how to write the code for it, please submit your ideas to the Planet Community .","tags":"integrations-qgis-v1","url":"https://developers.planet.com/docs/integrations/qgis/v1/","loc":"https://developers.planet.com/docs/integrations/qgis/v1/"},{"title":"Getting Started","text":"Installation & Configuration Make sure QGIS is downloaded and installed. ( Need help? Check out our guide to installing QGIS ) Launch QGIS and from the dropdown menus along the top, choose Plugins --> Manage and Install Plugins . Search for the plugin planet_explorer , click Install Using the Plugin After installation is complete, make sure the Planet QGIS Plugin is activated in the Manage and Install Plugins interface (Plugins --> Manage and Install Plugins...) Then from the QGIS menu bar, select Web --> Planet Explorer --> Planet Explorer : Alternatively, you can click the quick icon that by default appears in the tools ribbon in QGIS: Log in to your Planet account The login interface lets you to log in with the email and password associated with your Planet account. Selecting the option to Save Credentials will cache your login within QGIS's authentication system to save time when working in the same project. Once the plugin is open, you'll see this login interface. Enter your Planet account information, or click the Sign Up! link to be in touch with our team and begin a free 14-day trial. Once logged in, the imagery available to your account will be accessible, along with the same search tools available in Planet Explorer.","tags":"integrations-qgis-v1","url":"https://developers.planet.com/docs/integrations/qgis/v1/quickstart/","loc":"https://developers.planet.com/docs/integrations/qgis/v1/quickstart/"},{"title":"Getting Started","text":"Installation & Configuration Make sure ESRI ArcGIS Pro is downloaded and installed Find the Add-In here Once downloaded, click to open the Add-In file, and install. When you open ArcGIS Pro, you should see a Planet Imagery tab on the top Ribbon You can learn more about managing and installing Add-Ins in ArcGIS Pro here Planet Login The login interface allows users to log in with their email and password associated with their Planet account. To log in, click Planet Imagery --> Planet Login. Enter your Planet account information, or click the Contact us link to get connected with the Planet team. Once logged in, the imagery available to your account will be accessible through the Planet Imagery tab. Planet Add-In Interface The Planet Add-In ribbon operates similar to the Planet Explorer website application. There are options for searching for imagery, filtering results, ordering images, and streaming preview images to the map view.","tags":"integrations-arcgis-v1","url":"https://developers.planet.com/docs/integrations/arcgis/v1/quickstart/","loc":"https://developers.planet.com/docs/integrations/arcgis/v1/quickstart/"},{"title":"Searching and Downloading Imagery","text":"Planet Add-In Interface The Planet ribbon operates similar to the Planet Explorer website application. There are options for searching for imagery, filtering results, ordering images, and streaming preview images to the map view. Search for Planet Imagery The next section in the Planet Imagery ribbon is the Search for Planet Imagery tool section. In this section, you can choose to Search for Planet imagery (PlanetScope, SkySat and RapidEye) as well as imagery from the leading Open satellites (LandSat and Sentinel) using the AOI tools detailed above, or you can use the selection in another layer to create the boundaries of the search. Note: there is a 500 vertex limit on the Search by Selected Feature tool - you will need to either simplify your polygon or create a simple AOI to use this feature. Regardless of which tool you choose above, the Search for Planet Imagery pane will appear in the same location as the Table of Contents panel. In this case, a simple polygon was chosen for this Search. At the top of the left-hand Search for Planet Imagery pane there are two buttons: Search and Orders . Search This search interface provides options for a number of filters to set before the search is conducted. These parameters include Date Acquired, Source, Cloud Cover, Area Cover and a shortcut button to All Filters which includes some extra options. Date Acquired (Range) You can set the start and end date of your time of interest for your AOI. Source You can choose which sources you are interested in. Cloud Cover By percentage, you can filter the imagery to have less than a certain percentage of cloud cover. Area Cover By percentage, you can filter the imagery to have more than a certain percentage of their area inside the AOI you are using. All Filters The All Filters tab includes the same filters as above (Date Acquired, Source, Cloud Cover and Area Cover - and stay pre-filled with any options you may have chosen in those tabs). More filtering options are available in this tab, including Ground Sample Distance, Off-nadir Angle, Sun Azimuth, Sun Elevation as well as toggling on/off Ground Control and Access Filter . When all filters and requirements are set, click the Search button to display imagery that meets the criteria. Orders To the right of the Search tab is the Orders tab. Clicking on the Orders tab shows the Orders and Downloads interface. Under the Orders header, you will see the orders you have placed, their status, and if successful, a link to Download the data. Farther to the right in the Orders table, you will see the unique ID of each image. Once you click the Download link, a browse window will open and you can choose where to save the files. When you have chosen a location, click OK. The imagery will begin downloading, and you should see a status appear in the lower Downloads header. When the imagery has been successfully downloaded, the status should read Archive extracted; added to project , along with the local path to the imagery. Planet Info The last section of the Planet Imagery ribbon is the Planet Info button. Clicking on this button reveals several links to helpful and useful Planet sites, including Planet.com, Imagery Product Specifications, Support Community, Documentation and the Terms of Service . Clicking on any of these links will open a new browser window for that site.","tags":"integrations-arcgis-v1","url":"https://developers.planet.com/docs/integrations/arcgis/v1/search/","loc":"https://developers.planet.com/docs/integrations/arcgis/v1/search/"},{"title":"Searching for Imagery","text":"Orienting yourself to the plugin interface The Planet QGIS Plugin window is essentially a smaller version of Planet Explorer built directly in to your QGIS workspace. There are options for searching for imagery, and filtering results by an area of interest (AOI), time of interest (TOI), and other imagery metadata fields. Additionally, users can order images to download directly within the plugin, and stream preview images to the map view in QGIS. The top dropdown menu offers either Daily Imagery or other basemap alternatives. Next to the dropdown is the Search button. In order to search for imagery, you must first define an Area of Interest (AOI) by using the Area of Interest dialogue box. Within this box, there are a number of options for creating an AOI to Search for imagery such as a draw rectangle tool or an option to select the active map extent.","tags":"integrations-qgis-v1","url":"https://developers.planet.com/docs/integrations/qgis/v1/search/","loc":"https://developers.planet.com/docs/integrations/qgis/v1/search/"},{"title":"Viewing Search Results & Ordering Imagery","text":"Viewing Search Results If all goes well, you should see a list of imagery results, ordered by date. To the far right of each set of imagery, there is a gear icon. When this icon is clicked, you are presented with some options. Depending on the level of the imagery you are on, you can Zoom to Footprint , Add Preview Layer to Map , or Copy ID to Clipboard : From here, you can zoom to an image's footprint directly in your map window, or choose to add a preview of the image to your map as a new layer. Using the image previews, you can decide with image search results best fit your needs. Once you've decided which images you want to download, the next step is to place an Order . Ordering Imagery If you click on the checkbox next to any of the resulting imagery sets, the Order button on the lower left becomes active and references the number of images in the batch group that was chosen. Clicking the Order button opens a dialogue window for ordering imagery to be downloaded. In this window, you can choose whether to Bundle the images together using specific criteria, and whether to Clip items to AOI . You also must give a name to your order. Once you have named your order and made any optional selections, you'll see the Place Order button in the bottom right becomes clickable. Watch the video below to see this process in action: Once you have clicked Place Order , you'll see an Order request log window pane appear in the bottom half of the window, with details about your order and a link to the Orders monitorlog where you can check to see if your imagery is ready to download. Another way to get to the Orders monitorlog is via the account button in the bottom right of the Planet plugin pane: The Orders Monitor Log shows all the orders you have open that are ready to download, or are being prepped (or have failed for some reason). You can filter the list to show only orders that are available to download. You can also manually refresh the list to see if an order has become ready. You can see in the image below an example of each type of status: running , success and failed . Once you click download, the plugin passes information to the QGIS task manager to automatically download and add the image to your current map view. Once downloaded, you can interact with the imagery as a local file (i.e. you can geoprocess it, add it to current workflows, etc.). Watch the video below to see a demonstration of downloading an order and adding the results to a QGIS workspace:","tags":"integrations-qgis-v1","url":"https://developers.planet.com/docs/integrations/qgis/v1/orderingresults/","loc":"https://developers.planet.com/docs/integrations/qgis/v1/orderingresults/"},{"title":"Compare Imagery Over Time","text":"Number Description 1 Timeline. Thumbnails showing different time periods over the AOI 2 Detection Time. The locked time period from which the detection was generated 3 Side-By-Side View. View two time periods side by side to see change over time. 4 Slider View. View two time periods with a time slider to see change over time.","tags":"apps-feedviewer","url":"https://developers.planet.com/docs/apps/feedviewer/view_over_time/","loc":"https://developers.planet.com/docs/apps/feedviewer/view_over_time/"},{"title":"Visual Basemaps","text":"Planet's Visual Basemaps are 8-bit, time series mosaic products which are optimized for visual consistency and minimize the effects of clouds, haze, and other image variability. They are ideal for use in visual backdrops or machine learning to enable an understanding of change over time. PlanetScope Visual Basemaps (Zoom Level 15 - 4.77 meter, Zoom Level 16 - 2.38 meter cell size at the equator) are generated with a proprietary \"best scene on top\" algorithm which selects the highest quality imagery from Planet's catalog over specified time intervals, based on cloud cover and image sharpness. PlanetScope Visual Basemaps can be purchased over custom areas of interest at a quarterly, monthly, biweekly, or weekly cadence. SkySat Visual Basemaps (Zoom Level 18 - 0.596 meter cell size at the equator) are also generated with this algorithm, but typically select from imagery which is first tasked by Planet over a custom area and time of interest. SkySat Visual Basemaps may be purchased at quarterly, monthly, weekly, or custom cadence, and as an add-on to our Flexible Tasking product. Visual Basemaps are available for download via the Basemaps API and Basemaps Viewer , and can be streamed via Planet Web Tile Services . You can read a more detailed overview of our Basemap Product Specification here . Imagery Products Overview Below is a high level overview of our PlanetScope and SkySat Visual Basemaps products. Source Imagery Download (GeoTIFF) Bands Streaming (WMTS) Bands Monitoring Frequency Zoom Level Normalization PlanetScope visual assets RGB RGB Quarterly, monthly, biweekly, weekly 15, 16 MODIS SkySat ortho_visual assets RGB RGB Quarterly, monthly, weekly, custom 18 Planetscope (balanced to MODIS), none (unbalanced) Publication Planet aims to publish all standard select basemaps 7 days after the end of the acquisition period. However, there may be instances where publishing may take longer. Publishing times for custom basemaps are determined on a case-by-case basis. Cadence Basemaps are generated at a specified cadence based on the \"first_acquired\" and \"last_acquired\" UTC timestamps for underlying source imagery. Cadence first_acquired last_acquired Quarterly January 1st, April 1st, July 1st, and October 1st at 00:00:00 UTC March 31st, June 30th, September 30th, and December 31st at 23:59:59 UTC Monthly The first day of each month at 00:00:00 UTC The last day of each month at 23:59:59 UTC Biweekly Every other Monday (starting at 1/1/2018 00:00:00 UTC) 14 days after Biweekly first_acquired date Weekly Mondays at 00:00:00 UTC Sundays at 23:59:59 UTC Scene Provenance During the Basemap generation process, a record of each individual PlanetScope or SkySat image used is retained. All source scenes are traceable through Planet's Basemaps API and Basemaps Viewer . Basemap Quads Basemaps can be downloaded as a set of \"basemap quads\", or simply \"quads.\" Quads are a distributed grid of GeoTIFF files which compose the basemap. Basemap with quad boundaries An individual Visual Basemap quad has the following standard specifications: Attribute Description Imagery PlanetScope and RapidEye, or SkySat Pixel size (resolution) PlanetScope: 4.77 meter (Zoom Level 15) and 2.39 meter (Zoom Level 16) at the equator; SkySat: 0.597 meter (Zoom Level 18) at the equator Image bit depth 8 bits per pixel Bands Red, Green, Blue, Alpha Projection WGS84 Web Mercator (EPSG:3857) Size 4096 x 4096 pixels The projection used in Planet Basemaps has been selected to match what standard web mapping applications (Web Mercator Projection). The last band in the GeoTIFF of every mosaic quad includes an Alpha Mask which indicates areas of the quad where there is no imagery data available. Single quad within a basemap Product Naming The name of each PlanetScope and SkySat Visual Basemap is custom and will be made available to you following the purchase of your basemap product. The name of each basemap quad within the Basemaps API is designed to represent the x and y position of the quad within the two dimensional grid which makes up the basemap. It is generally {X}-{Y}, where X and Y are the x and y position of the quad in the grid. Example: 439-1220 Upon download, the name of the downloaded quad is designed to represent the zoom level and the mosaic's tiling scheme. Example: L15-0439E-1220N.tif Processing Normalization Following scene selection, Visual Basemap source scenes are normalized to a monthly MODIS-based surface reflectance target to minimize variability between scenes and reduce atmospheric effects. Each scene is processed with a unique color curve optimized to remove haze and broadly match the colors of the target while still preserving the hue of neutral colors (i.e. clouds/snow stay white). After adjacent scenes have been combined into a mosaic tile, a seamline-reduction algorithm is applied to minimize any remaining local differences between scenes. This algorithm is optimized for landmass coverage, and may exhibit inconsistencies in visual quality over open water. While Planet cannot guarantee that a basemap will not contain visible scene lines or artifacts resulting from the mosaicing process, these approaches generally make the imagery appear more consistent and seamless. Packaging Basemaps are converted into a Web Mercator projection and resampled to a default pixel size of 4.77 meters or 0.596 meters for SkySat. The resulting quads are then indexed within the Planet platform so that they may be downloaded for offline use via the Mosaics API. Lower zoom level overviews are created to populate the full stack of web tiles. These feed into Planet's Web Tile Services, which are easily integrated in other applications, serving up only the part of the basemap a user needs. Quality In addition to basemap production techniques described above to ensure quality output, basemap quality and coverage are also functions of source imagery input constraints based on the specified time of interest and cadence of delivery. For a smaller time of interest and shorter cadence periods, basemap quality and coverage are more likely to be impacted.","tags":"data","url":"https://developers.planet.com/docs/data/visual-basemaps","loc":"https://developers.planet.com/docs/data/visual-basemaps"},{"title":"WMTS Basemap Tile Service","text":"The Planet WMTS Basemap Service allows users to access a listing of Planet's entire catalog of basemaps. WMTS Catalog Access Request Structure https://api.planet.com/basemaps/v1/mosaics/wmts?api_key={api-key} False-color visualizations & indices Optionally, you may also include the proc={index value} parameter to specify a dynamically-rendered false color visualization, for example NDVI: https://api.planet.com/basemaps/v1/mosaics/wmts?api_key={api-key}&proc=ndvi Learn more about false-color visualizations in Planet Basemaps here , or reference this list of Index Legends for a complete list of available indices and corresponding query parameter index values. WMTS Protocol Overview The WMTS protocol is similar to the XYZ protocol , but has a broader set of compatible 3rd party applications. It adds a uniform catalog protocol allowing discovery and display of tiled imagery. It provides a pyramid of tiles at 16 zoom levels so that it can be easily displayed in web browsers and various other clients. Planet's WMTS services are compatible with QGIS desktop , ArcGIS Pro , ArcOnline , CesiumJS and others. As with other WMTS tiling services, Planet WMTS tiles have these attributes: Tiles are 256 × 256 pixels. Tiles use the Web Mercator coordinate reference system (EPSG:3857). Tiles are available between zoom levels 0 and 18. Tiles are rendered in the PNG format with an alpha channel for transparency. Grid is a rectangle with 2*z rows and 2*z columns, where z is the zoom level. Grid uses 0,0 as the top, left corner in the grid.","tags":"basemaps","url":"https://developers.planet.com/docs/basemaps/tile-services/wmts/","loc":"https://developers.planet.com/docs/basemaps/tile-services/wmts/"},{"title":"XYZ Basemap Tile Service","text":"XYZ Basemap Tile Service Request Structure https://tiles{0-3}.planet.com/basemaps/v1/planet-tiles/{mosaic_name}/gmap/{z}/{x}/{y}.png?api_key={api-key} Parameter Value mosaic_name The name of mosaic. z Tile zoom level. x Tile row in the grid. y Tile column in the grid. api_key API key for authentication. As an example, a complete URL for a tile request for the global mosaic global_monthly_2016_05_mosaic would look like the following: XYZ Basemap Tile Service Example https://tiles0.planet.com/basemaps/v1/planet-tiles/global_monthly_2016_05_mosaic/gmap/0/0/0.png?api_key={api-key} False-color visualizations & indices Optionally, you may also include the proc={index value} parameter to specify a dynamically-rendered false color visualization. As an example, a complete URL for a tile request for an NDVI visualization for the surface reflectance mosaic taiwan_analytic_sr_may_2019_mosaic would look like the following: https://tiles0.planet.com/basemaps/v1/planet-tiles/taiwan_analytic_sr_may_2019_mosaic/gmap/0/0/0.png?api_key={api-key}&proc=ndvi Learn more about false-color visualizations in Planet Basemaps here , or reference this list of Index Legends for a complete list of available indices and corresponding query parameter index values. XYZ Protocol Overview The XYZ protocol describes how a mapping client (often from within a browser) can access tiled imagery. This is the same protocol that Planet Explorer uses to display tiled imagery. It provide a pyramid of tiles at 16 zoom levels so that it can efficiently be displayed in web browsers. As with other XYZ tiling services, Planet XYZ tiles have these attributes: Tiles are 256 × 256 pixels. Tiles use the Web Mercator coordinate reference system (EPSG:3857). Tiles are available between zoom levels 0 and 18. Tiles are rendered in the PNG format with an alpha channel for transparency. Grid is a rectangle with 2*z rows and 2*z columns, where z is the zoom level. Grid uses 0,0 as the top, left corner in the grid. Tiles are found at the path z/x/y.png , where z is the zoom level, and x and y are the positions in the tile grid.","tags":"basemaps","url":"https://developers.planet.com/docs/basemaps/tile-services/xyz/","loc":"https://developers.planet.com/docs/basemaps/tile-services/xyz/"},{"title":"January 7, 2020","text":"Planet Explorer updates: Fixed AOI clipping for non-square shapes Loading thumbnail preview images no longer uses tile service quota Updates and improvements to Explorer's look & feel","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Jan/07/explorer/2020-01-07/","loc":"https://developers.planet.com/changelog/2020/Jan/07/explorer/2020-01-07/"},{"title":"January 20, 2022","text":"New ✨ Planet now supports delivery to Oracle Cloud Storage. You can now use the Orders and Subscriptions API to order assets into Oracle Cloud Storage buckets. You provide your Oracle Cloud Storage information (credentials and storage-specific values), and we deliver your order to that bucket. Read details for receiving orders into your Oracle Cloud Storage. Read details for subscribing to continuous delivery into your Oracle Cloud Storage.","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Jan/20/orders-api/2022-01-20/","loc":"https://developers.planet.com/changelog/2022/Jan/20/orders-api/2022-01-20/"},{"title":"January 22 2020","text":"UDM and UDM2 files for SkySatCollect items no longer have their nodata value set to 1","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Jan/22/imagery/2020-01-22/","loc":"https://developers.planet.com/changelog/2020/Jan/22/imagery/2020-01-22/"},{"title":"January 23, 2020","text":"Planet Explorer updates: Updates to Statusbar to make notifications easier to see Users with an Access Only license no longer see erroneous download error messages Fixed: search result AOIs in Explorer map view no longer off-center Fixed: long text in info panels no longer trails past borders Broad updates and improved consistency in user interface and tool functionality","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Jan/23/explorer/2020-01-23/","loc":"https://developers.planet.com/changelog/2020/Jan/23/explorer/2020-01-23/"},{"title":"January 29, 2020","text":"Planet Explorer updates: Improved visibility of search panel opener Refined AOI selection, measuring and drawing tools guidance Fixed: \"low resolution\" warning message no longer displayed erroneously","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Jan/29/explorer/2020-01-29/","loc":"https://developers.planet.com/changelog/2020/Jan/29/explorer/2020-01-29/"},{"title":"February 3, 2022","text":"Improvements 🙌🏻 The Orders API Band Math tool now supports 15 bands. Planet has expanded Orders API Band Math tool to support up to 15 band calculations for users who want all original bands, plus additional calculations applied to their delivered asset. Read updates to the Orders Band Math tool.","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Feb/03/orders-api/2022-02-03/","loc":"https://developers.planet.com/changelog/2022/Feb/03/orders-api/2022-02-03/"},{"title":"February 10, 2022","text":"Improvements 🙌🏻 The panchromatic Usable Data Masks (UDM2) asset is now available in SkySatScene bundles. The panchromatic Usable Data Masks (UDM2) asset type basic_panchromatic_udm2 is now available in SkySatScene basic_panchromatic and basic_panchromatic_dn bundles. Read more about the SkySatScene panchromatic bundles. Read more about Usable Data Masks.","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Feb/10/orders-api/2022-02-10/","loc":"https://developers.planet.com/changelog/2022/Feb/10/orders-api/2022-02-10/"},{"title":"February 20, 2020","text":"Planet Explorer: NDVI Color Ramp Picker is now available in IE Imagery that has been downsampled is now designated with a color tint watermark Updates across the map tool UI include new map buttons & a new zoom tool Planet Stories: Users with scenes-only imagery access can now create Stories Planet Account page: Fixed bug where Account Settings didn't load properly in IE","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Feb/20/explorer/2020-02-20/","loc":"https://developers.planet.com/changelog/2020/Feb/20/explorer/2020-02-20/"},{"title":"March 05, 2020","text":"Planet Explorer: 5 band imagery is now available via the analytic_5b bundle in the Orders dialog Fixed a bug that was limiting display of imagery Sources in the filters dialog Fixed a dialog display bug for Safari users","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Mar/05/explorer/2020-03-05/","loc":"https://developers.planet.com/changelog/2020/Mar/05/explorer/2020-03-05/"},{"title":"Analytics API","text":"Our ship detection feed leverages a land mask to remove any erroneous detections made on land - we've updated it so that Venice, Italy and the port of Shanghai are not as aggressively covered so that we can detect ships more accurately in this area. We are now offering plane detection, silo bag detection and well pad detection as fully supported Analytic Feeds. Plane detection is offered in airports/airfields globally to enable users to track plane activity worldwide. Silo bag detection is offered in Argentina where farmers use silo bags to store their harvests until they're ready to bring to market. Well pad detection is offered in the Permian Basin in West Texas to enable our users to track well pad clearings which can provide valuable insight within the Energy market.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Mar/27/analytics/2020-03-27/","loc":"https://developers.planet.com/changelog/2020/Mar/27/analytics/2020-03-27/"},{"title":"April 7, 2020","text":"Bug Fixes 🐛 Explorer no longer crashes when previewing imagery and using the results sidebar scroll.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Apr/07/explorer/2020-04-07/","loc":"https://developers.planet.com/changelog/2020/Apr/07/explorer/2020-04-07/"},{"title":"April 9, 2020","text":"Orders API default order delivery layout was changed to support a simpler and more consistent structure. Customers will be able to use the legacy deprecated format until May 6th. More information on this change is available here: https://developers.planet.com/docs/orders/ordering-delivery/#order-delivery-layout","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Apr/09/orders-api/2020-04-09/","loc":"https://developers.planet.com/changelog/2020/Apr/09/orders-api/2020-04-09/"},{"title":"April 30, 2020","text":"New ✨ We now have a top navigation with easier access to common help items. You can find links to Planet's Help Center, What's New, take a contextual tour, view our Terms of Service and/or Submit Feedback. All of these things used to be spread throughout the application and now have a more centralized home. A cleaner base layer when an AOI is drawn to highlight the selected imagery better Improvements 🙌🏻 A better way to specify the time interval of interest in the results panel This used to be a dropdown, it is now a series of toggle buttons where the options are visible \"up-front\" The filters, date filter, sort options, and saving/updating a search actions are now closer together and easier to find With this change we no longer have \"quick-filters\", all filters can be accessed via the \"Filters\" button The sort menu now has a pop-up menu with the options, this is in preparation to bring more sorting options as we improve the application. We've added an empty state message in the sidebar when a user does not have access to certain basemaps, to avoid having an empty and sad panel The low resolution message is now a dismissible notification, rather than occupying space on the sidebar (this only applies to users with limited access) Super-Dove (PSB.SD) filter is now an option for all users and no longer requires a lab Bug Fixes 🐛 Spacebar toggle now works as expected, regardless of last area selected.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Apr/30/explorer/2020-04-30/","loc":"https://developers.planet.com/changelog/2020/Apr/30/explorer/2020-04-30/"},{"title":"October 5, 2020","text":"Subscriptions API is Planet's new data delivery API which allows you to subscribe to continuous cloud delivery of the imagery and metadata you care about with a single API call. The best of Planet search, processing, and delivery, the Subscription's API's set-it-and-forget-it ordering capability will automatically push imagery to you as soon as it becomes available.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Oct/05/subscriptions-api/2020-10-05/","loc":"https://developers.planet.com/changelog/2020/Oct/05/subscriptions-api/2020-10-05/"},{"title":"May 14, 2020","text":"New ✨ We heard that you missed the Satellite layer when viewing imagery. We now have an option to turn it on! We've added a new menu that allows you to toggle a Satellite view as well as the Street labels. Improvements 🙌🏻 The Filters panel has gotten a face-lift, amongst other improvements There are new grouped categories and they can be collapsed so that it is easier to navigate and see just what you want or need. The sliders now have a way to enter the values via a text field The instrument filter now uses checkboxes, so that it is easier to select more than one instrument at a time. You can reset the filters to the default values by clicking \"Clear All\" In order to apply the filters you must click on \"Apply Filters\"","tags":"changelog","url":"https://developers.planet.com/changelog/2020/May/14/explorer/2020-05-14/","loc":"https://developers.planet.com/changelog/2020/May/14/explorer/2020-05-14/"},{"title":"May 15 2020","text":"Data API now returns a list of supported asset types for each item type in all GET item_types calls. This field lists the set of asset types which may be produced for a given item type. You can reference this change in our API reference documentation here: https://developers.planet.com/docs/apis/data/reference/#operation/ListItemTypes","tags":"changelog","url":"https://developers.planet.com/changelog/2020/May/15/data-api/2020-05-15/","loc":"https://developers.planet.com/changelog/2020/May/15/data-api/2020-05-15/"},{"title":"May 19, 2020","text":"Planet is improving its algorithm for calculating Surface Reflectance in PlanetScope and RapidEye products. Planet is also now producing analytic_sr assets under the existing PSOrthoTile and REOrthoTile item types. The new Surface Reflectance algorithm should help reduce scene-to-scene difference due to rapidly varying atmospheric conditions. Reference the updated white paper on the support page: https://support.planet.com/hc/en-us/articles/360012629573-Planet-Surface-Reflectance-Product The new analytic_sr assets are available under the existing PSOrthoTile and REOrthoTile items listed in the Dev Center: https://developers.planet.com/docs/data/items-assets/","tags":"changelog","url":"https://developers.planet.com/changelog/2020/May/19/imagery/2020-05-19/","loc":"https://developers.planet.com/changelog/2020/May/19/imagery/2020-05-19/"},{"title":"May 20, 2020","text":"New (ish) ✨ Orders v2 is now the sole provider of orders in Explorer for all users. As announced last week, only those users that are part of the Beta Clipping + Raster Ops Program will have the ability to clip via the UI. For help with this please reach out in #product-support as it is not managed by Explorer. Deprecation ☠️ With the release of Orders v2 in Explorer comes the deprecation of the Orders v0 UI All orders previously made with orders v0 can be accessed via the account page for download and/or the API","tags":"changelog","url":"https://developers.planet.com/changelog/2020/May/20/explorer/2020-05-20/","loc":"https://developers.planet.com/changelog/2020/May/20/explorer/2020-05-20/"},{"title":"May 24 2019","text":"Added the ability for users to specify \"fallback bundles\" in the product_bundle field using a comma delimited list.","tags":"changelog","url":"https://developers.planet.com/changelog/2019/May/24/orders-api/2019-05-24/","loc":"https://developers.planet.com/changelog/2019/May/24/orders-api/2019-05-24/"},{"title":"May 29 2020","text":"Data API supports a new filter option: UpdateFilter. This filter can be used to filter items by changes to a specified metadata field value made after a specified date. It allows users to identify items which may have been republished with quality improvements or fixes, enabling them to keep internal catalogs up-to-date and make more informed redownload decisions. You can read more on this filter type here: https://developers.planet.com/docs/data/searches-filtering/#updatefilter","tags":"changelog","url":"https://developers.planet.com/changelog/2020/May/29/data-api/2020-05-29/","loc":"https://developers.planet.com/changelog/2020/May/29/data-api/2020-05-29/"},{"title":"June 4, 2020","text":"New ✨ Additional visualization indexes (e.g. NDWI) are now available through a Lab. Improvements 🙌🏻 Explorer's User Guide is now available from our Help Menu. The analytic_sr bundle and its assets is now available to order for PSOrthoTile and REOrthoTile items","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Jun/04/explorer/2020-06-04/","loc":"https://developers.planet.com/changelog/2020/Jun/04/explorer/2020-06-04/"},{"title":"June 17, 2020","text":"Next-Generation Planetscope imagery will now be published as both standard and test quality. 3 and 4 band data will be available through the existing PSScene3Band, PSScene4Band, and PSOrthotile items. Additionally, 5-band (blue, green, red, rededge, nir) imagery is available under the analytic_5b asset, which is in the PSOrthotile item type. The way to identify data in this release is by the \"psb.sd\" value in the \"instrument\" field. See https://developers.planet.com/docs/data/items-assets/ for details on Items/Assets. An Image Quality Report on data contained in this release is available at https://assets.planet.com/docs/Planet_Combined_Imagery_Product_Specs_letter_screen.pdf .","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Jun/17/imagery/2020-06-17/","loc":"https://developers.planet.com/changelog/2020/Jun/17/imagery/2020-06-17/"},{"title":"June 17 2020","text":"ArcGIS Add-In V1.2 New ✨ Users can now select and download their entire basemap (they're no longer limited at 50 basemap quads) The \"Create mosaic dataset\" post basemap download is now an optional setting when selecting your basemap quads Improvements 🙌🏻 The basemap downloader tool now uses the default folder browser to prevent remove permissions errors when creating the mosaic dataset Extracting downloads from your orders panel no longer fails when un-zipping","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Jun/17/integrations/2020-06-17/","loc":"https://developers.planet.com/changelog/2020/Jun/17/integrations/2020-06-17/"},{"title":"July 1, 2020","text":"New ✨ You can now preview our upcoming UI and feature updates at https://www.planet.com/products/explorer/ . This site will be up for a limited time. You can now pay for a basemap streaming license, online with your credit card. Explorer will include prompts to redirect you or you can visit https://www.planet.com/purchase . Bug Fixes 🐛 GeoJSON files that only have a geometry defined, without a Feature Collection definition now work as expected. Our Welcome dialog was causing some confusion as it alluded to our trial regardless of account status, we've made some updates!","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Jul/01/explorer/2020-07-01/","loc":"https://developers.planet.com/changelog/2020/Jul/01/explorer/2020-07-01/"},{"title":"July 6 2020","text":"Data API supports a new metadata field, \"publishing_stage\" to help you understand an item's publishing lifecycle and make decisions on when to download an item, based on whether your pipeline needs to optimize for data latency or data accuracy. This field is searchable and returned in the metadata.json file for all PlanetScope and SkySat items, published after June 19, 2020. More information on this field is available here: https://developers.planet.com/docs/data/items-assets/","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Jul/06/data-api/2020-07-06/","loc":"https://developers.planet.com/changelog/2020/Jul/06/data-api/2020-07-06/"},{"title":"July 13, 2020","text":"Planet Explorer updates: New ✨ New Explorer UI that brings a better user experience with relocated tools. Color Enhance for basemaps Auto Enhance, Snow, and Desert modes Custom enhancement via brightness, contrast, and saturation controls Additional Spectral Indices have been promoted from a Lab to the tool NDWI (using NIR), MTVI2, VARI, MSAVI2 You no longer need to draw an AOI to compare two basemaps","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Jul/13/explorer/2020-07-13/","loc":"https://developers.planet.com/changelog/2020/Jul/13/explorer/2020-07-13/"},{"title":"July 14, 2020","text":"Orders API supports a new \"file_format\" tool, which allows customers to convert their geoTIFFs to COGs (cloud-optimized geoTIFFs) and NITF 2.1 format to support more efficient workflows on the web. More information on this tool is available here: https://developers.planet.com/docs/orders/tools-reference/#file-format","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Jul/14/orders-api/2020-07-14/","loc":"https://developers.planet.com/changelog/2020/Jul/14/orders-api/2020-07-14/"},{"title":"July 15, 2020","text":"Planet Explorer updates: Bug Fixes 🐛 Open water searches now show results as expected","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Jul/15/explorer/2020-07-15/","loc":"https://developers.planet.com/changelog/2020/Jul/15/explorer/2020-07-15/"},{"title":"July 17 2020","text":"ArcGIS Add-In V1.2 New ✨ Users can now select and download their entire basemap (they're no longer limited at 50 basemap quads) The \"Create mosaic dataset\" post basemap download is now an optional setting when selecting your basemap quads Bug Fixes 🐛 The basemap downloader tool now uses the default folder browser to prevent remove permissions errors when creating the mosaic dataset Extracting downloads from your orders panel no longer fails when un-zipping","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Jul/17/integrations/2020-07-17/","loc":"https://developers.planet.com/changelog/2020/Jul/17/integrations/2020-07-17/"},{"title":"July 29, 2020","text":"Clip and Ship API The Clip and Ship API will be deprecated on September 1, 2020 . This API was previously deprecated and removed from our documentation in 2018. To continue downloading Planet imagery, we recommend using the Orders (v2) API . This API was especially designed for bulk ordering and offers unique delivery features, including delivery to cloud storage, zip, and email or webhook notifications. Please reach out to support by submitting a request for details on accessing our Orders API clipping feature. Legacy Ordering APIs The Orders v0 and v1 APIs will be deprecated on September 1, 2020 . These APIs was previously deprecated and removed from our documentation. To continue downloading Planet imagery, we recommend using the Orders (v2) API . This API was especially designed for bulk ordering and offers unique delivery features, including delivery to cloud storage, zip, and email or webhook notifications.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Jul/29/deprecating/2020-07-29/","loc":"https://developers.planet.com/changelog/2020/Jul/29/deprecating/2020-07-29/"},{"title":"July 29, 2020","text":"Planet Explorer: New ✨ You can now analyze imagery (scenes) by ordering them to a hosted folder. This feature is still in \"Beta\" and you can try it out by enabling it in the Labs. Improvements 🙌🏻 Timeline dropdowns Measure tooltips Bug Fixes 🐛 Weekly Basemaps labels Collection of bug fixes when switching between Enhancement Imagery, NDVI, and browsing.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Jul/29/explorer/2020-07-29/","loc":"https://developers.planet.com/changelog/2020/Jul/29/explorer/2020-07-29/"},{"title":"Next-Generation PlanetScope imagery released","text":"Next-generation scenes are now being published: users should expect to see them returned in API and Explorer queries when not excluding scenes with the instrument PS2.SD .","tags":"changelog","url":"https://developers.planet.com/changelog/2019/Aug/06/imagery/2019-08-06/","loc":"https://developers.planet.com/changelog/2019/Aug/06/imagery/2019-08-06/"},{"title":"August 13, 2020","text":"The \"Legacy Orders\" Tab on planet.com/account (backed by Orders v0 API) will be deprecated on August 31, 2020. Please take any necessary download or re-download action on orders placed through Planet's legacy ordering systems in advance of this date.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Aug/13/deprecating/2020-08-13/","loc":"https://developers.planet.com/changelog/2020/Aug/13/deprecating/2020-08-13/"},{"title":"August 19, 2020","text":"Coregistration is a new Orders API tool available in Beta to Preferred and Premium raster tool customers. This tool allows you to coregister a set of target items to a single anchor item within your order, making it easier to perform time series analysis of deep temporal imagery stacks. More information on this tool is available here: https://developers.planet.com/docs/orders/tools-reference/#coregister","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Aug/19/orders-api/2020-08-19/","loc":"https://developers.planet.com/changelog/2020/Aug/19/orders-api/2020-08-19/"},{"title":"August 19, 2020","text":"Planet Explorer updates: New ✨ Saved Searches can be saved without an end date. This means that every time you load it, it will load the most recent results. You can select which Measurement System you want to use for the Measurement Tools, metric or united states customary, alongside new and more explicit units. The units will be respected and will not change regardless of the size of the area drawn. Improvements 🙌🏻 Spectral Analysis panel is now grouped to differentiate between Band Combinations and Spectral Indices You can now provide direct feedback regarding our Spectral Analysis feature Metadata Panel updates For PlanetScope items you can now see the Instrument information Tooltips that add more context to each field PSScene3Band analytic assets can now be ordered via the Orders interface Bug Fixes 🐛 Fixed some issues with incorrect metadata being shown for items SkySatCollects now have the correct rectification notification.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Aug/19/explorer/2020-08-19/","loc":"https://developers.planet.com/changelog/2020/Aug/19/explorer/2020-08-19/"},{"title":"August 21, 2020","text":"Bugs fixed related to order and captures states: captures being stuck in PROCESSING, orders being stuck in IN_PROGRESS, orders moving to IN_PROGRESS after being EXPIRED, Stereo Orders being stuck in REQUESTED and expecting for more captures after already having relevant successful captures published","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Aug/21/tasking/2020-08-21/","loc":"https://developers.planet.com/changelog/2020/Aug/21/tasking/2020-08-21/"},{"title":"August 28, 2020","text":"New & Updated Tasking Dashboard features Extended the timeout for stuck queued captures from 15h to 30h after which the capture gets FAILED and the order continues re-tasking or expires. Order details are grouped in a more constructive way in Order Details View. Requested area in sqkm is exposed on order level.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Aug/28/tasking/2020-08-28/","loc":"https://developers.planet.com/changelog/2020/Aug/28/tasking/2020-08-28/"},{"title":"September 1, 2020","text":"The SkySat cloud_cover field is now computed as the sum of cloud_percent and heavy_haze_percent so all cloud values are consistent. Note that cloud_cover is still in the range 0-1 (a ratio), while cloud_percent and heavy_haze_percent are percentages in the range 0 to 100. The properties of the archive have not been changed at this time, but may be changed in the future to also reflect this change.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Sep/01/imagery/2020-09-01/","loc":"https://developers.planet.com/changelog/2020/Sep/01/imagery/2020-09-01/"},{"title":"September 10, 2020","text":"Planet Explorer updates: New ✨ The Imagery Type filter is now grouped by resolution. The group checkboxes can be used to select/deselect all MGRS support when searching. Users can now use the Military Grid Reference System with 10km, 1km, and 100m precisions. Improvements 🙌🏻 The instrument filter is no longer applied by default, to avoid excluding items without instrument in the metadata. Bug Fixes 🐛 Fixed an issue when following a deep link and the user was not logged in, the search would not load properly.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Sep/10/explorer/2020-09-10/","loc":"https://developers.planet.com/changelog/2020/Sep/10/explorer/2020-09-10/"},{"title":"September 11, 2020","text":"New & Updated Tasking Dashboard features Order Lock-in cancellation threshold changed to 8hrs Monitoring Cadence is now exposed in Task and Capture endpoints Show fulfilled area (in sqkm) over requested area (in sqkm) Disable editing cloud_cover_min / max for all order types Validate Geojson area size against max AOI size Help / Request access for a new dashboard user","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Sep/11/tasking/2020-09-11/","loc":"https://developers.planet.com/changelog/2020/Sep/11/tasking/2020-09-11/"},{"title":"September 16, 2020","text":"You can now query on \"satellite_azimuth\" for all PSScene3Band, PSScene4Band, and PSOrthoTile items published after September 9, 2020 in the Data API. This property will also be returned in the json metadata for those items.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Sep/16/data-api/2020-09-16/","loc":"https://developers.planet.com/changelog/2020/Sep/16/data-api/2020-09-16/"},{"title":"September 23 2020","text":"GEE Delivery Integration v1 Planet has a new Google Earth Engine (GEE) Delivery Integration that streamlines the delivery to GEE experience. Learn more by visiting the GEE Docs .","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Sep/23/integrations/2020-09-23/","loc":"https://developers.planet.com/changelog/2020/Sep/23/integrations/2020-09-23/"},{"title":"September 25, 2020","text":"The Orders API Coregistration tool is now Generally Available to Preferred and Premium Raster Tool customers. This tool allows you to coregister a set of target items to a single anchor item within your order, making it easier to perform time series analysis of deep temporal imagery stacks. More information on this tool is available here: https://developers.planet.com/docs/orders/tools-reference/#coregister","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Sep/25/orders-api/2020-09-25/","loc":"https://developers.planet.com/changelog/2020/Sep/25/orders-api/2020-09-25/"},{"title":"Improved band metadata in PlanetScope scenes and orthotiles","text":"All bands now have human readable band descriptions (ie red, blue, green, NIR) and the color interpretation for 4-band imagery now reflects the BGRN band: band ordering in GIS tools such as QGIS or GDAL will now correctly reflect BGRN ordering instead of assuming RGBN.","tags":"changelog","url":"https://developers.planet.com/changelog/2019/Sep/28/imagery/2019-09-28/","loc":"https://developers.planet.com/changelog/2019/Sep/28/imagery/2019-09-28/"},{"title":"September 29, 2020","text":"Planet Explorer now displays both the 'gsd' and 'pixel_resolution' parameters for both SkySatScenes and SkySatCollects. The 'gsd' parameter represents the ground sample distance of the basic SkySat product, whereas the 'pixel_resolution' parameter represents the resampled resolution of the orthorectified assets.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Sep/29/imagery/2020-09-29/","loc":"https://developers.planet.com/changelog/2020/Sep/29/imagery/2020-09-29/"},{"title":"September 30, 2020","text":"Analytics Feed Viewer New functionality in the Feed Viewer is now live! Updates include: Heatmaps A compare view to see change over time Ability to see multiple time period's worth of detections at once Updated metadata view Summary Statistics Summary Statistics are now live! Existing Ships, Planes, Silo Bags and Well Pad feeds can be queried for Summary Stats to easily get counts of detections over time. Users can also query road and building detection feeds to track the square meters covered by each class over time.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Sep/30/analytics/2020-09-30/","loc":"https://developers.planet.com/changelog/2020/Sep/30/analytics/2020-09-30/"},{"title":"September 30, 2020","text":"Planet Explorer updates: New ✨ You can now access our Tasking Dashboard to task a high resolution image, directly from Explorer. Hosted Data folders can now be renamed. Improvements 🙌🏻 You can now use MGRS coordinates with higher precision (10m, 1m) and it will be converted to a Lat/Lon coordinate. Bug Fixes 🐛 Fixed an issue where the number fields for the area coverage filter would get stuck on certain values.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Sep/30/explorer/2020-09-30/","loc":"https://developers.planet.com/changelog/2020/Sep/30/explorer/2020-09-30/"},{"title":"October 6, 2020","text":"New Tasking Functionality Order Lock-In Our SkySat Assured Tasking customers will now be able to see upcoming collection opportunities for each of their targets, and lock-in the specific access windows they would like captured. This allows customers full control of their daily collection plan, with visibility into full constellation daily access, with precisely forecasted collection opportunities. We call this capability Order Lock-In . Email Notifications & Order History Email Notifications and Order History are part of the notification and status reporting system that provides an extensive support to monitor and operate orders within the Tasking API and Dashboard. Our users will receive a certain set of emails triggered by order and capture activities including an interface to opt in / out and customise notifications as needed. The Tasking Dashboard will be extended with a historical view on order level where we'll populate the same set of order and capture activities that brings a better visibility about order progress.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Oct/06/tasking/2020-10-06/","loc":"https://developers.planet.com/changelog/2020/Oct/06/tasking/2020-10-06/"},{"title":"October 8 2020","text":"ArcGIS Add-In v1.3 Bug fix: ArcGIS Pro 2.6 introduced a new autosave project functionality. This upgrade was causing frequent pop-up messages from the Planet ArcGIS Add-In alerting users that their API key may be embedded in their project if they are using a Planet tile streaming service. Planet has decoupled these pop-up warnings from the autosave function in ArcGIS Pro with the Planet ArcGIS Add-In v1.3 patch. The warning has been re-associated with ArcGIS Pro \"Share\" capabilities like Share Project and Share Web Map. Additionally, users now have the option to disable the warning message for their project by selecting \"Don't show again for this project. Users can download the latest version here.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Oct/08/integrations/2020-10-08/","loc":"https://developers.planet.com/changelog/2020/Oct/08/integrations/2020-10-08/"},{"title":"Release 1.2","text":"Enables the extension of end dates in subscriptions","tags":"changelog","url":"https://developers.planet.com/changelog/2019/Oct/22/analytics/2019-10-22/","loc":"https://developers.planet.com/changelog/2019/Oct/22/analytics/2019-10-22/"},{"title":"October 22 2019","text":"Added usage tracker to the bottom of Explorer Improved Contact Sales Form Added Weekly Basemaps","tags":"changelog","url":"https://developers.planet.com/changelog/2019/Oct/22/explorer/2019-10-22/","loc":"https://developers.planet.com/changelog/2019/Oct/22/explorer/2019-10-22/"},{"title":"New ship detection model","text":"Updated the ship detection model with an improved version","tags":"changelog","url":"https://developers.planet.com/changelog/2019/Oct/23/analytics/2019-10-23/","loc":"https://developers.planet.com/changelog/2019/Oct/23/analytics/2019-10-23/"},{"title":"October 25 2019","text":"Canceling an order is now possible cloud_filter operation parameters are now optional","tags":"changelog","url":"https://developers.planet.com/changelog/2019/Oct/25/orders-api/2019-10-25/","loc":"https://developers.planet.com/changelog/2019/Oct/25/orders-api/2019-10-25/"},{"title":"Analytics API","text":"Conforms with OGC Features 1.0","tags":"changelog","url":"https://developers.planet.com/changelog/2019/Oct/30/analytics/2019-10-30/","loc":"https://developers.planet.com/changelog/2019/Oct/30/analytics/2019-10-30/"},{"title":"November 1 2019","text":"Explorer bug fixes: Fixed Compare mode for Daily Imagery Fixed issue with flickering Basemaps Now showing most up-to-date Basemaps Image Footprint visible on map when hovering over search result in left sidebar Adjusted SkySat preview zoom level to 13 (from 10)","tags":"changelog","url":"https://developers.planet.com/changelog/2019/Nov/01/explorer/2019-11-01/","loc":"https://developers.planet.com/changelog/2019/Nov/01/explorer/2019-11-01/"},{"title":"November 15 2019","text":"For bucket delivery, users are now required to provide an account with both write and delete access to the given bucket. This applies to all platforms, including AWS/S3, Google Cloud Storage, and Azure.","tags":"changelog","url":"https://developers.planet.com/changelog/2019/Nov/15/orders-api/2019-11-15/","loc":"https://developers.planet.com/changelog/2019/Nov/15/orders-api/2019-11-15/"},{"title":"New NDVI tool for Basemaps in Explorer","text":"New NDVI tool for basemaps added to Explorer: Surface Reflectance Basemaps now available in Explorer New button with NDVI, False Color and RGB options for Surface Reflectance Basemaps Additional indices in Labs tab in Explorer Index visualization available in Compare mode Bug fixes: Pixel Diff Lab is working","tags":"changelog","url":"https://developers.planet.com/changelog/2019/Nov/15/explorer/2019-11-15/","loc":"https://developers.planet.com/changelog/2019/Nov/15/explorer/2019-11-15/"},{"title":"Bulk ordering in Explorer","text":"Bulk ordering of imagery now possible with keyboard shortcut (Press Shift to select multiple results)","tags":"changelog","url":"https://developers.planet.com/changelog/2019/Nov/20/explorer/2019-11-20/","loc":"https://developers.planet.com/changelog/2019/Nov/20/explorer/2019-11-20/"},{"title":"November 22 2019","text":"Users can now specify more than one fallback bundle in the product_bundle field","tags":"changelog","url":"https://developers.planet.com/changelog/2019/Nov/22/orders-api/2019-11-22/","loc":"https://developers.planet.com/changelog/2019/Nov/22/orders-api/2019-11-22/"},{"title":"December 02, 2019","text":"New Accounts page released: log in with your Planet account at https://www.planet.com/account/ for a fresh new interface.","tags":"changelog","url":"https://developers.planet.com/changelog/2019/Dec/02/admin/2019-12-02/","loc":"https://developers.planet.com/changelog/2019/Dec/02/admin/2019-12-02/"},{"title":"December 3, 2019","text":"Planet Explorer updates: Image previews in Explorer are now tinted magenta in areas where scenes have been downsampled The NDVI button is now disabled when viewing daily imagery where NDVI is not available Planet Stories bug fix: \"Compare Stories\" embed link no longer generates an error when embedded in HTML.","tags":"changelog","url":"https://developers.planet.com/changelog/2019/Dec/03/explorer/2019-12-03/","loc":"https://developers.planet.com/changelog/2019/Dec/03/explorer/2019-12-03/"},{"title":"December 12 2019","text":"Pansharpened and Visual SkySat data product generation has been updated. The scaling of the BGRN pansharpened products is reduced to the scaling of the multispectra (a 16x reduction in DN values)","tags":"changelog","url":"https://developers.planet.com/changelog/2019/Dec/09/imagery/2019-12-09/","loc":"https://developers.planet.com/changelog/2019/Dec/09/imagery/2019-12-09/"},{"title":"December 11, 2019","text":"Planet Explorer update: SuperDove data is now available to EAP users via the PSB.SD Filter in Labs.","tags":"changelog","url":"https://developers.planet.com/changelog/2019/Dec/11/explorer/2019-12-11/","loc":"https://developers.planet.com/changelog/2019/Dec/11/explorer/2019-12-11/"},{"title":"Jan 11 2018","text":"This is a major release. We have switched to a new API endpoint and have changed API syntax. Refer to the API docs for more information. In summary, here is what has changed: Switched to Product Bundles Introducing Raster Toolkit with 8 tools: Clip Crops the raw imagery to desired boundaries TOAR Convert radiance to top of atmospheric (TOR) imagery Tile Tiles images to desired specification Composite Merge multiples images into a single image Reproject Converts coordinate projection system Band Math Perform arbitrary band math to create outputs like NDVI Image co-registration Aligns multiple images within few pixels over a same geographical area Zip per product bundle or entire results in a single zip file. Improved error messages","tags":"changelog","url":"https://developers.planet.com/changelog/2018/Jan/11/orders-api/2018-01-11/","loc":"https://developers.planet.com/changelog/2018/Jan/11/orders-api/2018-01-11/"},{"title":"Jul 16 2018","text":"This is a minor release with a few user facing changes. Most changes are new and old behavior should not change. Incorrect archive_type results in a validation error. See Zipping Results section of documentation. This is an optional field and if you haven't been setting it, the type will default to zip . You can now specify your webhook callback to be per_order: true . This is an optional parameter and, if omitted, the default behavior will be used whereby you'll receive a webhook callback per bundle. See the Webhook section of documentation. We have new validation rules on orders to ensure correct type of parameters (you can't use a number in a string field), and cannot specify operations that do not exist.","tags":"changelog","url":"https://developers.planet.com/changelog/2018/Jul/16/orders-api/2018-07-16/","loc":"https://developers.planet.com/changelog/2018/Jul/16/orders-api/2018-07-16/"},{"title":"Sept 20 2018","text":"This is a minor release. Notification emails were previously being sent in text/plain format only. They will now be sent in multipart/alternative and include both plaintext and HTML formatting. The original plaintext version of the email is formatted exactly as it was prior to this change.","tags":"changelog","url":"https://developers.planet.com/changelog/2018/Sep/20/orders-api/2018-09-20/","loc":"https://developers.planet.com/changelog/2018/Sep/20/orders-api/2018-09-20/"},{"title":"April 2019","text":"Data API exceptions will now be returned with a 500 status code, not 502","tags":"changelog","url":"https://developers.planet.com/changelog/2019/Apr/01/data-api/2019-04-01/","loc":"https://developers.planet.com/changelog/2019/Apr/01/data-api/2019-04-01/"},{"title":"May 2019","text":"Exceeding quota when attempting to download will now return with a 403 status code, not 429 Authentication should now be properly honored/required on all asset type and item type endpoints, e.g. /data/v1/asset-types /data/v1/asset-types/analytic_range /data/v1/item-types /data/v1/item-types/SkySatScene","tags":"changelog","url":"https://developers.planet.com/changelog/2019/May/01/data-api/2019-05-01/","loc":"https://developers.planet.com/changelog/2019/May/01/data-api/2019-05-01/"},{"title":"June 2019","text":"Renamed the SkySatScene asset type from analytic to ortho_analytic","tags":"changelog","url":"https://developers.planet.com/changelog/2019/Jun/01/data-api/2019-06-01/","loc":"https://developers.planet.com/changelog/2019/Jun/01/data-api/2019-06-01/"},{"title":"September 2019","text":"Added new SkySatScene asset type basic_analytic_udm","tags":"changelog","url":"https://developers.planet.com/changelog/2019/Sep/01/data-api/2019-09-01/","loc":"https://developers.planet.com/changelog/2019/Sep/01/data-api/2019-09-01/"},{"title":"24 October 2019","text":"This is a major release with a few important changes. The order states QUEUED and PROCESSING have been moved to the capture level, which now includes the following states: QUEUED (new) PROCESSING PUBLISHED FAILED To show more visibility into granular capture states at the order level, the following two fields were introduced to the orders response: capture_status_queued_count lists the number of captures in QUEUED state capture_status_processing_count lists the number of captures in PROCESSING state Together the following calls can be used to identify corders which were previously considered QUEUED or PROCESSING : GET /tasking/v2/orders/?capture_status_queued_count__gt=0 GET /tasking/v2/orders/?capture_status_processing_count__gt=0 The order state FINALIZING was introduced. This state represents an order with an end time that has expired, but still has one or more captures in QUEUED or PROCESSING states. This state will ensure an order isn't marked as EXPIRED when a SUCCESS capture is about to be PUBLISHED . New endpoint /tasking/v2/orders/aggregates/status/ was introduced to give you a roll-up of all your organization's orders by status. The endpoint /tasking/v1/orders/<order_id>/captures is now deprecated.","tags":"changelog","url":"https://developers.planet.com/changelog/2019/Oct/24/tasking/2019-10-24/","loc":"https://developers.planet.com/changelog/2019/Oct/24/tasking/2019-10-24/"},{"title":"January 2020","text":"Authentication should now be properly honored/required on all Data API endpoints, specifically including: /data/v1/download /data/v1/spec /data/v1/stats /data/v1/swagger","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Jan/13/data-api/2020-01-13/","loc":"https://developers.planet.com/changelog/2020/Jan/13/data-api/2020-01-13/"},{"title":"February 6 2020","text":"SkySatVideo item type now available for search and download via the Data API and Python CLI. Item type information is available here: https://developers.planet.com/docs/data/skysatvideo/","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Feb/06/data-api/2020-02-06/","loc":"https://developers.planet.com/changelog/2020/Feb/06/data-api/2020-02-06/"},{"title":"February 10 2020","text":"Users can now view (lat, lon) coordinates of a Point Order in the Order Details view of the Tasking Dashboard","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Feb/10/tasking/2020-02-10/","loc":"https://developers.planet.com/changelog/2020/Feb/10/tasking/2020-02-10/"},{"title":"February 11 2020","text":"Clicking on Planet icon now opens the Order Table View with no rows selected.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Feb/11/tasking/2020-02-11/","loc":"https://developers.planet.com/changelog/2020/Feb/11/tasking/2020-02-11/"},{"title":"February 21 2020","text":"all and all_udm2 product bundles are no longer supported in the Orders API. For information on available product bundle types, please see our Bundle Reference documentation: https://developers.planet.com/docs/orders/product-bundles-reference/ On April 1st, we plan to make changes to the order delivery layout for all Orders API orders. You can begin testing these new layout changes by specifying a layout format in your order. We're also granting an option to use the layout field to allow you to maintain your current structure until May 6th. See here for more details: https://developers.planet.com/docs/orders/ordering-delivery/#order-delivery-layout","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Feb/21/orders-api/2020-02-21/","loc":"https://developers.planet.com/changelog/2020/Feb/21/orders-api/2020-02-21/"},{"title":"February 24 2020","text":"Filtering items by available assets is now available via the AssetFilter filtering option of the Data API. More information on this filter type is available here: https://developers.planet.com/docs/data/searches-filtering/#asset-filters","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Feb/24/data-api/2020-02-24/","loc":"https://developers.planet.com/changelog/2020/Feb/24/data-api/2020-02-24/"},{"title":"February 24 2020","text":"Users can now edit start and end time for their active area orders depending on order state, PENDING or IN_PROGRESS respectively.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Feb/24/tasking/2020-02-24/","loc":"https://developers.planet.com/changelog/2020/Feb/24/tasking/2020-02-24/"},{"title":"February 26 2020","text":"Making Planet's changelog more accessible you can now follow changelog updates via Atom feed: https://developers.planet.com/feeds/changelog.atom.xml tags on each changelog entry are now clickable & allow you to browse changelog archives by product: e.g., https://developers.planet.com/tag/orders-api.html","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Feb/26/devcenter/2020-02-26/","loc":"https://developers.planet.com/changelog/2020/Feb/26/devcenter/2020-02-26/"},{"title":"March 2 2020","text":"Users can now visualize their AOI size on the map as part of Order Entry:","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Mar/02/tasking/2020-03-02/","loc":"https://developers.planet.com/changelog/2020/Mar/02/tasking/2020-03-02/"},{"title":"March 18 2020","text":"Users can now filter by order type in Order Table View, so that they can filter and differentiate stereo orders from other order types.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Mar/18/tasking/2020-03-18/","loc":"https://developers.planet.com/changelog/2020/Mar/18/tasking/2020-03-18/"},{"title":"March 19 2020","text":"Users can now select IMAGE or STEREO Order Type on order creation process:","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Mar/19/tasking/2020-03-19/","loc":"https://developers.planet.com/changelog/2020/Mar/19/tasking/2020-03-19/"},{"title":"March 20 2020","text":"analytic_sr assets are now available for PSOrthoTile and REOrthoTile item types. You can search for and order these assets via the Data API, Orders API ( analytic_sr product bundle), and Python CLI.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Mar/20/data-api/2020-03-20/","loc":"https://developers.planet.com/changelog/2020/Mar/20/data-api/2020-03-20/"},{"title":"March 20 2020","text":"Area Orders can now task larger areas with a polygon of interest up to 500 sqkm.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Mar/20/tasking/2020-03-20/","loc":"https://developers.planet.com/changelog/2020/Mar/20/tasking/2020-03-20/"},{"title":"March 25 2020","text":"Enabled Stereo Orders as a new order type to task 3 stereo capture orders.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Mar/25/tasking/2020-03-25/","loc":"https://developers.planet.com/changelog/2020/Mar/25/tasking/2020-03-25/"},{"title":"April 1 2020","text":"Stereo captures from the same pass and date are now grouped.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Apr/01/tasking/2020-04-01/","loc":"https://developers.planet.com/changelog/2020/Apr/01/tasking/2020-04-01/"},{"title":"April 6 2020","text":"Users can now see order dimensions on the map: Point order 5x5: ~25 sqkm Area order: AOI size of a requested geometry","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Apr/06/tasking/2020-04-06/","loc":"https://developers.planet.com/changelog/2020/Apr/06/tasking/2020-04-06/"},{"title":"April 7 2020","text":"Users can now submit area orders with the size up to 5000 sqkm.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Apr/07/tasking/2020-04-07/","loc":"https://developers.planet.com/changelog/2020/Apr/07/tasking/2020-04-07/"},{"title":"April 30, 2020","text":"New Content A new Planet Explorer User Guide has been added: you can find it at developers.planet.com/docs/apps/explorer Navigation Update A dedicated listing of Planet's API documentation can now be found at developers.planet.com/docs/apis","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Apr/30/devcenter/2020-04-30/","loc":"https://developers.planet.com/changelog/2020/Apr/30/devcenter/2020-04-30/"},{"title":"May 13 2020","text":"Order entry now includes the number of stereo captures: now users can submit a stereo order with 2 or 3 captures.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/May/13/tasking/2020-05-13/","loc":"https://developers.planet.com/changelog/2020/May/13/tasking/2020-05-13/"},{"title":"May 19 2020","text":"Validation on allowed geometries when submitting a GeoJSON file is now enabled. For example, multipolygons or 3D objects are not supported. Visualising area orders are now automatically tessellated and displayed on order creation:","tags":"changelog","url":"https://developers.planet.com/changelog/2020/May/19/tasking/2020-05-19/","loc":"https://developers.planet.com/changelog/2020/May/19/tasking/2020-05-19/"},{"title":"May 29 2020","text":"Order fulfilment percentage of \"progress\" is now displayed:","tags":"changelog","url":"https://developers.planet.com/changelog/2020/May/29/tasking/2020-05-29/","loc":"https://developers.planet.com/changelog/2020/May/29/tasking/2020-05-29/"},{"title":"June 5, 2020","text":"New Planet School resources A new Jupyter Notebook has been added to our collection of guides and tutorials: learn how to generate a heatmap from vector analytic change detections . New tutorial: learn how to explore Planet Analytic Ship Detection feeds & visualize collections over an AOI using QGIS","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Jun/05/devcenter/2020-06-05/","loc":"https://developers.planet.com/changelog/2020/Jun/05/devcenter/2020-06-05/"},{"title":"June 17, 2020","text":"New Planet School resource New video tutorial: Getting Started with REST APIs . New: Dev Newsletter You can now sign up to get the latest dev-focused updates on Planet's platform & APIs","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Jun/17/devcenter/2020-06-17/","loc":"https://developers.planet.com/changelog/2020/Jun/17/devcenter/2020-06-17/"},{"title":"June 17 2020","text":"Users can now see order dimensions in the order summary exactly calculated by the system and not with an approximation.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Jun/17/tasking/2020-06-17/","loc":"https://developers.planet.com/changelog/2020/Jun/17/tasking/2020-06-17/"},{"title":"June 22 2020","text":"Customers can now connect their tools with the Tasking Dashboard directly via a deeplink that lands on Order Creation with pre-filled order details that have been configured in the URL. URL parameters (all parameters are optional): Pl-number product start time end time geometry order type number of stereo captures","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Jun/22/tasking/2020-06-22/","loc":"https://developers.planet.com/changelog/2020/Jun/22/tasking/2020-06-22/"},{"title":"June 26, 2020","text":"New user resources New video tutorial: Get Started with Planet CLI: Searching for Data . The Tasking Dashboard guide is now available at developers.planet.com/docs/apps/taskingdashboard . New & improved \"Quickstart\" guides are now at developers.planet.com/quickstart .","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Jun/26/devcenter/2020-06-26/","loc":"https://developers.planet.com/changelog/2020/Jun/26/devcenter/2020-06-26/"},{"title":"July 01 2020","text":"Users can now access a map view with all orders visualised in clusters. While zooming in these clusters are ungrouped to order shapes. We also enabled a geographic filter that can be drawn on the map filtering orders inside this filter. Table view will reflect the geographic filter and respective orders.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Jul/01/tasking/2020-07-01/","loc":"https://developers.planet.com/changelog/2020/Jul/01/tasking/2020-07-01/"},{"title":"July 6 2020","text":"Users will get a pop up notification as soon as the a new version of the Tasking Dashboard is released so they can reload and can see the new features:","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Jul/06/tasking/2020-07-06/","loc":"https://developers.planet.com/changelog/2020/Jul/06/tasking/2020-07-06/"},{"title":"July 9 2020","text":"When selecting an order on the map and then jumping to the table the selected order will be still selected in the table:","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Jul/09/tasking/2020-07-09/","loc":"https://developers.planet.com/changelog/2020/Jul/09/tasking/2020-07-09/"},{"title":"July 02 2020","text":"Users can now use the URL for directly linking to sub-pages in order to share the interface in a given state:","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Jul/02/tasking/2020-07-02/","loc":"https://developers.planet.com/changelog/2020/Jul/02/tasking/2020-07-02/"},{"title":"July 20 2020","text":"Question icon for GeoJSON informs the user about current capabilities of the chosen product:","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Jul/20/tasking/2020-07-20/","loc":"https://developers.planet.com/changelog/2020/Jul/20/tasking/2020-07-20/"},{"title":"August 3 2020","text":"Operators can now set all parameters via Deeplink in the Tasking Dashboard.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Aug/03/tasking/2020-08-03/","loc":"https://developers.planet.com/changelog/2020/Aug/03/tasking/2020-08-03/"},{"title":"August 14, 2020","text":"NEW: Developer Trial Program This week we launched our new Developer Trial Program: read more in this blog post , then apply to the program here .","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Aug/14/devcenter/2020-08-14/","loc":"https://developers.planet.com/changelog/2020/Aug/14/devcenter/2020-08-14/"},{"title":"October 12, 2020","text":"New ✨ Ability to order Hosted Data (beta) We've moved the color enhancements to its own tab. You can now see the color histogram and color curve and adjust it.. This will make it a \"manual\" enhancement. Improvements 🙌🏻 We've made some more improvements to the results layout, added some more iconography to accommodate more information at a glance","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Oct/12/explorer/2020-10-12/","loc":"https://developers.planet.com/changelog/2020/Oct/12/explorer/2020-10-12/"},{"title":"October 12, 2020","text":"Block creating too many orders:","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Oct/12/tasking/2020-10-12/","loc":"https://developers.planet.com/changelog/2020/Oct/12/tasking/2020-10-12/"},{"title":"October 15, 2020","text":"Expose satellite elevation configuration on Order Entry:","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Oct/15/tasking/2020-10-15/","loc":"https://developers.planet.com/changelog/2020/Oct/15/tasking/2020-10-15/"},{"title":"October 20, 2020","text":"Grouping of stereo captures on several passes in one day","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Oct/20/tasking/2020-10-20/","loc":"https://developers.planet.com/changelog/2020/Oct/20/tasking/2020-10-20/"},{"title":"October 21, 2020","text":"Updates to on-hover progress in Order Detail View:","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Oct/21/tasking/2020-10-21/","loc":"https://developers.planet.com/changelog/2020/Oct/21/tasking/2020-10-21/"},{"title":"October 22, 2020","text":"Improvements 🙌🏻 We've given Basemaps Viewer a light face-lift. We added the top navigation bar similar to Explorer so that it is easier to navigate our different apps.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Oct/22/explorer/2020-10-22/","loc":"https://developers.planet.com/changelog/2020/Oct/22/explorer/2020-10-22/"},{"title":"October 22, 2020","text":"Rank parameter has been temporarily removed until its further re-design.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Oct/22/tasking/2020-10-22/","loc":"https://developers.planet.com/changelog/2020/Oct/22/tasking/2020-10-22/"},{"title":"October 23, 2020","text":"QGIS Proxy settings can now be enabled for all Planet API calls. Previously, QGIS's proxy settings were not considered in the Planet QGIS Plugin. Users can access the latest patch directly in the QGIS Plugin Repository .","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Oct/23/integrations/2020-10-23/","loc":"https://developers.planet.com/changelog/2020/Oct/23/integrations/2020-10-23/"},{"title":"October 29, 2020","text":"Improvements 🙌🏻 Results selection is now back to the previous behavior where only one item is selected at a time. To select multiple results you can still use CTRL + click. Bug Fixes 🐛 Application no longer crashes when loading results in IE 11","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Oct/29/explorer/2020-10-29/","loc":"https://developers.planet.com/changelog/2020/Oct/29/explorer/2020-10-29/"},{"title":"November 05, 2020","text":"Enable editing of a drawn geographic filter. This allows adding new vertices between two existing as well as moving them.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Nov/05/tasking/2020-11-05/","loc":"https://developers.planet.com/changelog/2020/Nov/05/tasking/2020-11-05/"},{"title":"November 06, 2020","text":"Improvements 🙌🏻 We've updated our Imagery Type groupings to reflect \"Non-Planet Datasets\" Bug Fixes 🐛 When you enter a scene id into the search bar it now returns just the scene you wanted and not every scene that matched the date range. We were flagging some scenes as not rectified when they were. Our default searches were being submitted with local timestamps instead of UTC","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Nov/06/explorer/2020-11-06/","loc":"https://developers.planet.com/changelog/2020/Nov/06/explorer/2020-11-06/"},{"title":"November 18, 2020","text":"Automagically populate product for order entry if there is just one","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Nov/18/tasking/2020-11-18/","loc":"https://developers.planet.com/changelog/2020/Nov/18/tasking/2020-11-18/"},{"title":"November 19, 2020","text":"Improvements 🙌🏻 Basemap results list items now look the same as daily scene results list items We've swapped the sort button and the save search button, so that the former is closer to the results. Bug Fixes 🐛 We had some issues with the date picker reflecting the selected dates when in different time zones. Everything is UTC but it was not being reflected correctly. The application can now be loaded correctly in MS Edge Legacy (v44)","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Nov/19/explorer/2020-11-19/","loc":"https://developers.planet.com/changelog/2020/Nov/19/explorer/2020-11-19/"},{"title":"November 20, 2020","text":"A new REJECTED state was added to the Order Lock-In feature, indicating when a lock-in order could not be confirmed, rather than setting the order to FAILED as was done previously Lock-In orders are now failed if no capture arrives in the Pipeline 5 hours after the capture was meant to be taken","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Nov/20/tasking/2020-11-20/","loc":"https://developers.planet.com/changelog/2020/Nov/20/tasking/2020-11-20/"},{"title":"December 14, 2020","text":"New ✨ Users with access to SkySat imagery can now order it for Hosted Analysis. Currently Imagery Enhancement is not available for these items. If you have ordered imagery for Hosted Analysis you can now move the items to a different or new folder. Improvements 🙌🏻 We've improved the way we display your basemap tile view usage. We will no longer display the usage bar, but will notify users when they are almost out of quota at approximately 80% consumption and when they have completely run out. There is also a new \"My Usage\" tab to view usage (access via Settings Panel). Bug Fixes 🐛 Fixed an issue where typing into the filters number fields was not working as expected. Fixed an issue where the layers displayed on the map were not ordered as expected. Fixed an issue when searching by scene id was not returning results due to an incorrect date filter.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Dec/14/explorer/2020-12-14/","loc":"https://developers.planet.com/changelog/2020/Dec/14/explorer/2020-12-14/"},{"title":"December 14, 2020","text":"Monitoring Tasking v1.0 release. This functionality enables our Flexible customers to schedule their flexible orders with a cadence.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Dec/14/tasking/2020-12-14/","loc":"https://developers.planet.com/changelog/2020/Dec/14/tasking/2020-12-14/"},{"title":"December 15, 2020","text":"Disabled sorting/ordering functionality on calculated fields: some fields can't be (plausibly) sorted, so users are no longer able to click the table header on these fields / columns.","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Dec/15/tasking/2020-12-15/","loc":"https://developers.planet.com/changelog/2020/Dec/15/tasking/2020-12-15/"},{"title":"December 17, 2020","text":"The \"active\" Subscriptions API status has been renamed to \"running\", to reduce confusion upon future release of the backfill subscriptions capability. More details on Subscription Statuses are available here: https://developers.planet.com/docs/subscriptions/#subscription-status Pagination has now been added to the GET Subscriptions endpoint. You can see a sample response in our API Reference here: https://developers.planet.com/docs/subscriptions/reference/#operation/getSubscription","tags":"changelog","url":"https://developers.planet.com/changelog/2020/Dec/17/subscriptions-api/2020-12-17/","loc":"https://developers.planet.com/changelog/2020/Dec/17/subscriptions-api/2020-12-17/"},{"title":"January 04, 2021","text":"The Order Detail View now shows a quick filter to only show fulfilling images and furthermore presents all images stacked on top of each other on the right side.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Jan/04/tasking/2021-01-04/","loc":"https://developers.planet.com/changelog/2021/Jan/04/tasking/2021-01-04/"},{"title":"January 06, 2021","text":"\"Folders\" for saved filters : With the renaming function and backslashes (\"\\\") you can now organize your favorite saved filters into neat folders: Renamed 'recurrence' to 'frequency':","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Jan/06/tasking/2021-01-06/","loc":"https://developers.planet.com/changelog/2021/Jan/06/tasking/2021-01-06/"},{"title":"January 12, 2021","text":"LineStrings (strips) are made available for Flexible orders Cloud Cover Values are now shown as percentages:","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Jan/12/tasking/2021-01-12/","loc":"https://developers.planet.com/changelog/2021/Jan/12/tasking/2021-01-12/"},{"title":"January 15, 2021","text":"It is now possible to select specific satellites for Order Lock-In requests.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Jan/15/tasking/2021-01-15/","loc":"https://developers.planet.com/changelog/2021/Jan/15/tasking/2021-01-15/"},{"title":"January 18, 2021","text":"Show the schedule of monitoring orders on Order Detail View:","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Jan/18/tasking/2021-01-18/","loc":"https://developers.planet.com/changelog/2021/Jan/18/tasking/2021-01-18/"},{"title":"January 19, 2021","text":"Planet ArcGIS Add-In V2.0 Released Improved metadata display and customization in the Planet Imagery Search Panel New ability to save your search to preserve search filters from the Planet Imagery Search Panel More Search filters Clip imagery downloads to your AOI Improved Planet Basemap discovery interface and Basemap download tools Ability to determine contributing source scene to a Planet Basemap Ability to set an AOI for high-res tasking in ArcGIS And more! Planet QGIS Plugin V2.0 Released Improved metadata display and customization in the Planet Imagery Search Panel Ability to save your search to preserve search filters from the Planet Imagery Search Panel Additional search filters Improved Planet Basemap discovery interface and Basemap download tools Ability to determine contributing source scene in a Planet Basemap Ability to set an AOI for high-res tasking in QGIS And more!","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Jan/19/integrations/2021-01-19/","loc":"https://developers.planet.com/changelog/2021/Jan/19/integrations/2021-01-19/"},{"title":"January 25, 2021","text":"Tasking order summaries now show original geometries (i.e., Point, Polygon, or Linestring):","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Jan/25/tasking/2021-01-25/","loc":"https://developers.planet.com/changelog/2021/Jan/25/tasking/2021-01-25/"},{"title":"February 01, 2021","text":"Users are now warned before reloading an order entry screen, to avoid losing inputs.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Feb/01/tasking/2021-02-01/","loc":"https://developers.planet.com/changelog/2021/Feb/01/tasking/2021-02-01/"},{"title":"February 04, 2021","text":"Surface Reflectance (SR) assets will now be published for all SkySat images (including archive), except where MODIS imagery did not overlap the SkySat AOI on the same day as capture. The SR assets will be available for both SkySatScene and SkySatCollect item-types, as the new asset-type ‘analytic_sr'. However note SR assets will not be available in Explorer or the Command Line Interface until the end of February. A new SkySat asset, the ‘basic_l1a_all_frames' (aka All-Frames) is now available under the SkySatCollect item-type. This asset is published for all SkySat imagery dating back to October 2017. The All-frames asset includes all of the originally captured frames in a Collect, up to 50 frames per second, uncalibrated and in a raw digital number format. Delivered as a zip file containing all frames as basic L1A panchromatic DN imagery files, with accompanying RPC txt files, and a JSON pinhole camera model.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Feb/04/imagery/2021-02-04/","loc":"https://developers.planet.com/changelog/2021/Feb/04/imagery/2021-02-04/"},{"title":"February 05, 2021","text":"The \"Earth Engine Resource Writer\" IAM permissions are now beta supported in Google Cloud Projects. I.e., there is no longer a need to request these IAM roles from Google to enable your EE delivery from Planet today.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Feb/05/integrations/2021-02-05/","loc":"https://developers.planet.com/changelog/2021/Feb/05/integrations/2021-02-05/"},{"title":"February 05, 2021","text":"Strip orders are now enabled for Flexible, Monitoring and Order Lock-In Tasking Orders","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Feb/05/tasking/2021-02-05/","loc":"https://developers.planet.com/changelog/2021/Feb/05/tasking/2021-02-05/"},{"title":"February 18, 2021","text":"NEW: Enhanced order entry tools.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Feb/18/tasking/2021-02-18/","loc":"https://developers.planet.com/changelog/2021/Feb/18/tasking/2021-02-18/"},{"title":"February 24, 2021","text":"Collected captures are now sorted based on frequency.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Feb/24/tasking/2021-02-24/","loc":"https://developers.planet.com/changelog/2021/Feb/24/tasking/2021-02-24/"},{"title":"March 03, 2021","text":"The resolution limit over Israel has been updated from 2m to 0.4m, hence full resolution SkySat products may now be produced over Israel. This applies to both new captures and archive imagery.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Mar/03/imagery/2021-03-03/","loc":"https://developers.planet.com/changelog/2021/Mar/03/imagery/2021-03-03/"},{"title":"March 3, 2021","text":"404 page redesigned. When submitting an area order with such a geometry with both sides of it's minimal rotated bounding box less then 5km, a validation error will be thrown.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Mar/03/tasking/2021-03-03/","loc":"https://developers.planet.com/changelog/2021/Mar/03/tasking/2021-03-03/"},{"title":"March 04, 2021","text":"Added a loading text when fetching imaging windows.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Mar/04/tasking/2021-03-04/","loc":"https://developers.planet.com/changelog/2021/Mar/04/tasking/2021-03-04/"},{"title":"March 09, 2021","text":"Safari page re-designed. Preview endpoint will select order type from a default product (before it was always IMAGE).","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Mar/09/tasking/2021-03-09/","loc":"https://developers.planet.com/changelog/2021/Mar/09/tasking/2021-03-09/"},{"title":"March 11, 2021","text":"Show central point and middle-line on linestring and point geometries while moving them in the order entry map.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Mar/11/tasking/2021-03-11/","loc":"https://developers.planet.com/changelog/2021/Mar/11/tasking/2021-03-11/"},{"title":"March 15, 2021","text":"Show supported aoi in order entry. System assessment is removed.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Mar/15/tasking/2021-03-15/","loc":"https://developers.planet.com/changelog/2021/Mar/15/tasking/2021-03-15/"},{"title":"March 16, 2021","text":"Handle area geometries smaller than 25 km2 better, this means showing any errors coming from the backend, and allowing the user go back and change the geometry so it can be entered.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Mar/16/tasking/2021-03-16/","loc":"https://developers.planet.com/changelog/2021/Mar/16/tasking/2021-03-16/"},{"title":"March 22, 2021","text":"Use a maximum of 6 digits in coordinates precision since we have 0.65m ground sample distance anyways. https://xkcd.com/2170/","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Mar/22/tasking/2021-03-22/","loc":"https://developers.planet.com/changelog/2021/Mar/22/tasking/2021-03-22/"},{"title":"March 24, 2021","text":"We no longer support checking out with a credit card. You can still obtain a quote and get in touch with our Sales Team.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Mar/24/purchase/2021-03-24/","loc":"https://developers.planet.com/changelog/2021/Mar/24/purchase/2021-03-24/"},{"title":"March 24, 2021","text":"Enable GeoJSON of order AOI for copy/paste or download.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Mar/24/tasking/2021-03-24/","loc":"https://developers.planet.com/changelog/2021/Mar/24/tasking/2021-03-24/"},{"title":"March 25, 2021","text":"Update Order lock in reaction time from 12h to 6h.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Mar/25/tasking/2021-03-25/","loc":"https://developers.planet.com/changelog/2021/Mar/25/tasking/2021-03-25/"},{"title":"March 29, 2021","text":"Show better mapView error. Handle the case when BE returns a 400 with too many objects error. New message in order history when a successfully locked in order fails during image processing. Fix order entry crash when a polygon with an incorrect coordinates array is pasted into the GeoJSON input field.","tags":"chagelog","url":"https://developers.planet.com/chagelog/2021/Mar/29/tasking/2021-03-29/","loc":"https://developers.planet.com/chagelog/2021/Mar/29/tasking/2021-03-29/"},{"title":"April 01, 2021","text":"Validate geojson but without forcing right-hand rule.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Apr/01/tasking/2021-04-01/","loc":"https://developers.planet.com/changelog/2021/Apr/01/tasking/2021-04-01/"},{"title":"April 07, 2021","text":"Planet updated the way that it selects and composites SkySat \"anchor frames\" or Scenes. Hence now SkySatCollects which would have previously faulted or been truncated due to faulty anchor frame selection will now publish to their full extent, potentially allowing gaps in the imagery. Note, faulty imagery will publish to the archive, however will not qualify to fulfill revenue orders.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Apr/07/imagery/2021-04-07/","loc":"https://developers.planet.com/changelog/2021/Apr/07/imagery/2021-04-07/"},{"title":"April 08, 2021","text":"New ✨ Orders UI refresh, making it easier to order assets As you get used to the new look and feel, you can opt-out of this UI and revert back to the old UI via the Labs (see screenshot below) The new interface removes the dropdown options and now has explicit listing of the available assets grouped by rectification (rectified vs unrectified) You can select as many assets as desired, each selection will result in a separate order. Each order can be configured individually with respect to file format, clipping, and selected items. We will no longer modify the order name, the orders panel will give sufficient context as to what was ordered. The downloaded zip will follow the pattern of <order_name>_<item_type>_<bundleName>.zip Snapshot Lab - this feature is only available for customers. By turning on the Snapshot Lab you can download a JPEG image of your current Explorer screen with pre-embedded metadata. Improvements 🙌🏻 You can now filter for standard quality imagery (which excludes test imagery). If turned on , you will only see standard imagery If turned off , both standard & test imagery is included in the search results","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Apr/08/explorer/2021-04-08/","loc":"https://developers.planet.com/changelog/2021/Apr/08/explorer/2021-04-08/"},{"title":"April 12, 2021","text":"\"Best capture\" layer for customers and internal users. Add more captures filters. AOI upload from drive (supporting different formats)","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Apr/12/tasking/2021-04-12/","loc":"https://developers.planet.com/changelog/2021/Apr/12/tasking/2021-04-12/"},{"title":"April 15, 2021","text":"FE: Enable \"All\" as a default filter in Captures tab.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Apr/15/tasking/2021-04-15/","loc":"https://developers.planet.com/changelog/2021/Apr/15/tasking/2021-04-15/"},{"title":"April 19, 2021","text":"Update max line string length for stereo order to 20 km","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Apr/15/tasking/2021-04-19/","loc":"https://developers.planet.com/changelog/2021/Apr/15/tasking/2021-04-19/"},{"title":"April 26, 2021","text":"Support uploading shapefile with a different projection (.prj file) Imaging window selection design improvements","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Apr/26/tasking/2021-04-26/","loc":"https://developers.planet.com/changelog/2021/Apr/26/tasking/2021-04-26/"},{"title":"April 29, 2021","text":"Updating the url format - Instead of the old format: /orders/#/columns/name,status/criteria/status=CANCELLED,REJECTED&name=test/filterName/My%20Segment/ordering/name/ We now use: /orders/My%20Segment/?columns=name,status&ordering=name&status=CANCELLED,REJECTED&name=test","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Apr/29/tasking/2021-04-29/","loc":"https://developers.planet.com/changelog/2021/Apr/29/tasking/2021-04-29/"},{"title":"May 04, 2021","text":"Add Active tasks predefined segment - it will show all orders that are currently active (not in a final state)","tags":"changelog","url":"https://developers.planet.com/changelog/2021/May/04/tasking/2021-05-04/","loc":"https://developers.planet.com/changelog/2021/May/04/tasking/2021-05-04/"},{"title":"May 06, 2021","text":"Some filters now support to search for NOT - so that you can negate the query.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/May/06/tasking/2021-05-05/","loc":"https://developers.planet.com/changelog/2021/May/06/tasking/2021-05-05/"},{"title":"May 20, 2021","text":"New ✨ Planet is making changes to the trial, moving away from 14-day trial to a usage based trial. To learn more go to https://www.planet.com/get-started On July 1, 2021 we will stop supporting Internet Explorer. If you use this browser you will see a notification when you first load Explorer. Improvements 🙌🏻 New API Dialog when clicking the API {:} button. Same content, same ability to copy your API Key, cURL Request, and Selected Item Ids.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/May/20/explorer/2021-05-20/","loc":"https://developers.planet.com/changelog/2021/May/20/explorer/2021-05-20/"},{"title":"May 22, 2021","text":"Released a 2.0.1 patch for the Planet QGIS Plugin, which fixes the timestamp users were seeing in their imagery search results to make sure dates reflect the acquired date, not the published date.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/May/22/integrations/2021-05-22/","loc":"https://developers.planet.com/changelog/2021/May/22/integrations/2021-05-22/"},{"title":"May 24, 2021","text":"Bug Fixes 🐛 Fixed an issue where new users could not accept the Terms & Conditions. Fixed an issue where the application could crash when doing a new search and the previous one had not completed loading results.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/May/24/explorer/2021-05-24/","loc":"https://developers.planet.com/changelog/2021/May/24/explorer/2021-05-24/"},{"title":"June 03, 2021","text":"The AOI selected on order entry can be cleared with one click","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Jun/03/tasking/2021-06-03/","loc":"https://developers.planet.com/changelog/2021/Jun/03/tasking/2021-06-03/"},{"title":"June 04, 2021","text":"Customers can now bring their own service account to manage GEE scene delivery, offering users a dedicated ingest queue and independence from Planet's default delivery service account","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Jun/04/integrations/2021-06-04/","loc":"https://developers.planet.com/changelog/2021/Jun/04/integrations/2021-06-04/"},{"title":"June 10, 2021","text":"Enable SkySat Collects and Scenes when going to Explorer","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Jun/10/tasking/2021-06-10/","loc":"https://developers.planet.com/changelog/2021/Jun/10/tasking/2021-06-10/"},{"title":"June 17, 2021","text":"Extend order history messages with Express Orders rejection messages","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Jun/17/tasking/2021-06-17/","loc":"https://developers.planet.com/changelog/2021/Jun/17/tasking/2021-06-17/"},{"title":"June 23 2021","text":"Email preferences moved to the side drawer","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Jun/23/tasking/2021-06-23/","loc":"https://developers.planet.com/changelog/2021/Jun/23/tasking/2021-06-23/"},{"title":"July 01, 2021","text":"We are no longer supporting Internet Explorer 11. User's will see a notification to this effect if they load the app in that browser with directions to use another browser. Improvements 🙌🏻 It is now possible to enter your filters and date range before executing a search. We've also made it so that you don't lose those filters after clearing a drawn AOI. Bug Fixes 🐛 Fixed an issue where using the Enter Key to execute a search via the search bar did not work.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Jul/01/explorer/2021-07-01/","loc":"https://developers.planet.com/changelog/2021/Jul/01/explorer/2021-07-01/"},{"title":"July 05 2021","text":"Cloud forecast for assured order Cloud forecast in order detail view of assured order","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Jul/05/tasking/2021-07-05/","loc":"https://developers.planet.com/changelog/2021/Jul/05/tasking/2021-07-05/"},{"title":"July 08 2021","text":"New angle fields on order entry","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Jul/08/tasking/2021-07-08/","loc":"https://developers.planet.com/changelog/2021/Jul/08/tasking/2021-07-08/"},{"title":"July 12, 2021","text":"The 2.1 patch makes a number of quality improvements incl bug fixes and standardizing experiences between Planet's QGIS Plugin and Explorer apps, it also significantly revamps the download/order checkout process. In 2.1 Users can find: Full support for imagery assets across all Planet item types such as rectified and un-rectified assets Consistent download experience between Planet Explorer and the ArcGIS Add-In An improved imagery checkout process with clearer documentation for imagery assets Support for arbitrary geometry clipping and multi-polygon clipping","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Jul/12/integrations/2021-07-12/","loc":"https://developers.planet.com/changelog/2021/Jul/12/integrations/2021-07-12/"},{"title":"July 21 2021","text":"Validate filter input value according to api specs","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Jul/21/tasking/2021-07-21/","loc":"https://developers.planet.com/changelog/2021/Jul/21/tasking/2021-07-21/"},{"title":"July 28, 2021","text":"Update angle svgs simultaneously as value changes","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Jul/29/tasking/2021-07-28/","loc":"https://developers.planet.com/changelog/2021/Jul/29/tasking/2021-07-28/"},{"title":"August 12, 2021","text":"Check approximation and localization for all orders in order entry. Make it apparent that the length and area measurements in the Tasking Dashboard are only approximations.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Aug/12/tasking/2021-08-12/","loc":"https://developers.planet.com/changelog/2021/Aug/12/tasking/2021-08-12/"},{"title":"August 23, 2021","text":"Display length value next to the drawn line on the map","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Aug/23/tasking/2021-08-23/","loc":"https://developers.planet.com/changelog/2021/Aug/23/tasking/2021-08-23/"},{"title":"September 20, 2021","text":"Going forward, fast-publish asset provisioning (reference L1A in Planet's imagery spec) will be AOI based, in that only the scenes that overlap the customers' AOIs will be available for view and download by the customer. The final ortho assets will continue to be provisioned for the full overlapping SkySatCollect segment. Additionally, only the SkySatCollect segments that overlap the tasking customers' AOIs will be available for view and download by the customer. Hence, if a SkySat capture is broken up into multiple SkySatCollect segments, only those that overlap the customer's AOI will be provisioned to them.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Sep/20/imagery/2021-09-20/","loc":"https://developers.planet.com/changelog/2021/Sep/20/imagery/2021-09-20/"},{"title":"October 04, 2021","text":"New ✨ Account has a new look and new functionality. Simple visualizations so that you can see at a glance, how much quota has been used + how much is still available per plan. Ability to download reports that are generated daily to show the usage of the previous day. This includes all download plans, including Area Under Management. Organization Admins can: Easily view all of the organizations under their management, see their respective plans and understand the quota already used + still available. Download reports for all of the plans they manage. View all users within the organization(s) they manage. General Users can view how much quota has already been used + is still available, per plan. NICFI Users can now sign up for access to NICFI Basemaps in Google Earth Engine via \"My Settings\". If you had previously signed up, no action is required and you will see your access reflected in the application. Improvements 🙌🏻 We've been working hard at making things more consistent and have done some nomenclature updates. Namely \"Plan Subscriptions\" is now \"Plans\" Other Changes ⚙️ We've removed the \"Usage\" tab. You can now download reports by going directly to the Plan you'd like a report for.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Oct/04/account/2021-10-04/","loc":"https://developers.planet.com/changelog/2021/Oct/04/account/2021-10-04/"},{"title":"October 04, 2021","text":"The 2.1.1 patch addresses a number of quality improvements, including a time-stamp discrepancy issue impacting the image search results from the Planet inspector tool, compared to the timestamp on results returned by the image search panel. These time stamps are now consistent and accurate.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Oct/04/integrations/2021-10-04/","loc":"https://developers.planet.com/changelog/2021/Oct/04/integrations/2021-10-04/"},{"title":"October 28, 2021","text":"Improvements 🙌🏻 If you have access to bi-weekly basemap series they are now discoverable under the \"weekly\" cadence. If you have clipping permissions for ordering, the tool will now be enabled by default. You will now see how much tile quota you have used when looking at \"My Usage\" to make it consistent with our latest release of Account. The \"My Usage\" tab has been updated to show tile quota used, and is now consistent with what you see in your Account. SkySat imagery delivered to Hosted Data no longer look over saturated. Bug Fixes 🐛 Fixed an issue where the selected Spectral Index would not be persisted when switching between basemaps","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Oct/28/explorer/2021-10-28/","loc":"https://developers.planet.com/changelog/2021/Oct/28/explorer/2021-10-28/"},{"title":"November 18, 2021","text":"Quick and Saved Searches responses now includes a new \"assets\" object that lists all available assets for a particular item so developers no longer have to call the \"List Item Assets\" endpoint to list all assets for a specific item.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Nov/18/data-api/2021-11-18/","loc":"https://developers.planet.com/changelog/2021/Nov/18/data-api/2021-11-18/"},{"title":"November 18, 2021","text":"Improvements 🙌🏻 When searching for imagery, customers will now see only imagery they have access to, by default. If you would like to see Planet's entire catalog (including imagery you don't have access to), you can click the \"View Entire Catalog\" toggle in the search results and filters panel. Color enhancements are now faster and smoother. The auto-enhancement feature is now in the same panel as sliders to adjust for brightness, contrast, and saturation. These tools work for Basemaps and Hosted Data Scenes. Bug Fixes 🐛 Orders that are delivered to cloud storage cannot be downloaded via Explorer. We have removed the \"download\" button for orders that cannot be downloaded via Explorer.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Nov/18/explorer/2021-11-18/","loc":"https://developers.planet.com/changelog/2021/Nov/18/explorer/2021-11-18/"},{"title":"November 22, 2021","text":"AUM customers can now order archive imagery with the Subscriptions API. With the backfill subscriptions capability, you can now create a subscription with a start time (and end time) in the past. More details on Backfill subscriptions are available here: https://developers.planet.com/docs/subscriptions/#forwardfill-and-backfill-subscriptions","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Nov/22/subscriptions-api/2021-11-22/","loc":"https://developers.planet.com/changelog/2021/Nov/22/subscriptions-api/2021-11-22/"},{"title":"December 10, 2021","text":"New ✨ You can now use the Color Enhancement tool with SkySat images delivered to your Hosted Data folders.","tags":"changelog","url":"https://developers.planet.com/changelog/2021/Dec/10/explorer/2021-12-10/","loc":"https://developers.planet.com/changelog/2021/Dec/10/explorer/2021-12-10/"},{"title":"January 7, 2022","text":"Bug Fix 🐛 In a few cases, selecting some interactive elements stalled content refreshing. Now, selecting an interactive element does not prevent content from loading.","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Jan/07/tasking/2022-01-07/","loc":"https://developers.planet.com/changelog/2022/Jan/07/tasking/2022-01-07/"},{"title":"February 10, 2022","text":"New ✨ We have introduced the Band Math tool to the Subscriptions API! Customers are now able to configure up to 15 band calculations in their subscriptions to have all original bands, and additional calculations in their delivered asset. Read about the Subscriptions Band Math tool.","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Feb/10/subscriptions-api/2022-02-10/","loc":"https://developers.planet.com/changelog/2022/Feb/10/subscriptions-api/2022-02-10/"},{"title":"February 10, 2022","text":"Improvements 🙌🏻 Off-nadir angle is now the default display convention, with the ability to toggle to satellite elevation. Angle display conventions in the Tasking dashboard caused some confusion for users. In the imaging window selection dialog, the off-nadir angle is now displayed by default. Users can toggle to view the satellite elevation.","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Feb/10/tasking/2022-02-10/","loc":"https://developers.planet.com/changelog/2022/Feb/10/tasking/2022-02-10/"},{"title":"February 24, 2022","text":"New ✨ We have introduced the TOAR and File Format tools to the Subscriptions API! The Subscriptions API now includes TOAR and File Format tools. Read more about these new tools in the Subscriptions Tools.","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Feb/24/subscriptions-api/2022-02-24/","loc":"https://developers.planet.com/changelog/2022/Feb/24/subscriptions-api/2022-02-24/"},{"title":"February 28, 2022","text":"New ✨ New raster processing tool in Subscriptions API: Harmonize We have introduced the Harmonization tool to the Subscriptions API! Read more about this new Subscriptions Tool.","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Feb/28/subscriptions-api/2022-02-28/","loc":"https://developers.planet.com/changelog/2022/Feb/28/subscriptions-api/2022-02-28/"},{"title":"Hello, World!","text":"Who are we? We're Developer Relations at Planet: a team of curious geo-people, passionate space nerds, Pythonistas, educators and more (most of us wear multiple hats at once, too). We believe in using space to help life on earth, and the way we do that best is by empowering a global community of technical users (that's you!) to do amazing things with Planet's platform and data. Who are you? You'll notice that I said technical users above. We know that for many of you, the word \"developer\" doesn't necessarily capture all that you do. Many of you are Data Scientists or Analysts first. Others might be most comfortable labeling themselves as Remote Sensing or GIS professionals. And some of you may be developers exploring the potential of satellite imagery for the first time. We know, because the same can be said for our team and Planet as a whole. Planeteers come from a variety of backgrounds, each with a unique collection of skills and talents, as do you. The common thread here—and what we mean when we say \"developer\"—is using Planet's platform and data as a means to a greater end. So whether you use Planet APIs , a Command Line Interface , GIS Integration or all of the above: you belong here. Hackers at Planet Hack Coming Soon We've got an exciting collection of new content and resources heading your way over the next few months, including: An all-new Python SDK & CLI! A developer-first toolkit ready to integrate into your platform & workflows. NEW geo-friendly processes & examples! More Cloud-Native Geospatial tools! Native STAC support in Planet APIs, COG streaming, GIS integration support, and more. Get in touch! To get updates from the Planet Dev Rel team in the future, follow our blog feed . To reach out to the team directly, send us an email via developers@planet.com .","tags":"blog","url":"https://developers.planet.com/blog/2022/Apr/11/hello-world/","loc":"https://developers.planet.com/blog/2022/Apr/11/hello-world/"},{"title":"On this Earth Day: Join NICFI Satellite Data Program and Access Planet HiRes Tropical Data","text":"Half a century ago, the first Earth Day started an environmental revolution. Since then, many strategies, movements, and actions have been taken to create a more sustainable future. This year, 2022, Earth Day is focused on the engagement of \"more than 1 billion people, governments, institutions, and businesses to recognize our collective responsibility and to help accelerate the transition to an equitable, prosperous green economy for all.\" Tropical forests are a critical element in the balance of the global systems. Its loss is not only a major cause of climate change and mass extinction, but also of rising social inequality and instability. In September 2020, the NICFI Satellite Data Program, envisioned by Norway's International Climate and Forest Initiative (NICFI) started providing free access to satellite images of the tropics to anyone, anywhere. The program was implemented by Kongsberg Satellite Services (KSAT), Airbus, and Planet. The Program makes high-resolution (<5m per pixel) optical satellite data of the tropics available to all, for the purpose of helping stop deforestation and combat climate change. This includes PlanetScope Visual Mosaics and PlanetScope Surface Reflectance Mosaics from 2015 onwards. To celebrate this year's Earth Day theme, \"everyone accounted for, and everyone accountable,\" we would like to invite you to join the NICFI Satellite Data Program, and to gain access to high-resolution satellite images of the tropics and to take action: reduce and reverse the loss of tropical forests combat climate change conserve biodiversity contribute to forest regrowth, restoration and enhancement facilitate sustainable development Dive into the NICFI Satellite Data Program resources The NICFI Satellite Data Program is making available satellite data over the tropics going back to 2015. There are more than ten thousand registered users, representing more than 145 countries, that have collectively streamed or downloaded more than 30 millions of images. You can become part of this user community by signing up with NICFI Satellite Data Program at Planet . After signing up, you can discover, preview, stream, and download Planet imagery data in the following interfaces: Planet APIs for direct access for searching, downloading and streaming web tiles QGIS or ArcGIS plugins to search and download data into desktop GIS tools Google Earth Engine integration to access Planet data directly in the GEE environment Geospatial data libraries like GDAL Planet Explorer for visualizing data online with Planet's web app User ecosystem Because satellite images can be used in many different ways and workflows, the NICFI Satellite Data Program serves a vast diversity of individual and organization users with varying degrees of technical expertise. Purpose Allies NICFI's Purpose Allies are key to help amplify the reach and impact of the program by developing tools, promoting knowledge transfer and capacity building in response to specific user group needs. Despite sharing common goals, each Purpose Ally has a different target audience and technical approach, making up an interesting collection of geospatial platforms and tools: Global Forest Watch, Mapbiomas, Sentinel Hub, and UN-FAO's SEPAL & Collect Earth. Global Forest Watch Global Forest Watch (GFW) \"is an online platform that provides data and tools for monitoring forests. By harnessing cutting-edge technology, GFW allows anyone to access near real-time information about where and how forests are changing around the world.\" Through GFW, the Planet-NICFI basemaps have been visited more than 170 thousand times since the beginning of the program. MapBuilder allows users to \"combine their own datasets with GFW's cutting-edge data and analysis tools\" in ArcGIS Online. The source code for GFW is on GitHub, available under a MIT License . Planet-NICFI basemap in GFW showing natural color contextualization of integrated deforestation alerts in Mainland Southeast Asia Mapbiomas MapBiomas is a network of land use and biomes experts, remote science specialists and computer scientists dedicated to map and monitor all land cover and land use changes happening in Brazil, Indonesia and throughout South America. Besides integrating the Planet-NICFI basemaps into their land cover and land use platform they develop a series of scripts , tools and plugins dedicated to land cover land use maps based on multiple geospatial data and technologies. Mapbiomas displaying Brazil land use/land cover data overlaid on NICFI Tropical basemap Sentinel Hub Sentinel Hub is a cloud-based API that makes Earth Observation imagery seamlessly accessible for browsing, visualization and analysis, directly in one's existing application or machine learning workflow. In addition to providing tech and extensive documentation , Sentinel Hub offers open source code and regularly organizes competitions for its developer community. Planet-NICFI imagery data processing within Sentinel Hub's EO Browser for the identification of areas with change of vegetation over time UN-FAO UN-FAO, \"in collaboration with over 70 countries and partners, has developed a suite of [open source] innovative forest and land monitoring tools, conceived to meet the urgent need for (national and local) systems that enable accurate yet cost-effective measurement, monitoring, and reporting of forest and other land cover.\" SEPAL and Collect Earth , two of the Open Foris tools, now integrate Planet-NICFI data that can be used by \"over 9,000 users from 185 countries\" to monitor and report on their ecosystems, namely for the UNFCCC. SEPAL interface with NICFI-Planet basemaps Platform Partners The NICFI Satellite Data Program has been proactively working to establish collaboration to further increase its reach, as well as to elevate its users' resources and efforts. Acknowledging that there is no unique solution to our planet's problems, the Program tries to engage and adjust to the strategies that different sectors of activity may adopt in their efforts to tackle deforestation, biodiversity loss, and the climate crisis. Google Earth Engine (GEE) supports geospatial processing at scale, powered by the Google Cloud Platform. In GEE you can find \"petabyte-scale catalog of public and free-to-use geospatial datasets\" including, since September 2021, the Planet NICFI Basemaps for Tropical Forest Monitoring . Moving data to GEE was enthusiastically received by the NICFI community of users, who are experimenting with time series algorithms like LandTrendr and deep learning with TensorFlow . Of about 11,000 registered NICFI registered users, currently more than 1,300 are using Google Earth Engine to analyze the Planet-NICFI Basemaps and benefiting from the speed and scale of hosted cloud computing. Any given day, there are between 400 and 600 active analyses of the high-resolution tropical monitoring data being run on the platform. The GEO-Microsoft Planetary Computer partnership is supporting selected projects using the NICFI Satellite Data and the Planetary Computer to address environmental challenges. Microsoft's Planetary Computer \"combines a multi-petabyte catalog of global environmental data with intuitive APIs.\" And because communication is crucial to NICFI imagery users, the NICFI Satellite Data Program paired up with Mapbox to create a series of templates and step-by-step instructions for making custom web maps for displaying and comparing NICFI imagery, using Mapbox GL JS. Mapbox GL JS template for swipe interaction to display two sets of Planet-NICFI imagery side-by-side for easy comparison Here's the code snippet from the Mapbox NICFI Compare tutorial : // YOUR TURN: Set the center coordinates and zoom level for the 'before' map on the left const beforeMap = new mapboxgl.Map({ container: \"before\", style: \"mapbox://styles/mapbox/satellite-streets-v11\", center: [2, -2], zoom: 2, hash: true }); // YOUR TURN: Set the center coordinates and zoom level for the 'after' map on the right const afterMap = new mapboxgl.Map({ container: \"after\", style: \"mapbox://styles/mapbox/satellite-streets-v11\", center: [2, -2], zoom: 2, hash: true }); // YOUR TURN: Add your Planet NICFI API key const NICFI_API_KEY = \"{YOUR_NICFI_API_KEY}\"; Developer community In the first year of the Program, the majority of the outreach activities, and training, were designed and directed at professionals working in the forestry, land use change and, generally speaking, earth observation industries. NICFI Satellite Data Program was the topic of a FOSS4G Session and Hackathon in October 2021, and featured in Geo for Good in November of the same year. Your path to exploring NICFI data With the most recent IPCC Report that concludes that we have less than a decade to reverse course on global emissions, this is the time to invest in our planet. This means our business, politics, and daily action all count. We have already achieved a lot , but we need better solutions, new approaches, and collaboration because we believe \"Everyone accounted for, and everyone accountable.\" And once again, to celebrate Earth Day 2022, we would like to propose your developer path to NICFI Satellite Data exploration on this Earth Day 2022: Sign up Get a Planet API key Download the tropical basemaps or quads to view NICFI mosaics Read through the NICFI User Guide , especially the NICFI Basemaps addendum Use the Planet Basemaps API to visualize imagery over time Check out other interfaces, such as the Google Earth Engine NICFI integration Reach out to nicfi-servicedesk@ksat.no if you have a question or need support regarding the NICFI Satellite Data Program. Next steps Learn more Sign up with Planet Planet NICFI products and services Get in touch with Planet Developer Relations To get updates from the Planet Dev Rel team in the future, follow our blog feed . To reach out to the Developer Relations team directly, send us an email via developers@planet.com .","tags":"blog","url":"https://developers.planet.com/blog/2022/Apr/21/on-this-earth-day-join-nicfi-satellite-data-program-and-access-planet-hires-tropical-data/","loc":"https://developers.planet.com/blog/2022/Apr/21/on-this-earth-day-join-nicfi-satellite-data-program-and-access-planet-hires-tropical-data/"},{"title":"April 25, 2022","text":"Improvements 🙌🏻 In the Table View for Order Progress, the flyout menu for the order details is now resizable.","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Apr/25/tasking/2022-04-25/","loc":"https://developers.planet.com/changelog/2022/Apr/25/tasking/2022-04-25/"},{"title":"April 26, 2022","text":"New ✨ We have a new way for you to share your Explorer session with others. The days of long URLs are over! You will notice that we no longer update the URL as you take different actions in the application or as data loads. We have added a way to generate a share link via a new \"Share Session\" button (see screenshot), this link contains the same information as our \"old\" long URLs but in a more compact form. Improvements 🙌🏻 Measurement tools now use geodesic calculations to better measure areas near the equator.","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Apr/26/explorer/2022-04-26/","loc":"https://developers.planet.com/changelog/2022/Apr/26/explorer/2022-04-26/"},{"title":"April 26, 2022","text":"Tasking Dashboard Updates New ✨ New shortcuts are available in the capture modal view. In addition to the arrow keys, you can select the B key (for before) and the N key (for next) to move between images. Improvements 🙌🏻 The order detail view now has a back button that links to home. Bug Fixes 🐛 More precise active orders count warning On rare occasions, the Dashboard did not warn if the maximum amount of allowed orders had been reached before the user opened a new order. Now, the warning correctly accounts for the current contract maximum.","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Apr/26/tasking/2022-04-26/","loc":"https://developers.planet.com/changelog/2022/Apr/26/tasking/2022-04-26/"},{"title":"Subscriptions API for Daily Agriculture Monitoring","text":"The Subscriptions API At Planet, our satellites capture near-daily imagery of Earth's entire landmass. You can use this data to build monitoring solutions for everything from directed field scouting to field performance monitoring to precision applications and more. The historical archive data that Planet has collected can be used to gather historical context, train models, and perform time-series analysis. For these persistent, always-on monitoring solutions, we provide the Subscriptions API to make it easier for you to integrate Planet data into your solutions. With a single API call, the Subscriptions API allows you to subscribe to a continuous delivery of imagery to the cloud of your choice. You can set it up so you only receive data you're interested in by making use of filters for your area of interest (AOI), time of interest (TOI), and more. As new imagery is added to our catalog, the Subscriptions API automatically checks to see if it meets your criteria. If it does, imagery is sent directly to your cloud storage destination. This significantly reduces the complexity of building a monitoring solution. You don't need to build your own infrastructure or application for polling an API to search for newly available data. Let's take, for example, a solution for monitoring the health and performance of an agricultural field. Below is a sample API request over our field AOI for the 2018-2022 growing seasons: POST https://api.planet.com/subscriptions/v1/ { \"name\": \"Agriculture Field 12345\", \"source\": { \"type\": \"catalog\", \"parameters\": { \"geometry\": { \"coordinates\": [[[-115.43197,32.924028], [-115.42354,32.923947], [-115.423616,32.93051], [-115.431959,32.930542], [-115.43197,32.924028]]], \"type\": \"Polygon\" }, \"start_time\": \"2018-03-01T00:00:00Z\", \"end_time\": \"2022-11-01T00:00:00Z\", \"rrule\": \"FREQ=MONTHLY;BYMONTH=3,4,5,6,7,8,9,10\", \"item_types\": [\"PSScene\"], \"asset_types\": [\"ortho_analytic_8b\"] } }, \"delivery\": { ... } } Create subscription API example request (left); map of agriculture field AOI (right) For the above order, the TOI spans from our start date, March 1, 2018, until our end date, November 1, 2022. If you are not interested in monitoring during off-season months, you can use Recurrence Rules (rrule) to filter for data from certain months. In the above example, we set a rule to send data only during the months between March (3) and October (10). This reduces the volume of data by not sending off-season data to your cloud. The TOI is set to include data from previous growing seasons to use as a baseline for analysis of this growing season. For example, you could use the historical data to identify areas of persistent under-performance within a field. Or, you can use this data for time series analysis, identifying dates when events like tilling, planting, or harvesting occurred. As part of Planet's Area Under Management (AUM) offering, you have access to Planet's archive for the areas that you choose to monitor at no additional cost. Time series analysis of average CIRE value in the field for the 2021 growing season; high values indicate significant vegetation and low values indicate recent harvesting When you place an order for a timeframe which includes dates that have already passed, the order is \"backfilled.\" In other words, historical imagery from Planet's archive for your TOI is sent to your cloud storage at the time of order. If your TOI extends into the future, imagery is delivered to your cloud storage as it is added to Planet's catalog in what we call \"forward fill.\" Raster processing with Subscriptions API tools Remote sensing data requires a significant amount of processing to be turned into a usable form. Planet handles much of the preprocessing, including radiometric calibration, orthorectification, and more. To further help with preprocessing, the Subscriptions API supports a collection of tools that can prepare your data prior to cloud delivery. Below is a list of currently supported tools: Tool Description Harmonize Harmonize PlanetScope imagery with Sentinel-2. Top of Atmosphere Reflectance (TOAR) Convert Analytic assets from radiance to reflectance. Clip Clips imagery assets to your area of interest. Reproject Reproject, resample, and rescale imagery products to a new projected coordinate system and resolution. Band Math Apply mathematical expressions using the spectral bands of Planet imagery to produce outputs and indices. These tools help to leverage PlanetScope data for visualization and analysis. For example, in agricultural field monitoring applications, the Clip tool is critical for reducing the size of the data because the area of a field is likely much smaller than the area of a PlanetScope scene. The Clip tool clips the rasters that are delivered to the extent of your AOI, as defined in your parameters when you create a Subscription. By clipping the data, you can reduce your cloud storage costs, analyze data faster, and visualize data in mapping applications more efficiently and effectively. The Harmonize tool adjusts the Surface Reflectance measurements from PlanetScope instruments to align them with Sentinel-2. The tool is helpful when performing analysis across multiple PlanetScope sensor types from archive data because it minimizes scene-to-scene and sensor-to-sensor variability. This tool is especially useful when working with Dove Classic data as newer Doves, including SuperDoves, are already closely aligned with Sentinel-2. However, this tool has caveats and should be tested in your area of interest as it may not work as well in areas of rapid change (agricultural fields) or when scenes include bodies of water. For more information, please read: Scene Level Normalization and Harmonization of Planet Dove Imagery . Another very useful tool for agriculture is Band Math . PlanetScope imagery captured by the SuperDove fleet includes 8 spectral bands which can be used for true color and false color visualizations. The Band Math tool in the Subscriptions API enables you to perform calculations using the different spectral bands and store the resulting values in a new raster. These 8 spectral bands can also be used to create indices such as: Acronym Index Name Formula NDVI Normalized Difference Vegetation Index ( NIR - R ) / ( NIR + R ) NDRE Normalized Difference Red Edge ( NIR - RedEdge ) / ( NIR + RedEdge ) CIRE Chlorophyll Index Red Edge ( ( NIR / RedEdge ) - 1 ) MSAVI2 Modified Soil-adjusted Vegetation Index 2 ( 2 * NIR + 1 - sqrt ( ( 2 * NIR + 1 ) &#94; 2 - 8 * ( NIR - RED ) ) ) / 2 EVI Enhanced Vegetation Index 2.5 * ( NIR - RED ) / ( NIR + 6 * R - 7.5 * B + 1 ) Band Math creates an additional imagery output file which supports up to 15 bands with different calculations. Computation for calculating indices is completed before the imagery arrives in your cloud storage, reducing the time and steps you need to take to build your final solution. Several images of this field with different indices Cloud Delivery & Format Now that we have created a Subscription for our AOI & TOI, and we have defined our processing tools, we are ready to deliver the data. When you create a Subscription you need to define your cloud storage destination from one of the supported delivery options . Using the File Format tool, you can also specify the file format for the rasters that are delivered as Cloud Optimized GeoTiffs (COGs). COGs are a Cloud Native Geospatial data format which is an efficient file format for on-the-fly processing and geospatial visualization. They enable any tool or client to request portions of the file based on the area of interest. By utilizing the Subscriptions API, you are able to set up a regular delivery of satellite imagery to your cloud storage on a near-daily basis. The imagery can be filtered to fit your criteria and processed to your specifications prior to delivery. The Subscriptions API can reduce the cost and effort needed to prepare your data to be ready for visualization and analysis, ultimately reducing the time it takes for data to reach its end-users for decision making. Workflow diagram for steps from creating a subscription to visualizing data Next steps… The Subscriptions API can be a powerful tool for use-cases where you need historical data and/or ongoing monitoring, making it highly valuable for agriculture monitoring. You can find documentation for the Subscriptions API in the Developer Center and sample notebooks for using the Subscriptions API in our GitHub repo . Also subscribe to our Developer Newsletter and get more information like this!","tags":"blog","url":"https://developers.planet.com/blog/2022/May/12/subscriptions-api-for-daily-agriculture-monitoring/","loc":"https://developers.planet.com/blog/2022/May/12/subscriptions-api-for-daily-agriculture-monitoring/"},{"title":"May 25, 2022","text":"Improvements 🙌🏻 Imagery Type labels now include a more accurate range in their labels: Medium Resolution from 2m-10m to 3m-7m High Resolution from <2m to <1m Bug Fixes 🐛 Fixed an issue where some customers experienced a \"blank map\" when they didn't have any supported basemaps provisioned.","tags":"changelog","url":"https://developers.planet.com/changelog/2022/May/25/explorer/2022-05-25/","loc":"https://developers.planet.com/changelog/2022/May/25/explorer/2022-05-25/"},{"title":"Planet and Cloud-Native Geospatial","text":"After Sara's announcement of our new blog , I have the honor of writing the second substantive post on this blog. I've been at Planet for a long time and have always felt developers are our most important users. So I'm pleased to share that just recently I shifted my role to become the Product Manager of the Developer Relations team that Sara leads. Most exciting for me is that we've expanded the scope of the team to include what we call \"Open Initiatives,\" one of which is \" Cloud-Native Geospatial ,\" encompassing all the work I've been doing on things like SpatioTemporal Asset Catalogs (STAC) and Cloud-Optimized GeoTIFFs (COG) , plus new topics like GeoParquet . A lot of my time recently went into organizing the Cloud-Native Geospatial Outreach Event that happened last month. Planet was a top sponsor, and a number of Planeteers gave talks. It's super cool to watch the videos of the talks and to see how the community just continues to explode. With over 1600 registrations, I think we'll see another jump in momentum after the event. I wanted to share a bit about Planet's pioneering role in Cloud-Native Geospatial, as well as what we're working on next and why we're excited about this great ecosystem. Planet and the genesis of Cloud-Native Geospatial Planet was lucky to be among the first \"cloud-native\" satellite imagery providers (perhaps even the first). It was really a matter of timing, as Planet was founded right when any sensible Silicon Valley startup trying to achieve scale moved to the cloud. At that time, a standard image processing pipeline would involve image processing experts using desktop software to produce the imagery for customers. But Planet had huge aspirations of scale, with the mission to \"image the whole earth every day\" at the center of what everyone did. The amount of data coming in from Planet's planned constellation meant that everything needed to be automated. So Planet just built its data pipeline and data hosting platform out right, and became a big supporter of the \"cloud-native geospatial\" movement before it even had a name. The movement clearly started with the advent of the Cloud-Optimized GeoTIFF , which Planet played a key role in creating. The idea behind COG was discussed and built out in the AWS Landsat Public Dataset project, with Planet as a key contributor. Then it came together as a standard in a meeting I remember at Planet headquarters. We had a whiteboard session with Frank Warmerdam of GDAL fame, Matt Hancher who co-founded Google Earth Engine, and Rob Emanuele who led RasterFoundry at Azavea and now leads engineering on Microsoft Planetary Computer. We wanted a format that Planet could produce and that would be streamable into these two new cloud-native geospatial compute engines. And one that is ideally backwards compatible with a standard GeoTIFF, so it would still work for local workflows. Planet then funded Even Rouault to create the original specification and document the GDAL drivers. Planet also worked on the evolution of SpatioTemporal Asset Catalogs (STAC), which started when Radiant Earth convened a diverse group of geospatial experts and organizations in Boulder, CO to collaborate on the interoperability of data catalogs . I recently posted on the history of Planet's support of STAC . Planet's role in STAC is one of the things I'm most proud of, and it's fun to see it integrating into Planet's API's. Why we support Cloud-Native Geospatial Planet supports cloud-native geospatial because our imagery must be much more accessible to have the impact we aspire for. I'd like to explain a bit more as to why we support this ecosystem. There are two critical economic shifts transforming the world: The Digital Transformation, where organizations are using Big Data and Artificial Intelligence to understand what they do and to do it more efficiently The Sustainability Transformation, where data about our planet is key to valuing natural systems in the economy Geospatial Information is useful for many organizations found in either or both of these movements. But the benefit will not be realized if everyone must become experts in remote sensing and GIS. It is incumbent upon us to make information about the earth accessible and integrated into the workflows people use everyday. And the biggest challenges always need more data sources, combined in insightful ways. Planet's APIs and data formats need to be in the formats, tools, and channels used to create solutions that make a difference. Cloud-native geospatial has the potential to make geospatial data far more accessible within existing workflows and architectures. By doing so, users don't need to be experts in remote sensing and GIS. They just need to understand how to work with data. Making Planet's data more accessible to developers Planet is working hard to ensure the developer experience is as solid as possible. The headline news of 8-band data availability is certainly cool, but what I've personally found especially impressive is how the team has greatly improved the quality of the imagery and reduced the complexity to access it. Improvements in our data pipeline include better alignment between pixels, a reduction in the number of artifacts, and a sharpening of the visual quality. And the new PSScene product simplifies and future-proofs how users and developers access imagery. Not quite as new, but seeing substantial adoption, is the Subscriptions API , which greatly simplifies the development time to integrate any monitoring workflow with Planet. Another great feature is the new harmonization tool , one of the key operations for Planet's delivery tools in providing full Analysis Ready Data in an On-Demand workflow. Together these improvements are a huge step towards data that \"just works,\" enabling developers to order a atmospherically-corrected, pixel- and sensor-aligned stack of imagery for time series analysis without having to even think about all the complexities of remote sensing. The next frontier in making Planet even more accessible to developers is the higher level data products that directly extract insights from satellite imagery. For example, Planet offers our Road and Building Change Analytics and what we call \" Planetary Variables\" , including Soil Water Content, Land Surface Temperature, and a proxy for Vegetation Biomass. These Planetary Variables go beyond just Planet's imagery, fusing several different data sources, and will open up new use cases. Planet moving further up the stack, and into the \"vector\" area of geospatial, means much more access for new developers. And there are some interesting interoperability opportunities that we hope to contribute to. What's next for Planet and Cloud-Native Geospatial? Planet data generates far more insight when it can be combined with other data. So we believe in helping create an ecosystem of tools and data that have interoperability at their core. One route is supporting tools like GDAL and Rasterio , which translate between any format. Another route is work toward the interoperability of the next generation of workflows, as COG and STAC do. Building our team Planet has recently been increasing its resources working on developer relations and cloud-native geospatial, including bringing on folks to work full-time on \"open initiatives.\" Sean Gillies joined the developer relations team a few months ago. Planet is supporting his time on Rasterio , Shapely , and Fiona —some of the most important geospatial tools in the Python ecosystem. The other project he's helping out on is a new version of Planet's Python client and command-line library , which you'll hear about soon on this blog. Tim Schaub is one of the best developers I've worked with. You may know him as a leader of the open source OpenLayers JavaScript toolkit that Planet uses extensively. Tim has been going deep on Go, helping build Planet's multi-source ARD product called \"Fusion Monitoring.\" The developers relations team has also had a number of other great new hires, who you'll hear from on this blog. COG and STAC In order for cloud-native geospatial to reach its full potential, COG and STAC will have to \" cross the chasm \" to mainstream adoption. To do so, we want to help everyone get a sense of just how much data there is in STAC and COG. If we can't measure how much data is available in these new formats then we won't be able to actually track progress and determine which of the various initiatives are working. To start, we're focused on a crawler pointed at STAC Catalogs that reports back stats on the number of STAC Items, STAC Extensions used, and what format (COG, JP2K, Zarr, etc.) the assets are stored in. This, in turn, will help inform a new STAC extension making reporting easier, so we're not having to hand crawl tens of millions of STAC records. We hope to report on the overall STAC and COG data holdings that anyone can access. We'll work to integrate with STACIndex.org , which is where this idea originally came from. To support this, Tim has revived the Planet go-stac open source library, getting it up to speed with STAC 1.0.0, and improving its crawling and validation capabilities. It's now capable of very fast recursive crawling, with more improvements coming soon. We are also starting to use the library internally to build and deploy Planet's STAC Catalog of open data . Cloud-Native Vector Another area where we'll be focused is the standards that can make our higher-level \"Planetary Variables\" data more interoperable. The goal is to have these available in \"vector\" data formats—the points, lines, and polygons that can be represented as rows in a database. Indeed, one end goal would be delivering daily information as simple tabular values against known geometries. This would mean a user already has the geometry of a state, county or even a field and they'd just get a daily update—say, of the plant biomass or soil moisture reading for the day. Cloud data warehouses like BigQuery, Snowflake, and Redshift are driving a revolution in how organizations handle all of their data, and all have native geospatial support. So there is an opportunity to fit Planet's daily variables about our earth directly into the workflows being used today. This has led us to helping seed efforts like GeoParquet . Javier de la Torre, from Carto, wrote a great overview introducing GeoParquet . Planet is working to build the community and the specification, and we funded the development of the GDAL/OGR reader that is included in GDAL 3.5.0 . An interoperable format would enable us to publish data once and stream to a variety of cloud tools. Next step: Join us We've gotten this far by collaborating with others, and I think the opportunity to make geospatial more accessible is limitless. We hope others will join us in open collaboration. If you'd like to continue to get updates on what we're up to in cloud-native geospatial, as well as all kinds of content about our API's, tools, and the geo technical developer community in general, please follow our blog . And do check out our contributions to the Cloud-Native Geospatial Outreach Event, see the playlist on youtube for all the content. Forward-looking Statements Except for the historical information contained herein, the matters set forth in this blog are forward-looking statements within the meaning of the \"safe harbor\" provisions of the Private Securities Litigation Reform Act of 1995, including, but not limited to, the Company's ability to capture market opportunity and realize any of the potential benefits from current or future product enhancements, new products, or strategic partnerships and customer collaborations. Forward-looking statements are based on the Company's management's beliefs, as well as assumptions made by, and information currently available to them. Because such statements are based on expectations as to future events and results and are not statements of fact, actual results may differ materially from those projected. Factors which may cause actual results to differ materially from current expectations include, but are not limited to the risk factors and other disclosures about the Company and its business included in the Company's periodic reports, proxy statements, and other disclosure materials filed from time to time with the Securities and Exchange Commission (SEC) which are available online at www.sec.gov , and on the Company's website at www.planet.com . All forward-looking statements reflect the Company's beliefs and assumptions only as of the date such statements are made. The Company undertakes no obligation to update forward-looking statements to reflect future events or circumstances.","tags":"blog","url":"https://developers.planet.com/blog/2022/May/26/planet-and-cloud-native-geospatial/","loc":"https://developers.planet.com/blog/2022/May/26/planet-and-cloud-native-geospatial/"},{"title":"June 09, 2022","text":"Bug Fixes 🐛 Harmonize API conforms to OpenAPI Specification On rare occasions, users generating clients based on the OpenAPI specification may have found that OpenAPI Operation IDs were not consistently following conventional constructions of VerbNoun or were pluralized when they should be singular. We have updated the Harmonize API to conform to the OpenAPI specification convention of VerbNoun and singular IDs.","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Jun/09/data-api/2022-06-09/","loc":"https://developers.planet.com/changelog/2022/Jun/09/data-api/2022-06-09/"},{"title":"July 7, 2022","text":"Bug Fixes 🐛 When attempting to edit date ranges, you may have been unable to select the most recent date. We've fixed issues in our date picker so the most recent date available can now be selected. We've also reverted the default date range from one week back to three months.","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Jul/07/explorer/2022-07-07/","loc":"https://developers.planet.com/changelog/2022/Jul/07/explorer/2022-07-07/"},{"title":"Eroding Coastlines: A GeoSpatial and Computer Vision Analysis","text":"According to their website, the annual SciPy Conference \"brings together attendees from industry, academia, and government to showcase their latest projects, learn from skilled users and developers, and collaborate on code development.\" Participants of Mansi and Kevin's workshop gained hands-on experience exploring some of Planet's publicly-available satellite imagery using Python tools such as rasterio, numpy, matplotlib, scipy, and openCV, to analyze medium- and high-resolution imagery data. During the second half of the workshop, participants applied what they learned to identify and analyze instances of coastal erosion, one of the most pressing environmental and humanitarian challenges facing our planet today. The tutorial involved a combination of slides and hands-on, live coding with real-world publicly-available data in Jupyter notebooks – no previous experience with geospatial or computer vision Python libraries necessary. Coastal Erosion – Why It Matters Coastal erosion is defined as the loss or displacement of land on coastlines due to waves, currents, tide, wind, waterborne ice, storm impact, and other natural and unnatural forces. While the natural weathering of coastlines is normal, human-led activities such as coastal mining, infrastructure development, and construction can accentuate the issue. Let's also not forget rising sea levels are a result of climate change. The IPCC states with high confidence that the Global Mean Sea Level (GMSL) has risen 3.6mm each year, on average, from 2006-2015. Risk related to sea level rise, including erosion along all low-lying coasts, is expected to significantly increase by the end of this century without major additional adaptation efforts. Long-term impacts of coastal erosion include loss of habitat quality, degradation of coral reefs, increased turbidity of water, reduced tolerance for communities in the face of natural disasters, and reduced sand volume. These environmental impacts are in addition to the millions of dollars lost and spent annually on coastal property loss, tourism collapse, and erosion control measures in the U.S. alone . Inspired by Crawford et. al (2020) , the case study for this tutorial analyzed a severe example of coastal erosion, centered on a small, 7 km (4 mi), coastal region in Kamalnagar, Bangladesh. This region is located in Southern Bangladesh, where the ocean (Bay of Bengal) meets a major inlet, the Meghna River. Coastal erosion in Bangladesh is a recurring problem, causing thousands of people to be displaced annually. In fact, coastal Bangladesh experiences erosion rates that are among the highest in the world. The workshop began with some geospatial and computer vision techniques, then moved on to apply those techniques to detect and analyze coastal erosion. The workshop focused on: extracting data from multi-band imagery computing the normalized difference water index (NDWI) using the NDWI to identify regions of water and land within the area of interest (AOI) applying classical image processing and computer vision techniques to analyze coastal erosion The folks attending the workshop created a data and image processing pipeline. Then they detected and measured the effects of coastal erosion in Kamalnagar, Bangladesh. They found that over the past 5 years the land had receded about 2 km (1.2 mi) and that the region had lost about 11 km2 (2742 acres) of landmass. On average, this translates to the region losing about 400m (1300 ft) of coastline and about 2.2 km2 (550 acres) of landmass, each year. In addition to identifying coastal recession, our analysis showed that the recession was speeding up year-over-year, consistent with what the authors of Crawford et. al (2020) had found. The workshop demonstrated that not only can geospatial data be beautiful, but it can also be used for great scientific purposes. In this case, it can be used to identify areas critically affected by natural disasters, which are prime candidates for humanitarian aid. Planet & Environment Our planet is important to us. One of Planet's ethical principles is to protect the environment: \"we actively develop and support uses of our data, products and services that address the critical planetary crises of our time, from climate change to the loss of nature.\" This carries into our work in Developer Relations. We reflect this deep care for the environment in our work. Whether our tutorial attendees are environmental scientists, geospatial experts, or completely new to the field, a key part of our role on team DevRel is to engage and empower developers. At Planet, we enable technical users to do amazing and intentional things with our data. We're here to support the search for answers. Next Steps Kevin and Mansi were excited to engage with users of Planet's data and the broader Python developer community around technical topics and environmental issues that matter. This was Planet Developer Relations' first in-person presence at such a conference since 2020. We're looking forward to reconnecting with old connections and building new ones. And we hope to see you there! Mansi Shah and Kevin Lacaille presented their tutorial at the SciPy 2022 conference in Austin, TX on July 11, 2022 from 8:00am-12:00pm CDT. Watch their presentation on YouTube . Try your hand at the Coastal Erosion Jupyter Notebook .","tags":"blog","url":"https://developers.planet.com/blog/2022/Aug/04/eroding-coastlines-a-geospatial-and-computer-vision-analysis/","loc":"https://developers.planet.com/blog/2022/Aug/04/eroding-coastlines-a-geospatial-and-computer-vision-analysis/"},{"title":"August 4, 2022","text":"Improvements 🙌🏻 You can now filter your saved searches by name. Bug Fixes 🐛 Actions for recently ordered Hosted Data were showing as disabled. You can now move or order items again. Imagery Enhancement is now working for Basemaps.","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Aug/04/explorer/2022-08-04/","loc":"https://developers.planet.com/changelog/2022/Aug/04/explorer/2022-08-04/"},{"title":"August 24, 2022","text":"Improvements 🙌🏻 We've made some updates to improve our location search. We heard your feedback that it was challenging to find natural features, such as volcanos, and this update should make that easier. Bug Fixes 🐛 We fixed an issue that was causing the application to crash when uploading large files (4MB+)","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Aug/24/explorer/2022-08-24/","loc":"https://developers.planet.com/changelog/2022/Aug/24/explorer/2022-08-24/"},{"title":"August 31, 2022","text":"New ✨ Navigate to your AOI without spending any tile view quota: when you first load Explorer you will see a Global reference image that you can use to find your area of interest. Only spend tile views once you find relevant date: We used to auto-select the most recent image. Now, once you create your area of interest, you will see the menu of data results and can select the data that meets your criteria. You will only start spending tile views once you select a data product. If you are loading a saved session from a shared link, you will see your selected image and use tile views for that. Basemaps have a new home! They now have a dedicated sidebar with some improved filters. The search input to search for a location has also been moved to be in the map.","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Aug/31/explorer/2022-08-31/","loc":"https://developers.planet.com/changelog/2022/Aug/31/explorer/2022-08-31/"},{"title":"State of STAC","text":"The number of imagery providers hosting data online has increased over the years. Search interfaces and metadata formats have also grown to describe and provide access to that data. The SpatioTemporal Asset Catalog ( STAC ) specification aims to provide a unified framework for describing and linking to earth observation data, with the goal of increasing the interoperability of search tools and making it easier to access the data. Since its release in May of 2021, the specification has been gaining popularity, with massive archives of publicly accessible geospatial data being hosted with STAC compliant metadata. The USGS hosts STAC metadata for the entire Landsat Collection 2 archive . Microsoft's Planetary Computer provides a STAC API with access to imagery archives of Landsat, MODIS, Sentinel, and more. Planet sees STAC as a key component in making earth observation data more accessible to developers, and helping advance it is a core part of our \"Open Initiatives\" as previously described . STAC's adoption has felt very rapid, but we wanted more concrete metrics to establish a baseline for its actual adoption. Building up knowledge of how data is exposed as STAC can help us understand how the standard is being used and how mature various extensions are. This, in turn, can help us prioritize what we work on to increase its uptake. So to better understand how STAC is being used, we recently deployed a crawler to visit publicly accessible STAC endpoints, recording millions of statistics about the catalogs, collections, items, and assets linked from those endpoints. STAC in a Nutshell The STAC specification describes a few different resource types: catalogs, collections, and items. Items represent the individual spatio-temporal data entries and have references to the data assets. Collections are used to group similar items. Catalogs are the top-level entry and can also be used as sub-groupings of collections or items. STAC implementations come with two different flavors of interface: static files and API. The static flavor can be thought of as an online folder or directory of JSON documents linking to one another. The API flavor is designed to provide more efficient pagination through large collections of items and may provide more advanced search functionality. Crawl Summary Starting with just 27 endpoints, sourced from the amazing stacindex.org , our crawl visited over 120 million items, spread across almost four thousand collections. We gathered statistics on over 550 million assets referenced by those items. About 97% of the collections were from static catalogs, while over 99% of the items and assets came from STAC API implementations. planetarycomputer.microsoft.com/api/stac/v1 landsatlook.usgs.gov/stac-server eod-catalog-svc-prod.astraea.earth stac.amskepler.com/v100 meeo-s5p.s3.amazonaws.com/catalog.json globalnightlight.s3.amazonaws.com/VIIRS_npp_catalog.json nasa-iserv.s3-us-west-2.amazonaws.com/catalog/catalog.json earth-search.aws.element84.com/v0 pta.data.lit.fmi.fi/stac/root.json franklin.nasa-hsi.azavea.com 10k 100k 1M 10M 100M Top ten catalogs ordered by number of assets (log scale). Static API Total Catalogs 10,084 26,041 36,125 Collections 3,736 131 3,867 Items 1,077,616 122,258,062 123,335,678 Assets 1,497,447 550,133,772 551,631,219 Counts of catalogs, collections, items, and assets crawled, organized by implementation type. The numbers suggest that people use collections far more frequently in static catalogs, presumably providing a way for users to explore reasonably small batches of items. While the STAC API implementations are dominated by catalogs with relatively small numbers of collections. Those API collections include many more items compared with their static counterparts. Because the STAC API provides search capabilities, catalogs and collections don't need to be used as navigational aids in finding relevant items. STAC Versions The core STAC specification reached a stable 1.0 version in May of 2021, and the STAC API specification had its first release candidate toward 1.0 in March of 2022. Of the catalog, collection, and item resources we crawled, 88% conform with version 1.0.0. About 12% are still using version 1.0.0-beta.2. And a few stragglers are still on versions 1.0.0-rc.2, 1.0.0-rc.3, and 0.8.1. Version Catalogs Collections Items 1.0.0 35,984 3,258 108,967,770 1.0.0-rc.3 0 0 10,000 1.0.0-rc.2 2 0 0 1.0.0-beta.2 123 597 14,352,545 0.8.1 16 12 5,345 Counts of catalogs, collections, and items organized by STAC version. These counts don't distinguish between STAC API versions and core STAC versions. It is encouraging to see the number of implementations that comply with the stable 1.0.0 version. Perhaps those still using an earlier version have a path to upgrade. STAC Extensions The core STAC specification limits itself to describing the spatial and temporal aspects of the data—specifying metadata fields for the geographic location and time range associated with the data. STAC extensions provide a way to add information specific to a given domain. Extensions exist for adding metadata specific to electro-optical data, for adding additional coordinate reference system information, for adding detail about raster bands, and more. Of the 120 million STAC items crawled, 86% referenced at least one extension to the STAC core. In total, 46 different extensions were used by the catalogs, collections, and items visited in the crawl. Extension Items https://stac-extensions.github.io/projection/v1.0.0/schema.json 105,849,954 https://stac-extensions.github.io/eo/v1.0.0/schema.json 93,319,320 https://stac-extensions.github.io/classification/v1.0.0/schema.json 53,532,402 https://stac-extensions.github.io/view/v1.0.0/schema.json 40,515,007 https://stac-extensions.github.io/storage/v1.0.0/schema.json 39,689,788 https://stac-extensions.github.io/alternate-assets/v1.1.0/schema.json 39,689,788 https://stac-extensions.github.io/raster/v1.0.0/schema.json 37,603,144 https://landsat.usgs.gov/stac/landsat-extension/v1.1.1/schema.json 37,283,628 https://stac-extensions.github.io/file/v1.0.0/schema.json 26,627,418 https://stac-extensions.github.io/sat/v1.0.0/schema.json 24,991,718 Top ten extensions based on item counts. This information collected on extension usage should be useful to help give real metrics to establish the proper maturity classification of proposed extensions—suggesting which might be candidates to graduate to a stable classification or which might be candidates for deprecation due to lack of use. STAC Asset Types Assets in STAC provide access to the underlying spatio-temporal data. For STAC items representing satellite imagery, the assets could be GeoTIFF rasters. Items may have assets that refer to additional JSON or HTML documents. The STAC asset metadata includes a \"type\" property advertising the asset media type. Values like \"image/tiff\" represent a generic TIFF image; \"image/tiff; application=geotiff; profile=cloud-optimized\" represents the Cloud Optimized GeoTIFF variety. Asset Type Count application/json 101,831,216 application/xml 87,647,164 image/tiff; application=geotiff; profile=cloud-optimized 75,945,405 image/png 72,572,728 image/jpeg 50,259,307 text/plain 41,762,282 text/html 41,139,833 image/vnd.stac.geotiff; cloud-optimized=true 39,807,777 application/x-hdf 16,489,141 application/netcdf 10,252,878 image/jp2 3,639,899 application/gml+xml 3,619,721 application/vnd.laszip+copc 3,313,116 image/tiff; application=geotiff 946,859 application/x.mrf 902,162 text/xml 620,780 image/tiff 402,485 application/wmo-GRIB2 143,509 application/x-ndjson 143,509 application/x-netcdf 127,042 (missing) 25,051 application/html 10,000 application/vnd.google-earth.kml+xml 9,249 application/gzip 9,249 application/geopackage+sqlite3 5,854 application/geo+json 2,846 application/vnd+zarr 1,119 application/octet-stream 569 application/x-parquet 411 application/zip 58 Asset type counts. At first glance, it is surprising to see the high counts of asset types that refer to additional metadata – the \"application/json\" and \"application/xml\" asset types, for example. We had anticipated that STAC assets would refer primarily to the spatiotemporal data instead of additional metadata describing that data. As it turns out, many implementations use assets to point to additional metadata that either doesn't fit into STAC or provides an alternate representation of the same metadata found in the STAC resources. In total, just under 50% of the 550 million assets could be classified as metadata assets as opposed to actual data assets. Considering all of its varieties together, TIFF is the most common asset type, representing over 20% of all assets crawled. About 99% of the TIFF assets are advertised as GeoTIFFs. It is possible the remaining TIFFs are GeoTIFFs as well, but simply use \"image/tiff\" as their asset type. Of the GeoTIFFs, over 99% are of the Cloud Optimized variety. It appears that people are still not sure about what media type is appropriate for Cloud Optimized GeoTIFF (COG). Although there is not yet an officially specified MIME type for COGs, there is growing consensus around \"image/tiff; application=geotiff; profile=cloud-optimized\" as a candidate for specification. Under the Hood The service used to perform the crawl made heavy use of go-stac , which has been expanded with a full set of \"crawler\" utilities. The crawling done by go-stac is now quite robust against errors and failures, and multiple end-points can be used, with a task queue to go through large amounts of data concurrently. The validate and stats commands in the go-stac command-line interface use the same crawling backend, so it's now a great tool to use with large STAC catalogs. The crawl results were stored in a BigQuery table, and we'll work to make the resulting data available to the community. It will be great to see what other insights might come from this data. What's Next We hope that reporting on real world implementations helps the community understand how the STAC specification is being used. We are looking forward to running another crawl and updating the results as more implementations are rolled out and the STAC spec continues to evolve. While the linked nature of STAC makes it possible to crawl and gather statistics on publicly accessible resources, it is not the most efficient way to summarize this information – particularly for very deep collections and relatively small page sizes. We have proposed a lightweight stats extension for reporting counts of resource types, versions, extensions, and asset types accessible in catalogs and collections. In future crawls, when the crawler encounters stats like those described in the extension, it will stop crawling deeper and increment counts based on what is advertised in the stats metadata. The stats extension is not yet finalized, so try it out with your catalogs and API implementations, and share any feedback or contributions in our issue tracker . And please upgrade to STAC 1.0.0 and STAC API 1.0.0.rc.1 and register on stacindex.org to be included in our next crawl!","tags":"blog","url":"https://developers.planet.com/blog/2022/Aug/31/state-of-stac/","loc":"https://developers.planet.com/blog/2022/Aug/31/state-of-stac/"},{"title":"September 14, 2022","text":"Improvements 🙌🏻 All data available in your area of interest is now visible. Previously, to narrow results a three month date range was auto-populated. With this change, all available data going back to the first capture is displayed. You can use the date range filter to narrow results according to your time of interest. Bug Fixes 🐛 We have fixed some issues that caused the application to fail unexpectedly for some customers.","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Sep/14/explorer/2022-09-14/","loc":"https://developers.planet.com/changelog/2022/Sep/14/explorer/2022-09-14/"},{"title":"September 22, 2022","text":"New Releases of the Planet Add-ins for ArcGIS Pro Planet Add-in 3.0 and 2.2.1 both provide an indicator that shows the size of the area-of-interest (AOI) used to search for imagery and Basemap quads. Planet Add-in Version 3.0 Planet Add-in 3.0 for ArcGIS is the first version of the add-in that is compatible with ArcGIS Pro 3.x. Planet Add-in 3.0 provides the ability to download imagery with STAC metadata. STAC metadata is more compatible with ArcGIS and similar applications. Planet Add-in Version 2.2.1 Version 2.2.1 is the final version of the add-in compatible with ArcGIS Pro 2.x.","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Sep/22/integrations/2022-09-22/","loc":"https://developers.planet.com/changelog/2022/Sep/22/integrations/2022-09-22/"},{"title":"September 29, 2022","text":"Planet API Quick search API - Removed unimplemented strict parameter from public documentation.","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Sep/29/data-api/2022-09-29/","loc":"https://developers.planet.com/changelog/2022/Sep/29/data-api/2022-09-29/"},{"title":"September 29, 2022","text":"Tasking Dashboard Updates Improvements 🙌🏻 An improved export function provides the ability to download the current filter or table as either CSV or GeoJSON files. We now use the filter name for the file. Previously the export function used the current timestamp as the filename. For example, If you save a filter as \"Orders in Mexico,\" the download is \"Orders in Mexico.csv.\" If you use a pre-defined filter such as \"All Orders\" the filter name is used. Note : Special characters that are not allowed in a filename are replaced with an exclamation mark (!). Special characters include slashes (\\ and /) and periods (.). You can now select all columns at once using the Column Picker.","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Sep/29/tasking/2022-09-29/","loc":"https://developers.planet.com/changelog/2022/Sep/29/tasking/2022-09-29/"},{"title":"October 06, 2022","text":"Draw and Measurement Tool Improvements 🙌🏻 There are improvements to the draw and measurement tools in Planet Explorer. By default, you can view the size of your area of interest. You can also edit and download each drawn geometry, including the area of interest and the measurements. The orders steps are consolidated and you can now choose between \"Direct Download\" or \"Hosted Data\" on the first step of the dialog.","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Oct/06/explorer/2022-10-06/","loc":"https://developers.planet.com/changelog/2022/Oct/06/explorer/2022-10-06/"},{"title":"Raster Data in the Client with NumpyTiles","text":"Atmosphere: it's the one thing that anyone who works with visual data has to negotiate. To enhance visual imagery at Planet, we use processing techniques, such as color corrections, reducing the effects of atmospheric haze, sharpening, or adjusting pixels near scene boundaries to minimize the effect of scene lines. For a Planet Basemap , our automated processing uses a \"best scene on top\" methodology to select the highest quality scenes for use in a mosaic. This means, when you look at a Basemap, say in Planet Explorer , you see sharp images that contain the lowest cloud coverage. Performing spectral analysis using RGB true color visualization You may, however, want to manipulate the image a bit further for your particular use. You may want to play with the brightness, contrast, or saturation to pull out some detail. Planet Explorer provides a tool to do so called the Enhance tool. Using the Image Enhancement Tool, you can enhance any scene in hosted data folders or analytic Basemaps Even more, when you use the Image Enhancement Tool, you're not just making a prettier picture, you're actually doing remote sensing. This is because the image you've loaded is the actual data: all 12 bits per pixel. The red, green, and blue pixel data are used to display the browser-friendly colors. The other data are free to be used to perform the enhancement. How's it done? Web browsers are an amazing way to get data into the hands of users. In the last 10 years, mapping applications through the browser have exploded. That explosion has pushed a number of innovations in vector formats. It has become easier than ever to take large data files of parcels, lakes, collections of millions of points, and stream them into the browser. The same evolution has not been available to the wide range of raster data. When we display raster imagery in the browser, we're limited to eight bits of data that define a color. This is called a true, or natural, color because it conforms to visual expectations–the colors you see in the world, for example, green grass or gray pavement. That's what you'd expect the browser to display: the colors needed for a visual representation of the world. All web-browser image formats are limited to displaying Red, Green, Blue, and some transparency, to display that image in true color. Remote sensing in the browser Given that the browser is limited to eight bits for each one of these channels, we reduce the imagery's extra bands of color and bit-depth down, by applying a \"color curve\" and selecting the true colors to use in the browser. Our \"global\" color curve is designed to work across all types of Planet data. Of course, there is no one-to-one mapping from 12-bits to 8-bits. So while the satellite is capturing lots of rich data, the global color curve addresses the most common imagery situations. This means some of that data, if it's rarely used for representing most of the world, will not be visible in the color curve we use. Some imagery, such as the desert image above, may look washed out. But Planet's satellites are far more capable! The imagery still has additional data that would be useful to manipulate in order to do remote sensing right in the browser. Working with only the RGB bits in the browser limits the ability to do raster-data based calculations, such as NDVI , or to see the images past that 8-bit limitation. To pass the large imagery data required for analysis to the browser interface requires getting that additional data through the network. Cloud Optimized GeoTIFF s (COGs) have helped show the potential of in-browser analysis with tools like geotiff.js . But COG's are not optimized for the web and have some limitations: COGs do not always have overviews. This then requires streaming the entire image into the browser from the server. Zoomed out, this means processing a lot of high resolution data for one view. Varying compression algorithms can create decoding issues, including overwhelming the client's CPU. COGs are not guaranteed to be in the same projection as the map, forcing the need for raster projection and opening the door for creating rectification issues. Here at Planet, we needed a technique that enables efficient streaming of multi-band, multi-byte data without the overhead of parsing a TIFF in the browser. Our solution? NumpyTiles. What is NumpyTiles? NumpyTiles is an open specification that Planet published on GitHub, designed to be both easy to serve and easy to parse on the client. \"NumpyTiles\" is a portmanteau of both \" NumPy ,\" the popular Python numerical library, and \"Tiles,\" which refers to slippy-map tiles. Each NumpyTile is a NumpyArray which is 256 columns wide, 256 rows long, with any number of bands represented as additional dimensions to the array. NumpyTiles is compatible with any slippy map specification (WMTS, XYZ, TileJSON, OGC API - Tiles, etc), as it is just an alternate output format, like PNG or JPEG. Planet open sourced OpenLayers NumpyTiles (ol-numpytiles) library to serve as a reference implementation that anyone can use. A demo of how this works can be found in the official OpenLayers examples as well as Planet Explorer. Examples in Planet Explorer The Enhance feature in Explorer is powered by NumpyTiles. The browser loads the images as NumpyTiles and applies the enhancements dynamically, based on the user's viewport. This dynamic segmenting and loading provides the full range of relevant details for the pixels being displayed. The result is a more descriptive visualization of the data. When the global color curve is insufficient, say for dense coniferous forests, you can use the Image Enhancement Tool to adjust local views dynamically This is accomplished by leveraging the OpenLayer native WebGL rendering chain and lowering the amount of abstraction between \"NumpyTiles\" on a tile server and the rendered formats. This improved output allowed us to experiment with enhancement methods. Beyond the dynamic color curve, we could now add Brightness, Contrast, and Saturation sliders to update the image in real time, giving instant feedback to the user as to how their changes affect what they are seeing. No enhancement Old enhancement New enhancement The Growing NumpyTile Ecosystem TiTiler Remember the old days when you prepared the raster data and then had to push a PNG of the file for display in the browser? Now, Titiler , pronounced tee-tiler (ti is the diminutive version of the french petit which means small), provides a set of simple python modules for building your own raster dynamic map tile services. TiTiler works with NumpyTiles , serving up any input data as NumpyTiles to be used in applications. You can go even further, by using the Titiler.PgSTAC plugin to connect to a PgSTAC database and create dynamic mosaics based on a search query. Unfolded Studio Ready to conduct powerful geospatial data analysis from your browser? Unfolded Studio is a geospatial visualization tool that lets you create maps from your geospatial data, perform powerful analytics, share and publish maps, and much more. Check out their sample maps for inspiration. Their raster data support leverages NumpyTiles for rich interactions. This can be seen in their COG support , which uses TiTiler under the hood to convert COG's to NumpyTiles, and their Planet NICFI integration, which uses NumpyTiles from Planet's tile service. NDVI of Planet NICFI Data with 3d Population overlay Next steps Check out the NumpyTiles spec and the OpenLayers Rendering 16-bit NumpyTiles JavaScript example. Let us know what you're building on Twitter .","tags":"blog","url":"https://developers.planet.com/blog/2022/Oct/06/raster-data-in-the-client-with-numpytiles/","loc":"https://developers.planet.com/blog/2022/Oct/06/raster-data-in-the-client-with-numpytiles/"},{"title":"October 20, 2022","text":"Improvements 🙌🏻 KMZ File Support The Planet Explorer Importer now supports KMZ files to specify an area of interest (AOI). KMZ files are Zip-compressed .KML files that store map locations viewable in various geographic information systems (GIS) applications, including Planet Explorer.","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Oct/20/explorer/2022-10-20/","loc":"https://developers.planet.com/changelog/2022/Oct/20/explorer/2022-10-20/"},{"title":"November 16, 2022","text":"Improvements 🙌🏻 You can now clip Hosted Data orders if you have clipping permissions. You can re-order a previous order from the Orders tab. When searching for a specific address, a pin marker indicates a single point at the searched location. Bug Fixes 🐛 When in compare mode, compare cards did not correctly display the timestamp. Searching for locations could result in a default selection of the first item in the result list instead of the desired selection from the list.","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Nov/16/explorer/2022-11-16/","loc":"https://developers.planet.com/changelog/2022/Nov/16/explorer/2022-11-16/"},{"title":"December 08, 2022","text":"Improvements 🙌🏻 The Import Dialog is updated to provide improved validation and assistance when a geometry needs to be simplified. If you upload a multi-feature file (multiple geometries in one file), all features display on the map. You can easily inspect your selections with a geo reference instead of a thumbnail. You can choose to select or deselect all. If your geometry contains more than 500 vertices or if it contains self intersecting points, you are presented with simplified alternatives. These alternatives are supported when selected. Measurements no longer display as abbreviating measurements. For example, 1,500 km2 instead of 1.5k km2. Bug Fixes 🐛 This release fixed an issue when moving Hosted Data items to folders. Now only selected data is moved. There were issues reordering past orders that were not clipped. Now you can now reorder without issues.","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Dec/08/explorer/2022-12-08/","loc":"https://developers.planet.com/changelog/2022/Dec/08/explorer/2022-12-08/"},{"title":"Simplifying Your Complex Area of Interest: a Planet Developers Deep Dive","text":"Introduction Planet's APIs use spatial information on both ends, input and output. You can filter data catalog search results by comparing items to an area of interest. You can point a SkySat at the region on Earth that you are studying. You can order products derived from these sources and have them clipped to spatial boundaries that you provide. Planet Data API search results are represented using GeoJSON features. This allows the footprints of, e.g., PlanetScope scenes, to be viewed on a map along with your area of interest. Figure 1: An area of study and footprints of PlanetScope scenes acquired on Oct 30, 2022. The shapes of these areas of interest, regions, and boundaries could be simple as triangles and squares or could be less perfect and more intricate agricultural fields or watersheds. The complexity of these shapes can adversely impact your experience as much as their area does, adding time to your analysis . But don't worry—this post will help you understand how to analyze and treat that complexity so that you can get the most out of Planet data. What do we mean by complexity? By and large, the shapes of features on Earth's surface are represented in Planet APIs by GeoJSON geometry objects. A triangular shape on the ground, for example, is represented by a JSON object with two members. The first member is a coordinate array consisting of three unique points (pairs of numbers) plus the first point, repeated to explicitly close the coordinate sequence. The second member is type , which has the value Polygon . { \"coordinates\": [ [ [ -1.859709, 15.634462 ], [ -3.933013, 12.424525 ], [ -0.423789, 12.315333 ], [ -1.859709, 15.634462 ] ] ], \"type\": \"Polygon\" } Snippet 1: a large triangular region of Africa. By complexity of a shape, we mean the number of edge segments or the number of coordinate pairs that are the boundaries of the segments. A square polygon has five such coordinate pairs, which we will refer to as vertices. One coordinate pair is a vertex. More realistic polygons might have 100 vertices or more. A shape with more vertices is more complex than a shape with fewer. Imagine a copy of the triangle above, but with one additional vertex added midway along one side, collinear with the original points on that side. This new polygon has the same area as the original triangle and is more or less equivalent to the original as far as common algorithms are concerned. Its domain (internal connected region) is the same as the triangle's domain. But it is more complex due to the extra vertex. Complexity increases with each additional vertex, and complexity comes with a cost. Even more about complexity Why did we say that the complexity of shapes adversely impacts your experience? The algorithm we use to implement Orders API clipping involves reducing your clipping shape into a set of triangles. The time it takes to compute this triangulation is on the order of n * log(n), where n is the number of vertices of the clipping shape. In other words, it takes about 15 times longer to clip using a 100-vertex shape compared to 10-vertex shape. And 13 times yet longer to scale from 100 to 1000 vertices. This is a fact of life for geographic information systems: even our best general-purpose geometry algorithms struggle with complex shapes. Computing the bounding box of your shape—as is done in Data API search and Tasking API orders—takes time on the order of n, where n is again the number of vertices. Complexity affects these operations almost as much as it affects clipping. It takes about 10 times longer to compare a 100-vertex shape to Planet's catalog compared to a 10-vertex shape. The greatest impact on your experience, however, is due to the cost of copying and passing long arrays of coordinates throughout Planet's systems. Data transfer, whether from disk to memory, or across a network, is orders of magnitude slower than operations in a computer's CPU. Shape data volume increases with the number of shape vertices: this is a fact of life. The more complex your shapes, the slower your search, order, and subscription results. What about the area of shapes? Is this property not significant? Planet's catalog is spatially indexed. The time to find results increases only slightly with the area of your shape. The area of a shape relative to the ground resolution of Planet product pixels affects search response time mainly by yielding more results that must be serialized and sent back to you. The area of your shapes thus affects your experience, but it is a different problem from the one posed by shape complexity. Planet APIs constrain the complexity of your shapes so that you don't have the experience of being in computational limbo. Data volume is not directly correlated to the area of your shapes and so area is not explicitly limited. Data API search requests are limited to 1MB in size, which limits the number of vertices of search shapes in these requests. Orders and Subscriptions API clip shape vertices are limited. However, the Orders or Subscriptions API clip tool is most valuable whenever you have areas of interest that are small compared to the size of Planet imagery scenes. Use it, because it reduces the time to apply other tools like bandmath and harmonization, and reduces the amount of data you need to download. The important thing is to manage the complexity of shapes that you provide in requests, using only as much as needed to get good results. Managing complexity Now that we've defined complexity and its impact, let's consider how to manage complexity. Our goal with managing complexity is to create a simpler shape that covers the entire original area while increasing total area as little as possible. Counting vertices The first step is measuring the complexity of your area of interest. Specifically, this means counting the number of vertices. ArcGIS and QGIS allow this through their expression engines as !shape!.pointcount and num_points($geometry) , respectively. QGIS also exposes this as a derived attribute of all features. In PostGIS, you can use the function ST_NPoints . In a Python program you can count vertices using the Shapely library. Here is an example that uses recursion. def vertex_count(obj) -> int: \"\"\"\"Count the vertices of a GeoJSON-like geometry object. Parameters ---------- obj: a GeoJSON-like mapping or an object that provides __geo_interface__ Returns ------- int \"\"\" shp = shape(obj) if hasattr(shp, \"geoms\"): return sum(vertex_count(part) for part in shp.geoms) elif hasattr(shp, \"exterior\"): return vertex_count(shp.exterior) + sum(vertex_count(rng) for rng in shp.interiors) else: return len(shp.coords) Snippet 2: a Python function that counts the vertices of a shape. If your shape is within the vertex limit, you can use it as an Orders or Subscriptions API clip geometry with no modifications. If your shape has fewer than about 20,000 vertices, you can use it for a Data API search with no modifications. This is because the Data API strictly limits search requests to 1MB of JSON text. You can assume each vertex, or coordinate pair, is represented in the GeoJSON by 40-46 bytes of text with each coordinate printed to 15 decimal places of precision (the default of OGR and QGIS). Given the 1MB limit and the amount of text required per vertex, this sets a rough upper limit of 20,000 vertices. Reducing complexity The recipe we suggest for reducing complexity is this: Dissolve internal boundaries in your area of interest. If that doesn't bring your area of interest under the limit, compute the convex hull. *Buffer to compensate for concavities or use the latest in outer concavity algorithms. If your area of interest has too many vertices, the first thing to check is whether redundant interior vertices can be eliminated by dissolving parts of your area of interest into a larger whole. For example, your area of interest might be a set of adjacent districts, watersheds, or zones extracted from other imagery. These shapes may share edges and vertices along those edges. Consider this map of Rocky Mountain National Park's (RMNP) wilderness patrol zones. These 25 zones share boundaries and have redundant vertices. Figure 2: the wilderness patrol zones of Rocky Mountain National Park. This area is interesting in that some of its boundaries follow natural features of the landscape and some are purely matters of real estate. It is several PlanetScope scenes high and about one scene wide. The 25 zones cover 1081 km² and are described by a total of 28,915 vertices. The vertices are spaced about 10-20 meters apart along the zone boundaries. This area of interest is not suited for search or clipping in this form. It is too complex. QGIS's dissolve geoprocessing tool can eliminate 24,302 of these vertices along the interior boundaries, yielding a single shape with 5613 vertices. ArcGIS also has a dissolve tool. If you're managing areas of interest with PostGIS, you can use ST_UnaryUnion . In Python, shapely provides unary_union . All of these are capable of dissolving areas of interest before Planet searches, orders, or subscriptions are made. Figure 3: wilderness patrol zones of Rocky Mountain National Park dissolved into one shape with the same area (1081 km²) and 80% fewer vertices (5613). An 80% reduction in the number of vertices without losing any area is a step in the right direction. You could search with this new shape, it is well under the 1 MB size limit, but 5613 is still beyond the vertex limits for other Planet APIs. Fortunately, we have more cards to play. We can use simpler approximations of our areas of interest. Convex hull The smallest convex set that contains a shape is called its convex hull. The boundary of the convex hull of your area of interest looks like an elastic band stretched around it. It is an excellent approximation for mostly convex shapes as it hugs (for example,headlands), but less excellent for shapes with concavities as it fills in (for example, bays). Figure 4: the convex hull of the RMNP zones (in green) has 43 vertices (-99% compared to the dissolved zones) and covers 1272 km² (+18%). A useful property of the convex hull is that it covers every point in your area of interest. When it comes to searching and clipping, this means that you will find every catalog item that you would have found with the shape of your complex area of interest and will get every bit of data in your order or subscription that you would get if you could use your exact area of interest. A convex hull is radically less complex than the shape it surrounds. In this example, it is only 43 vertices. 99.9% of the original complexity has been removed. Planet API requests using this simplified shape will be speedily processed. On the other hand, a convex hull is necessarily larger in area than your area of interest. In the present example, we have a +18% increase in area. That translates to a small chance of false positive search results: finding a Planet scene which intersects a filled-in \"bay,\" but not any of the original zones. It also means you'll download data in those same filled-in regions that you may not use. In this example, 191 km² more. Convex hull, the sequel It turns out that one way to get a better approximation of your area of interest is to use even more convex hulls. If you take the convex hull of each zone separately and then dissolve those 25 convex hulls, you get a shape that hugs the original boundary more tightly. 99.4% of the complexity has been removed while only increasing the area by 5.7% (62 km²). This union of hulls is a great fit for Data API searching and Orders and Subscriptions API clipping. Figure 5: the shape obtained by dissolving the 25 separate convex hulls has 151 vertices (-97% compared to the dissolved zones) and covers 1143 km² (+4.7%). Simplified buffers If your area of interest is dominated by concavities, the convex hull approach may not be useful at all. For example, the convex hull of an N or Z-shaped region is a full rectangle and maximizes the number of false positive search results and extra clipped data volume. In such cases, we've often recommended the approach of buffering and then simplifying areas of interest because the outcome can follow the outline of the original concave shape better than a convex hull can. Figure 6: the buffered and simplified (100 meter distances for each) approximation of the RMNP zones is shown in dark red. It barely extends beyond the original area, has 274 vertices (-95%) and covers 1100 km² (+1.8%). The difficulty with buffering and simplifying is that there are more parameters to adjust compared to the convex hull approximation. Success can vary greatly depending on these parameters and on the complexity of your area of interest. By simplification, we mean removal of vertices from the boundary of a shape, leaving the most important ones. The Visvalingam–Whyatt algorithm (ref TODO) uses local area-based criteria for importance. The widely used Douglas-Peucker algorithm has global distance-based criteria. Imagine the original vertices of the boundary of your area of interest and the line segments between them, and another smaller set of vertices and line segments which approximates that boundary. The Hausdorff distance is the distance that we would need to dilate each of these sets so that they mutually cover each other. Given a distance like this, the Douglas-Peucker algorithm finds a simplified set of vertices that has an equal Hausdorff distance. Both algorithms result in loss of boundary detail, erosion of convex corners, and filling of concave corners. Erosion of convex corners has an impact on Data API search and Orders and Subscriptions API clipping: searches may miss items in the catalog and pixels may be missing from delivered data. Thus, simplification must practically be preceded by buffering. The shape buffering operations offered by ArcGIS, QGIS, PostGIS, and Shapely have parameters setting the number of buffer segments around shape corners and the distance of these segments from the original shape. The effect of buffering on complexity is somewhat complicated. A buffer operation is constructive and creates a new shape with an entirely new set of vertices. More vertices are necessarily created around corners of the original area of interest. If you buffer a point and specify five segments per quarter circle around the point (the QGIS default, it's eight for PostGIS), you get a 20-sided polygon (an icosagon) with 20 vertices. For buffer distances that are large compared to the distance between vertices, you'll observe that buffering reduces complexity. In the extreme, a buffer shape approaches that which you would get when buffering a point. Figure 7: an approximately 100 km buffer (with five segments per quarter-circle) around the RMNP zones (in purple) approaches the shape of a regular polygon and has 175 vertices. Such a large buffer is useless in practice. You'll want to use buffer distances smaller than the size of the area of interest so as not to unnecessarily inflate its area. However, for buffer distances that are the same order of magnitude as the distance between original vertices, or smaller, you'll observe that buffering tends to increase complexity. On convex corners, 1-10 extra vertices may be created. Inversely, some vertices may be removed at concave corners. For the relatively small buffer distances that we are likely to use, the net result is to increase complexity. Buffering the RMNP zones by a distance of 100 meters and using five segments per quarter-circle gives a shape which has 598 more vertices (+11%). Figure 8: Detail of the original shape is shown in magenta, the buffer in brown. Buffering with five segments per quarter-circle (the QGIS default) adds five vertices at the convex corner. Note that 1 vertex is lost at the concave corner. If you subsequently perform a Douglas-Peucker simplification (available from ArcGIS, PostGIS, QGIS, Python, and other software) with a tolerance less than or equal to the buffer distance, extra corner vertices will be removed and some non-corner vertices will also be removed. Using a tolerance greater than the buffer distance is likely to result in loss of some of your area of interest due to convex corner erosion. The best practice for buffering, simplifying, and not creating too many new vertices is this: use a buffer distance larger than the distance between vertices of your original shape. simplify using a tolerance that is no larger than the buffer distance. Outer concave hulls The future of approximating the shapes of areas of interest which have both convexities and concavities is the outer concave hull . Version 3.11 of the GEOS library provides an outer concave hull algorithm. This feature is thus coming soon to QGIS, PostGIS, and Shapely 2.0.0. Below is a short script which uses an unreleased version of Shapely (2.0rc1) to construct the concave hulls of Rocky Mountain National Park's Wilderness Patrol Zones, dissolve them, and write the results to a GeoJSON file which can be opened and displayed in QGIS. import json import fiona from shapely.geometry import mapping, shape from shapely import concave_hull, unary_union with fiona.open(\"Wilderness_Patrol_Zones.shp\") as collection: hulls = [concave_hull(shape(feat[\"geometry\"]), ratio=0.4) for feat in collection] dissolved_hulls = unary_union(hulls) feat = dict(type=\"Feature\", properties={}, geometry=mapping(dissolved_hulls)) with open( \"dissolved-concave-hulls.geojson\", \"w\", ) as f: collection = json.dump({\"type\": \"FeatureCollection\", \"features\": [feat]}, f) Snippet 3: a script to compute the dissolved concave hulls of a set of features. Figure 9: the shape obtained by dissolving the 25 separate concave hulls (with ratio parameter of 0.4) has 293 vertices (-94% compared to the dissolved zones) and covers 1119 km² (+3.5%). This concave hull hugs the area of interest more closely than the convex hull and still has the important property of an outer hull: every point in the original area of interest is covered. Conclusion When your area of interest is overly complex, there are tools available to handle the complexity and maximize the value of Planet's platform. Desktop GIS software and programming libraries can measure the complexity of your areas of interest and provide tools to help you simplify your shapes to meet the vertex limit of Planet APIs: convex hulls, simplified buffers, and concave hulls. Today, convex hulls and simplified buffers are the most accessible methods. In the future, concave hulls may make the less predictable simplified buffer approach obsolete. Next Steps Check out our new simplification helpers in Planet Explorer . Let us know of any interesting simplification workflows you've done by Tweeting us @PlanetDevs . Sign up for Wavelengths , the Planet Developer Relations newsletter, to get more information on the tech behind the workflows.","tags":"blog","url":"https://developers.planet.com/blog/2022/Dec/15/simplifying-your-complex-area-of-interest-a-planet-developers-deep-dive/","loc":"https://developers.planet.com/blog/2022/Dec/15/simplifying-your-complex-area-of-interest-a-planet-developers-deep-dive/"},{"title":"December 15, 2022","text":"Tasking Dashboard Updates Improvements 🙌🏻 The Tasking Dashboard has added support for KML files with the elevation parameter. KML files store map locations that are viewable in various geographic information systems (GIS) applications. In Tasking Dashboard > Create an Order > Other Requirements , the Order Type selection has changed as shown in the following illustration:","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Dec/15/tasking/2022-12-15/","loc":"https://developers.planet.com/changelog/2022/Dec/15/tasking/2022-12-15/"},{"title":"February 28, 2022","text":"Improvements 🙌🏻 Harmonization with Sentinel-2 with the Orders Harmonization tool. With the Sentinel-2 target sensor, the Orders Harmonize tool harmonizes PSScene surface reflectance bundle types to Sentinel-2 radiometry. Read more about this update to the Orders Harmonize tool .","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Feb/28/orders-api/2022-02-28/","loc":"https://developers.planet.com/changelog/2022/Feb/28/orders-api/2022-02-28/"},{"title":"March 1, 2022","text":"Deprecating PSScene3Band and PSScene4Band ⚠️ PSScene3Band and PSScene4Band item types will be deprecated on March 1, 2022 with plans to formally end-of-life the item types on January 31, 2023. In its place, Planet is introducing PSScene, a new item type that allows you to search and download all PlanetScope data in a unified way. PSScene provides the same PlanetScope 3-band and 4-band items as PSScene3Band and PSScene4Band item types, but allows users to search one item type for all available 3-band, 4-Band, and 8-Band assets. Using the PSScene data type, users can also access 8-band PlanetScope data at no additional cost. We recommend all customers begin today to migrate to the PSScene item type. Visit the PSScene FAQ to learn more. Read about automated migration and steps to take in the Deprecation and Migration Plan . Begin using PSScene today.","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Mar/01/deprecating/2022-03-01/","loc":"https://developers.planet.com/changelog/2022/Mar/01/deprecating/2022-03-01/"},{"title":"March 03, 2022","text":"Improvements 🙌🏻 UDM and UDM2 files for SkySatScene and SkySatCollect items now set to clear for Panchromatic without Multispectral coverage UDM and UDM2 assets for SkySatScene and SkySatCollect item types have been slightly adjusted to include data values where we have Panchromatic but no Multispectral coverage, resulting in no cloud mask information. These areas, previously marked as nodata , are now to be marked as valid, with a cloud classification of clear with a confidence of 1 (the lowest).","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Mar/03/imagery/2022-03-03/","loc":"https://developers.planet.com/changelog/2022/Mar/03/imagery/2022-03-03/"},{"title":"April 28, 2022","text":"Previous generation of Doves (instrument ids PS2 and PS2.SD) imaging turned off On March 1, 2022 Planet released the next generation of Planet Scope images that consist of near daily 8-band imagery. Planet has been maintaining near-daily 8-band coverage coverage since August, 2021. With the recent successful launch of 44 8-band Doves, Planet has made the decision to turn off imaging with the previous generation of Doves (Instrument ids PS2 and PS2.SD) that only consists of 4-Bands (RGBNIR). The goal is to optimize for 8-band coverage and allocate all available ground station resources to improve publication time of 8-band imagery. For more information on PlanetScope constellation and sensors, see PlanetScope documentation. For an overview of PlanetScope sensors, see Understanding PlanetScope Instruments .","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Apr/28/imagery/2022-04-28/","loc":"https://developers.planet.com/changelog/2022/Apr/28/imagery/2022-04-28/"},{"title":"May 20, 2022","text":"Planet Labs Stratus GitHub project archived ⚠️ The Planet Labs Stratus GitHub project code is no longer actively maintained. The GitHub repository has been archived.","tags":"changelog","url":"https://developers.planet.com/changelog/2022/May/20/deprecating/2022-05-20/","loc":"https://developers.planet.com/changelog/2022/May/20/deprecating/2022-05-20/"},{"title":"May 23, 2022","text":"Improvements 🙌🏻 As of April 8, 2022, all SuperDoves and SkySats use the Sentinel-2 target sensor as a reference in radiometric correction of Planet Analytic and Surface Reflectance assets.","tags":"changelog","url":"https://developers.planet.com/changelog/2022/May/23/imagery/2022-05-23/","loc":"https://developers.planet.com/changelog/2022/May/23/imagery/2022-05-23/"},{"title":"June 22, 2022","text":"Improvements 🙌🏻 Users can now get tile usage using the Reports API. Tile usage was available through the reporting user interface. We have now integrated tile usage into the Reports API. Users can go to the new endpoint and get their tile view usage with the parameters they enter. For more information, checkout getTilesUsageReport in the Reports API reference .","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Jun/22/imagery/2022-06-22/","loc":"https://developers.planet.com/changelog/2022/Jun/22/imagery/2022-06-22/"},{"title":"October 3, 2022","text":"New ✨ Orders API now supports Planet Basemaps With the Orders API, users can now apply raster tools like clip, bandmath, reproject, and merge to Planet Basemaps, and have them delivered along side with sourcetrace and UDM2 metadata to Planet's support cloud storage locations. Customers who have a plan that enables access to Planet Basemaps can take advantage of this new feature. NICFI Basemaps can only be ordered from the Orders API by those with Level 2 NICFI access. Read more about Ordering Basemaps .","tags":"changelog","url":"https://developers.planet.com/changelog/2022/Oct/03/orders-api/2022-10-03/","loc":"https://developers.planet.com/changelog/2022/Oct/03/orders-api/2022-10-03/"},{"title":"January 19, 2023","text":"Tasking Dashboard Updates Improvements 🙌🏻 A link to Planet help and support resources is added to the Tasking Dashboard's main navigation. The Estimated quota cost for the sqkm of an order request is now displayed: In the footer of the Create an order page. At the bottom of the ORDER SUMMARY page. Also, the CONTRACT TO DEDUCT FROM is listed.","tags":"changelog","url":"https://developers.planet.com/changelog/2023/Jan/19/tasking/2023-01-19/","loc":"https://developers.planet.com/changelog/2023/Jan/19/tasking/2023-01-19/"},{"title":"January 26, 2023","text":"Planet Add-in for ArcGIS Pro Updates Improvements 🙌🏻 You can now view a size estimate when you draw an area of interest to search for Basemap quads. Bug Fixes 🐛 The auto-fill coordinates feature now correctly completes fields in the Tasking Dashboard when specifying a location in the Tasking panel. The Planet Add-in for ArcGIS Pro now supports organizations that are using system proxies.","tags":"changelog","url":"https://developers.planet.com/changelog/2023/Jan/26/integrations/2023-01-26/","loc":"https://developers.planet.com/changelog/2023/Jan/26/integrations/2023-01-26/"},{"title":"February 08, 2023","text":"Improvements 🙌🏻 It is now easier to select your time of interest in Explorer, especially for date ranges beyond two months. You can now enter your start and end date ranges as well as select them on the calendar. We have made improvements to Compare mode. You can now see the search field while in Compare mode. If you'd like to search for another location, you can do so faster now. If you try to place an order clipped to a complex geometry, the order will fail. We now include a fail safe in Explorer that disables the clipping option if your geometry is too complex. This way, you can place an order that will go through successfully. We have changed the defaults when you place an order. Harmonization will no longer be on by default; this tool is best applied if someone is ordering PlanetScope data from various constellations (for example, SuperDove and Dove-R); this situation does not apply to most people because SuperDoves provide full coverage. The clipping tool will remain on by default. Bug Fixes 🐛 Small AOIs will now show their area correctly up to 3 decimal places instead of 0 km2. We've fixed an issue that led to the application crashing when SkySat items were ordered as Hosted Data.","tags":"changelog","url":"https://developers.planet.com/changelog/2023/Feb/08/explorer/2023-02-08/","loc":"https://developers.planet.com/changelog/2023/Feb/08/explorer/2023-02-08/"},{"title":"February 16, 2023","text":"Planet QGIS Plugin Version 2.3 Updates Improvements 🙌🏻 An area estimate is displayed when you draw an area of interest to search for Basemap quads to download. STAC metadata is now available as an option when placing an order. A new Add to Map button is included in the Orders panel. When Add to Map is selected, a true color visualization of PlanetScope or SkySat imagery is automatically rendered in the QGIS map. An improved multi-polygon search has been added. You can now search for individual polygons in a multi-polygon or select a bounding box around the multi-polygon extent. Bug Fixes 🐛 The auto-fill coordinates feature now correctly completes fields in the Tasking Dashboard and a location is specified in the Tasking panel. The Basemap series cadence is now in the correct sequential order. The metadata fields in imagery footprints now display the correct data type.","tags":"changelog","url":"https://developers.planet.com/changelog/2023/Feb/16/integrations/2023-02-16/","loc":"https://developers.planet.com/changelog/2023/Feb/16/integrations/2023-02-16/"},{"title":"The Next Release of the Planet SDK for Python is in Beta","text":"Introduction We are excited to announce the Beta release of version two of our Planet SDK for Python! The Planet SDK (Software Development Kit) for Python is a Python package developed and maintained by the Developer Relations team at Planet. It is version two of what was previously known as the Planet Python Client and works with Python 3.7+. Version two is currently in development and has long been in the works. The beta version has been released and we're pleased to introduce you to it. This blog post provides an introduction to the Planet SDK for Python and is the first in a blog series which will cover specific aspects of the SDK in more detail. The Planet SDK for Python is a Python package developed and maintained by the Developer Relations team at Planet. It is version two of what was previously known as the Planet Python Client and it works with Python 3.7+. Currently, it is in development and the beta version has just been released. This blog post provides an introduction to the Planet SDK for Python and is the first in a blog series which will cover specific aspects of the SDK in more detail. The Planet SDK for Python interfaces with the Planet APIs and has two parts: a Python client library and a command-line interface (CLI). It is free and open source (maintained on github) and available for use by anyone with a Planet API key. It allows developers to automate their tasks and workflows and enables integration with existing processes using Python and more accessible API interactions via the CLI. In addition to providing Python and CLI interfaces for API endpoints, the SDK also simplifies tasks such as managing paged results, polling for when a resource is ready, and downloading resources. Additionally, it is optimized for fast and reliable http communication. The Python library speeds up complex and bulk operations through asynchronous communication with the servers. The CLI, on the other hand, is designed to fit into complex workflows with piping. These three functionalities will be covered in depth in future posts in this series. Improvements over version one include a first-class, full-functionality Python library and optimized, robust communication with the servers. CLI Usage The CLI is designed to be simple enough to allow for quick interactions with the Planet APIs while also being suitable for inclusion in complex workflows. It supports JSON/GeoJSON as inputs and outputs, which can be provided and handled as files or standard input/output. Here, we demonstrate using the CLI to create and download an order with the Orders API. Creating an order from an order request that has been saved in a file is pretty simple: planet orders create order_request.json The output of this command is the description of the created order. The order id from the description can be used to wait and download the order. Waiting for the order to be ready and downloading the order is achieved with: planet orders wait 65df4eb0-e416-4243-a4d2-38afcf382c30 \\ && planet orders download 65df4eb0-e416-4243-a4d2-38afcf382c30 Additionally, the CLI provides support for creating order requests. These requests can be saved as a file or piped directly into the command for creating the order: planet orders request --item-type PSScene \\ --bundle analytic_sr_udm2 \\ --name 'Two Item Order' \\ 20220605_124027_64_242b,20220605_124025_34_242b \\ | planet orders create - See the CLI documentation for more examples and a code example for how to search the Data API for a PSScene item id for use in defining the order. Python Library Usage Planet's Python library provides optimized and robust communication with the Planet servers. To provide lightning-fast communication in bulk operations, this library is asynchronous. Asynchronous support was added to the Python standard library in version 3.7. Our Python library documentation provides coding examples specifically geared toward the use of the SDK asynchronously. The Python asyncio module documentation is also a great resource. Here, we demonstrate using the Python library to create and download an order with a defined order request: import asyncio from planet import reporting, Session, OrdersClient request = { \"name\": \"Two Item Order\", \"products\": [ { \"item_ids\": [ \"20220605_124027_64_242b\", \"20220605_124025_34_242b\" ], \"item_type\": \"PSScene\", \"product_bundle\": \"analytic_sr_udm2\" } ], \"metadata\": { \"stac\": {} } } # use \"async def\" to create an async coroutine async def create_poll_and_download(): async with Session() as sess: cl = OrdersClient(sess) with reporting.StateBar(state='creating') as bar: # create order via Orders client # use \"await\" to run a coroutine order = await cl.create_order(request) bar.update(state='created', order_id=order['id']) # poll...poll...poll... await cl.wait(order['id'], callback=bar.update_state) # The order completed. Yay! Now download the files await cl.download_order(order['id']) # run the entire coroutine in the event loop asyncio.run(create_poll_and_download()) The Python library also provides support for creating an order request with the order_request module: from planet import order_request item_ids = [\"20220605_124027_64_242b\", \"20220605_124025_34_242b\"] products = [ order_request.product(item_ids, \"analytic_sr_udm2\", \"PSScene\") ] tools = [ order_request.reproject_tool(projection=\"EPSG:4326\", kernel=\"cubic\") ] request = order_request.build_request( \"Two Item Order, reprojected\", products=products, tools=tools) See the Python library documentation for more examples and a code example for how to search the Data API for the PSScene item ids used in defining the order. Next Steps Check it out for yourself! Get instructions on how to install the Planet SDK for Python, learn more about the package, and get plenty of code examples at https://planet-sdk-for-python-v2.readthedocs.io . Browse the source code and track progress at https://github.com/planetlabs/planet-client-python . Check out our Resources Page of Jupyter Notebooks for help getting started. Our Jupyter Notebooks include: Get started guides for Planet API Python Client , Order API & Planet SDK , the Analysis Ready Data Tutorial Part 1: Introduction and Best Practices , and the Analysis Ready Data Tutorial Part 2 . Chat with us about any ideas or issues at https://community.planet.com/developers-55 . Follow us on twitter @planetdevs .","tags":"blog","url":"https://developers.planet.com/blog/2023/Feb/16/the-next-release-of-the-planet-sdk-for-python-is-in-beta/","loc":"https://developers.planet.com/blog/2023/Feb/16/the-next-release-of-the-planet-sdk-for-python-is-in-beta/"},{"title":"GEE Integration: a Planet Developers Deep Dive","text":"Do you need some time and space? With Planet's high resolution, multi-band, daily imagery, with large color depth, users have a lot of data! Do you find your computer always reminding you that you need to \"make more space available?\" Are you always running late because your data processing is taking too long? Please let me present: ✨ Planet's Google Earth Engine Delivery Integration ✨ Google Earth Engine , or GEE for short, is a cloud-based platform for geospatial analysis and remote sensing applications. It is part of Google's larger Earth platform, which includes the popular Google Earth mapping software. GEE gives users the opportunity to store their Planet data on Google's cloud storage and harness Google's computing infrastructure. GEE is used to analyze and monitor the Earth's changing environment. It can be used to measure land cover and vegetation health, track changes in surface water, monitor wildfires, and measure other impacts of climate change. It can also be used to generate maps, 3D models, and other visualizations. GEE has become a popular platform for geospatial analysis and remote sensing applications, and has been used for a range of projects, from monitoring crop yields in Canada to tracking deforestation in the Amazon. Planet 𝗑 Google Google Earth Engine is used to run large-scale geospatial data analysis or to perform a few simple commands on geospatial data. GEE leverages Google's tools and services, and performs computations at scale with a user-friendly interface. This sort of geospatial working environment makes analyzing your Planet data fast and easy. Planet users can easily have their data delivered directly to their GEE project thanks to Planet's Google Earth Engine Delivery Integration - a simpler way for GEE users to incorporate Planet data into their existing workflows and ongoing projects. This integration simplifies the GEE delivery experience by creating a direct connection from Planet's Orders API to GEE, so that you don't have to download then re-upload images or spin up temporary cloud storage when moving imagery to your GEE account. In this blog post we are going to cover: How to prepare your Google Earth Engine account for data delivery via Planet's Orders API How to use Planet's GEE Delivery Integration service on your GEE project A basic and advanced example JSON requests and responses A Python example using Planet's Python SDK , hosted in a Jupyter Notebook A Planet CLI example How to deliver your data to GEE To deliver data to your GEE project, you must first sign up for an Earth Engine account, create a Cloud Project, enable the Earth Engine API, and grant access to a Google service account. Set up GEE Before we get into the coding aspect of it all, we need to set up our GEE project. 1. Sign up for an EE account First thing's first, let's sign up for an Earth Engine account. Go to: https://signup.earthengine.google.com/ 2. Register a Google Cloud Project (GCP) project Now that you have an Earth Engine account, let's create a new Cloud Project for your account. This will simultaneously create an empty ImageCollection . This ImageCollection is where all of your data will be delivered to. Go to: https://code.earthengine.google.com/register/ 3. Enable the EE API for the project In order to allow Planet's Orders API to interact with GEE, we must first enable the Earth Engine API. Go to: https://console.cloud.google.com/apis/library/earthengine.googleapis.com 4. Grant Planet access to deliver to your GEE project Lastly, you need to create a service account , which in this case is essentially a virtual account, which will be used to automate our GEE integration. To create this service account, return to the console and select: Navigation menu > IAM & Admin > Service Accounts Then we can create a service account by clicking \"+CREATE SERVICE ACCOUNT\". Here we will add Planet's Google service account, named planet-gee-uploader@planet-earthengine-staging.iam.gserviceaccount.com Finally, your service account must be granted the role of \"Earth Engine Resource Writer \", which will allow it to deliver your data to your ImageCollection. Examples Now that you have a GEE project that Planet has access to, here's how you tell Planet how to access that GEE project. To communicate with Planet's servers, we use RESTful endpoints. Regardless of the language you use to make a network request, here's the body of the request. In the language that you use, you'll need to provide the following to successfully make a request: API endpoint (https://api.planet.com/compute/ops/orders/v2) Basic auth using your Planet API key Header to specify that the Content-Type is application/json Body, the specifics of what you're requesting Basic JSON request REST method: POST https://api.planet.com/compute/ops/orders/v2/ An example JSON request body for delivery for: Order name: iowa_order Item IDs: 20200925_161029_69_2223, 20200925_161027_48_2223 Item type: PSScene Product bundle: analytic_sr_udm2 GEE project name: planet-devrel-dev ImageCollection name: gee-integration-testing Request: { \"name\": \"iowa_order\", \"products\": [ { \"item_ids\": [ \"20200925_161029_69_2223\", \"20200925_161027_48_2223\" ], \"item_type\": \"PSScene\", \"product_bundle\": \"analytic_sr_udm2\" } ], \"delivery\": { \"google_earth_engine\": { \"project\": \"planet-devrel-dev\", \"collection\": \"gee-integration-testing\" } } } Response: ​​{ \"_links\": { \"_self\": \"https://api.planet.com/compute/ops/orders/v2/1e4ade86-20dd-45bc-a3cf-4e6f378b5774\" }, \"created_on\": \"2022-11-30T19:08:34.193Z\", \"error_hints\": [], \"id\": \"1e4ade86-20dd-45bc-a3cf-4e6f378b5774\", \"last_message\": \"Preparing order\", \"last_modified\": \"2022-11-30T19:08:34.193Z\", \"metadata\": { \"stac\": {} }, \"name\": \"iowa_order\", \"products\": [ { \"item_ids\": [ \"20200925_161029_69_2223\", \"20200925_161027_48_2223\" ], \"item_type\": \"PSScene\", \"product_bundle\": \"analytic_sr_udm2\" } ], \"state\": \"queued\" } Advanced JSON request GEE integration also supports two tools, clipping , and sensor harmonization . To include them, we add them to the \"tools\" schema. Adding to the previous example, if we want to clip to an AOI defined as a polygon and harmonize our data to Sentinel-2's sensor, the JSON request would look like: Request: { \"name\": \"iowa_order\", \"products\": [ { \"item_ids\": [ \"20200925_161029_69_2223\", \"20200925_161027_48_2223\" ], \"item_type\": \"PSScene\", \"product_bundle\": \"analytic_sr_udm2\" } ], \"delivery\": { \"google_earth_engine\": { \"project\": \"planet-devrel-dev\", \"collection\": \"gee-integration-testing\" } }, \"tools\": [ { \"clip\": { \"aoi\": { \"type\": \"Polygon\", \"coordinates\": [ [ [-91.198465, 42.893071], [-91.121931, 42.893071], [-91.121931, 42.946205], [-91.198465, 42.946205], [-91.198465, 42.893071] ] ] } } }, { \"harmonize\": { \"target_sensor\": \"Sentinel-2\" } } ] } Response: ​​{ \"_links\": { \"_self\": \"https://api.planet.com/compute/ops/orders/v2/1e4ade86-20dd-45bc-a3cf-4e6f378b5774\" }, \"created_on\": \"2022-11-30T19:08:34.193Z\", \"error_hints\": [], \"id\": \"1e4ade86-20dd-45bc-a3cf-4e6f378b5774\", \"last_message\": \"Preparing order\", \"last_modified\": \"2022-11-30T19:08:34.193Z\", \"metadata\": { \"stac\": {} }, \"name\": \"iowa_order\", \"products\": [ { \"item_ids\": [ \"20200925_161029_69_2223\", \"20200925_161027_48_2223\" ], \"item_type\": \"PSScene\", \"product_bundle\": \"analytic_sr_udm2\" } ], \"state\": \"queued\", \"tools\": [ { \"clip\": { \"aoi\": { \"coordinates\": [ [ [-91.198465, 42.893071], [-91.121931, 42.893071], [-91.121931, 42.946205], [-91.198465, 42.946205], [-91.198465, 42.893071] ] ], \"type\": \"Polygon\" } } }, { \"harmonize\": { \"target_sensor\": \"Sentinel-2\" } } ] } Integration with Python Users can integrate their Planet data delivery with GEE with Python via Planet's Python SDK 2.0 . Using the SDK, users can generate their request, order data using the Orders API, then have it delivered directly to GEE. For an in-depth example, please see this Jupyter Notebook . import planet import asyncio # The area of interest (AOI) defined as a polygon iowa_aoi = { \"type\": \"Polygon\", \"coordinates\": [[[-91.198465, 42.893071], [-91.121931, 42.893071], [-91.121931, 42.946205], [-91.198465, 42.946205], [-91.198465, 42.893071]]] } # The item IDs we wish to order iowa_images = ['20200925_161029_69_2223', '20200925_161027_48_2223'] # Google Earth Engine configuration cloud_config = planet.order_request.google_earth_engine( project='planet-devrel-dev', collection='gee-integration-testing') # Order delivery configuration delivery_config = planet.order_request.delivery(cloud_config=cloud_config) # Product description for the order request data_products = [ planet.order_request.product(item_ids=iowa_images, product_bundle='analytic_sr_udm2', item_type='PSScene') ] # Build the order request iowa_order = planet.order_request.build_request(name='iowa_order', products=data_products, delivery=delivery_config) # Create a function to create and deliver an order async def create_and_deliver_order(order_request, client): '''Create and deliver an order. Parameters: order_request: An order request client: An Order client object ''' with planet.reporting.StateBar(state='creating') as reporter: # Place an order to the Orders API order = await client.create_order(order_request) reporter.update(state='created', order_id=order['id']) # Wait while the order is being completed await client.wait(order['id'], callback=reporter.update_state, max_attempts=0) # Grab the details of the orders order_details = await client.get_order(order_id=order['id']) return order_details # Create a function to run the create_and_deliver_order function async def main(): async with planet.Session() as ps: # The Orders API client client = ps.client('orders') # Create the order and deliver it to GEE order_details = await create_and_deliver_order(iowa_order, client) return order_details # Deliver data to GEE and return the order's details order_details = asyncio.run(main()) Using the Planet CLI Lastly, we can use the Planet command line interface (CLI) to deliver data to GEE. If we want to clip or harmonize our data, first we need to create a file called tools.json containing the following information: [ { \"clip\": { \"aoi\": { \"type\": \"Polygon\", \"coordinates\": [ [ [-91.198465, 42.893071], [-91.121931, 42.893071], [-91.121931, 42.946205], [-91.198465, 42.946205], [-91.198465, 42.893071] ] ] } } }, { \"harmonize\": { \"target_sensor\": \"Sentinel-2\" } } ] Then, to order and deliver data with the Planet CLI, we query the Orders API with 3 commands: 1. Generate an order request The request function requires that you give it an item type, product bundle, an order name, and item IDs. $ planet orders request \\ 20200925_161029_69_2223,20200925_161027_48_2223 \\ --item-type psscene \\ --bundle analytic_sr_udm2 \\ --name \"iowa_order\" \\ --tools tools.json \\ > my_order.json Here, we are saving the order request into a file called my_order.json , which we will use to create the order. 2. Create an order $ planet orders create my_order.json {\"_links\": {\"_self\": \"https://api.planet.com/compute/ops/orders/v2/1e4ade86-20dd-45bc-a3cf-4e6f378b5774\"}, \"created_on\": \"2022-11-30T19:08:34.193Z\", \"error_hints\": [], \"id\": \"1e4ade86-20dd-45bc-a3cf-4e6f378b5774\", \"last_message\": \"Preparing order\", \"last_modified\": \"2022-11-30T19:08:34.193Z\", \"metadata\": {\"stac\": {}}, \"name\": \"iowa_order\", \"products\": [{\"item_ids\": [\"20200925_161029_69_2223\", \"20200925_161027_48_2223\"], \"item_type\": \"PSScene\", \"product_bundle\": \"analytic_sr_udm2\"}], \"state\": \"queued\", \"tools\": [{\"clip\": {\"aoi\": {\"coordinates\": [[[-91.198465, 42.893071], [-91.121931, 42.893071], [-91.121931, 42.946205], [-91.198465, 42.946205], [-91.198465, 42.893071]]], \"type\": \"Polygon\"}}}, {\"harmonize\": {\"target_sensor\": \"Sentinel-2\"}}]} Alternatively, we can combine steps 1 and 2 into a single command by harnessing the power of STDIN with the format <request command> | <create command> - . $ planet orders request 20200925_161029_69_2223,20200925_161027_48_2223 --item-type psscene --bundle analytic_sr_udm2 --name \"iowa_order\" | planet orders create - We can find the order ID in the response from the Orders API under the field called \"id\". In this case, the order ID is \"1e4ade86-20dd-45bc-a3cf-4e6f378b5774\" 3. Report the state of the order $ planet orders wait 1e4ade86-20dd-45bc-a3cf-4e6f378b5774 08:25 - order 1e4ade86-20dd-45bc-a3cf-4e6f378b5774 - state: running If successful, the states will go from queued > running > success ! Results in GEE Now that you've delivered your data to GEE, here's where you'll find it. Head on over to your GEE console, https://code.earthengine.google.com/, click the \"Assets\" tab on the left hand side of the screen, and below you will find the Cloud Project you created under the tab called \"CLOUD ASSETS\". Under the your Cloud Project name you will find your ImageCollection, and within you will find the images you requested. Next steps In this example, we relied on Planet's Google Service Account for data delivery. However, this Service Account is used by many users and may be subject to delays if it reaches its maximum delivery quota. To avoid this, you can create your own Service Account, which would provide you with a dedicated delivery queue and sooner access to your data. In a future blog post, we will discuss the benefits of using a custom Service Account and provide instructions on how to integrate it with your GEE project. Chat with us about any ideas or issues at https://community.planet.com/developers-55 . Follow us on Twitter @planetdevs .","tags":"blog","url":"https://developers.planet.com/blog/2023/Feb/23/gee-integration-a-planet-developers-deep-dive/","loc":"https://developers.planet.com/blog/2023/Feb/23/gee-integration-a-planet-developers-deep-dive/"},{"title":"Planet's Role in Sustaining the Python Geospatial Stack","text":"Planet's customers don't only use Planet products via commercial or open source desktop GIS or partner platforms. Many of you are integrating Planet's products and services into custom-built GIS systems, which use the open source Python Geospatial Stack. This post attempts to explain what the Python Geospatial Stack is and Planet's role in keeping the stack in good shape so that developers like you continue to get value from it. Can Planet data or the Planet platform be used with Python? It can, and not by accident. Planet is working to make it so. You can help, too. What is the Python Geospatial Stack? The Python Geospatial Stack is a set of Python packages that use a smaller set of non-standard system libraries written in C/C++: GEOS, PROJ, and GDAL. GEOS is a library of 2-D computational geometry routines. PROJ is a library for cartographic projections and geodetic transformations. GDAL is a model for computing with raster and vector data and a collection of format drivers to allow data access and translation on your computer or over your networks. Planet engineers, including myself, have contributed significantly to these system libraries. Principal Engineer Frank Warmerdam is the author of GDAL, a longtime maintainer of PROJ version 4, and a major contributor to GEOS. Shapely , Pyproj , Fiona , Rasterio , GeoPandas , PDAL , and Xarray are the core of the stack. Shapely draws upon GEOS. Shapely is useful to developers for filtering asset catalog search results, comparing catalog item footprints to areas of interest, and much more. Pyproj wraps PROJ. Pyproj is helpful for calculating the projected area of regions that are described in longitude and latitude coordinates, and more. Fiona and Rasterio are based on GDAL and allow developers to read and write vector and raster data. PDAL translates and manipulates point cloud data , GeoPandas and Xarray use Fiona and Rasterio and provide higher levels of abstraction for analysis of column-oriented tabular and gridded scalar data, respectively. How did the stack come about? Why are so many organizations using Python for GIS work? Isn't it slow? Only an instructional language? Timing explains a lot. When Bruce Dodson started looking at alternatives to Avenue, the scripting language of Esri's ArcView GIS version 3, Python was ready . Python had a good extension story in 2000, meaning that although Python was relatively slow, it was fairly easy to extend with fast code written in C. When you compute and dissolve the convex hulls of multiple shapes using Shapely , all of the intensive calculation is done by native code, not Python bytecode. The open source native code (GDAL, GEOS, PROJ, etc) just happened to rise up at the same point in time. Timing really is everything. To close the loop, the Geospatial Stack has helped make the Python language sticky. Developers chose Python from many options for the availability of solid, feature-rich, decently-documented libraries in a particular domain, and end up staying for all the other nice things about the Python language and community. The reason why Python is the second best language for many domains is that the same discovery happened in Numerical Analysis, Machine Learning, Image Processing, and elsewhere. How is Planet helping? Software and software communities need care and feeding. Planet is involved through financial sponsorship, project governance, code maintenance, and builds of binary distributions. In 2021, Planet became an inaugural platinum sponsor of GDAL. Planet is helping to pay for infrastructure costs and for the labor of full-time maintainers for GDAL and affiliated projects like GEOS and PROJ. In addition, two Planet engineers (Frank Warmerdam and I) serve on GDAL's project steering committee. The impact of this sponsorship is huge. GDAL has a better and faster build system, which makes it easier to contribute to and which reduces the cost of every bug fix and new feature. Most importantly, the sponsorship makes it possible for GDAL's longtime maintainers to avoid burnout, stay involved, and mentor their eventual successors. Planet's Developer Relations team is mainly involved at the Python level. I'm the release manager for Fiona and Rasterio. I make sure that binary distributions (aka \"wheels\") for Linux, MacOS, and Windows are uploaded to Python's Package Index so that when developers run \"pip install rasterio\" almost everybody gets pre-compiled Python packages with GDAL, GEOS, and PROJ batteries included. Packages that \"just work\" for many cases on laptops and in hosted notebooks. A major new version of Shapely was released at the end of 2022 through collaboration with core GeoPandas developers. Shapely 2.0 adds vectorized operations that radically speed up GeoPandas and keep this piece of the stack relevant as projects like GeoParquet start to change the nature of vector data . Fiona 1.9.0 was released on Jan 20, 2023 and also provides a boost to GeoPandas. Planet's Developer Relations team is currently building new tools that integrate with this new version of the Geospatial Stack's vector data package. They will be announced soon. Multiple teams at Planet helped make Rasterio 1.3.0, Shapely 2.0.0, and Fiona 1.9.0 successful releases by testing beta releases of these packages. Planet is financially sustaining the open source projects that form the foundation of the stack. The DevRel team is engaged with the open source communities that write the stack's code. At Planet we consider the health of the Python Geospatial Stack to be a big factor in the overall experience of our platform. Next Steps Are you using Fiona, Rasterio, or Shapely? Upgrade to the latest versions and try them out. Chat with us about any ideas or issues with using these packages with Planet data at https://community.planet.com/developers-55 . Follow us on twitter @planetdevs .","tags":"blog","url":"https://developers.planet.com/blog/2023/Mar/16/planets-role-in-sustaining-the-python-geospatial-stack/","loc":"https://developers.planet.com/blog/2023/Mar/16/planets-role-in-sustaining-the-python-geospatial-stack/"},{"title":"March 22, 2023","text":"Improvements 🙌🏻 We continue to make improvements to our date selectors, users can now enter human readable dates, i.e. \"Jan 10 2022\" in addition to the traditional month-day-year (01-10-2022) format. Bug Fixes 🐛 We've fixed an issue with our date picker in tablet devices.","tags":"changelog","url":"https://developers.planet.com/changelog/2023/Mar/22/explorer/2023-03-22/","loc":"https://developers.planet.com/changelog/2023/Mar/22/explorer/2023-03-22/"},{"title":"April 19, 2023","text":"New ✨ It is now easier to preview and order imagery. When you search for imagery, you will see three new buttons. Click X items button to check out each satellite image from that date and make the best choice. Click the eye button to preview the imagery from that date on the map. Click the cart button to add the imagery to your order. You can select and de-select imagery from multiple dates. You can also lock the footprint of an image onto the map to get a better sense of coverage. When you place an order, there is a new option to composite images, which stitches them together. You will receive fewer files and consume less quota. Composite all will give you one file and composite by strip will provide the most consistency (spatial, spectral, environmental, etc). Take a look at the impact of each option on the map to get a sense of what you will receive. You can now more easily use your Hosted Data in other tools and platforms. Download the Cloud Optimized GeoTIFF (COG) and pull it into other web applications at no extra cost. Improvements 🙌🏻 You can now select MGRS as a format in Settings, under the Coordinate System section. You can also easily copy MGRS coordinates out of Explorer to paste into other systems. The coordinates can be found in the bottom banner of the app. Please note: precision varies by the zoom level and resolution.","tags":"changelog","url":"https://developers.planet.com/changelog/2023/Apr/19/explorer/2023-04-19/","loc":"https://developers.planet.com/changelog/2023/Apr/19/explorer/2023-04-19/"},{"title":"March 23, 2023","text":"Improvements 🙌🏻 Composite orders with multiple product bundles are no longer supported To ensure a more streamlined process and reduce the occurrence of failures, we have decided to discontinue support for composite orders that contain multiple product bundles. This change prevents downstream failures, resulting in a more efficient and reliable process. Going forward, users cannot submit composite orders with multiple product bundles, but must submit only one order per product bundle.","tags":"changelog","url":"https://developers.planet.com/changelog/2023/Mar/23/orders-api/2023-03-23/","loc":"https://developers.planet.com/changelog/2023/Mar/23/orders-api/2023-03-23/"},{"title":"April 2017","text":"Planet API Data API - Added ground_control to field PSScene3Band, PSScene4Band, PSOrthoTile and REOrthoTile item meta. Data API - Added width parameter to item thumbnail endpoint. Data API - Added thumbnail to the links array in item responses. Data API - Python API client and command-line interface tools have been released for users developing applications in Python. Data API - JavaScript API client has been released for users developing applications in JavaScript. Mosaics API - Planet Basemaps are now available as a stand-alone XYZ Web Service. Imagery Products Added visual asset to the Sentinel2L1C item type. Full monthly basemaps now available. Planet Explorer Added basemap compare tool, allowing you to compare two timelapse mosaics side-by-side.","tags":"changelog","url":"https://developers.planet.com/changelog/2017/Apr/01/archive/2017-04-01/","loc":"https://developers.planet.com/changelog/2017/Apr/01/archive/2017-04-01/"},{"title":"April 2018","text":"Planet API The Clips API has been deprecated - we will no longer be supporting the standalone Clip and Ship service. Bug Fix - Saved search email notification have been reenabled. Basemaps and Mosaics March monthly mosaic released. Desert region boundaries smoothing, decreasing visible sharp lines. White balance adjusted to produce deserts with more contrast. Updated snowline and color target to better represent snowy regions. De-weighting of RapidEye within snowline to avoid patches.","tags":"changelog","url":"https://developers.planet.com/changelog/2018/Apr/01/archive/2018-04-01/","loc":"https://developers.planet.com/changelog/2018/Apr/01/archive/2018-04-01/"},{"title":"August 2017","text":"Data API - Added unorthorectified SkySat items to the Data API.","tags":"changelog","url":"https://developers.planet.com/changelog/2017/Aug/01/archive/2017-08-01/","loc":"https://developers.planet.com/changelog/2017/Aug/01/archive/2017-08-01/"},{"title":"Dec 2016","text":"Quick search API - Bug fix: Searches using permission filters not returning the correct results. Searches now return data that can be downloaded. Data API - Added /thumb endpoint to items. Each item now allows direct access to a down-sampled preview of the data. Data API - Disassociated activation and download throttling. There used to be a single rate limit for activating and downloading assets, but Planet has split this into two separate rates that can be controlled separately. This should give API users greater control over how they access data and apply backoff strategies to prevent 429 error codes. Data API - Increased download rate limit to 2 requests per second. Data API - Bug fix: Removed incorrectly-advertised analytic asset from some items. Not all PSScene3Band and PSScene4Band items have analytic assets.","tags":"changelog","url":"https://developers.planet.com/changelog/2016/Dec/01/archive/2016-12-01/","loc":"https://developers.planet.com/changelog/2016/Dec/01/archive/2016-12-01/"},{"title":"Dec 2017","text":"Planet Explorer Added new status bar with many new features. Added new measurement tools, allowing you to interactively measure line and area features. Added new bearing tool, allowing you to find distance/direction between two points. Added New settings panel, allowing you to configure the units and positions. Add new ground control option, allowing you toggle ground locked imagery. Planet API Data API - Added SkySatScene items to the Data API.","tags":"changelog","url":"https://developers.planet.com/changelog/2017/Dec/01/archive/2017-12-01/","loc":"https://developers.planet.com/changelog/2017/Dec/01/archive/2017-12-01/"},{"title":"Feb 2017","text":"Data API - Added standard terrain-corrected Landsat 8 scenes (item type: Landsat8L1G ). Data API - Added level 1C Sentinel-2 scenes (item type: Sentinel2L1C ). Data API - Bug fix: Removed assets from the /assets endpoint when the user does not have download permissions.","tags":"changelog","url":"https://developers.planet.com/changelog/2017/Feb/01/archive/2017-02-01/","loc":"https://developers.planet.com/changelog/2017/Feb/01/archive/2017-02-01/"},{"title":"Feb 2018","text":"Planet API Quick search API - Added strict parameter to strictly remove false positives from geo intersection. Mosaics API - Added name__is and name__contains search parameters . Developer's Center - Release of comprehensive API docs . Quick Search API - Search performance improvements. Data API - Reduction of rate limits on certain endpoints. Imagery Products Updates to the Relative Spectral Response (RSR) Curves . Basemaps and Mosaics Added 4 Band Surface Reflectance Basemap. January monthly mosaic released. Adjusted color curve to avoid black scenes. Adjusted color balance to enhance contrast in deserts and reducing blockiness of snow. Improved WTMS support for base maps with different max zoom levels. Improved API performance when listing many quads.","tags":"changelog","url":"https://developers.planet.com/changelog/2018/Feb/01/archive/2018-02-01/","loc":"https://developers.planet.com/changelog/2018/Feb/01/archive/2018-02-01/"},{"title":"Jan 2017","text":"Planet API Data API - Increased activation and download rate limit to 5 requests per second. Data API - Added md5_digest field to the assets endpoint for use in tracking asset version changes and corrupted downloads. Data API - Added strip_id field to the PlanetScope item metadata for use in associating items to collections. Data API - Added anomalous_pixels field to the PlanetScope and RapidEye items metadata which indicates the percentage of pixels that may be problematic. Imagery Products Improved sharpening algorithms have been applied to PSScene3Band, PSOrthoTile and REOrthoTile item types. Added acquisition time in UTC as TIFFTAG_DATETIME tag in PlanetScope GeoTIFF assets. Planet Explorer Planetscope 4-band scenes now available in Planet Explorer for easier access to NIR band.","tags":"changelog","url":"https://developers.planet.com/changelog/2017/Jan/01/archive/2017-01-01/","loc":"https://developers.planet.com/changelog/2017/Jan/01/archive/2017-01-01/"},{"title":"Mar 2017","text":"Planet API Data API - Added quality_category field to the PlanetScope item metadata as documented in the product specification guide. Data API - Increased download rate limit to 15 requests per second. Imagery Products Basemap color-balancing techniques added to improving color balancing, scene line minimization and removing artifacts due to snow and clouds. Planet Explorer Planet Explorer is open to the public! Planet explorer now has improved timeline manipulations allowing users to easily step through our automated time-lapse basemaps.","tags":"changelog","url":"https://developers.planet.com/changelog/2017/Mar/01/archive/2017-03-01/","loc":"https://developers.planet.com/changelog/2017/Mar/01/archive/2017-03-01/"},{"title":"March 2018","text":"Basemaps and Mosaics February monthly mosaic released. Desert and snow regions produced with region specific color balancing.","tags":"changelog","url":"https://developers.planet.com/changelog/2018/Mar/01/archive/2018-03-01/","loc":"https://developers.planet.com/changelog/2018/Mar/01/archive/2018-03-01/"},{"title":"May 2017","text":"Mosaics API - Added XYZ tile services for items in the Data API.","tags":"changelog","url":"https://developers.planet.com/changelog/2017/May/01/archive/2017-05-01/","loc":"https://developers.planet.com/changelog/2017/May/01/archive/2017-05-01/"},{"title":"May 2018","text":"Imagery Products Added analytic asset type to the SkySatScene item type. Added SkySatCollect item type to the Data API. Basemaps and Mosaics Use of a new filter to reduce over-saturated scenes. Improved water color target to avoid coastline artifacts. WMTS basemaps service now provides a latest layer that points to the most recently available timelapse. Planet Explorer You must now have a Planet account in order to use Planet Explorer.","tags":"changelog","url":"https://developers.planet.com/changelog/2018/May/01/archive/2018-05-01/","loc":"https://developers.planet.com/changelog/2018/May/01/archive/2018-05-01/"},{"title":"Oct 2017","text":"Planet Explorer All SkySat imagery and products are now available in Planet Explorer. Imagery Products Added surface reflectance ( analytic_sr asset type) asset to the PlanetScope item type.","tags":"changelog","url":"https://developers.planet.com/changelog/2017/Oct/01/archive/2017-10-01/","loc":"https://developers.planet.com/changelog/2017/Oct/01/archive/2017-10-01/"},{"title":"Sept 2017","text":"Data API - Added orthorectified SkySat items to the Data API.","tags":"changelog","url":"https://developers.planet.com/changelog/2017/Sep/01/archive/2017-09-01/","loc":"https://developers.planet.com/changelog/2017/Sep/01/archive/2017-09-01/"}]};